[
  {
    "id": "go-interview_表锁和行锁机制_000",
    "text": "**适用场景**：表锁通常适用于读写操作较少、并发要求较低的场景。适用于需要确保整个表一致性的操作，例如批量更新或删除操作。",
    "answer": "**适用场景**：表锁通常适用于读写操作较少、并发要求较低的场景。适用于需要确保整个表一致性的操作，例如批量更新或删除操作。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "表锁",
      "并发控制",
      "数据一致性",
      "批量操作",
      "性能影响"
    ],
    "followup_points": [
      "1. 在批量更新或删除操作中，如果表锁导致其他查询被阻塞，有哪些优化策略可以减少这种阻塞的影响？",
      "2. 除了读写操作较少和并发要求较低的场景，表锁是否还有其他特定的适用场景，比如在数据迁移或备份过程中？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/表锁和行锁机制.md",
    "code_examples": []
  },
  {
    "id": "go-interview_表锁和行锁机制_001",
    "text": "行锁是指对表中的特定行加锁，这样在锁定期间其他线程（或事务）只能对这些特定的行进行操作，而不会影响其他行。",
    "answer": "行锁是指对表中的特定行加锁，这样在锁定期间其他线程（或事务）只能对这些特定的行进行操作，而不会影响其他行。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "行锁",
      "事务隔离",
      "并发控制",
      "数据库锁",
      "MySQL"
    ],
    "followup_points": [
      "1. 行锁在哪些具体场景下会被触发，例如在执行哪些SQL语句时？",
      "2. 行锁可能存在哪些潜在的性能问题或死锁风险，以及如何避免？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/表锁和行锁机制.md",
    "code_examples": []
  },
  {
    "id": "go-interview_表锁和行锁机制_002",
    "text": "**适用场景**：行锁适用于高并发的场景，特别是当操作的表中只有部分行需要锁定时。适用于需要高并发的在线事务处理（OLTP）系统。",
    "answer": "**适用场景**：行锁适用于高并发的场景，特别是当操作的表中只有部分行需要锁定时。适用于需要高并发的在线事务处理（OLTP）系统。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "行锁",
      "高并发",
      "OLTP",
      "事务处理",
      "部分行锁定"
    ],
    "followup_points": [
      "1. 在高并发OLTP系统中，行锁相比表锁或间隙锁，具体能带来哪些性能优势或潜在的开销？",
      "2. 当多个事务同时锁定不同行时，数据库如何避免死锁？有哪些常见的死锁预防或检测机制？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/表锁和行锁机制.md",
    "code_examples": []
  },
  {
    "id": "go-interview_表锁和行锁机制_003",
    "text": "**InnoDB存储引擎**：支持行锁。InnoDB存储引擎通过实现行级锁来提高并发性，并且支持事务和多版本并发控制（MVCC）。",
    "answer": "**InnoDB存储引擎**：支持行锁。InnoDB存储引擎通过实现行级锁来提高并发性，并且支持事务和多版本并发控制（MVCC）。 选择使用表锁还是行锁取决于应用场景的需求，比如数据的访问模式、并发要求以及对性能的期望。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "InnoDB存储引擎",
      "行级锁",
      "事务",
      "MVCC",
      "并发性"
    ],
    "followup_points": [
      "1. InnoDB的行锁是如何实现和管理的？具体是通过什么机制来避免死锁？",
      "2. 在高并发场景下，InnoDB的MVCC是如何通过版本号和undo日志来保证事务隔离级别的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/表锁和行锁机制.md",
    "code_examples": []
  },
  {
    "id": "go-interview_记录锁、间隙锁与临键锁_000",
    "text": "如果有一个表 `employees`，事务A对某一员工记录加锁，那么在事务A提交或回滚之前，其他事务不能对该员工记录进行修改。",
    "answer": "如果有一个表 `employees`，事务A对某一员工记录加锁，那么在事务A提交或回滚之前，其他事务不能对该员工记录进行修改。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "数据库事务",
      "行级锁",
      "并发控制",
      "锁机制",
      "隔离级别"
    ],
    "followup_points": [
      "1. 事务A对员工记录加锁时，具体使用了哪种类型的锁（如行锁、表锁、共享锁、排他锁）？不同类型的锁对其他事务的访问限制有何区别？",
      "2. 如果事务A长时间未提交或回滚，导致其他事务被阻塞，有哪些机制可以检测或处理这种死锁/阻塞情况？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/记录锁、间隙锁与临键锁.md",
    "code_examples": []
  },
  {
    "id": "go-interview_记录锁、间隙锁与临键锁_001",
    "text": "间隙锁是对记录间隙（即数据行之间的空白区间）加锁，以防止在该区间内插入新的记录。间隙锁防止了其他事务在当前事务锁定的区间内插入新的数据行，从而确保数据一致性。",
    "answer": "间隙锁是对记录间隙（即数据行之间的空白区间）加锁，以防止在该区间内插入新的记录。间隙锁防止了其他事务在当前事务锁定的区间内插入新的数据行，从而确保数据一致性。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "间隙锁",
      "记录间隙",
      "数据一致性",
      "防止插入",
      "事务锁定"
    ],
    "followup_points": [
      "1. 间隙锁在什么具体场景下会被触发，例如在范围查询、唯一索引冲突还是其他情况下？",
      "2. 间隙锁是否会影响当前事务对区间内已有记录的更新或删除操作，以及它与其他锁（如记录锁、意向锁）的交互是怎样的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/记录锁、间隙锁与临键锁.md",
    "code_examples": []
  },
  {
    "id": "go-interview_记录锁、间隙锁与临键锁_002",
    "text": "在一个有序的表 `employees` 上，事务A对某一范围的记录进行查询或修改，InnoDB会在该范围内加锁，以防止其他事务插入新的记录到该范围内。",
    "answer": "在一个有序的表 `employees` 上，事务A对某一范围的记录进行查询或修改，InnoDB会在该范围内加锁，以防止其他事务插入新的记录到该范围内。",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "InnoDB",
      "间隙锁",
      "Next-Key Lock",
      "幻读",
      "事务隔离级别"
    ],
    "followup_points": [
      "1. InnoDB在什么具体情况下会使用这种范围锁，而不是使用更细粒度的锁（如行锁或间隙锁）？",
      "2. 如果事务A查询的范围条件包含非索引列，InnoDB是否会仍然使用范围锁，或者会降级为其他锁策略？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/记录锁、间隙锁与临键锁.md",
    "code_examples": []
  },
  {
    "id": "go-interview_记录锁、间隙锁与临键锁_003",
    "text": "临键锁是记录锁和间隙锁的组合，锁定一个记录及其前面的间隙。临键锁确保了对某一记录的锁定，并同时锁定该记录之前的间隙，从而防止其他事务插入到该记录的前面或修改该记录。",
    "answer": "临键锁是记录锁和间隙锁的组合，锁定一个记录及其前面的间隙。临键锁确保了对某一记录的锁定，并同时锁定该记录之前的间隙，从而防止其他事务插入到该记录的前面或修改该记录。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "临键锁",
      "记录锁",
      "间隙锁",
      "MySQL",
      "事务隔离"
    ],
    "followup_points": [
      "1. 临键锁在什么具体场景下会被触发？例如在哪些SQL操作或事务隔离级别下会使用临键锁？",
      "2. 临键锁与间隙锁相比，在防止幻读方面有什么优势或不同之处？能否举例说明？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/记录锁、间隙锁与临键锁.md",
    "code_examples": []
  },
  {
    "id": "go-interview_记录锁、间隙锁与临键锁_004",
    "text": "**应用场景**：适用于需要避免幻读的事务，特别是在有唯一索引的表中，临键锁能够确保事务的隔离性和一致性。",
    "answer": "**应用场景**：适用于需要避免幻读的事务，特别是在有唯一索引的表中，临键锁能够确保事务的隔离性和一致性。",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "临键锁",
      "幻读",
      "事务隔离性",
      "唯一索引",
      "一致性"
    ],
    "followup_points": [
      "1. 在有唯一索引的表中，临键锁是如何具体避免幻读的？能否举例说明其锁定的范围和机制？",
      "2. 如果表中没有唯一索引，临键锁是否还能有效避免幻读？此时会有哪些替代方案或潜在问题？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/记录锁、间隙锁与临键锁.md",
    "code_examples": []
  },
  {
    "id": "go-interview_记录锁、间隙锁与临键锁_005",
    "text": "在表 `employees` 中，如果事务A对某一记录加锁，InnoDB会锁定该记录及其前面的间隙，以防止其他事务插入新的记录到该记录前面的间隙中。",
    "answer": "在表 `employees` 中，如果事务A对某一记录加锁，InnoDB会锁定该记录及其前面的间隙，以防止其他事务插入新的记录到该记录前面的间隙中。",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "InnoDB",
      "间隙锁",
      "记录锁",
      "事务隔离",
      "锁机制"
    ],
    "followup_points": [
      "1. 如果事务A对记录加锁后，事务B尝试在该记录前面的间隙中插入新记录，会发生什么具体现象？是直接阻塞还是报错？",
      "2. InnoDB的间隙锁是否会影响同一事务内对其他记录的并发操作？例如事务A能否同时锁定多个记录及其间隙？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/记录锁、间隙锁与临键锁.md",
    "code_examples": []
  },
  {
    "id": "go-interview_记录锁、间隙锁与临键锁_006",
    "text": "**提高并发性**：通过锁定粒度较小的行，而不是整个表，InnoDB能够在高并发环境下提供更好的性能和可伸缩性。",
    "answer": "**提高并发性**：通过锁定粒度较小的行，而不是整个表，InnoDB能够在高并发环境下提供更好的性能和可伸缩性。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "InnoDB",
      "行级锁",
      "并发性",
      "锁粒度",
      "性能优化"
    ],
    "followup_points": [
      "1. InnoDB在行级锁的实现中，如何处理不同事务对同一行记录的锁冲突，以及这种机制对并发性能的具体影响是什么？",
      "2. 在实际应用中，如果查询条件无法有效利用索引，导致InnoDB退化为表锁，有哪些优化策略可以避免这种情况并保持行级锁的优势？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/记录锁、间隙锁与临键锁.md",
    "code_examples": []
  },
  {
    "id": "go-interview_记录锁、间隙锁与临键锁_007",
    "text": "**保证事务隔离性**：行锁机制通过控制数据的并发访问，确保事务的隔离性和一致性，避免了数据竞争和不一致的问题。",
    "answer": "**保证事务隔离性**：行锁机制通过控制数据的并发访问，确保事务的隔离性和一致性，避免了数据竞争和不一致的问题。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "事务隔离性",
      "行锁机制",
      "并发访问",
      "数据一致性",
      "数据竞争"
    ],
    "followup_points": [
      "1. 行锁机制在实现隔离性时，如何处理不同隔离级别（如读未提交、读已提交、可重复读、串行化）下的锁策略差异？",
      "2. 在高并发场景下，行锁可能引发死锁，数据库是如何检测和解决死锁问题的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/记录锁、间隙锁与临键锁.md",
    "code_examples": []
  },
  {
    "id": "go-interview_记录锁、间隙锁与临键锁_008",
    "text": "**临键锁**：组合了记录锁和间隙锁，锁定记录及其前面的间隙，确保事务隔离性。",
    "answer": "**临键锁**：组合了记录锁和间隙锁，锁定记录及其前面的间隙，确保事务隔离性。 这三种锁机制在InnoDB中共同工作，以处理复杂的并发操作和数据一致性问题。在设计数据库和事务时，了解这些锁机制有助于优化性能和避免潜在的并发问题。",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "临键锁",
      "记录锁",
      "间隙锁",
      "事务隔离性",
      "InnoDB"
    ],
    "followup_points": [
      "1. 临键锁在什么具体场景下会被触发，例如在哪些SQL操作或事务隔离级别下会使用临键锁？",
      "2. 临键锁与记录锁、间隙锁相比，在解决并发问题（如幻读、不可重复读）时有哪些独特的优势和潜在的性能影响？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/记录锁、间隙锁与临键锁.md",
    "code_examples": []
  },
  {
    "id": "go-interview_数据库三范式_000",
    "text": "**第三范式 (3NF)**：在满足2NF的基础上，确保非主属性不依赖于其他非主属性，消除传递依赖。",
    "answer": "**第三范式 (3NF)**：在满足2NF的基础上，确保非主属性不依赖于其他非主属性，消除传递依赖。 通过应用这些范式，可以帮助设计出更具逻辑性、更加规范的数据库结构，减少数据冗余和维护复杂性。",
    "category": "system-design",
    "difficulty": 2,
    "tags": [
      "数据库范式",
      "第三范式 (3NF)",
      "传递依赖",
      "数据冗余",
      "数据库设计"
    ],
    "followup_points": [
      "1. 在实际项目中，如何判断一个表是否违反了第三范式？能否举例说明传递依赖的具体场景和解决方法？",
      "2. 如果为了满足第三范式而拆分表后，查询时需要频繁进行多表连接，这种情况下如何权衡规范化与查询性能的取舍？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/数据库三范式.md",
    "code_examples": []
  },
  {
    "id": "go-interview_当前读与快照读_000",
    "text": "事务 `A` 即使再次执行 `SELECT`，也只能看到快照中的旧数据，而不会看到事务 `B` 提交的新数据。",
    "answer": "事务 `A` 即使再次执行 `SELECT`，也只能看到快照中的旧数据，而不会看到事务 `B` 提交的新数据。",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "MVCC",
      "事务隔离级别",
      "快照读",
      "不可重复读",
      "一致性读"
    ],
    "followup_points": [
      "1. 事务 `A` 的快照是在什么时候创建的？是在事务开始时，还是在第一次执行 `SELECT` 时？",
      "2. 如果事务 `A` 在执行 `SELECT` 之前，先执行了一个 `INSERT` 或 `UPDATE` 操作，它还会基于同一个快照读取数据吗？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/当前读与快照读.md",
    "code_examples": []
  },
  {
    "id": "go-interview_当前读与快照读_001",
    "text": "**当前读**用于需要修改数据或加锁的操作，它确保读写一致性，读取最新数据，且通过锁机制避免并发冲突。",
    "answer": "**当前读**用于需要修改数据或加锁的操作，它确保读写一致性，读取最新数据，且通过锁机制避免并发冲突。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "当前读",
      "读写一致性",
      "读取最新数据",
      "锁机制",
      "并发冲突"
    ],
    "followup_points": [
      "1. 在当前读中，锁机制具体是如何实现并发冲突避免的？比如，使用的是行锁还是表锁，锁的粒度如何选择？",
      "2. 当前读在读取最新数据时，如何处理事务隔离级别（如RR、RC）对可见性的影响？不同隔离级别下当前读的行为是否有差异？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/当前读与快照读.md",
    "code_examples": []
  },
  {
    "id": "go-interview_当前读与快照读_002",
    "text": "**快照读**用于只读的查询操作，它通过 MVCC 保证读到的始终是事务启动时的快照，避免幻读、不可重复读等问题，同时无需加锁，因此并发性能较好。",
    "answer": "**快照读**用于只读的查询操作，它通过 MVCC 保证读到的始终是事务启动时的快照，避免幻读、不可重复读等问题，同时无需加锁，因此并发性能较好。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "快照读",
      "MVCC",
      "不可重复读",
      "幻读",
      "并发性能"
    ],
    "followup_points": [
      "1. 快照读是如何确定事务启动时的快照版本的？是通过 undo log 记录的版本链来实现的吗？",
      "2. 在高并发场景下，快照读是否会因为版本链过长或事务长时间未提交导致性能问题？如何优化？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/当前读与快照读.md",
    "code_examples": []
  },
  {
    "id": "go-interview_mysql事务是怎么保证最终一致性_000",
    "text": "这些机制共同作用，确保即使在系统故障或并发操作的情况下，数据最终也能保持一致。你想深入了解哪个方面吗？",
    "answer": "这些机制共同作用，确保即使在系统故障或并发操作的情况下，数据最终也能保持一致。你想深入了解哪个方面吗？",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "数据一致性",
      "故障恢复",
      "并发控制",
      "最终一致性",
      "系统容错"
    ],
    "followup_points": [
      "1. 在系统故障恢复过程中，这些机制如何协同工作以检测并修复数据不一致的情况？",
      "2. 针对高并发场景，不同机制（如锁、事务日志、版本控制等）是否存在优先级或冲突，如何确保它们的协同效率？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/mysql事务是怎么保证最终一致性.md",
    "code_examples": []
  },
  {
    "id": "go-interview_聚簇索引和非聚簇索引_000",
    "text": "聚簇索引是一种将表中的数据行与索引按顺序存储的索引类型。在一个表中，数据的物理存储顺序与聚簇索引的键值顺序相同。",
    "answer": "聚簇索引是一种将表中的数据行与索引按顺序存储的索引类型。在一个表中，数据的物理存储顺序与聚簇索引的键值顺序相同。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "聚簇索引",
      "数据存储顺序",
      "索引键值顺序",
      "物理存储",
      "数据行"
    ],
    "followup_points": [
      "1. 聚簇索引与非聚簇索引在物理存储和查询性能方面有哪些主要区别？",
      "2. 为什么一个表只能有一个聚簇索引，而可以有多个非聚簇索引？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/聚簇索引和非聚簇索引.md",
    "code_examples": []
  },
  {
    "id": "go-interview_聚簇索引和非聚簇索引_001",
    "text": "**存储结构**：聚簇索引的叶子节点包含实际的数据行，而不是指向数据行的指针。这意味着通过聚簇索引查找数据时，不需要再进行额外的回表操作。",
    "answer": "**存储结构**：聚簇索引的叶子节点包含实际的数据行，而不是指向数据行的指针。这意味着通过聚簇索引查找数据时，不需要再进行额外的回表操作。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "聚簇索引",
      "存储结构",
      "数据行",
      "叶子节点",
      "回表操作"
    ],
    "followup_points": [
      "1. 聚簇索引的叶子节点存储实际数据行时，如果数据行较大（比如包含TEXT或BLOB类型字段），是否会影响索引的查询性能？",
      "2. 在InnoDB中，一张表只能有一个聚簇索引，那么当业务场景需要频繁按多个不同字段查询时，如何选择聚簇索引的字段以优化整体查询效率？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/聚簇索引和非聚簇索引.md",
    "code_examples": []
  },
  {
    "id": "go-interview_聚簇索引和非聚簇索引_002",
    "text": "**查询性能**：对于范围查询（如 `BETWEEN`、`<`、`>`）、排序操作，以及需要读取连续数据的查询，聚簇索引性能较高，因为数据物理上是连续存储的。",
    "answer": "**查询性能**：对于范围查询（如 `BETWEEN`、``）、排序操作，以及需要读取连续数据的查询，聚簇索引性能较高，因为数据物理上是连续存储的。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "聚簇索引",
      "范围查询",
      "排序操作",
      "连续数据读取",
      "物理存储"
    ],
    "followup_points": [
      "1. 在聚簇索引中，如果表数据量非常大且频繁进行范围查询，是否会出现“页分裂”或“碎片化”问题，从而影响性能？如何优化？",
      "2. 对于非聚簇索引，如果查询需要回表（通过二级索引找到主键后再查聚簇索引），在什么场景下会比直接使用聚簇索引更高效？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/聚簇索引和非聚簇索引.md",
    "code_examples": []
  },
  {
    "id": "go-interview_聚簇索引和非聚簇索引_003",
    "text": "非聚簇索引是一种独立于数据存储顺序的索引类型。非聚簇索引的叶子节点存储的是指向数据行的指针，而不是实际的数据行。",
    "answer": "非聚簇索引是一种独立于数据存储顺序的索引类型。非聚簇索引的叶子节点存储的是指向数据行的指针，而不是实际的数据行。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "非聚簇索引",
      "索引结构",
      "叶子节点",
      "数据指针",
      "数据存储顺序"
    ],
    "followup_points": [
      "1. 非聚簇索引的叶子节点存储的指针具体是什么形式（如行ID、物理地址等），不同数据库（如MySQL、SQL Server）的实现是否有差异？",
      "2. 当通过非聚簇索引查询数据时，数据库如何通过指针定位到实际数据行，这个过程是否会导致额外的I/O开销？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/聚簇索引和非聚簇索引.md",
    "code_examples": []
  },
  {
    "id": "go-interview_聚簇索引和非聚簇索引_004",
    "text": "**存储结构**：非聚簇索引的叶子节点包含索引键值和指向对应数据行的指针。这意味着通过非聚簇索引查找数据时，可能需要通过指针进行额外的回表操作来获取实际数据。",
    "answer": "**存储结构**：非聚簇索引的叶子节点包含索引键值和指向对应数据行的指针。这意味着通过非聚簇索引查找数据时，可能需要通过指针进行额外的回表操作来获取实际数据。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "存储结构",
      "非聚簇索引",
      "叶子节点",
      "索引键值",
      "回表操作"
    ],
    "followup_points": [
      "1. 在什么情况下，非聚簇索引的回表操作会显著影响查询性能，如何优化这类场景？",
      "2. 如果表中同时存在多个非聚簇索引，不同索引的指针指向是否相同？索引的选择是否会影响回表的效率？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/聚簇索引和非聚簇索引.md",
    "code_examples": []
  },
  {
    "id": "go-interview_聚簇索引和非聚簇索引_005",
    "text": "**查询性能**：非聚簇索引在精确查找（如查找某个具体值）时性能较好，但对于需要大量回表的查询，性能可能不如聚簇索引。",
    "answer": "**查询性能**：非聚簇索引在精确查找（如查找某个具体值）时性能较好，但对于需要大量回表的查询，性能可能不如聚簇索引。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "索引类型",
      "聚簇索引",
      "非聚簇索引",
      "回表",
      "查询性能"
    ],
    "followup_points": [
      "1. 如何判断一个查询是否会触发大量回表？有哪些具体的指标或方法可以衡量回表的代价？",
      "2. 在什么场景下，即使需要大量回表，仍然会选择非聚簇索引而非聚簇索引？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/聚簇索引和非聚簇索引.md",
    "code_examples": []
  },
  {
    "id": "go-interview_说说脏读、不可重复读、幻读，怎么解决的_000",
    "text": "**`REPEATABLE READ`**：事务在开始时所读取的数据在整个事务期间保持一致，避免了不可重复读。",
    "answer": "**`REPEATABLE READ`**：事务在开始时所读取的数据在整个事务期间保持一致，避免了不可重复读。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "事务隔离级别",
      "REPEATABLE READ",
      "不可重复读",
      "数据一致性",
      "MySQL"
    ],
    "followup_points": [
      "1. 在 `REPEATABLE READ` 隔离级别下，如果另一个事务执行了 `INSERT` 操作并提交，当前事务是否会感知到新插入的数据？为什么？",
      "2. `REPEATABLE READ` 虽然避免了不可重复读，但如何解决幻读问题？MySQL 的 MVCC 机制在其中具体是如何实现的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/说说脏读、不可重复读、幻读，怎么解决的.md",
    "code_examples": []
  },
  {
    "id": "go-interview_说说脏读、不可重复读、幻读，怎么解决的_001",
    "text": "**不可重复读**：同一事务多次读取同一数据结果不一致，通过 `REPEATABLE READ` 解决。",
    "answer": "**不可重复读**：同一事务多次读取同一数据结果不一致，通过 `REPEATABLE READ` 解决。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "不可重复读",
      "REPEATABLE READ",
      "事务隔离级别",
      "数据库一致性",
      "并发控制"
    ],
    "followup_points": [
      "1. 在 `REPEATABLE READ` 隔离级别下，如果事务期间其他事务修改了数据，当前事务多次读取的结果为什么会保持一致？",
      "2. `REPEATABLE READ` 是如何通过 MVCC（多版本并发控制）或其他机制实现不可重复读的？具体实现细节是什么？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/说说脏读、不可重复读、幻读，怎么解决的.md",
    "code_examples": []
  },
  {
    "id": "go-interview_说说脏读、不可重复读、幻读，怎么解决的_002",
    "text": "**幻读**：同一事务多次查询结果集不一致，通过 `SERIALIZABLE` 解决。",
    "answer": "**幻读**：同一事务多次查询结果集不一致，通过 `SERIALIZABLE` 解决。 在实际应用中，根据业务需求选择合适的隔离级别，平衡性能与数据一致性。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "幻读",
      "事务隔离级别",
      "SERIALIZABLE",
      "数据一致性",
      "数据库性能"
    ],
    "followup_points": [
      "1. 除了 `SERIALIZABLE` 隔离级别，其他隔离级别（如 `REPEATABLE READ`）是否也能通过特定机制（如间隙锁）部分解决幻读问题？",
      "2. 在实际业务中，如何判断是否必须使用 `SERIALIZABLE` 隔离级别，还是可以通过乐观锁或版本控制等替代方案避免幻读？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/说说脏读、不可重复读、幻读，怎么解决的.md",
    "code_examples": []
  },
  {
    "id": "go-interview_sql语句性能分析_000",
    "text": "**定义**：`EXPLAIN` 是 MySQL 提供的一个命令，用于显示 SQL 查询的执行计划，包括查询过程中涉及的各个步骤、使用的索引、扫描的行数等信息。",
    "answer": "**定义**：`EXPLAIN` 是 MySQL 提供的一个命令，用于显示 SQL 查询的执行计划，包括查询过程中涉及的各个步骤、使用的索引、扫描的行数等信息。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "EXPLAIN",
      "SQL执行计划",
      "索引",
      "行数扫描",
      "MySQL"
    ],
    "followup_points": [
      "1. `EXPLAIN` 命令中的 `type` 列有哪些常见的值，它们分别代表什么含义？",
      "2. 如何通过 `EXPLAIN` 的结果判断查询是否存在性能问题，比如全表扫描或索引失效？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/sql语句性能分析.md",
    "code_examples": []
  },
  {
    "id": "go-interview_sql语句性能分析_002",
    "text": "**定义**：`SHOW PROFILE` 可以显示 SQL 语句执行的各个阶段所消耗的时间，帮助分析执行过程中可能的瓶颈。",
    "answer": "**定义**：`SHOW PROFILE` 可以显示 SQL 语句执行的各个阶段所消耗的时间，帮助分析执行过程中可能的瓶颈。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "SQL性能分析",
      "查询执行计划",
      "性能瓶颈定位",
      "MySQL工具",
      "时间消耗分析"
    ],
    "followup_points": [
      "1. 除了 `SHOW PROFILE`，还有哪些工具或方法可以用于分析 SQL 语句的执行性能瓶颈？",
      "2. `SHOW PROFILE` 提供的各个阶段时间信息中，哪些阶段通常是性能优化的重点关注对象？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/sql语句性能分析.md",
    "code_examples": []
  },
  {
    "id": "go-interview_sql语句性能分析_004",
    "text": "**定义**：`SHOW STATUS` 显示 MySQL 的全局或会话级别的状态变量，其中包括一些与 SQL 语句执行相关的统计信息。",
    "answer": "**定义**：`SHOW STATUS` 显示 MySQL 的全局或会话级别的状态变量，其中包括一些与 SQL 语句执行相关的统计信息。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "MySQL",
      "SHOW STATUS",
      "状态变量",
      "全局级别",
      "会话级别"
    ],
    "followup_points": [
      "1. 能否举例说明 `SHOW STATUS` 中哪些状态变量与 SQL 语句执行性能直接相关，以及如何通过这些变量定位慢查询问题？",
      "2. 在高并发场景下，`SHOW STATUS` 的会话级别状态变量和全局级别状态变量在统计结果上可能存在哪些差异？如何合理选择使用？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/sql语句性能分析.md",
    "code_examples": []
  },
  {
    "id": "go-interview_sql语句性能分析_006",
    "text": "**定义**：`SHOW VARIABLES` 命令显示 MySQL 的配置参数，这些参数会影响 SQL 语句的执行效率。",
    "answer": "**定义**：`SHOW VARIABLES` 命令显示 MySQL 的配置参数，这些参数会影响 SQL 语句的执行效率。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "MySQL配置",
      "SQL执行效率",
      "SHOW VARIABLES命令",
      "参数调优",
      "性能监控"
    ],
    "followup_points": [
      "1. 在实际优化工作中，您通常重点关注哪些 `SHOW VARIABLES` 的参数？为什么这些参数对执行效率影响较大？",
      "2. 如果发现某个 `SHOW VARIABLES` 参数的当前值与默认值差异较大，您会如何进一步分析和调整它？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/sql语句性能分析.md",
    "code_examples": []
  },
  {
    "id": "go-interview_sql语句性能分析_008",
    "text": "**定义**：`Performance Schema` 是一个 MySQL 内建的诊断工具，用于收集数据库内部执行的低级信息，如等待事件、锁定、阶段和对象访问等。",
    "answer": "**定义**：`Performance Schema` 是一个 MySQL 内建的诊断工具，用于收集数据库内部执行的低级信息，如等待事件、锁定、阶段和对象访问等。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "Performance Schema",
      "MySQL",
      "数据库诊断",
      "等待事件",
      "锁定"
    ],
    "followup_points": [
      "1. Performance Schema 收集的数据存储在哪里？如何查看这些收集到的数据？",
      "2. Performance Schema 的启用和配置有哪些关键参数？如何根据实际需求调整其性能开销？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/sql语句性能分析.md",
    "code_examples": []
  },
  {
    "id": "go-interview_sql语句性能分析_010",
    "text": "**启用和查询**：",
    "answer": "- 启用 `Performance Schema` 需要在启动 MySQL 时配置，之后可以通过 SQL 语句查询相关信息：",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "Performance Schema",
      "MySQL 配置",
      "SQL 查询",
      "数据库监控",
      "性能分析"
    ],
    "followup_points": [
      "1. 在启动 MySQL 时，具体需要配置哪些参数来启用 `Performance Schema`？",
      "2. 启用后，可以通过哪些 SQL 语句查询 `Performance Schema` 的相关信息，能否举例说明常用查询场景？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/sql语句性能分析.md",
    "code_examples": [
      {
        "code": "SELECT * FROM performance_schema.events_statements_history WHERE THREAD_ID = 'your_thread_id';",
        "language": "sql"
      }
    ]
  },
  {
    "id": "go-interview_sql语句性能分析_011",
    "text": "**MySQL Enterprise Monitor**：适用于 MySQL 企业版用户的监控工具，提供高级的 SQL 性能分析功能。",
    "answer": "**MySQL Enterprise Monitor**：适用于 MySQL 企业版用户的监控工具，提供高级的 SQL 性能分析功能。",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "MySQL监控",
      "企业版工具",
      "SQL性能分析",
      "数据库管理",
      "性能优化"
    ],
    "followup_points": [
      "1. MySQL Enterprise Monitor 具体提供了哪些高级的 SQL 性能分析功能，这些功能如何帮助用户定位和优化慢查询？",
      "2. 与开源的监控工具（如 Prometheus + Grafana、Percona Monitoring）相比，MySQL Enterprise Monitor 在企业级场景下有哪些独特优势或差异化特性？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/sql语句性能分析.md",
    "code_examples": []
  },
  {
    "id": "go-interview_sql语句性能分析_012",
    "text": "**慢查询日志（Slow Query Log）**：记录执行时间超过指定阈值的 SQL 语句，用于发现和分析慢查询。",
    "answer": "**慢查询日志（Slow Query Log）**：记录执行时间超过指定阈值的 SQL 语句，用于发现和分析慢查询。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "慢查询日志",
      "SQL性能分析",
      "查询优化",
      "数据库监控",
      "阈值设置"
    ],
    "followup_points": [
      "1. 慢查询日志的阈值（long_query_time）通常如何设置？是否需要根据业务场景动态调整？",
      "2. 慢查询日志记录的信息是否包含执行计划、索引使用情况等关键分析数据？如何通过日志优化查询性能？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/sql语句性能分析.md",
    "code_examples": []
  },
  {
    "id": "go-interview_sql语句性能分析_013",
    "text": "**增加内存分配**：合理配置 `innodb_buffer_pool_size` 等内存相关参数，以减少磁盘 IO。",
    "answer": "**增加内存分配**：合理配置 `innodb_buffer_pool_size` 等内存相关参数，以减少磁盘 IO。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "innodb_buffer_pool_size",
      "内存优化",
      "磁盘IO优化",
      "MySQL性能调优",
      "参数配置"
    ],
    "followup_points": [
      "1. 如何根据服务器的物理内存和业务负载情况，合理确定 `innodb_buffer_pool_size` 的具体取值范围？",
      "2. 除了 `innodb_buffer_pool_size`，还有哪些内存相关参数（如 `innodb_log_buffer_size`、`query_cache_size` 等）对磁盘 IO 有显著影响，如何协同优化？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/sql语句性能分析.md",
    "code_examples": []
  },
  {
    "id": "go-interview_sql语句性能分析_014",
    "text": "**分区表**：对于非常大的表，可以考虑使用分区表，以减少查询扫描的行数。",
    "answer": "**分区表**：对于非常大的表，可以考虑使用分区表，以减少查询扫描的行数。 通过以上工具和方法，可以深入分析 SQL 语句的执行情况，发现潜在的性能瓶颈并进行优化，提高数据库的整体性能。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "分区表",
      "数据库性能优化",
      "SQL查询优化",
      "大数据处理",
      "索引策略"
    ],
    "followup_points": [
      "1. 分区表的具体实现方式有哪些？它们各自适用于什么场景？",
      "2. 在分区表设计中，如何选择合适的分区键（Partition Key）以最大化查询性能？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/sql语句性能分析.md",
    "code_examples": []
  },
  {
    "id": "go-interview_二阶段提交_000",
    "text": "**准备阶段**：在事务提交之前，InnoDB会将事务的更改记录到redo log中。这确保了即使在二阶段提交协议的“准备”阶段完成后系统崩溃，事务的数据也不会丢失，因为 redo log 保存了这些更改。",
    "answer": "**准备阶段**：在事务提交之前，InnoDB会将事务的更改记录到redo log中。这确保了即使在二阶段提交协议的“准备”阶段完成后系统崩溃，事务的数据也不会丢失，因为 redo log 保存了这些更改。",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "InnoDB",
      "事务",
      "redo log",
      "二阶段提交",
      "数据持久性"
    ],
    "followup_points": [
      "1. 在准备阶段，redo log的具体写入机制是怎样的？是顺序写入还是随机写入，为什么？",
      "2. 如果redo log在准备阶段记录了事务更改，那么在崩溃恢复时，InnoDB如何确保这些更改不会与未提交的事务冲突？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/二阶段提交.md",
    "code_examples": []
  },
  {
    "id": "go-interview_二阶段提交_001",
    "text": "**提交阶段**：在收到协调者的提交请求后，InnoDB会将事务的状态从准备状态变为提交状态，并在redo log中记录这一变更。系统重启后，redo log会用来完成已提交事务的操作。",
    "answer": "**提交阶段**：在收到协调者的提交请求后，InnoDB会将事务的状态从准备状态变为提交状态，并在redo log中记录这一变更。系统重启后，redo log会用来完成已提交事务的操作。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "事务提交",
      "两阶段提交",
      "redo log",
      "崩溃恢复",
      "InnoDB"
    ],
    "followup_points": [
      "1. 在提交阶段，InnoDB除了将事务状态从准备状态变为提交状态并记录redo log外，还会进行哪些关键操作？",
      "2. 系统重启后，redo log如何确保已提交事务的操作被正确完成？具体是通过哪些机制或步骤实现的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/二阶段提交.md",
    "code_examples": []
  },
  {
    "id": "go-interview_二阶段提交_002",
    "text": "**复制**：MySQL的主从复制基于binlog，从数据库通过读取binlog来同步主数据库的数据变更。",
    "answer": "**复制**：MySQL的主从复制基于binlog，从数据库通过读取binlog来同步主数据库的数据变更。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "MySQL主从复制",
      "binlog",
      "数据同步",
      "主从架构",
      "数据复制"
    ],
    "followup_points": [
      "1. 从数据库在读取binlog后，是如何解析和应用这些日志记录到本地数据库的？",
      "2. 主从复制过程中，如果binlog损坏或网络中断，从数据库如何处理数据一致性问题？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/二阶段提交.md",
    "code_examples": []
  },
  {
    "id": "go-interview_二阶段提交_003",
    "text": "**准备阶段**：在准备阶段，事务的更改还不会被提交到binlog。binlog的记录是为了支持数据复制和恢复。",
    "answer": "**准备阶段**：在准备阶段，事务的更改还不会被提交到binlog。binlog的记录是为了支持数据复制和恢复。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "事务",
      "binlog",
      "数据复制",
      "数据恢复",
      "MySQL"
    ],
    "followup_points": [
      "1. 在准备阶段，事务的更改具体是如何被暂存的？是通过内存中的临时日志还是其他机制？",
      "2. 如果在准备阶段发生故障（如MySQL崩溃），未提交的事务更改会如何处理？binlog中是否会有相关记录？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/二阶段提交.md",
    "code_examples": []
  },
  {
    "id": "go-interview_二阶段提交_004",
    "text": "**提交阶段**：在事务提交时，binlog会记录事务的更改操作。这是因为binlog用于确保数据在主从数据库之间的一致性。在提交阶段，事务的更改会被写入binlog，确保所有参与者都看到相同的数据变更。",
    "answer": "**提交阶段**：在事务提交时，binlog会记录事务的更改操作。这是因为binlog用于确保数据在主从数据库之间的一致性。在提交阶段，事务的更改会被写入binlog，确保所有参与者都看到相同的数据变更。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "事务提交",
      "binlog",
      "数据一致性",
      "主从复制",
      "数据变更"
    ],
    "followup_points": [
      "1. 在提交阶段，binlog的写入是同步的还是异步的？如果主节点在写入binlog后崩溃，从节点是否会接收到未提交的事务变更？",
      "2. 如果事务在提交阶段失败（例如binlog写入失败），MySQL会如何处理该事务？是否会有回滚机制，以及如何保证主从数据的一致性？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/二阶段提交.md",
    "code_examples": []
  },
  {
    "id": "go-interview_二阶段提交_005",
    "text": "**准备阶段**：在准备阶段，undo log中记录了事务的操作以便在需要时可以回滚。即使事务处于准备状态，undo log也确保了事务的操作可以被撤销。",
    "answer": "**准备阶段**：在准备阶段，undo log中记录了事务的操作以便在需要时可以回滚。即使事务处于准备状态，undo log也确保了事务的操作可以被撤销。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "undo log",
      "事务回滚",
      "两阶段提交",
      "事务准备阶段",
      "数据一致性"
    ],
    "followup_points": [
      "1. 在准备阶段，undo log具体记录了哪些操作信息，这些信息如何帮助实现事务的回滚？",
      "2. 如果事务在准备阶段失败，undo log的回滚机制是否会与其他日志（如redo log）协同工作，以确保数据一致性？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/二阶段提交.md",
    "code_examples": []
  },
  {
    "id": "go-interview_二阶段提交_006",
    "text": "**提交阶段**：如果事务在提交阶段成功完成，undo log中的信息会被清理。否则，如果协调者决定回滚事务，undo log将用于撤销事务中的所有更改。",
    "answer": "**提交阶段**：如果事务在提交阶段成功完成，undo log中的信息会被清理。否则，如果协调者决定回滚事务，undo log将用于撤销事务中的所有更改。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "事务提交",
      "事务回滚",
      "undo log",
      "协调者",
      "两阶段提交"
    ],
    "followup_points": [
      "1. 在提交阶段成功完成后，undo log的清理是立即执行还是延迟执行？如果有延迟，具体的触发条件和时机是什么？",
      "2. 当协调者决定回滚事务时，undo log的撤销操作是同步执行还是异步执行？如果涉及分布式事务，如何保证各节点的undo log回滚一致性？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/二阶段提交.md",
    "code_examples": []
  },
  {
    "id": "go-interview_MyISAM和InnoDB_000",
    "text": "**表锁**：MyISAM使用表锁来管理并发访问，这意味着在对表进行写操作时，整个表会被锁定，其他的读写操作会被阻塞。",
    "answer": "**表锁**：MyISAM使用表锁来管理并发访问，这意味着在对表进行写操作时，整个表会被锁定，其他的读写操作会被阻塞。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "表锁",
      "MyISAM",
      "并发访问",
      "写操作",
      "阻塞"
    ],
    "followup_points": [
      "1. 在高并发写入场景下，MyISAM的表锁机制会导致哪些具体的性能问题？是否有实际的案例或数据可以说明？",
      "2. 除了阻塞其他读写操作，MyISAM的表锁是否会影响表级别的维护操作（如`ALTER TABLE`或`OPTIMIZE TABLE`）？如果有，如何优化这类操作的影响？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/MyISAM和InnoDB.md",
    "code_examples": []
  },
  {
    "id": "go-interview_MyISAM和InnoDB_001",
    "text": "**存储格式**：数据和索引分别存储在不同的文件中，数据文件的扩展名通常为`.MYD`，索引文件为`.MYI`。",
    "answer": "**存储格式**：数据和索引分别存储在不同的文件中，数据文件的扩展名通常为`.MYD`，索引文件为`.MYI`。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "存储格式",
      "文件扩展名",
      "数据文件",
      "索引文件",
      "分离存储"
    ],
    "followup_points": [
      "1. 这种数据和索引分离的存储方式对数据库的读写性能有哪些具体影响？",
      "2. 在高并发场景下，这种存储格式如何管理和协调数据文件与索引文件的访问冲突？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/MyISAM和InnoDB.md",
    "code_examples": []
  },
  {
    "id": "go-interview_MyISAM和InnoDB_002",
    "text": "**支持事务**：InnoDB支持事务，包括ACID特性（原子性、一致性、隔离性、持久性），可以进行事务回滚和提交。",
    "answer": "**支持事务**：InnoDB支持事务，包括ACID特性（原子性、一致性、隔离性、持久性），可以进行事务回滚和提交。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "InnoDB",
      "事务",
      "ACID",
      "原子性",
      "一致性"
    ],
    "followup_points": [
      "1. InnoDB是如何通过redo log和undo log来实现事务的持久性和原子性的？",
      "2. 在高并发场景下，InnoDB的隔离级别（如RR、RC）是如何通过锁机制和MVCC来保证数据一致性的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/MyISAM和InnoDB.md",
    "code_examples": []
  },
  {
    "id": "go-interview_MyISAM和InnoDB_003",
    "text": "**聚集索引**：InnoDB的主键索引是聚集索引，数据是按主键排序存储的，这可以提高基于主键的查询效率。",
    "answer": "**聚集索引**：InnoDB的主键索引是聚集索引，数据是按主键排序存储的，这可以提高基于主键的查询效率。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "聚集索引",
      "InnoDB",
      "主键索引",
      "数据存储",
      "查询效率"
    ],
    "followup_points": [
      "1. 如果表没有显式定义主键，InnoDB会如何选择聚集索引？",
      "2. 聚集索引的叶子节点存储了整行数据，这对非主键字段的查询（如范围查询或非主键条件查询）有什么影响？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/MyISAM和InnoDB.md",
    "code_examples": []
  },
  {
    "id": "go-interview_MyISAM和InnoDB_004",
    "text": "**表空间**：InnoDB将表数据存储在表空间中，可以在多个文件中进行数据存储，通常是`.ibd`文件。",
    "answer": "**表空间**：InnoDB将表数据存储在表空间中，可以在多个文件中进行数据存储，通常是`.ibd`文件。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "InnoDB",
      "表空间",
      ".ibd文件",
      "数据存储",
      "文件管理"
    ],
    "followup_points": [
      "1. InnoDB表空间分为系统表空间和独立表空间，这两种表空间在数据存储、管理和性能方面有哪些具体区别？",
      "2. 在实际应用中，如何根据业务需求（如数据量、并发访问量等）选择合适的表空间类型或配置多个表空间文件？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/MyISAM和InnoDB.md",
    "code_examples": []
  },
  {
    "id": "go-interview_MyISAM和InnoDB_005",
    "text": "**并发控制**：InnoDB通过行锁和MVCC实现更好的并发控制。",
    "answer": "**并发控制**：InnoDB通过行锁和MVCC实现更好的并发控制。 选择存储引擎时，需要根据具体应用的需求，如事务处理能力、并发性能、数据完整性等，来决定使用MyISAM还是InnoDB。",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "并发控制",
      "行锁",
      "MVCC",
      "存储引擎",
      "事务处理"
    ],
    "followup_points": [
      "1. InnoDB的行锁和MVCC是如何协同工作以实现并发控制的？能否举例说明一个具体场景？",
      "2. 在高并发场景下，MyISAM和InnoDB的并发性能差异主要体现在哪些方面？如何根据业务需求选择合适的存储引擎？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/MyISAM和InnoDB.md",
    "code_examples": []
  },
  {
    "id": "go-interview_四种事务隔离级别_000",
    "text": "原子性（Atomicity）：事务开始后所有操作，要么全部做完，要么全部不做，不可能停滞在中间环节。事务执行过程中出错，会回滚到事务开始前的状态，所有的操作就像没有发生一样。也就是说事务是一个不可分割的整体，就像化学中学过的原子，是物质构成的基本单位。",
    "answer": "原子性（Atomicity）：事务开始后所有操作，要么全部做完，要么全部不做，不可能停滞在中间环节。事务执行过程中出错，会回滚到事务开始前的状态，所有的操作就像没有发生一样。也就是说事务是一个不可分割的整体，就像化学中学过的原子，是物质构成的基本单位。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "事务",
      "原子性",
      "ACID",
      "回滚",
      "数据一致性"
    ],
    "followup_points": [
      "1. 在实际开发中，如何确保一个包含多个数据库操作的事务满足原子性要求？",
      "2. 如果事务在执行过程中遇到系统崩溃（如数据库服务器宕机），原子性是如何保证的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/四种事务隔离级别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_四种事务隔离级别_001",
    "text": "一致性（Consistency）：事务开始前和结束后，数据库的完整性约束没有被破坏 。比如A向B转账，不可能A扣了钱，B却没收到。",
    "answer": "一致性（Consistency）：事务开始前和结束后，数据库的完整性约束没有被破坏 。比如A向B转账，不可能A扣了钱，B却没收到。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "事务",
      "数据库",
      "一致性",
      "ACID",
      "完整性约束"
    ],
    "followup_points": [
      "1. 在分布式数据库场景下，如何保证跨节点事务的一致性，特别是在网络分区或节点故障时？",
      "2. 除了转账场景，数据库的一致性还涉及哪些具体的完整性约束类型（如外键、唯一约束、检查约束等），这些约束在事务中是如何被维护的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/四种事务隔离级别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_四种事务隔离级别_002",
    "text": "隔离性（Isolation）：同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账。",
    "answer": "隔离性（Isolation）：同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "事务隔离性",
      "并发控制",
      "数据库事务",
      "数据一致性",
      "锁机制"
    ],
    "followup_points": [
      "1. 在实际数据库系统中，隔离性是通过哪些隔离级别（如读未提交、读已提交、可重复读、串行化）来实现的，不同级别之间如何权衡性能与数据一致性？",
      "2. 如果多个事务同时请求同一数据，数据库如何解决并发冲突（如使用锁机制、乐观锁或MVCC），这些机制对隔离性的具体影响是什么？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/四种事务隔离级别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_四种事务隔离级别_003",
    "text": "不可重复读：事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果 不一致。",
    "answer": "不可重复读：事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果 不一致。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "事务隔离级别",
      "不可重复读",
      "并发控制",
      "数据库事务",
      "脏读"
    ],
    "followup_points": [
      "1. 在实际业务场景中，不可重复读问题通常会对哪些具体业务逻辑或数据一致性要求产生较大影响？",
      "2. 除了使用事务隔离级别（如可重复读）来解决不可重复读问题，还有哪些常见的数据库优化或业务层面的应对策略？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/四种事务隔离级别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_四种事务隔离级别_004",
    "text": "幻读：系统管理员A将数据库中所有学生的成绩从具体分数改为ABCDE等级，但是系统管理员B就在这个时候插入了一条具体分数的记录，当系统管理员A改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。",
    "answer": "幻读：系统管理员A将数据库中所有学生的成绩从具体分数改为ABCDE等级，但是系统管理员B就在这个时候插入了一条具体分数的记录，当系统管理员A改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。 小结：不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "幻读",
      "不可重复读",
      "事务隔离级别",
      "锁机制",
      "并发控制"
    ],
    "followup_points": [
      "1. 在解决幻读时，锁表操作会对系统性能产生哪些具体影响？有没有比锁表更优的替代方案？",
      "2. 如果系统管理员A的事务隔离级别设置为READ COMMITTED，而管理员B的操作发生在A执行修改之前，这种情况下还会出现幻读吗？为什么？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/四种事务隔离级别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_四种事务隔离级别_005",
    "text": "**问题**: 可能导致 **脏读（Dirty Read）**。即，一个事务可以读到另一个事务尚未提交的数据，如果该事务回滚，读到的数据就是无效的。",
    "answer": "**问题**: 可能导致 **脏读（Dirty Read）**。即，一个事务可以读到另一个事务尚未提交的数据，如果该事务回滚，读到的数据就是无效的。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "脏读",
      "事务隔离级别",
      "数据库事务",
      "并发控制",
      "数据一致性"
    ],
    "followup_points": [
      "1. 在什么具体场景下（例如电商订单状态更新、银行转账等），脏读会对业务逻辑产生最直接的影响？",
      "2. 如何通过数据库隔离级别（如READ COMMITTED）或锁机制（如共享锁/排他锁）来避免脏读？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/四种事务隔离级别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_四种事务隔离级别_006",
    "text": "**问题**: 可能导致 **不可重复读（Non-repeatable Read）**。即，在同一个事务中，多次读取同一行数据，结果可能不同，因为其他事务可能在期间修改并提交了该数据。",
    "answer": "**问题**: 可能导致 **不可重复读（Non-repeatable Read）**。即，在同一个事务中，多次读取同一行数据，结果可能不同，因为其他事务可能在期间修改并提交了该数据。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "事务隔离级别",
      "不可重复读",
      "并发控制",
      "数据库事务",
      "脏读"
    ],
    "followup_points": [
      "1. 在实际业务中，哪些场景下不可重复读会对数据一致性产生显著影响？",
      "2. 数据库的隔离级别（如Read Committed、Repeatable Read）如何通过锁机制或MVCC来避免不可重复读？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/四种事务隔离级别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_四种事务隔离级别_007",
    "text": "**应用场景**: 是许多数据库的默认隔离级别（如 Oracle）。适用于不需要数据完全一致但希望避免脏读的场景。",
    "answer": "**应用场景**: 是许多数据库的默认隔离级别（如 Oracle）。适用于不需要数据完全一致但希望避免脏读的场景。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "数据库隔离级别",
      "读已提交",
      "脏读",
      "Oracle",
      "数据一致性"
    ],
    "followup_points": [
      "1. 在这种隔离级别下，如何处理不可重复读和幻读的问题？有哪些常见的业务场景可以容忍这些问题？",
      "2. 如果业务需要避免不可重复读但又要保持较高的并发性能，有哪些优化方案或替代策略？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/四种事务隔离级别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_四种事务隔离级别_008",
    "text": "**特点**: 确保在同一事务中，多次读取同一行数据的结果是一致的。事务开始后，其他事务的修改在当前事务中不可见。",
    "answer": "**特点**: 确保在同一事务中，多次读取同一行数据的结果是一致的。事务开始后，其他事务的修改在当前事务中不可见。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "事务隔离",
      "读一致性",
      "不可见性",
      "幻读",
      "可重复读"
    ],
    "followup_points": [
      "1. 在实现该特点时，数据库是如何处理不同隔离级别下的不可见修改的？例如，在可重复读隔离级别下，数据库会采用什么机制来确保事务期间的数据一致性？",
      "2. 如果事务中读取的数据行在事务执行期间被其他事务修改，当前事务是否会感知到这种修改？如果会，是通过什么方式（如快照读、当前读）实现的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/四种事务隔离级别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_四种事务隔离级别_009",
    "text": "**问题**: 可能导致 **幻读（Phantom Read）**。即，一个事务在读取某个条件下的行时，如果另一个事务插入了符合条件的新行，前一个事务再次查询时会看到 \"幻影\" 行。",
    "answer": "**问题**: 可能导致 **幻读（Phantom Read）**。即，一个事务在读取某个条件下的行时，如果另一个事务插入了符合条件的新行，前一个事务再次查询时会看到 \"幻影\" 行。",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "幻读",
      "事务隔离级别",
      "并发控制",
      "数据库",
      "SQL标准"
    ],
    "followup_points": [
      "1. 在哪些具体的事务隔离级别下，幻读现象会被允许发生，而在哪些隔离级别下会被避免？",
      "2. 除了插入操作，更新或删除操作是否也可能导致幻读？如果是，请举例说明。"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/四种事务隔离级别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_四种事务隔离级别_010",
    "text": "**特点**: 是最高级别的隔离，确保事务完全串行化执行，仿佛所有事务是一个接一个顺序执行的，而非并发执行的。",
    "answer": "**特点**: 是最高级别的隔离，确保事务完全串行化执行，仿佛所有事务是一个接一个顺序执行的，而非并发执行的。",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "数据库事务隔离级别",
      "串行化",
      "并发控制",
      "ACID特性",
      "数据一致性"
    ],
    "followup_points": [
      "1. 在实际应用中，串行化隔离级别通常通过哪些技术手段（如锁、时间戳排序或乐观并发控制）来实现，这些手段各自存在哪些优缺点？",
      "2. 串行化隔离级别虽然解决了并发问题，但可能会显著降低系统性能，是否有折中的方案（如可重复读或读已提交）在保证数据一致性的同时提升并发效率？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/四种事务隔离级别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_四种事务隔离级别_011",
    "text": "**可串行化**：最高级别，避免所有并发问题，但性能开销最大。",
    "answer": "**可串行化**：最高级别，避免所有并发问题，但性能开销最大。 每种隔离级别在不同的业务需求下有不同的适用场景，选择合适的隔离级别是设计数据库事务的重要考量。",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "可串行化",
      "隔离级别",
      "并发控制",
      "事务",
      "性能开销"
    ],
    "followup_points": [
      "1. 能否举例说明哪些具体业务场景必须选择可串行化隔离级别，即使它性能开销较大？",
      "2. 在实际应用中，如何平衡可串行化隔离级别的强一致性需求与系统性能开销，有没有优化策略？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/四种事务隔离级别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_binlog、redo log和undo log_000",
    "text": "**定义**：`binlog` 是 MySQL 中的二进制日志，记录了所有对数据库进行更改的操作，包括 `INSERT`、`UPDATE`、`DELETE` 等语句，但不包括查询语句（`SELECT`）。",
    "answer": "**定义**：`binlog` 是 MySQL 中的二进制日志，记录了所有对数据库进行更改的操作，包括 `INSERT`、`UPDATE`、`DELETE` 等语句，但不包括查询语句（`SELECT`）。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "MySQL",
      "binlog",
      "数据库日志",
      "数据变更",
      "SQL语句"
    ],
    "followup_points": [
      "1. binlog 的主要作用是什么？它在 MySQL 的高可用、主从复制或数据恢复中具体如何应用？",
      "2. binlog 有哪几种格式（如 STATEMENT、ROW、MIXED）？不同格式的优缺点和适用场景是什么？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/binlog、redo log和undo log.md",
    "code_examples": []
  },
  {
    "id": "go-interview_binlog、redo log和undo log_002",
    "text": "**存储格式**：`binlog` 以二进制格式存储，并且按顺序记录每个事务的所有更改，支持 `ROW`、`STATEMENT` 和 `MIXED` 三种日志格式。",
    "answer": "**存储格式**：`binlog` 以二进制格式存储，并且按顺序记录每个事务的所有更改，支持 `ROW`、`STATEMENT` 和 `MIXED` 三种日志格式。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "binlog",
      "存储格式",
      "日志格式",
      "ROW",
      "STATEMENT"
    ],
    "followup_points": [
      "1. 在 `ROW`、`STATEMENT` 和 `MIXED` 三种日志格式中，各自的优缺点是什么？在什么场景下会选择使用其中一种格式？",
      "2. `binlog` 的二进制存储方式对数据恢复和主从复制有哪些具体影响？是否需要额外的工具或步骤来解析二进制日志？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/binlog、redo log和undo log.md",
    "code_examples": []
  },
  {
    "id": "go-interview_binlog、redo log和undo log_003",
    "text": "**定义**：`redo log` 是 MySQL InnoDB 存储引擎中的重做日志，用于保证事务的持久性（即 `D` in ACID）。它记录了已经提交的事务对数据页的物理更改。",
    "answer": "**定义**：`redo log` 是 MySQL InnoDB 存储引擎中的重做日志，用于保证事务的持久性（即 `D` in ACID）。它记录了已经提交的事务对数据页的物理更改。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "MySQL",
      "InnoDB",
      "redo log",
      "事务持久性",
      "ACID"
    ],
    "followup_points": [
      "1. `redo log` 的写入机制是怎样的？为什么采用物理日志而非逻辑日志？",
      "2. `redo log` 和 `undo log` 在事务处理中如何协同工作？它们分别解决了什么问题？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/binlog、redo log和undo log.md",
    "code_examples": []
  },
  {
    "id": "go-interview_binlog、redo log和undo log_005",
    "text": "**日志格式**：`redo log` 记录了数据页的物理更改，并以固定大小的循环缓冲区存储。当日志写满时，会覆盖最早的日志内容。",
    "answer": "**日志格式**：`redo log` 记录了数据页的物理更改，并以固定大小的循环缓冲区存储。当日志写满时，会覆盖最早的日志内容。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "redo log",
      "物理更改",
      "循环缓冲区",
      "日志覆盖",
      "日志写满"
    ],
    "followup_points": [
      "1. 当 `redo log` 覆盖最早的日志内容时，如何确保已提交的事务不会因日志覆盖而导致数据丢失？",
      "2. `redo log` 的循环缓冲区设计是否会影响事务的持久性？如果有影响，数据库是如何通过其他机制（如 `checkpoint`）来保证数据一致性的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/binlog、redo log和undo log.md",
    "code_examples": []
  },
  {
    "id": "go-interview_binlog、redo log和undo log_006",
    "text": "**定义**：`undo log` 是 MySQL InnoDB 存储引擎中的回滚日志，记录了事务在执行过程中产生的对数据库的逻辑更改，主要用于实现事务的回滚和多版本并发控制（MVCC）。",
    "answer": "**定义**：`undo log` 是 MySQL InnoDB 存储引擎中的回滚日志，记录了事务在执行过程中产生的对数据库的逻辑更改，主要用于实现事务的回滚和多版本并发控制（MVCC）。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "MySQL",
      "InnoDB",
      "事务",
      "回滚日志",
      "MVCC"
    ],
    "followup_points": [
      "1. `undo log` 在记录逻辑更改时，具体是如何存储这些更改的？是记录原始值还是逆向操作？",
      "2. 在 MVCC 机制中，`undo log` 如何支持版本链的构建和旧版本的读取？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/binlog、redo log和undo log.md",
    "code_examples": []
  },
  {
    "id": "go-interview_binlog、redo log和undo log_008",
    "text": "**存储方式**：`undo log` 记录的是逻辑操作，例如删除一条记录会记录下被删除的行数据。`undo log` 通常存储在特殊的回滚段中。",
    "answer": "**存储方式**：`undo log` 记录的是逻辑操作，例如删除一条记录会记录下被删除的行数据。`undo log` 通常存储在特殊的回滚段中。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "undo log",
      "逻辑操作",
      "回滚段",
      "行数据存储",
      "数据恢复"
    ],
    "followup_points": [
      "1. 为什么 `undo log` 需要记录逻辑操作而不是物理操作？这种设计对事务回滚和 MVCC 有什么具体优势？",
      "2. 回滚段是如何管理 `undo log` 的生命周期（如分配、回收、版本链维护）？在高并发场景下如何保证其一致性和性能？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/binlog、redo log和undo log.md",
    "code_examples": []
  },
  {
    "id": "go-interview_binlog、redo log和undo log_009",
    "text": "当事务提交时，MySQL 会将修改写入 `redo log`，这时事务被视为持久化，但修改的数据页可能尚未写入磁盘。",
    "answer": "当事务提交时，MySQL 会将修改写入 `redo log`，这时事务被视为持久化，但修改的数据页可能尚未写入磁盘。",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "事务持久化",
      "redo log",
      "MySQL",
      "数据页",
      "磁盘写入"
    ],
    "followup_points": [
      "1. 如果在数据页尚未写入磁盘时发生系统崩溃，MySQL 是如何利用 `redo log` 来恢复未持久化的事务数据的？",
      "2. `redo log` 的写入和刷盘策略（如 `innodb_flush_log_at_trx_commit` 参数）如何影响事务的持久性和性能？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/binlog、redo log和undo log.md",
    "code_examples": []
  },
  {
    "id": "go-interview_binlog、redo log和undo log_010",
    "text": "`redo log` 和 `binlog` 会被分别写入，用于恢复和复制操作。`redo log` 确保系统崩溃后数据的持久性，而 `binlog` 记录所有变更，支持数据恢复和主从复制。",
    "answer": "`redo log` 和 `binlog` 会被分别写入，用于恢复和复制操作。`redo log` 确保系统崩溃后数据的持久性，而 `binlog` 记录所有变更，支持数据恢复和主从复制。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "redo log",
      "binlog",
      "数据恢复",
      "主从复制",
      "持久性"
    ],
    "followup_points": [
      "1. 在写入 `redo log` 和 `binlog` 时，如果发生崩溃，MySQL 如何保证两者的一致性？",
      "2. `redo log` 和 `binlog` 的写入策略（如 `sync_binlog` 和 `innodb_flush_log_at_trx_commit`）对性能和数据安全性的影响是什么？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/binlog、redo log和undo log.md",
    "code_examples": []
  },
  {
    "id": "go-interview_binlog、redo log和undo log_011",
    "text": "在事务提交的过程中，MySQL 会首先将事务的操作记录到 `redo log`，然后再更新 `binlog`。如果系统崩溃，可以通过 `redo log` 恢复已提交但未写入磁盘的数据；而 `binlog` 则用于数据恢复和主从复制。",
    "answer": "在事务提交的过程中，MySQL 会首先将事务的操作记录到 `redo log`，然后再更新 `binlog`。如果系统崩溃，可以通过 `redo log` 恢复已提交但未写入磁盘的数据；而 `binlog` 则用于数据恢复和主从复制。",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "MySQL事务",
      "redo log",
      "binlog",
      "数据恢复",
      "主从复制"
    ],
    "followup_points": [
      "1. 为什么 MySQL 在事务提交时选择先写 `redo log` 再更新 `binlog`，而不是反过来？这种设计对数据一致性和性能有什么影响？",
      "2. 如果在写入 `redo log` 后、更新 `binlog` 前发生系统崩溃，MySQL 如何保证主从复制的数据一致性？是否有机制避免主从数据不一致的问题？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/binlog、redo log和undo log.md",
    "code_examples": []
  },
  {
    "id": "go-interview_binlog、redo log和undo log_012",
    "text": "**`undo log`**：用于事务回滚和 MVCC，记录事务开始前的数据状态。",
    "answer": "**`undo log`**：用于事务回滚和 MVCC，记录事务开始前的数据状态。 理解这三种日志的区别和用途对于掌握数据库的持久性和一致性机制至关重要。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "undo log",
      "事务回滚",
      "MVCC",
      "数据状态",
      "持久性和一致性"
    ],
    "followup_points": [
      "1. 在 MVCC 机制中，`undo log` 如何实现多版本数据的管理，以及不同事务隔离级别下对 `undo log` 的读取策略有何不同？",
      "2. 当事务回滚时，`undo log` 如何确保数据恢复的原子性，以及在高并发场景下，`undo log` 的清理机制如何避免与正在使用的历史版本冲突？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/binlog、redo log和undo log.md",
    "code_examples": []
  },
  {
    "id": "go-interview_主键索引和非主键索引的区别_000",
    "text": "**聚集索引**：InnoDB存储引擎中的主键索引通常是聚集索引（Clustered Index）。这意味着表的数据实际上是按主键的顺序存储在磁盘上的。其他索引会包含主键值作为其键的一部分。",
    "answer": "**聚集索引**：InnoDB存储引擎中的主键索引通常是聚集索引（Clustered Index）。这意味着表的数据实际上是按主键的顺序存储在磁盘上的。其他索引会包含主键值作为其键的一部分。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "聚集索引",
      "InnoDB存储引擎",
      "主键索引",
      "数据存储",
      "索引结构"
    ],
    "followup_points": [
      "1. 如果表没有显式定义主键，InnoDB会如何选择聚集索引？",
      "2. 聚集索引的叶子节点存储的是完整的行数据，而其他索引（二级索引）的叶子节点存储的是主键值，这种设计对查询性能有什么具体影响？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/主键索引和非主键索引的区别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_主键索引和非主键索引的区别_001",
    "text": "**非聚集索引**：在InnoDB存储引擎中，非主键索引是非聚集索引（Secondary Index）。非主键索引存储的是索引列的值和主键值的组合。数据的实际存储是按主键排序的，非主键索引会通过主键来访问数据。",
    "answer": "**非聚集索引**：在InnoDB存储引擎中，非主键索引是非聚集索引（Secondary Index）。非主键索引存储的是索引列的值和主键值的组合。数据的实际存储是按主键排序的，非主键索引会通过主键来访问数据。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "非聚集索引",
      "InnoDB存储引擎",
      "二级索引",
      "索引列与主键组合",
      "主键回表"
    ],
    "followup_points": [
      "1. 当通过非聚集索引查询数据时，如果查询的列都包含在非聚集索引中（即覆盖索引），是否还需要回表查询主键？",
      "2. 在高并发写入场景下，非聚集索引的维护（如插入、更新、删除）对主键索引的影响有哪些潜在的性能问题？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/主键索引和非主键索引的区别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_主键索引和非主键索引的区别_002",
    "text": "**数据存储**：主键索引直接决定了表的数据存储顺序（对于InnoDB），而非主键索引则通过主键值访问数据。",
    "answer": "**数据存储**：主键索引直接决定了表的数据存储顺序（对于InnoDB），而非主键索引则通过主键值访问数据。 主键索引和非主键索引各有其独特的作用和适用场景。在设计数据库表时，需要根据具体的查询需求和数据特性选择合适的索引策略。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "主键索引",
      "非主键索引",
      "数据存储顺序",
      "InnoDB",
      "索引策略"
    ],
    "followup_points": [
      "1. 在InnoDB中，主键索引的存储结构（如B+树叶子节点存储完整数据行）与非主键索引的存储结构（如叶子节点存储主键值+索引列值）具体有哪些差异，这些差异如何影响查询性能？",
      "2. 当表数据量较大且查询涉及非主键索引时，如何优化主键选择（例如自增主键 vs 业务主键）以减少非主键索引回表的开销？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/主键索引和非主键索引的区别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_悲观锁与乐观锁区别及使用场景_000",
    "text": "悲观锁是一种保守的锁策略，它假设会发生冲突，因此在读取或修改数据时会立即锁定数据，以防止其他事务同时修改这些数据。悲观锁的核心思想是“锁住一切”，确保数据在事务执行期间不会被其他事务修改。",
    "answer": "悲观锁是一种保守的锁策略，它假设会发生冲突，因此在读取或修改数据时会立即锁定数据，以防止其他事务同时修改这些数据。悲观锁的核心思想是“锁住一切”，确保数据在事务执行期间不会被其他事务修改。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "悲观锁",
      "事务",
      "数据锁定",
      "冲突预防",
      "并发控制"
    ],
    "followup_points": [
      "1. 悲观锁在实际应用中常见的实现方式有哪些？例如，数据库中的行锁、表锁或者Java中的synchronized关键字等。",
      "2. 悲观锁虽然能保证数据一致性，但可能会降低并发性能，有哪些优化策略可以在保证数据安全的同时减少锁的持有时间？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/悲观锁与乐观锁区别及使用场景.md",
    "code_examples": []
  },
  {
    "id": "go-interview_悲观锁与乐观锁区别及使用场景_001",
    "text": "**行级锁**：在MySQL的InnoDB存储引擎中，通过使用 `SELECT ... FOR UPDATE` 或 `SELECT ... LOCK IN SHARE MODE` 语句实现。前者用于在读取时锁定数据以进行更新，后者用于读取数据并允许其他事务读取但不修改数据。",
    "answer": "**行级锁**：在MySQL的InnoDB存储引擎中，通过使用 `SELECT ... FOR UPDATE` 或 `SELECT ... LOCK IN SHARE MODE` 语句实现。前者用于在读取时锁定数据以进行更新，后者用于读取数据并允许其他事务读取但不修改数据。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "MySQL",
      "InnoDB",
      "行级锁",
      "SELECT FOR UPDATE",
      "SELECT LOCK IN SHARE MODE"
    ],
    "followup_points": [
      "1. 当使用 `SELECT ... FOR UPDATE` 锁定某一行数据后，如果该事务长时间未提交或回滚，其他事务尝试访问该行时会遇到什么问题？如何避免这种情况？",
      "2. 在高并发场景下，如果多个事务同时使用 `SELECT ... FOR UPDATE` 锁定不同的行，但最终因事务顺序问题导致死锁，MySQL会如何处理？有哪些常见的死锁排查和优化方法？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/悲观锁与乐观锁区别及使用场景.md",
    "code_examples": []
  },
  {
    "id": "go-interview_悲观锁与乐观锁区别及使用场景_002",
    "text": "**表级锁**：通过 `LOCK TABLES` 语句或 `LOCK TABLES ... WRITE` 锁定整个表，从而在事务执行期间防止其他事务对该表进行任何操作。",
    "answer": "**表级锁**：通过 `LOCK TABLES` 语句或 `LOCK TABLES ... WRITE` 锁定整个表，从而在事务执行期间防止其他事务对该表进行任何操作。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "表级锁",
      "LOCK TABLES",
      "事务",
      "并发控制",
      "MySQL"
    ],
    "followup_points": [
      "1. 表级锁在什么场景下更适合使用，相比行级锁和页级锁有哪些优势和劣势？",
      "2. 使用 `LOCK TABLES` 时，如果事务中涉及多个表的锁定，如何避免死锁，以及释放锁的正确顺序是什么？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/悲观锁与乐观锁区别及使用场景.md",
    "code_examples": []
  },
  {
    "id": "go-interview_悲观锁与乐观锁区别及使用场景_003",
    "text": "**数据一致性**：由于数据在事务期间被锁定，确保了数据的一致性和完整性，避免了并发更新导致的数据冲突。",
    "answer": "**数据一致性**：由于数据在事务期间被锁定，确保了数据的一致性和完整性，避免了并发更新导致的数据冲突。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "数据一致性",
      "事务",
      "数据锁定",
      "并发更新",
      "数据冲突"
    ],
    "followup_points": [
      "1. 在高并发场景下，数据锁定的粒度（如表锁、行锁）如何选择以平衡一致性和性能？",
      "2. 除了锁定机制，是否还有其他策略（如乐观锁、MVCC）可以保障数据一致性，它们各自的适用场景是什么？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/悲观锁与乐观锁区别及使用场景.md",
    "code_examples": []
  },
  {
    "id": "go-interview_悲观锁与乐观锁区别及使用场景_004",
    "text": "乐观锁是一种假设冲突不会发生的锁策略，它在事务开始时不立即锁定数据，而是在提交时检查数据是否被其他事务修改。如果数据在事务期间被修改，则提交操作会失败，事务需要重新尝试或进行补救。",
    "answer": "乐观锁是一种假设冲突不会发生的锁策略，它在事务开始时不立即锁定数据，而是在提交时检查数据是否被其他事务修改。如果数据在事务期间被修改，则提交操作会失败，事务需要重新尝试或进行补救。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "乐观锁",
      "并发控制",
      "事务管理",
      "冲突检测",
      "重试机制"
    ],
    "followup_points": [
      "1. 乐观锁在实现时，通常采用哪些具体的机制（如版本号、时间戳等）来检测数据是否被修改？这些机制各自的优缺点是什么？",
      "2. 当乐观锁检测到冲突（提交失败）时，除了重试事务，还有哪些常见的冲突解决策略或补救措施可以采用？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/悲观锁与乐观锁区别及使用场景.md",
    "code_examples": []
  },
  {
    "id": "go-interview_悲观锁与乐观锁区别及使用场景_005",
    "text": "**版本号**：在表中添加一个版本号字段，每次更新数据时，版本号都会递增。事务在提交时检查版本号是否匹配，如果不匹配则回滚或重试。",
    "answer": "**版本号**：在表中添加一个版本号字段，每次更新数据时，版本号都会递增。事务在提交时检查版本号是否匹配，如果不匹配则回滚或重试。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "乐观锁",
      "并发控制",
      "事务管理",
      "数据一致性",
      "版本控制"
    ],
    "followup_points": [
      "1. 版本号字段在并发更新场景下如何保证原子性？",
      "2. 版本号递增时是否考虑使用数据库内置机制（如自动更新）或应用层控制？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/悲观锁与乐观锁区别及使用场景.md",
    "code_examples": []
  },
  {
    "id": "go-interview_悲观锁与乐观锁区别及使用场景_006",
    "text": "**时间戳**：在表中添加一个时间戳字段，每次更新时记录时间戳。事务在提交时检查时间戳是否匹配，确保数据在提交期间没有被修改。",
    "answer": "**时间戳**：在表中添加一个时间戳字段，每次更新时记录时间戳。事务在提交时检查时间戳是否匹配，确保数据在提交期间没有被修改。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "时间戳",
      "乐观锁",
      "并发控制",
      "事务提交",
      "数据一致性"
    ],
    "followup_points": [
      "1. 如果时间戳在事务提交期间被其他事务修改，系统如何处理冲突？是否有重试机制或回滚策略？",
      "2. 时间戳字段的数据类型选择（如INT、BIGINT、DATETIME）对性能和并发控制有何影响？是否有最佳实践推荐？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/悲观锁与乐观锁区别及使用场景.md",
    "code_examples": []
  },
  {
    "id": "go-interview_悲观锁与乐观锁区别及使用场景_007",
    "text": "**处理复杂性**：事务需要检查数据版本或时间戳，如果发生冲突，事务可能需要重新执行或处理失败的情况。",
    "answer": "**处理复杂性**：事务需要检查数据版本或时间戳，如果发生冲突，事务可能需要重新执行或处理失败的情况。",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "事务管理",
      "并发控制",
      "乐观锁",
      "冲突检测",
      "重试机制"
    ],
    "followup_points": [
      "1. 在处理事务冲突时，你们是如何判断是选择重试事务还是直接返回失败的？具体有哪些业务场景会影响这个决策？",
      "2. 对于需要重试的事务，你们是如何设计重试机制的（比如重试次数、间隔时间、幂等性处理）？遇到过哪些重试失败的场景，又是如何优化的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/悲观锁与乐观锁区别及使用场景.md",
    "code_examples": []
  },
  {
    "id": "go-interview_悲观锁与乐观锁区别及使用场景_008",
    "text": "**悲观锁**：在事务执行期间锁定数据，以确保一致性和完整性，适用于高冲突或复杂事务场景。缺点是可能导致性能下降和死锁。",
    "answer": "**悲观锁**：在事务执行期间锁定数据，以确保一致性和完整性，适用于高冲突或复杂事务场景。缺点是可能导致性能下降和死锁。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "悲观锁",
      "事务",
      "数据锁定",
      "一致性",
      "死锁"
    ],
    "followup_points": [
      "1. 在高冲突场景中，如何优化悲观锁的粒度（如表锁、行锁）以平衡性能和一致性？",
      "2. 针对死锁问题，除了超时机制和死锁检测，还有哪些策略可以预防和减少死锁的发生？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/悲观锁与乐观锁区别及使用场景.md",
    "code_examples": []
  },
  {
    "id": "go-interview_悲观锁与乐观锁区别及使用场景_009",
    "text": "**乐观锁**：假设数据冲突不会发生，减少了锁的竞争，适用于低冲突环境或需要高并发性能的场景。缺点是处理冲突和重试可能增加复杂性。",
    "answer": "**乐观锁**：假设数据冲突不会发生，减少了锁的竞争，适用于低冲突环境或需要高并发性能的场景。缺点是处理冲突和重试可能增加复杂性。 根据应用场景和业务需求选择合适的锁策略，可以有效地管理并发访问和数据一致性。",
    "category": "system-design",
    "difficulty": 2,
    "tags": [
      "乐观锁",
      "并发控制",
      "数据一致性",
      "锁策略",
      "重试机制"
    ],
    "followup_points": [
      "1. 在乐观锁的重试机制中，如何设计合理的重试策略（如重试次数、退避算法）以避免无限重试或性能问题？",
      "2. 乐观锁通常通过版本号或时间戳实现，但在高并发场景下，这些机制可能引发哪些潜在问题（如版本号回滚、时间戳精度不足），如何优化？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/悲观锁与乐观锁区别及使用场景.md",
    "code_examples": []
  },
  {
    "id": "go-interview_垂直分表和水平分表和分表的跨表查询 _000",
    "text": "**查询复杂性**：涉及到需要联合查询的操作时，需要通过`JOIN`操作将多个表的数据合并，这可能导致性能下降。",
    "answer": "**查询复杂性**：涉及到需要联合查询的操作时，需要通过`JOIN`操作将多个表的数据合并，这可能导致性能下降。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "查询复杂性",
      "JOIN操作",
      "联合查询",
      "性能下降",
      "数据合并"
    ],
    "followup_points": [
      "1. 在实际项目中，您遇到过哪些具体的JOIN操作导致性能下降的情况？是如何定位和优化这些问题的？",
      "2. 除了JOIN操作，还有哪些因素会显著增加查询复杂性，您通常采取哪些策略来平衡查询效率和数据一致性？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/垂直分表和水平分表和分表的跨表查询 .md",
    "code_examples": []
  },
  {
    "id": "go-interview_垂直分表和水平分表和分表的跨表查询 _001",
    "text": "**数据冗余**：在一些情况下，可以使用数据冗余来减少跨表查询的需要，例如在不同表中存储相关的数据以便于更高效的查询。",
    "answer": "**数据冗余**：在一些情况下，可以使用数据冗余来减少跨表查询的需要，例如在不同表中存储相关的数据以便于更高效的查询。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "数据冗余",
      "数据库设计",
      "查询优化",
      "跨表查询",
      "数据一致性"
    ],
    "followup_points": [
      "1. 在实际项目中，您是如何平衡数据冗余带来的查询性能提升与数据一致性的维护成本的？",
      "2. 当数据冗余导致的数据不一致问题发生时，您通常采取哪些策略或机制来确保数据的准确性？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Mysql/垂直分表和水平分表和分表的跨表查询 .md",
    "code_examples": []
  },
  {
    "id": "go-interview_HTTP状态码_000",
    "text": "**203 Non-Authoritative Information**：服务器成功处理了请求，但返回的元信息可能来自另一来源。",
    "answer": "**203 Non-Authoritative Information**：服务器成功处理了请求，但返回的元信息可能来自另一来源。",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "HTTP状态码",
      "非权威响应",
      "元信息",
      "缓存机制",
      "服务器响应"
    ],
    "followup_points": [
      "1. 服务器在什么场景下会选择返回 203 状态码，而不是直接使用原始数据源的状态码（如 200）？",
      "2. 当返回的元信息来自另一来源时，客户端应如何处理这种\"非权威\"响应，是否存在潜在的安全或数据一致性风险？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/HTTP状态码.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HTTP状态码_001",
    "text": "**301 Moved Permanently**：请求的资源已被永久移动到新位置，新的URL在`Location`头部中给出。",
    "answer": "**301 Moved Permanently**：请求的资源已被永久移动到新位置，新的URL在`Location`头部中给出。",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "HTTP状态码",
      "重定向",
      "Location头部",
      "永久重定向",
      "URL跳转"
    ],
    "followup_points": [
      "1. 当服务器返回301状态码时，客户端（如浏览器或爬虫）应该如何处理`Location`头部中的新URL？是否所有客户端都会自动跟随重定向？",
      "2. 在SEO优化中，使用301重定向对原URL的权重传递是否完全无损？是否有需要注意的潜在问题（如重定向链过长或循环重定向）？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/HTTP状态码.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HTTP状态码_002",
    "text": "**303 See Other**：请求的资源可以在另一个URL处找到，客户端应使用GET方法请求新的URL。",
    "answer": "**303 See Other**：请求的资源可以在另一个URL处找到，客户端应使用GET方法请求新的URL。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "HTTP状态码",
      "重定向",
      "303 See Other",
      "GET方法",
      "URL资源定位"
    ],
    "followup_points": [
      "1. 在什么具体场景下，服务器会优先选择返回303状态码而不是302或307？",
      "2. 如果客户端在收到303响应后，未遵循GET请求新URL的规范，可能会引发哪些潜在问题或安全隐患？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/HTTP状态码.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HTTP状态码_003",
    "text": "**305 Use Proxy**：请求的资源必须通过代理访问，代理的URL在`Location`头部中给出。",
    "answer": "**305 Use Proxy**：请求的资源必须通过代理访问，代理的URL在`Location`头部中给出。",
    "category": "system",
    "difficulty": 3,
    "tags": [
      "HTTP状态码",
      "代理服务器",
      "Location头部",
      "网络请求",
      "资源访问"
    ],
    "followup_points": [
      "1. 在实际应用中，客户端应该如何处理 `305 Use Proxy` 响应，以确保正确地通过代理服务器访问目标资源？",
      "2. 如果代理服务器在 `Location` 头部中返回的 URL 无效或无法访问，客户端应该如何处理这种情况？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/HTTP状态码.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HTTP状态码_004",
    "text": "**307 Temporary Redirect**：请求的资源临时移动到新位置，客户端应继续使用原方法请求新位置。",
    "answer": "**307 Temporary Redirect**：请求的资源临时移动到新位置，客户端应继续使用原方法请求新位置。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "HTTP状态码",
      "重定向",
      "临时重定向",
      "307状态码",
      "请求方法保持"
    ],
    "followup_points": [
      "1. 当客户端收到307重定向后，如果原请求是POST方法，新位置的资源是否需要确保能正确处理POST请求？",
      "2. 如果307重定向的目标URL在后续请求中再次发生临时移动，客户端应该如何处理循环重定向的情况？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/HTTP状态码.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HTTP状态码_005",
    "text": "**308 Permanent Redirect**：请求的资源永久移动到新位置，客户端应使用原方法请求新位置。",
    "answer": "**308 Permanent Redirect**：请求的资源永久移动到新位置，客户端应使用原方法请求新位置。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "HTTP状态码",
      "重定向机制",
      "永久重定向",
      "资源位置变更",
      "客户端行为规范"
    ],
    "followup_points": [
      "1. 在什么具体场景下会选择使用308 Permanent Redirect而不是301 Redirect？",
      "2. 如果客户端在收到308响应后仍然使用旧URI发起请求，服务器应该如何处理这种情况？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/HTTP状态码.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HTTP状态码_006",
    "text": "**407 Proxy Authentication Required**：需要通过代理进行身份验证。",
    "answer": "**407 Proxy Authentication Required**：需要通过代理进行身份验证。",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "HTTP状态码",
      "代理服务器",
      "身份验证",
      "网络请求",
      "错误处理"
    ],
    "followup_points": [
      "1. 如果遇到407错误，你会如何排查代理服务器的配置问题？",
      "2. 在处理代理身份验证时，如何确保用户凭证的安全性？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/HTTP状态码.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HTTP状态码_007",
    "text": "**411 Length Required**：服务器要求请求中包含Content-Length头部。",
    "answer": "**411 Length Required**：服务器要求请求中包含Content-Length头部。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "HTTP状态码",
      "Content-Length",
      "HTTP请求头",
      "HTTP协议",
      "服务器响应"
    ],
    "followup_points": [
      "1. 如果请求中使用了Transfer-Encoding: chunked，是否还需要包含Content-Length头部？",
      "2. 在哪些场景下（如分块传输、动态生成内容）服务器会特别要求Content-Length头部？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/HTTP状态码.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HTTP状态码_008",
    "text": "**503 Service Unavailable**：服务器当前无法处理请求，通常是因为过载或维护。",
    "answer": "**503 Service Unavailable**：服务器当前无法处理请求，通常是因为过载或维护。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "HTTP状态码",
      "服务器过载",
      "服务器维护",
      "服务不可用",
      "错误处理"
    ],
    "followup_points": [
      "1. 当服务器返回503错误时，除了过载和维护，还有哪些常见原因可能导致服务不可用？",
      "2. 如何区分503错误是临时性过载还是计划内维护，并采取不同的应对策略？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/HTTP状态码.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HTTP状态码_009",
    "text": "**504 Gateway Timeout**：服务器作为网关或代理时，未能及时从上游服务器接收请求。",
    "answer": "**504 Gateway Timeout**：服务器作为网关或代理时，未能及时从上游服务器接收请求。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "HTTP状态码",
      "网关/代理",
      "上游服务器",
      "超时",
      "网络通信"
    ],
    "followup_points": [
      "1. 当出现504 Gateway Timeout错误时，你会如何排查上游服务器是否存在性能问题或服务不可用的情况？",
      "2. 在处理504错误时，你会采取哪些措施来优化网关或代理的配置，以减少此类错误的发生？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/HTTP状态码.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HTTP状态码_010",
    "text": "**505 HTTP Version Not Supported**：服务器不支持请求中使用的HTTP协议版本。",
    "answer": "**505 HTTP Version Not Supported**：服务器不支持请求中使用的HTTP协议版本。 这些状态码帮助客户端理解服务器对请求的处理结果，并根据需要采取相应的行动。",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "HTTP状态码",
      "HTTP协议版本",
      "服务器端错误",
      "505错误码",
      "客户端请求处理"
    ],
    "followup_points": [
      "1. 服务器通常在什么情况下会返回505错误，是客户端使用了过时的HTTP版本（如HTTP/1.0），还是使用了尚未广泛支持的实验性版本（如HTTP/3）？",
      "2. 当客户端收到505错误后，应该如何调整请求以兼容服务器支持的HTTP版本，是否有标准的降级或协商机制？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/HTTP状态码.md",
    "code_examples": []
  },
  {
    "id": "go-interview_了解网络攻击吗_000",
    "text": "**Content Security Policy (CSP)**：配置 CSP 策略，限制可执行的脚本来源。",
    "answer": "**Content Security Policy (CSP)**：配置 CSP 策略，限制可执行的脚本来源。",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "Content Security Policy (CSP)",
      "CSP 策略配置",
      "脚本来源限制",
      "XSS 防护",
      "安全策略"
    ],
    "followup_points": [
      "1. 在配置 CSP 策略时，如何平衡安全性和功能性，特别是当第三方脚本来源无法完全避免时，你会采取哪些具体措施？",
      "2. 如果 CSP 策略过于严格导致部分功能失效（如内联脚本或动态脚本被阻止），你会如何调试和优化策略以保障安全的同时不影响用户体验？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/了解网络攻击吗.md",
    "code_examples": []
  },
  {
    "id": "go-interview_了解网络攻击吗_001",
    "text": "用户在银行网站登录账户并转账。攻击者创建一个恶意页面，当用户访问该页面时，恶意页面通过用户的浏览器向银行网站发起转账请求。",
    "answer": "用户在银行网站登录账户并转账。攻击者创建一个恶意页面，当用户访问该页面时，恶意页面通过用户的浏览器向银行网站发起转账请求。",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "CSRF",
      "跨站请求伪造",
      "会话劫持",
      "Web安全",
      "钓鱼攻击"
    ],
    "followup_points": [
      "1. 攻击者如何确保恶意页面发起的转账请求能够绕过银行网站的身份验证机制（如CSRF Token验证）？",
      "2. 银行网站可以采取哪些措施（如SameSite Cookie、双重验证）来防御此类CSRF攻击？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/了解网络攻击吗.md",
    "code_examples": []
  },
  {
    "id": "go-interview_了解网络攻击吗_002",
    "text": "**使用 CSRF Token**：在每个请求中包含一个唯一的 CSRF Token，服务器验证请求中的 Token 是否有效。",
    "answer": "**使用 CSRF Token**：在每个请求中包含一个唯一的 CSRF Token，服务器验证请求中的 Token 是否有效。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "CSRF Token",
      "服务器验证",
      "请求安全",
      "会话管理",
      "跨站请求伪造防护"
    ],
    "followup_points": [
      "1. CSRF Token 的生成和存储机制是怎样的？是存储在 Session 中还是其他地方，如何确保其唯一性和安全性？",
      "2. 如果前端应用是单页应用（SPA），如何在不同页面或组件间安全地传递和刷新 CSRF Token？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/了解网络攻击吗.md",
    "code_examples": []
  },
  {
    "id": "go-interview_了解网络攻击吗_003",
    "text": "**使用 SameSite Cookies 属性**：设置 cookies 的 `SameSite` 属性，防止第三方网站通过跨站请求发送 cookies。",
    "answer": "**使用 SameSite Cookies 属性**：设置 cookies 的 `SameSite` 属性，防止第三方网站通过跨站请求发送 cookies。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "SameSite Cookies",
      "CSRF 防护",
      "Cookie 安全属性",
      "跨站请求",
      "HTTP Cookie"
    ],
    "followup_points": [
      "1. SameSite 属性有哪些可选值（Strict/Lax/None），它们的区别和适用场景是什么？",
      "2. 在什么情况下需要将 SameSite 设置为 None，同时需要注意哪些额外的安全措施（如 Secure 属性）？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/了解网络攻击吗.md",
    "code_examples": []
  },
  {
    "id": "go-interview_了解网络攻击吗_004",
    "text": "**XSS**：攻击者通过注入恶意脚本影响用户的浏览器和数据，主要防御措施包括输入验证、输出编码和 CSP。",
    "answer": "**XSS**：攻击者通过注入恶意脚本影响用户的浏览器和数据，主要防御措施包括输入验证、输出编码和 CSP。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "XSS",
      "输入验证",
      "输出编码",
      "CSP",
      "恶意脚本"
    ],
    "followup_points": [
      "1. 在实施输入验证时，如何平衡安全性与用户体验，避免过度限制合法输入？",
      "2. CSP策略中，除了常见的`default-src 'self'`，哪些高级指令（如`script-src`、`connect-src`）对防御XSS最关键，如何配置才能避免误拦截？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/了解网络攻击吗.md",
    "code_examples": []
  },
  {
    "id": "go-interview_了解网络攻击吗_005",
    "text": "**CSRF**：攻击者诱使用户在已认证的网页上执行伪造操作，主要防御措施包括使用 CSRF Token 和验证请求来源。",
    "answer": "**CSRF**：攻击者诱使用户在已认证的网页上执行伪造操作，主要防御措施包括使用 CSRF Token 和验证请求来源。 了解这些攻击及其防御措施对于提高 web 应用的安全性非常重要。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "CSRF",
      "CSRF Token",
      "请求来源验证",
      "Web安全",
      "认证与授权"
    ],
    "followup_points": [
      "1. 除了 CSRF Token 和验证请求来源，还有哪些防御 CSRF 攻击的措施（如 SameSite Cookie、双重提交 Cookie 等），各自的优缺点是什么？",
      "2. 在实现 CSRF Token 时，如何确保 Token 的安全性（如随机性、时效性、存储位置等）以及如何处理前后端分离场景下的 Token 传递问题？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/了解网络攻击吗.md",
    "code_examples": []
  },
  {
    "id": "go-interview_图解HTTPS_000",
    "text": "**HTTPS 工作流程**",
    "answer": "# - **客户端（浏览器） → 服务器：** - 客户端向服务器发送请求，要求建立 HTTPS 连接（如 `https://example.com`）。 - 服务器返回其 SSL/TLS 证书。 # - **证书交换：** - 服务器将其 SSL/TLS 证书发送给客户端，证书中包含服务器的公钥。 # - **客户端验证：** - 客户端验证服务器的证书是否有效（包括检查证书颁发机构是否可信，证书是否过期等）。 - 如果验证通过，客户端生成一个随机对称密钥，并用服务器的公钥加密。 # - **客户端 → 服务器：** - 客户端将加密后的对称密钥发送给服务器。 - 服务器用自己的私钥解密对称密钥。 # - **加密通信：** - 客户端和服务器使用对称加密进行数据通信，此时通信是加密的，确保数据安全。 # - **断开连接：** - 当通信结束时，客户端和服务器可以终止 SSL/TLS 连接。 --- 这个流程说明了 HTTPS 如何通过 SSL/TLS 协议确保客户端与服务器之间的通信是加密的，防止数据被窃取或篡改。",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "HTTPS",
      "SSL/TLS",
      "证书验证",
      "非对称加密",
      "对称密钥"
    ],
    "followup_points": [
      "1. 如果客户端验证服务器证书失败（如证书过期或颁发机构不可信），HTTPS 连接会中断，此时是否有降级到 HTTP 的风险？如何避免？",
      "2. 在证书交换阶段，服务器发送的 SSL/TLS 证书中除了公钥，还包含哪些关键信息？这些信息在后续流程中起到什么作用？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/图解HTTPS.md",
    "code_examples": [
      {
        "code": "┌───────────────┐\n│   浏览器请求  │\n│  https://example.com  │\n└───────────────┘\n         │\n         ▼\n┌───────────────┐\n│   服务器返回   │\n│  SSL/TLS 证书  │\n└───────────────┘",
        "language": ""
      },
      {
        "code": "┌───────────────┐\n│  客户端验证   │\n│  服务器证书   │\n└───────────────┘\n         │\n         ▼\n┌───────────────┐\n│  生成对称密钥 │\n│ 并用公钥加密  │\n└───────────────┘",
        "language": ""
      },
      {
        "code": "┌───────────────┐\n│  加密的对称密钥│\n│  发送给服务器  │\n└───────────────┘\n         │\n         ▼\n┌───────────────┐\n│  服务器用私钥解密│\n│  获得对称密钥  │\n└───────────────┘",
        "language": ""
      },
      {
        "code": "┌───────────────┐\n│   加密数据传输 │\n│  使用对称密钥 │\n└───────────────┘\n         │\n         ▼\n┌───────────────┐\n│   服务器接收   │\n│   并解密数据   │\n└───────────────┘",
        "language": ""
      },
      {
        "code": "┌───────────────┐\n│  终止 SSL/TLS │\n│  安全连接    │\n└───────────────┘",
        "language": ""
      }
    ]
  },
  {
    "id": "go-interview_TCP 协议的延迟 ACK 和累计应答_000",
    "text": "可能会导致不必要的数据重传，因为接收方可能会丢失数据包的 ACK，从而要求重新传输所有未确认的数据包。",
    "answer": "可能会导致不必要的数据重传，因为接收方可能会丢失数据包的 ACK，从而要求重新传输所有未确认的数据包。",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "TCP",
      "数据重传",
      "ACK丢失",
      "可靠传输",
      "网络拥塞"
    ],
    "followup_points": [
      "1. 在实际网络环境中，哪些因素会导致接收方频繁丢失ACK包？",
      "2. 除了重传所有未确认数据包，是否有优化机制可以减少不必要的数据重传？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/TCP 协议的延迟 ACK 和累计应答.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HTTP 1.0，1.1，2.0 的区别_000",
    "text": "**单次请求-响应**：HTTP 1.0 是无状态协议，每次请求都会建立一个新的TCP连接，服务器处理完请求后立即关闭连接。",
    "answer": "**单次请求-响应**：HTTP 1.0 是无状态协议，每次请求都会建立一个新的TCP连接，服务器处理完请求后立即关闭连接。",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "HTTP 1.0",
      "无状态协议",
      "TCP连接",
      "请求-响应",
      "连接关闭"
    ],
    "followup_points": [
      "1. HTTP 1.0 每次请求都建立新的TCP连接，这种设计对服务器性能和客户端响应速度有哪些具体影响？",
      "2. HTTP 1.0 的无状态特性在哪些场景下会带来挑战，后续版本（如HTTP 1.1/2.0）是如何改进的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/HTTP 1.0，1.1，2.0 的区别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HTTP 1.0，1.1，2.0 的区别_001",
    "text": "**请求头简化**：HTTP 1.0 请求头较为简单，不支持Host头部字段，因此不能直接支持虚拟主机。",
    "answer": "**请求头简化**：HTTP 1.0 请求头较为简单，不支持Host头部字段，因此不能直接支持虚拟主机。",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "HTTP/1.0",
      "请求头",
      "Host",
      "虚拟主机",
      "协议版本"
    ],
    "followup_points": [
      "1. HTTP 1.0 中不支持 Host 头部字段，那它是如何区分同一服务器上不同域名的请求的？",
      "2. 如果 HTTP 1.0 需要支持虚拟主机，可以通过哪些技术或方法来实现？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/HTTP 1.0，1.1，2.0 的区别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HTTP 1.0，1.1，2.0 的区别_002",
    "text": "**缓存控制**：HTTP 1.0 引入了简单的缓存控制机制，如通过 `Expires` 头部指定资源的过期时间。",
    "answer": "**缓存控制**：HTTP 1.0 引入了简单的缓存控制机制，如通过 `Expires` 头部指定资源的过期时间。",
    "category": "redis",
    "difficulty": 2,
    "tags": [
      "HTTP 1.0",
      "缓存控制",
      "Expires",
      "缓存机制",
      "HTTP 头部"
    ],
    "followup_points": [
      "1. HTTP 1.1 中引入了哪些更灵活的缓存控制头部，相比 `Expires` 有哪些优势？",
      "2. 在实际应用中，如何通过 `Cache-Control` 头部（如 `max-age`、`no-cache` 等）精细控制缓存行为？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/HTTP 1.0，1.1，2.0 的区别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HTTP 1.0，1.1，2.0 的区别_003",
    "text": "**持久连接**：HTTP 1.1 默认支持持久连接（Persistent Connection），即 `Connection: keep-alive`。多个请求可以复用同一个TCP连接，从而减少连接的建立和断开带来的开销。",
    "answer": "**持久连接**：HTTP 1.1 默认支持持久连接（Persistent Connection），即 `Connection: keep-alive`。多个请求可以复用同一个TCP连接，从而减少连接的建立和断开带来的开销。",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "HTTP/1.1",
      "持久连接",
      "Connection: keep-alive",
      "TCP连接复用",
      "连接开销优化"
    ],
    "followup_points": [
      "1. HTTP/1.1 中持久连接的默认超时时间是如何设置的，以及在实际应用中如何优化这个超时时间？",
      "2. 持久连接在什么场景下可能带来性能问题（如队头阻塞），HTTP/2 是如何通过多路复用来解决这个问题的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/HTTP 1.0，1.1，2.0 的区别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HTTP 1.0，1.1，2.0 的区别_004",
    "text": "**管道机制**：HTTP 1.1 引入了请求管线化（Pipelining），允许客户端在收到第一个响应前发送多个请求。但由于队头阻塞（Head-of-Line Blocking）问题，这个特性并没有得到广泛应用。",
    "answer": "**管道机制**：HTTP 1.1 引入了请求管线化（Pipelining），允许客户端在收到第一个响应前发送多个请求。但由于队头阻塞（Head-of-Line Blocking）问题，这个特性并没有得到广泛应用。",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "HTTP/1.1",
      "请求管线化",
      "队头阻塞",
      "管道机制",
      "HTTP协议"
    ],
    "followup_points": [
      "1. 在HTTP/1.1的管道机制中，队头阻塞问题具体是如何发生的？能否举例说明某个请求的延迟如何影响后续所有请求的处理？",
      "2. 除了队头阻塞，HTTP/1.1管道机制在实际应用中还可能面临哪些其他挑战（如连接管理、服务器处理顺序或兼容性问题）？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/HTTP 1.0，1.1，2.0 的区别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HTTP 1.0，1.1，2.0 的区别_005",
    "text": "**Host头**：HTTP 1.1 要求所有请求必须包含Host头部字段，支持同一服务器上多个域名的虚拟主机。",
    "answer": "**Host头**：HTTP 1.1 要求所有请求必须包含Host头部字段，支持同一服务器上多个域名的虚拟主机。",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "HTTP",
      "Host头",
      "虚拟主机",
      "HTTP 1.1",
      "请求头"
    ],
    "followup_points": [
      "1. 如果Host头缺失或格式错误，服务器会如何处理这样的请求？",
      "2. 在反向代理或负载均衡场景中，Host头可能会被修改，这会对虚拟主机的识别产生什么影响？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/HTTP 1.0，1.1，2.0 的区别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HTTP 1.0，1.1，2.0 的区别_006",
    "text": "**分块传输编码**：支持分块传输编码（Chunked Transfer Encoding），允许服务器在数据尚未全部准备好时开始传输，适用于流式数据传输。",
    "answer": "**分块传输编码**：支持分块传输编码（Chunked Transfer Encoding），允许服务器在数据尚未全部准备好时开始传输，适用于流式数据传输。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "分块传输编码",
      "Chunked Transfer Encoding",
      "流式数据传输",
      "HTTP传输",
      "服务器推送"
    ],
    "followup_points": [
      "1. 分块传输编码的具体实现机制是怎样的？比如数据块是如何划分和标识的？",
      "2. 分块传输编码在哪些实际场景中应用最广泛？比如流媒体、大文件上传或API响应中？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/HTTP 1.0，1.1，2.0 的区别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HTTP 1.0，1.1，2.0 的区别_007",
    "text": "**二进制协议**：HTTP 2.0 将HTTP消息封装为二进制帧（Binary Framing Layer），而不是文本协议。这种改进使得协议更加紧凑、高效，减少了解析开销。",
    "answer": "**二进制协议**：HTTP 2.0 将HTTP消息封装为二进制帧（Binary Framing Layer），而不是文本协议。这种改进使得协议更加紧凑、高效，减少了解析开销。",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "HTTP/2",
      "二进制帧",
      "协议效率",
      "解析开销",
      "数据封装"
    ],
    "followup_points": [
      "1. HTTP/2.0 的二进制帧具体采用了哪些编码方式来提升协议的紧凑性和效率？",
      "2. 相较于 HTTP/1.1 的文本协议，二进制帧在解析开销上具体减少了哪些操作或性能瓶颈？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/HTTP 1.0，1.1，2.0 的区别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HTTP 1.0，1.1，2.0 的区别_008",
    "text": "**多路复用**：HTTP 2.0 支持多路复用（Multiplexing），允许在一个TCP连接上同时发送多个请求和响应，消除了HTTP 1.x中的队头阻塞问题。",
    "answer": "**多路复用**：HTTP 2.0 支持多路复用（Multiplexing），允许在一个TCP连接上同时发送多个请求和响应，消除了HTTP 1.x中的队头阻塞问题。",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "HTTP 2.0",
      "多路复用",
      "Multiplexing",
      "队头阻塞",
      "TCP连接"
    ],
    "followup_points": [
      "1. HTTP/2.0 是如何通过二进制分帧实现多路复用的，具体帧结构中的哪些字段支持了这一机制？",
      "2. 在多路复用场景下，如果某个请求的处理耗时较长（如大文件下载），是否会影响其他请求的响应速度？为什么？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/HTTP 1.0，1.1，2.0 的区别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HTTP 1.0，1.1，2.0 的区别_009",
    "text": "**头部压缩**：HTTP 2.0 引入了HPACK头部压缩算法，大大减少了请求和响应中的头部大小，提升了传输效率。",
    "answer": "**头部压缩**：HTTP 2.0 引入了HPACK头部压缩算法，大大减少了请求和响应中的头部大小，提升了传输效率。",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "HTTP/2",
      "HPACK",
      "头部压缩",
      "传输效率",
      "网络优化"
    ],
    "followup_points": [
      "1. HPACK算法具体是通过哪些技术手段实现头部压缩的？",
      "2. 在高并发场景下，HPACK如何处理动态表更新和头部字段的重复利用，以确保压缩效率？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/HTTP 1.0，1.1，2.0 的区别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HTTP 1.0，1.1，2.0 的区别_010",
    "text": "**服务器推送**：HTTP 2.0 支持服务器推送（Server Push），允许服务器在客户端请求前主动推送资源，减少延迟。",
    "answer": "**服务器推送**：HTTP 2.0 支持服务器推送（Server Push），允许服务器在客户端请求前主动推送资源，减少延迟。",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "HTTP/2.0",
      "服务器推送",
      "Server Push",
      "资源推送",
      "减少延迟"
    ],
    "followup_points": [
      "1. HTTP/2 服务器推送在实际应用中可能面临哪些挑战或潜在问题？",
      "2. 如何判断哪些资源适合使用服务器推送，以及如何避免推送冗余资源导致性能下降？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/HTTP 1.0，1.1，2.0 的区别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HTTP 1.0，1.1，2.0 的区别_011",
    "text": "**HTTP 1.1**：引入了持久连接和请求管线化，优化了连接管理和缓存控制，增加了对虚拟主机的支持。",
    "answer": "**HTTP 1.1**：引入了持久连接和请求管线化，优化了连接管理和缓存控制，增加了对虚拟主机的支持。",
    "category": "redis",
    "difficulty": 2,
    "tags": [
      "HTTP 1.1",
      "持久连接",
      "请求管线化",
      "缓存控制",
      "虚拟主机"
    ],
    "followup_points": [
      "1. HTTP 1.1中的持久连接（Keep-Alive）是如何通过复用TCP连接来减少网络开销的？它与HTTP 1.0中的短连接相比，在性能优化上有哪些具体的改进？",
      "2. HTTP 1.1的请求管线化（Pipelining）在实际应用中为什么没有被广泛采用？它可能存在哪些问题，以及后来有哪些替代方案（如HTTP/2的多路复用）来解决这些问题？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/HTTP 1.0，1.1，2.0 的区别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HTTP 1.0，1.1，2.0 的区别_012",
    "text": "**HTTP 2.0**：采用二进制传输，多路复用，头部压缩和服务器推送等新特性，显著提升了传输效率和用户体验。",
    "answer": "**HTTP 2.0**：采用二进制传输，多路复用，头部压缩和服务器推送等新特性，显著提升了传输效率和用户体验。",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "HTTP 2.0",
      "二进制传输",
      "多路复用",
      "头部压缩",
      "服务器推送"
    ],
    "followup_points": [
      "1. HTTP/2.0 的多路复用是如何解决 HTTP/1.1 中队头阻塞问题的？",
      "2. HTTP/2.0 的头部压缩机制具体采用了什么技术，相比 HTTP/1.1 有哪些优势？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Network/HTTP 1.0，1.1，2.0 的区别.md",
    "code_examples": []
  },
  {
    "id": "go-interview_为什么要使用消息队列 _000",
    "text": "在传统的系统中，如果服务 A 直接调用服务 B，那么服务 A 和 B 会高度耦合。如果 B 发生改变，A 也需要调整。",
    "answer": "在传统的系统中，如果服务 A 直接调用服务 B，那么服务 A 和 B 会高度耦合。如果 B 发生改变，A 也需要调整。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "服务耦合",
      "服务依赖",
      "单体架构",
      "服务变更影响",
      "紧耦合设计"
    ],
    "followup_points": [
      "1. 除了直接调用导致耦合外，还有哪些常见的系统耦合场景会影响服务的可维护性？",
      "2. 在微服务架构中，通常采用哪些设计模式或中间件来解耦服务间的依赖关系？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Kafka/为什么要使用消息队列 .md",
    "code_examples": []
  },
  {
    "id": "go-interview_为什么要使用消息队列 _001",
    "text": "使用消息队列，服务 A 只需要将消息发布到队列中，而无需关心服务 B 的实现或状态。服务 B 可以在任意时间读取消息，处理完毕后，系统依然能正常工作。",
    "answer": "使用消息队列，服务 A 只需要将消息发布到队列中，而无需关心服务 B 的实现或状态。服务 B 可以在任意时间读取消息，处理完毕后，系统依然能正常工作。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "解耦",
      "异步通信",
      "削峰填谷",
      "可靠性",
      "最终一致性"
    ],
    "followup_points": [
      "1. 消息队列在服务 B 不可用或处理失败时，如何保证消息不丢失且能被后续正确处理？",
      "2. 如果消息队列中的消息积压过多，系统有哪些机制或策略来保障服务 B 的处理效率和数据的最终一致性？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Kafka/为什么要使用消息队列 .md",
    "code_examples": []
  },
  {
    "id": "go-interview_为什么要使用消息队列 _002",
    "text": "**Kafka 优势**：Kafka 提供了基于主题（Topic）进行消息发布与订阅的模型，生产者和消费者之间松散耦合，便于系统的灵活扩展。",
    "answer": "**Kafka 优势**：Kafka 提供了基于主题（Topic）进行消息发布与订阅的模型，生产者和消费者之间松散耦合，便于系统的灵活扩展。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "消息队列",
      "发布订阅模型",
      "松散耦合",
      "可扩展性",
      "Topic"
    ],
    "followup_points": [
      "1. 在实际生产环境中，Kafka 的主题（Topic）分区策略如何影响系统的扩展性和消息处理的并行度？",
      "2. 当生产者和消费者数量动态变化时，Kafka 如何保证松散耦合模型下的数据一致性和消费顺序性？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Kafka/为什么要使用消息队列 .md",
    "code_examples": []
  },
  {
    "id": "go-interview_为什么要使用消息队列 _003",
    "text": "在高并发场景下，系统往往会因为瞬时的流量峰值而被压垮。如果服务需要实时处理请求，可能导致资源耗尽或崩溃。",
    "answer": "在高并发场景下，系统往往会因为瞬时的流量峰值而被压垮。如果服务需要实时处理请求，可能导致资源耗尽或崩溃。",
    "category": "system-design",
    "difficulty": 3,
    "tags": [
      "高并发",
      "流量峰值",
      "资源耗尽",
      "系统崩溃",
      "实时处理"
    ],
    "followup_points": [
      "1. 在您提到的流量峰值场景中，系统通常采用哪些具体的限流或熔断策略来保护自身？这些策略是如何动态调整的？",
      "2. 除了实时处理请求，是否有考虑过通过异步化、消息队列或削峰填谷机制来缓解瞬时流量压力？如何平衡实时性和系统稳定性？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Kafka/为什么要使用消息队列 .md",
    "code_examples": []
  },
  {
    "id": "go-interview_为什么要使用消息队列 _004",
    "text": "**Kafka 优势**：Kafka 支持高吞吐量的消息处理，尤其适合大规模数据流处理，支持数据持久化，能够处理大量并发请求而不影响消费者。",
    "answer": "**Kafka 优势**：Kafka 支持高吞吐量的消息处理，尤其适合大规模数据流处理，支持数据持久化，能够处理大量并发请求而不影响消费者。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "高吞吐量",
      "数据持久化",
      "大规模数据流处理",
      "高并发",
      "消费者隔离"
    ],
    "followup_points": [
      "1. Kafka是如何通过分区和副本机制实现高吞吐量和数据持久化的？",
      "2. 在处理大量并发请求时，Kafka是如何确保消费者不受影响的，具体涉及哪些优化策略？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Kafka/为什么要使用消息队列 .md",
    "code_examples": []
  },
  {
    "id": "go-interview_为什么要使用消息队列 _005",
    "text": "在一些场景中，服务不需要立即响应，而可以进行异步处理，比如订单处理系统，用户提交订单后不需要立即完成所有订单流程，而是可以将订单任务放入队列中，后台服务逐步处理。",
    "answer": "在一些场景中，服务不需要立即响应，而可以进行异步处理，比如订单处理系统，用户提交订单后不需要立即完成所有订单流程，而是可以将订单任务放入队列中，后台服务逐步处理。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "异步处理",
      "消息队列",
      "任务队列",
      "订单系统",
      "后台服务"
    ],
    "followup_points": [
      "1. 在订单处理系统中，异步处理具体是如何保证订单任务的顺序性和一致性的？",
      "2. 当后台服务处理队列中的订单任务时，如果遇到异常或失败，系统是如何进行重试或错误处理的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Kafka/为什么要使用消息队列 .md",
    "code_examples": []
  },
  {
    "id": "go-interview_为什么要使用消息队列 _006",
    "text": "**Kafka 优势**：Kafka 支持异步消息处理，生产者将消息发布到队列，消费者异步处理，从而提高了系统的响应效率。",
    "answer": "**Kafka 优势**：Kafka 支持异步消息处理，生产者将消息发布到队列，消费者异步处理，从而提高了系统的响应效率。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "消息队列",
      "异步处理",
      "高吞吐量",
      "低延迟",
      "解耦"
    ],
    "followup_points": [
      "1. Kafka 如何保证异步消息处理过程中的数据一致性和可靠性？",
      "2. 在高并发场景下，Kafka 的异步处理机制如何避免消息积压或丢失？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Kafka/为什么要使用消息队列 .md",
    "code_examples": []
  },
  {
    "id": "go-interview_为什么要使用消息队列 _007",
    "text": "在分布式系统中，节点或服务可能会出现故障，导致部分请求处理失败。使用消息队列可以确保消息的持久化，当消费者服务恢复后仍然可以继续处理未处理的消息。",
    "answer": "在分布式系统中，节点或服务可能会出现故障，导致部分请求处理失败。使用消息队列可以确保消息的持久化，当消费者服务恢复后仍然可以继续处理未处理的消息。",
    "category": "system-design",
    "difficulty": 2,
    "tags": [
      "分布式系统",
      "消息队列",
      "消息持久化",
      "服务容错",
      "最终一致性"
    ],
    "followup_points": [
      "1. 消息队列如何确保消息在持久化过程中的可靠性，比如在消息写入磁盘前如果消费者服务崩溃，如何避免消息丢失？",
      "2. 当消费者服务恢复后，消息队列如何保证消息的重复消费问题，或者是否有机制去重？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Kafka/为什么要使用消息队列 .md",
    "code_examples": []
  },
  {
    "id": "go-interview_为什么要使用消息队列 _008",
    "text": "**Kafka 优势**：Kafka 提供了消息持久化、分区复制等机制，确保即使某些节点故障，也可以恢复消息处理。Kafka 中的消息可以被持久存储，并且通过日志文件防止消息丢失。",
    "answer": "**Kafka 优势**：Kafka 提供了消息持久化、分区复制等机制，确保即使某些节点故障，也可以恢复消息处理。Kafka 中的消息可以被持久存储，并且通过日志文件防止消息丢失。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "消息持久化",
      "分区复制",
      "故障恢复",
      "高可用",
      "数据可靠性"
    ],
    "followup_points": [
      "1. Kafka 的分区复制机制具体是如何实现故障恢复的？副本之间如何同步数据以保证一致性？",
      "2. Kafka 的消息持久化存储是如何管理日志文件的？比如日志文件的切割、保留策略以及如何影响磁盘空间和性能？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Kafka/为什么要使用消息队列 .md",
    "code_examples": []
  },
  {
    "id": "go-interview_为什么要使用消息队列 _009",
    "text": "消息队列能够将多个服务产生的数据汇聚到一起，方便进行实时的数据流处理和分析。例如，电商系统中的用户行为、订单数据等，可以通过 Kafka 进行实时分析。",
    "answer": "消息队列能够将多个服务产生的数据汇聚到一起，方便进行实时的数据流处理和分析。例如，电商系统中的用户行为、订单数据等，可以通过 Kafka 进行实时分析。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "消息队列",
      "实时数据流处理",
      "数据汇聚",
      "Kafka",
      "数据分析"
    ],
    "followup_points": [
      "1. 在电商系统中，使用 Kafka 进行实时数据流处理时，如何确保数据从多个服务到 Kafka 的传输可靠性和一致性？",
      "2. 当用户行为和订单数据量激增时，Kafka 如何保障实时分析的延迟和吞吐量，以及有哪些优化策略？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Kafka/为什么要使用消息队列 .md",
    "code_examples": []
  },
  {
    "id": "go-interview_为什么要使用消息队列 _010",
    "text": "**Kafka 优势**：Kafka 提供了强大的流处理能力（结合 Kafka Streams 等工具），使得开发者能够对大规模数据进行实时处理，处理后可以将结果写回 Kafka 或其他存储系统。",
    "answer": "**Kafka 优势**：Kafka 提供了强大的流处理能力（结合 Kafka Streams 等工具），使得开发者能够对大规模数据进行实时处理，处理后可以将结果写回 Kafka 或其他存储系统。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "Kafka",
      "流处理",
      "实时处理",
      "大规模数据",
      "Kafka Streams"
    ],
    "followup_points": [
      "1. 在实际项目中，Kafka Streams 与其他流处理框架（如 Flink、Spark Streaming）相比，您更倾向于选择哪种？为什么？",
      "2. 当处理大规模实时数据时，Kafka 如何保证数据处理的准确性和低延迟？是否遇到过性能瓶颈，如何优化的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Kafka/为什么要使用消息队列 .md",
    "code_examples": []
  },
  {
    "id": "go-interview_为什么要使用消息队列 _011",
    "text": "**Kafka 优势**：Kafka 提供了多订阅模式，同一条消息可以被多个消费者组消费，而不会互相影响。每个消费者组都可以独立消费相同的消息流。",
    "answer": "**Kafka 优势**：Kafka 提供了多订阅模式，同一条消息可以被多个消费者组消费，而不会互相影响。每个消费者组都可以独立消费相同的消息流。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "多订阅模式",
      "消费者组",
      "消息复用",
      "消费隔离",
      "独立消费"
    ],
    "followup_points": [
      "1. 在多订阅模式下，如果某个消费者组消费速度较慢，会对其他消费者组的消费性能产生影响吗？为什么？",
      "2. Kafka 如何保证不同消费者组之间的消费隔离性？具体是通过哪些机制实现的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Kafka/为什么要使用消息队列 .md",
    "code_examples": []
  },
  {
    "id": "go-interview_为什么要使用消息队列 _012",
    "text": "系统中的某些任务（如图片处理、数据转换）可能耗时较长，直接执行会占用资源。如果使用消息队列，将这些任务推迟到后台处理，可以大幅提升前端系统的性能。",
    "answer": "系统中的某些任务（如图片处理、数据转换）可能耗时较长，直接执行会占用资源。如果使用消息队列，将这些任务推迟到后台处理，可以大幅提升前端系统的性能。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "消息队列",
      "异步处理",
      "后台任务",
      "系统性能优化",
      "资源占用"
    ],
    "followup_points": [
      "1. 在选择消息队列时，主要考虑了哪些关键因素（如吞吐量、延迟、可靠性、社区支持等），这些因素如何影响最终的技术选型？",
      "2. 消息队列引入后，如何确保任务处理的顺序性和幂等性，特别是在高并发或任务失败的场景下？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Kafka/为什么要使用消息队列 .md",
    "code_examples": []
  },
  {
    "id": "go-interview_为什么要使用消息队列 _013",
    "text": "**Kafka 优势**：Kafka 支持高并发的消息处理能力，多个消费者可以同时并发处理多个分区中的消息，从而极大提高了系统的处理能力。",
    "answer": "**Kafka 优势**：Kafka 支持高并发的消息处理能力，多个消费者可以同时并发处理多个分区中的消息，从而极大提高了系统的处理能力。",
    "category": "system-design",
    "difficulty": 1,
    "tags": [
      "高并发",
      "消息处理",
      "消费者",
      "分区",
      "吞吐量"
    ],
    "followup_points": [
      "1. Kafka 是如何通过分区机制实现多个消费者的并发处理的？分区数量与消费者数量之间存在怎样的关系？",
      "2. 在高并发场景下，Kafka 如何保证消息的顺序性和一致性？如果消费者处理能力不足，会对系统产生哪些影响？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Kafka/为什么要使用消息队列 .md",
    "code_examples": []
  },
  {
    "id": "go-interview_消费者策略、Rebalance机制、Offset存储机制_001",
    "text": "2. Rebalance 机制",
    "answer": "Rebalance 是 Kafka 消费者组中的一个动态分区分配过程。它在以下场景中会被触发： - 消费者组中的消费者数量发生变化（新增或移除消费者）。 - `Topic` 的分区数变化（增加分区）。 - 由于消费者崩溃或超时，Kafka 需要重新分配 `Partition`。 # 1. 当 Kafka 检测到消费者组变化或分区变化时，消费者组中的所有消费者会被暂停消息消费。 2. Kafka 会根据分配策略（如 Range、RoundRobin 等）重新分配每个消费者所对应的 `Partition`。 3. 消费者组内的所有消费者获得新的分配后，会继续消费消息。 # - Rebalance 过程会导致一段时间的消费暂停（短暂的不可用），因为消费者需要等待新的分配完成后再恢复消费。这种现象被称为 **消费中断**。 - Rebalance 频繁发生时，会影响消费性能，因此在实际生产中，尽量减少不必要的 Rebalance 是优化 Kafka 消费者组的重点。 ---",
    "category": "system",
    "difficulty": 3,
    "tags": [
      "Rebalance机制",
      "消费者组动态分区分配",
      "分区分配策略",
      "消费者数量变化",
      "分区数变化"
    ],
    "followup_points": [
      "1. 在 Rebalance 过程中，消费者被暂停消息消费时，如何确保消息消费的连续性，避免数据丢失或重复消费？",
      "2. Kafka 提供了哪些分配策略（如 Range、RoundRobin），这些策略在什么场景下更适用，各自有什么优缺点？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Kafka/消费者策略、Rebalance机制、Offset存储机制.md",
    "code_examples": []
  },
  {
    "id": "go-interview_消费者策略、Rebalance机制、Offset存储机制_002",
    "text": "3. Offset 存储机制",
    "answer": "Kafka 使用偏移量（Offset）来跟踪每个消费者组在 `Topic` 中消费的进度。Offset 是每条消息在 `Partition` 中的唯一标识符，消费者通过保存 Offset 来实现精确的消息追踪和重放。 # Kafka 提供了多种方式来存储消费者的 Offset： ## - 默认情况下，Kafka 将消费者的 Offset 存储在内置的 `__consumer_offsets` 主题中，这是一种基于 Kafka 自身存储的方式。 - 通过定期提交（Commit）当前消费的 Offset，消费者可以确保在重新启动或发生故障后从上次提交的 Offset 开始消费。 - Offset 提交可以是手动或自动： - **自动提交（enable.auto.commit=true）**：Kafka 会定期自动提交当前消费者的 Offset，默认每 5 秒提交一次。 - **手动提交**：开发者可以控制在处理完一批消息或确保消息成功处理后手动提交 Offset，防止消息重复消费。 ## - 除了 Kafka 自身存储 Offset，用户也可以选择将 Offset 存储在外部系统（如数据库、ZooKeeper 等）中，以满足某些特殊的场景需求。 # - **同步提交**：消费者同步提交 Offset，确保提交成功后才继续消费。这种方式能保证每条消息的处理状态被确认，但会增加延迟。 - **异步提交**：Offset 提交不会阻塞消费者的消费流程，可以提高性能，但存在提交失败的风险。 # Kafka 提供了配置项用于处理消费过程中遇到的 Offset 异常情况（如 Offset 丢失或超过保留时间），常用的配置包括： - **auto.offset.reset**：当消费者请求的 Offset 在 Broker 上不存在（如被删除）时，Kafka 允许自动重置 Offset： - `latest`：从分区的最后一个 Offset 开始消费。 - `earliest`：从分区的第一个 Offset 开始消费。 ---",
    "category": "system",
    "difficulty": 3,
    "tags": [
      "Kafka Offset",
      "消费者组",
      "消息追踪",
      "Offset 提交",
      "__consumer_offsets 主题"
    ],
    "followup_points": [
      "1. Kafka 将 Offset 存储在 `__consumer_offsets` 主题中时，该主题的分区策略和副本机制是如何设计的，以确保高可用性和一致性？",
      "2. 在消费者定期提交 Offset 的过程中，如果提交失败（如网络问题或 Broker 宕机），Kafka 如何处理 Offset 的不一致问题，以及如何避免消息重复消费或丢失？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Kafka/消费者策略、Rebalance机制、Offset存储机制.md",
    "code_examples": []
  },
  {
    "id": "go-interview_架构原理及存储机制_000",
    "text": "Kafka 架构原理",
    "answer": "Kafka 的架构由以下几个核心组件组成： # - **Broker** 是 Kafka 的服务器实例，负责接收、存储和传输消息。Kafka 集群由一个或多个 Broker 组成，通常每个 Broker 是一个独立的物理或虚拟服务器。 - 每个 Broker 都可以存储多个 `Topic` 的数据，并为这些数据提供读取服务。Kafka 的分布式特性允许将数据分布在不同的 Broker 上，以实现水平扩展。 # - **Producer** 是消息的发送者，负责将数据发布到 Kafka 中的 `Topic`。 - Producer 可以指定消息发送到某个 `Partition`，也可以通过轮询或基于特定规则（如基于键的哈希值）来选择 Partition。 # - **Consumer** 是消息的读取者，负责从 Kafka 的 `Topic` 中订阅并读取消息。 - Consumer 组的概念允许多个 Consumer 实例组成一个组，来平衡消费不同 `Partition` 的消息。 # - **Topic** 是 Kafka 中消息的分类单位，类似于数据库中的表。每个 `Topic` 可以有多个 `Partition`，而 `Partition` 是 Kafka 的并行处理单位。 - 每个 `Partition` 是一个有序的、不可变的日志文件，每条消息在 `Partition` 中都有一个唯一的偏移量（offset）。`Partition` 保证了顺序性，而不同 `Partition` 之间可以并行处理。 # - Kafka 使用 **Zookeeper** 来管理集群元数据、协调 Broker 和维护 `Partition` 的 Leader 选举过程。 - 新的 Kafka 版本可以使用 Raft 协议来替代 Zookeeper，用于集群控制和选举 Leader。 # - 每个 `Partition` 都有一个 **Leader**，负责处理所有的读写请求。其他副本称为 **Follower**，它们从 Leader 同步数据。 - 当 Leader 宕机时，Kafka 会自动从 Follower 中选举新的 Leader，以保证高可用性。 ---",
    "category": "system-design",
    "difficulty": 3,
    "tags": [
      "Broker",
      "Producer",
      "Topic",
      "Partition",
      "分布式架构"
    ],
    "followup_points": [
      "1. Kafka 的副本机制（Replication）是如何保证数据高可用的？如果 Leader 副本宕机，选举过程是怎样的？",
      "2. Kafka 的分区（Partition）策略如何影响消息的顺序性和消费并行度？如果某个分区的消息量过大，会导致什么问题？如何优化？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Kafka/架构原理及存储机制.md",
    "code_examples": []
  },
  {
    "id": "go-interview_架构原理及存储机制_001",
    "text": "Kafka 的存储机制",
    "answer": "Kafka 的存储机制主要围绕 **日志（Log）** 文件来实现数据的高效存储和读取。每个 `Partition` 被存储为一个 **日志文件**，消息按照追加写的方式存储到日志中。 # Kafka 的消息被顺序写入磁盘，并通过分区日志进行管理。每个 `Partition` 都对应一个日志文件，Kafka 将消息追加到日志的末尾。这种顺序写磁盘的方式非常高效，因为现代操作系统针对顺序 I/O 进行了优化。 # - 每个 `Partition` 日志文件会进一步被分为多个 **Segment**。Segment 是物理上日志文件的一部分，当一个 Segment 达到预定大小或时间限制时，Kafka 会关闭这个 Segment 并开始写入下一个。 - 这种分段存储的方式使得 Kafka 在删除旧消息时不需要修改文件，只需要删除老的 Segment 文件即可。 # Kafka 允许配置消息的保留策略： - **基于时间保留**：可以配置 Kafka 将超过设定时间的消息删除，例如保留 7 天的数据。 - **基于大小保留**：可以根据每个 `Partition` 日志文件的大小来设置消息保留，超过设定大小后，删除最早的 Segment。 Kafka 的消息保留策略使其不仅适用于实时消息处理，还能够持久化消息，允许消费者在需要时重新读取过去的消息。 # - Kafka 提供 **日志压缩** 机制，用于永久保留最新版本的每个消息键。对于相同键的消息，Kafka 只保留最新的消息，删除较旧的版本。日志压缩适用于需要更新或保存最新状态的场景。 - 与保留策略不同，日志压缩不会完全删除旧数据，而是保留最新的键值对。 # - **顺序写入**：Kafka 的消息写入是顺序追加的，这种方式比随机写入更加高效，特别是在磁盘 I/O 上。 - **顺序读取**：消费者读取 Kafka 消息时，Kafka 通过消息的偏移量（offset）提供高效的顺序读取机制。消费者通过指定偏移量可以精确地控制从哪里开始读取消息。 # - Kafka 在数据传输过程中利用了 **零拷贝技术**，即数据在内存和网络之间的传输不经过 CPU 的数据拷贝，从而减少了 CPU 和内存的开销，极大提高了数据传输效率。这种技术在生产者发送消息、Broker 转发消息以及消费者消费消息时都能发挥作用。 ---",
    "category": "system",
    "difficulty": 3,
    "tags": [
      "日志文件",
      "分区",
      "顺序写磁盘",
      "Segment",
      "追加写"
    ],
    "followup_points": [
      "1. Kafka 中 Segment 文件的具体命名规则是什么？Segment 文件的大小和过期时间是如何配置的？",
      "2. Kafka 如何通过偏移量（Offset）管理消息的读取和删除？Segment 文件的清理机制是怎样的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Kafka/架构原理及存储机制.md",
    "code_examples": []
  },
  {
    "id": "go-interview_Md5过程_000",
    "text": "**填充**：输入消息会被填充，以确保其长度是512位的倍数。填充方式是在消息末尾添加一个'1'位，然后添加零。",
    "answer": "**填充**：输入消息会被填充，以确保其长度是512位的倍数。填充方式是在消息末尾添加一个'1'位，然后添加零。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "消息填充",
      "长度扩展",
      "512位倍数",
      "位填充",
      "'1'位填充"
    ],
    "followup_points": [
      "1. 填充的具体长度是如何确定的？是否需要考虑消息原始长度与512位倍数之间的差值？",
      "2. 如果消息长度已经是512位的倍数，是否还需要进行填充？如果需要，填充的具体规则是什么？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/Md5过程.md",
    "code_examples": []
  },
  {
    "id": "go-interview_Md5过程_001",
    "text": "**处理**：填充后的消息会被分成512位的块进行处理，通过一系列的位操作、模加法和常量异或操作。这些操作会重复进行4轮。",
    "answer": "**处理**：填充后的消息会被分成512位的块进行处理，通过一系列的位操作、模加法和常量异或操作。这些操作会重复进行4轮。",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "消息分块",
      "位操作",
      "模加法",
      "常量异或",
      "轮函数"
    ],
    "followup_points": [
      "1. 在这4轮处理中，每一轮的具体操作步骤和作用是什么？",
      "2. 这些位操作、模加法和常量异或操作分别针对消息块的哪些部分，以及它们如何共同确保哈希的安全性？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/Md5过程.md",
    "code_examples": []
  },
  {
    "id": "go-interview_Md5过程_002",
    "text": "**输出**：最终结果是一个128位（16字节）的哈希值，通常以32位的十六进制数表示。",
    "answer": "**输出**：最终结果是一个128位（16字节）的哈希值，通常以32位的十六进制数表示。 MD5广泛用于校验和和数据完整性验证，但由于存在允许碰撞攻击的漏洞，不建议在需要高安全性的加密场景中使用。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "哈希算法",
      "MD5",
      "数据完整性",
      "碰撞攻击",
      "输出长度"
    ],
    "followup_points": [
      "1. 在MD5的碰撞攻击中，攻击者具体是如何构造出两个不同输入产生相同哈希值的？",
      "2. 除了MD5，目前有哪些主流的哈希算法（如SHA-256、SHA-3）被推荐用于高安全性场景，它们与MD5的核心区别是什么？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/Md5过程.md",
    "code_examples": []
  },
  {
    "id": "go-interview_rpc实现原理_000",
    "text": "**序列化**：将客户端传入的参数序列化为可以通过网络传输的格式，如JSON、XML、Protobuf等。",
    "answer": "**序列化**：将客户端传入的参数序列化为可以通过网络传输的格式，如JSON、XML、Protobuf等。",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "序列化",
      "网络传输",
      "JSON",
      "XML",
      "Protobuf"
    ],
    "followup_points": [
      "1. 在选择序列化格式（如JSON、XML、Protobuf）时，通常会考虑哪些关键因素？",
      "2. 序列化和反序列化过程中，如何处理数据类型不匹配或字段缺失的情况？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/rpc实现原理.md",
    "code_examples": []
  },
  {
    "id": "go-interview_rpc实现原理_001",
    "text": "**请求封装**：将序列化后的参数封装成请求消息，并添加元数据（如方法名、超时设置、身份验证信息等）。",
    "answer": "**请求封装**：将序列化后的参数封装成请求消息，并添加元数据（如方法名、超时设置、身份验证信息等）。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "序列化",
      "请求封装",
      "元数据",
      "方法名",
      "超时设置"
    ],
    "followup_points": [
      "1. 在请求封装过程中，如何处理序列化后的参数与元数据的冲突或优先级问题？",
      "2. 对于不同的通信协议（如HTTP、gRPC、WebSocket），请求封装的实现方式会有哪些差异？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/rpc实现原理.md",
    "code_examples": []
  },
  {
    "id": "go-interview_rpc实现原理_002",
    "text": "**gRPC**：基于HTTP/2的高性能RPC框架，支持多种语言，默认使用Protobuf作为序列化协议。",
    "answer": "**gRPC**：基于HTTP/2的高性能RPC框架，支持多种语言，默认使用Protobuf作为序列化协议。",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "gRPC",
      "HTTP/2",
      "RPC框架",
      "多语言支持",
      "Protobuf"
    ],
    "followup_points": [
      "1. gRPC相比传统的REST API有哪些具体的性能优势？这些优势在实际应用场景中如何体现？",
      "2. gRPC的流式通信（如Unary、Server Streaming、Client Streaming、Bidirectional Streaming）分别适用于哪些业务场景？能否举例说明？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/rpc实现原理.md",
    "code_examples": []
  },
  {
    "id": "go-interview_rpc实现原理_003",
    "text": "**服务注册**：服务启动时，将自己的地址（如IP和端口）注册到服务注册中心（如Zookeeper、Consul、Eureka）。",
    "answer": "**服务注册**：服务启动时，将自己的地址（如IP和端口）注册到服务注册中心（如Zookeeper、Consul、Eureka）。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "服务注册",
      "服务发现",
      "注册中心",
      "微服务架构",
      "Zookeeper/Consul/Eureka"
    ],
    "followup_points": [
      "1. 服务注册过程中，如果注册中心不可用，服务启动时会有什么处理机制？比如是否支持重试、降级或本地缓存？",
      "2. 服务注册时，除了IP和端口，通常会携带哪些元数据信息（如服务名、版本、健康状态等），这些元数据如何被其他服务或治理工具使用？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/rpc实现原理.md",
    "code_examples": []
  },
  {
    "id": "go-interview_rpc实现原理_004",
    "text": "**服务发现**：客户端在调用服务之前，从注册中心获取可用服务实例的地址列表，并根据策略选择一个实例进行调用。",
    "answer": "**服务发现**：客户端在调用服务之前，从注册中心获取可用服务实例的地址列表，并根据策略选择一个实例进行调用。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "服务发现",
      "注册中心",
      "客户端负载均衡",
      "服务实例地址列表",
      "调用策略"
    ],
    "followup_points": [
      "1. 在服务发现过程中，如果注册中心返回的地址列表中存在不可用实例，客户端是如何处理的？",
      "2. 客户端在选择服务实例时，常用的负载均衡策略有哪些？这些策略的适用场景是什么？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/rpc实现原理.md",
    "code_examples": []
  },
  {
    "id": "go-interview_rpc实现原理_005",
    "text": "**熔断机制**：当某个服务的失败率超过一定阈值时，停止对其的调用一段时间，以保护系统其他部分不受影响。",
    "answer": "**熔断机制**：当某个服务的失败率超过一定阈值时，停止对其的调用一段时间，以保护系统其他部分不受影响。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "熔断机制",
      "服务降级",
      "失败率阈值",
      "系统保护",
      "容错设计"
    ],
    "followup_points": [
      "1. 熔断机制在触发后，如何确定恢复调用的时机？是直接恢复还是采用半开状态逐步尝试？",
      "2. 熔断机制中的“失败率”具体是如何计算的？是仅指HTTP错误码，还是包括超时、异常等场景？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/rpc实现原理.md",
    "code_examples": []
  },
  {
    "id": "go-interview_rpc实现原理_006",
    "text": "**TCC（Try-Confirm-Cancel）**：分为尝试、确认和取消三个阶段，确保业务操作的一致性。",
    "answer": "**TCC（Try-Confirm-Cancel）**：分为尝试、确认和取消三个阶段，确保业务操作的一致性。",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "分布式事务",
      "TCC模式",
      "业务一致性",
      "三阶段操作",
      "事务补偿"
    ],
    "followup_points": [
      "1. 在TCC模式中，如果Confirm阶段失败，系统通常会采用哪些重试机制或补偿策略来确保最终一致性？",
      "2. TCC模式中的Try阶段需要预留资源，这种预留机制在实际业务中可能面临哪些并发问题，以及如何解决？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/rpc实现原理.md",
    "code_examples": []
  },
  {
    "id": "go-interview_常见的乐观锁实现方式有几种_000",
    "text": "**原理**：每个数据项都有一个版本号或时间戳，操作时读取数据项及其版本号。提交时检查数据项的版本号是否已改变，如果没有改变，则更新数据项并增加版本号；如果版本号已改变，则操作失败，需要重新尝试。",
    "answer": "**原理**：每个数据项都有一个版本号或时间戳，操作时读取数据项及其版本号。提交时检查数据项的版本号是否已改变，如果没有改变，则更新数据项并增加版本号；如果版本号已改变，则操作失败，需要重新尝试。",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "乐观锁",
      "版本控制",
      "CAS (Compare-And-Swap)",
      "时间戳",
      "重试机制"
    ],
    "followup_points": [
      "1. 在高并发场景下，如果多个操作同时读取到相同的版本号，如何确保操作的原子性和一致性？",
      "2. 版本号或时间戳的存储和更新机制是如何实现的？是否需要额外的锁机制或分布式协调？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/常见的乐观锁实现方式有几种.md",
    "code_examples": []
  },
  {
    "id": "go-interview_常见的乐观锁实现方式有几种_001",
    "text": "**原理**：每个数据项有一个时间戳，操作时读取数据项及其时间戳。提交时检查数据项的时间戳是否在操作期间没有被修改过。如果时间戳匹配，则更新数据项和时间戳；如果时间戳不匹配，则操作失败，需要重新尝试。",
    "answer": "**原理**：每个数据项有一个时间戳，操作时读取数据项及其时间戳。提交时检查数据项的时间戳是否在操作期间没有被修改过。如果时间戳匹配，则更新数据项和时间戳；如果时间戳不匹配，则操作失败，需要重新尝试。",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "乐观锁",
      "时间戳",
      "CAS (Compare-And-Swap)",
      "并发控制",
      "重试机制"
    ],
    "followup_points": [
      "1. 如果操作期间时间戳不匹配导致失败，系统如何确保数据的一致性，避免脏读或不可重复读的问题？",
      "2. 在高并发场景下，频繁的时间戳冲突和重试可能影响性能，是否有优化策略（如乐观锁的退避机制或批量处理）来减少冲突概率？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/常见的乐观锁实现方式有几种.md",
    "code_examples": []
  },
  {
    "id": "go-interview_常见的乐观锁实现方式有几种_002",
    "text": "**原理**：CAS是基于硬件的原子操作，它比较内存中的值与预期值是否相等。如果相等，则将内存中的值更新为新值。CAS操作在并发环境下确保只有一个线程能成功更新数据项。",
    "answer": "**原理**：CAS是基于硬件的原子操作，它比较内存中的值与预期值是否相等。如果相等，则将内存中的值更新为新值。CAS操作在并发环境下确保只有一个线程能成功更新数据项。",
    "category": "system",
    "difficulty": 3,
    "tags": [
      "并发编程",
      "原子操作",
      "CAS",
      "乐观锁",
      "硬件指令"
    ],
    "followup_points": [
      "1. CAS操作在硬件层面是如何保证原子性的，具体是通过CPU的什么指令实现的？",
      "2. 在高并发场景下，CAS可能存在ABA问题，有哪些常见的解决方案来应对这个问题？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/常见的乐观锁实现方式有几种.md",
    "code_examples": []
  },
  {
    "id": "go-interview_常见的乐观锁实现方式有几种_003",
    "text": "**原理**：在一些复杂的系统中，可以将乐观锁和悲观锁结合使用。例如，在数据读取时使用乐观锁，而在写操作时使用悲观锁来确保数据一致性。",
    "answer": "**原理**：在一些复杂的系统中，可以将乐观锁和悲观锁结合使用。例如，在数据读取时使用乐观锁，而在写操作时使用悲观锁来确保数据一致性。",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "乐观锁",
      "悲观锁",
      "数据一致性",
      "并发控制",
      "锁机制"
    ],
    "followup_points": [
      "1. 在结合使用乐观锁和悲观锁时，如何避免因锁粒度不当导致的性能瓶颈？",
      "2. 当乐观锁版本号冲突时，系统如何选择重试策略或通知业务层处理冲突？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/常见的乐观锁实现方式有几种.md",
    "code_examples": []
  },
  {
    "id": "go-interview_常见的乐观锁实现方式有几种_004",
    "text": "**乐观锁与悲观锁结合**和**事务日志**适用于更复杂的场景，结合了乐观锁的高效性和悲观锁的安全性。",
    "answer": "**乐观锁与悲观锁结合**和**事务日志**适用于更复杂的场景，结合了乐观锁的高效性和悲观锁的安全性。",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "乐观锁",
      "悲观锁",
      "事务日志",
      "并发控制",
      "数据一致性"
    ],
    "followup_points": [
      "1. 在乐观锁与悲观锁结合的场景中，如何确定哪些操作适合用乐观锁，哪些适合用悲观锁？是否有具体的判断标准或策略？",
      "2. 事务日志在结合乐观锁和悲观锁时，如何保证日志记录的完整性和一致性？是否需要额外的机制来处理日志与锁状态同步的问题？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/常见的乐观锁实现方式有几种.md",
    "code_examples": []
  },
  {
    "id": "go-interview_通过分析系统，定位服务器问题_003",
    "text": "**`vmstat` 命令**：",
    "answer": "- **`b` 阻塞进程数**：过多的阻塞进程表明系统等待I/O资源。 - **`si` 和 `so`**：如果 `si`（每秒从磁盘读入虚拟内存的大小） 和 `so`（每秒虚拟内存写入磁盘的大小）值大于0，表明物理内存不足或存在内存泄露。 - **`bi` 和 `bo`**：表示块设备每秒接收和发送的块数量。如果 `bi` 或 `bo` 值很大，说明 I/O 操作过于频繁，需要进一步检查。 - **`cs` 上下文切换次数**：高频的上下文切换可能表明CPU资源被浪费在非生产性的任务上。",
    "category": "system",
    "difficulty": 2,
    "tags": [
      "vmstat",
      "系统监控",
      "I/O性能",
      "内存管理",
      "CPU性能"
    ],
    "followup_points": [
      "1. 当 `si` 和 `so` 值持续大于0时，除了检查物理内存不足或内存泄露，还有哪些具体排查步骤可以定位问题根源？",
      "2. 如果 `cs`（上下文切换次数）频繁，如何结合其他工具（如 `pidstat` 或 `top`）进一步分析是哪些进程导致的上下文切换过高？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/通过分析系统，定位服务器问题.md",
    "code_examples": []
  },
  {
    "id": "go-interview_通过分析系统，定位服务器问题_005",
    "text": "**网络连接分析**：",
    "answer": "- 使用 `netstat` 或 `ss` 命令查看当前系统的网络连接，尤其是大量的 `TIME_WAIT` 状态，可能表示连接管理不当。",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "netstat",
      "ss",
      "网络连接",
      "TIME_WAIT状态",
      "连接管理"
    ],
    "followup_points": [
      "1. 当发现大量 `TIME_WAIT` 状态的连接时，你会如何进一步排查是应用程序问题还是系统配置问题？",
      "2. 除了 `TIME_WAIT` 状态，还有哪些网络连接状态（如 `CLOSE_WAIT`、`ESTABLISHED`）需要重点关注，它们通常可能反映什么问题？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/通过分析系统，定位服务器问题.md",
    "code_examples": []
  },
  {
    "id": "go-interview_通过分析系统，定位服务器问题_006",
    "text": "**性能测试和压测**：",
    "answer": "- 使用工具如 `ab`（ApacheBench）或 `wrk` 来模拟高并发访问，分析系统的响应时间和稳定性。",
    "category": "system-design",
    "difficulty": 3,
    "tags": [
      "性能测试",
      "压测",
      "高并发",
      "响应时间",
      "稳定性"
    ],
    "followup_points": [
      "1. 在使用 `ab` 或 `wrk` 进行压测时，如何确定合适的并发数和请求持续时间？",
      "2. 压测过程中，除了响应时间和稳定性，还会关注哪些关键指标（如错误率、吞吐量、资源利用率）？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/通过分析系统，定位服务器问题.md",
    "code_examples": []
  },
  {
    "id": "go-interview_Linux系统态与用户态_000",
    "text": "在 Linux 操作系统中，系统态（Kernel Mode）和用户态（User Mode）是操作系统中两个重要的运行模式。这两种模式主要是为了保护系统资源的安全性和稳定性，并提高操作系统的可靠性。以下是它们的区别和各自的特点：",
    "answer": "在 Linux 操作系统中，系统态（Kernel Mode）和用户态（User Mode）是操作系统中两个重要的运行模式。这两种模式主要是为了保护系统资源的安全性和稳定性，并提高操作系统的可靠性。以下是它们的区别和各自的特点：",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "操作系统内核",
      "用户态与系统态",
      "系统资源保护",
      "CPU特权级",
      "内存管理"
    ],
    "followup_points": [
      "1. 在 Linux 中，系统调用（System Call）是如何从用户态切换到系统态的？请描述其具体过程和涉及的机制。",
      "2. 如果用户态程序试图直接访问受保护的内存区域（如内核空间），操作系统会采取哪些措施来防止这种情况发生？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/Linux系统态与用户态.md",
    "code_examples": []
  },
  {
    "id": "go-interview_网络io模型_000",
    "text": "**工作原理**：当应用程序发出 I/O 请求后，整个进程会被阻塞，直到数据准备好并完成 I/O 操作，才会返回继续执行。",
    "answer": "**工作原理**：当应用程序发出 I/O 请求后，整个进程会被阻塞，直到数据准备好并完成 I/O 操作，才会返回继续执行。",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "I/O阻塞",
      "进程阻塞",
      "同步I/O",
      "数据准备",
      "I/O操作"
    ],
    "followup_points": [
      "1. 在阻塞I/O模型中，当进程被阻塞时，操作系统是如何管理该进程的状态和资源的？",
      "2. 如果多个线程或进程同时发起阻塞I/O请求，操作系统如何处理这些请求的排队和调度？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/网络io模型.md",
    "code_examples": []
  },
  {
    "id": "go-interview_网络io模型_001",
    "text": "**工作原理**：应用程序发出 I/O 请求后，如果数据未准备好，不会阻塞进程，而是立即返回一个状态值，应用程序可以继续做其他事情，稍后再重复检查数据是否准备好。",
    "answer": "**工作原理**：应用程序发出 I/O 请求后，如果数据未准备好，不会阻塞进程，而是立即返回一个状态值，应用程序可以继续做其他事情，稍后再重复检查数据是否准备好。",
    "category": "system",
    "difficulty": 2,
    "tags": [
      "I/O多路复用",
      "非阻塞I/O",
      "轮询",
      "事件驱动",
      "同步I/O"
    ],
    "followup_points": [
      "1. 应用程序如何高效地“重复检查”数据是否准备好？是否有特定的轮询机制或事件通知方式（如select/poll/epoll）？",
      "2. 这种非阻塞I/O模式相比阻塞I/O，在哪些场景下优势更明显？是否存在潜在的性能瓶颈或适用限制？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/网络io模型.md",
    "code_examples": []
  },
  {
    "id": "go-interview_网络io模型_002",
    "text": "**缺点**：通常需要反复检查数据是否准备好，导致 \"忙轮询\"（Busy Polling），可能浪费 CPU 资源。",
    "answer": "**缺点**：通常需要反复检查数据是否准备好，导致 \"忙轮询\"（Busy Polling），可能浪费 CPU 资源。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "忙轮询",
      "CPU资源浪费",
      "数据准备检查",
      "轮询机制",
      "效率问题"
    ],
    "followup_points": [
      "1. 在实际项目中，你是如何判断和量化 \"忙轮询\" 带来的 CPU 资源浪费的具体影响？",
      "2. 除了忙轮询，还有哪些常见的 I/O 模式（如中断驱动、事件驱动）可以优化这个问题，各自的适用场景是什么？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/网络io模型.md",
    "code_examples": []
  },
  {
    "id": "go-interview_网络io模型_003",
    "text": "**工作原理**：使用 `select`、`poll` 或 `epoll` 等系统调用，允许一个进程监控多个文件描述符，一旦其中的某个或多个文件描述符准备好进行 I/O 操作，应用程序才会被通知，从而进行相应的处理。",
    "answer": "**工作原理**：使用 `select`、`poll` 或 `epoll` 等系统调用，允许一个进程监控多个文件描述符，一旦其中的某个或多个文件描述符准备好进行 I/O 操作，应用程序才会被通知，从而进行相应的处理。",
    "category": "system",
    "difficulty": 3,
    "tags": [
      "I/O多路复用",
      "select",
      "poll",
      "epoll",
      "文件描述符"
    ],
    "followup_points": [
      "1. 在 `select`、`poll` 和 `epoll` 中，`epoll` 相比前两者有哪些核心优势，尤其是在高并发场景下？",
      "2. 当使用 `epoll` 时，`ET`（边缘触发）和 `LT`（水平触发）模式的工作机制和适用场景有什么区别？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/网络io模型.md",
    "code_examples": []
  },
  {
    "id": "go-interview_网络io模型_004",
    "text": "**缺点**：`select` 和 `poll` 的效率在监控大量文件描述符时会下降；`epoll` 在 Linux 上优化了这一问题。",
    "answer": "**缺点**：`select` 和 `poll` 的效率在监控大量文件描述符时会下降；`epoll` 在 Linux 上优化了这一问题。",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "select",
      "poll",
      "epoll",
      "文件描述符",
      "I/O多路复用"
    ],
    "followup_points": [
      "1. 能否具体说明 `select` 和 `poll` 在监控大量文件描述符时效率下降的具体原因？",
      "2. `epoll` 是通过哪些机制（如 `LT`/`ET` 模式、红黑树等）优化这一问题的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/网络io模型.md",
    "code_examples": []
  },
  {
    "id": "go-interview_网络io模型_005",
    "text": "**工作原理**：应用程序向内核注册一个信号，当 I/O 设备准备好时，内核会发送一个信号通知应用程序进行 I/O 操作。",
    "answer": "**工作原理**：应用程序向内核注册一个信号，当 I/O 设备准备好时，内核会发送一个信号通知应用程序进行 I/O 操作。",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "信号驱动 I/O",
      "I/O 多路复用",
      "异步 I/O",
      "内核通知机制",
      "信号处理"
    ],
    "followup_points": [
      "1. 应用程序如何向内核注册信号？需要调用哪些系统调用或函数？",
      "2. 内核发送信号后，应用程序如何捕获并处理该信号？是否需要特定的信号处理函数？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/网络io模型.md",
    "code_examples": []
  },
  {
    "id": "go-interview_网络io模型_006",
    "text": "**工作原理**：应用程序发出 I/O 请求后，立即返回并继续执行其他任务，内核在 I/O 操作完成后，通过回调函数或信号通知应用程序结果。",
    "answer": "**工作原理**：应用程序发出 I/O 请求后，立即返回并继续执行其他任务，内核在 I/O 操作完成后，通过回调函数或信号通知应用程序结果。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "I/O多路复用",
      "异步I/O",
      "回调机制",
      "非阻塞I/O",
      "事件驱动"
    ],
    "followup_points": [
      "1. 在异步 I/O 中，回调函数或信号通知的具体实现机制是什么？",
      "2. 如果应用程序在 I/O 操作完成前需要取消该请求，是否有相应的取消机制，如何处理？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/网络io模型.md",
    "code_examples": []
  },
  {
    "id": "go-interview_物理内存、虚拟内存和共享内存_000",
    "text": "**定义**：物理内存是计算机实际安装的 RAM（随机存取内存）。它是系统可以直接使用的内存，处理器可以直接访问它。",
    "answer": "**定义**：物理内存是计算机实际安装的 RAM（随机存取内存）。它是系统可以直接使用的内存，处理器可以直接访问它。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "物理内存",
      "RAM",
      "随机存取内存",
      "处理器访问",
      "系统直接使用"
    ],
    "followup_points": [
      "1. 物理内存和虚拟内存的主要区别是什么？它们是如何协同工作的？",
      "2. 如果物理内存不足，系统通常会采取哪些优化策略来保证程序运行？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/物理内存、虚拟内存和共享内存.md",
    "code_examples": []
  },
  {
    "id": "go-interview_物理内存、虚拟内存和共享内存_001",
    "text": "**在 `top` 中的表示**：`top` 命令中通常以 `RES`（Resident Memory）表示实际占用的物理内存量。",
    "answer": "**在 `top` 中的表示**：`top` 命令中通常以 `RES`（Resident Memory）表示实际占用的物理内存量。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "top命令",
      "RES",
      "物理内存",
      "内存监控",
      "进程资源"
    ],
    "followup_points": [
      "1. `top` 命令中的 `RES` 和 `SHR`（Shared Memory）有什么区别，它们分别代表什么含义？",
      "2. 在 `top` 命令中，`RES` 列的数值是否会动态变化，哪些操作可能导致其增加或减少？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/物理内存、虚拟内存和共享内存.md",
    "code_examples": []
  },
  {
    "id": "go-interview_物理内存、虚拟内存和共享内存_002",
    "text": "**定义**：虚拟内存是操作系统创建的一种内存抽象，允许程序使用的地址空间比实际物理内存大。虚拟内存包括物理内存和磁盘上的交换空间（如交换文件或页面文件）的结合。",
    "answer": "**定义**：虚拟内存是操作系统创建的一种内存抽象，允许程序使用的地址空间比实际物理内存大。虚拟内存包括物理内存和磁盘上的交换空间（如交换文件或页面文件）的结合。",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "虚拟内存",
      "内存抽象",
      "地址空间",
      "物理内存",
      "交换空间"
    ],
    "followup_points": [
      "1. 虚拟内存是如何实现地址空间比物理内存大的？具体使用了哪些技术（如分页、分段）？",
      "2. 当程序访问的虚拟内存不在物理内存中时（缺页中断），操作系统是如何处理的？请描述完整的流程。"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/物理内存、虚拟内存和共享内存.md",
    "code_examples": []
  },
  {
    "id": "go-interview_物理内存、虚拟内存和共享内存_003",
    "text": "**作用**：虚拟内存使得程序可以使用比实际物理内存更多的内存空间，同时提供了内存保护和隔离。虚拟内存也使得程序可以运行在连续的内存空间中，即使物理内存碎片化。",
    "answer": "**作用**：虚拟内存使得程序可以使用比实际物理内存更多的内存空间，同时提供了内存保护和隔离。虚拟内存也使得程序可以运行在连续的内存空间中，即使物理内存碎片化。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "虚拟内存",
      "内存保护",
      "内存隔离",
      "内存连续性",
      "物理内存碎片化"
    ],
    "followup_points": [
      "1. 虚拟内存如何实现内存保护和隔离？具体是通过哪些机制（如页表、权限位）来防止一个进程访问另一个进程的内存空间？",
      "2. 当程序使用的虚拟内存空间超过物理内存时，操作系统如何通过页面置换算法（如LRU、FIFO）来管理内存的调入和调出？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/物理内存、虚拟内存和共享内存.md",
    "code_examples": []
  },
  {
    "id": "go-interview_物理内存、虚拟内存和共享内存_004",
    "text": "**在 `top` 中的表示**：`top` 命令中以 `VIRT`（Virtual Memory）表示程序使用的虚拟内存总量。",
    "answer": "**在 `top` 中的表示**：`top` 命令中以 `VIRT`（Virtual Memory）表示程序使用的虚拟内存总量。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "top命令",
      "虚拟内存",
      "VIRT",
      "内存管理",
      "进程监控"
    ],
    "followup_points": [
      "1. VIRT 包括哪些具体的内存组成部分，是否可以进一步细分说明？",
      "2. VIRT 和 RES（实际物理内存使用）之间有什么区别和关联？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/物理内存、虚拟内存和共享内存.md",
    "code_examples": []
  },
  {
    "id": "go-interview_物理内存、虚拟内存和共享内存_005",
    "text": "**定义**：共享内存是一种内存区域，可以被多个进程共享。共享内存允许进程之间高效地交换数据，因为多个进程可以访问相同的内存区域。",
    "answer": "**定义**：共享内存是一种内存区域，可以被多个进程共享。共享内存允许进程之间高效地交换数据，因为多个进程可以访问相同的内存区域。",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "共享内存",
      "进程间通信",
      "内存管理",
      "数据共享",
      "高效通信"
    ],
    "followup_points": [
      "1. 共享内存相比其他进程间通信方式（如管道、消息队列）有哪些具体的优势，特别是在性能和实时性方面？",
      "2. 在使用共享内存时，如何确保多个进程对共享数据的同步和互斥，以避免数据竞争或一致性问题？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/物理内存、虚拟内存和共享内存.md",
    "code_examples": []
  },
  {
    "id": "go-interview_物理内存、虚拟内存和共享内存_006",
    "text": "**作用**：共享内存常用于需要进程间通信（IPC）的场景，减少数据拷贝和提高性能。系统中的共享内存区域通常被用于实现高效的进程间通信。",
    "answer": "**作用**：共享内存常用于需要进程间通信（IPC）的场景，减少数据拷贝和提高性能。系统中的共享内存区域通常被用于实现高效的进程间通信。",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "进程间通信 (IPC)",
      "共享内存",
      "数据拷贝",
      "性能优化",
      "高效通信"
    ],
    "followup_points": [
      "1. 在多进程环境下，共享内存如何确保数据的一致性和同步性？",
      "2. 共享内存相比其他IPC机制（如管道、消息队列）有哪些优缺点，以及适用场景有何不同？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/物理内存、虚拟内存和共享内存.md",
    "code_examples": []
  },
  {
    "id": "go-interview_物理内存、虚拟内存和共享内存_007",
    "text": "**在 `top` 中的表示**：`top` 命令中以 `SHR`（Shared Memory）表示一个进程使用的共享内存量。",
    "answer": "**在 `top` 中的表示**：`top` 命令中以 `SHR`（Shared Memory）表示一个进程使用的共享内存量。",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "top命令",
      "共享内存",
      "SHR",
      "进程监控",
      "内存管理"
    ],
    "followup_points": [
      "1. 在 `top` 命令中，`SHR` 列显示的共享内存具体指的是哪些类型的共享内存（如 System V 共享内存、POSIX 共享内存等）？",
      "2. 如果一个进程使用了多种共享内存机制（如 `mmap` 的共享映射和 System V 共享内存），`SHR` 列的数值是如何计算和汇总的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/物理内存、虚拟内存和共享内存.md",
    "code_examples": []
  },
  {
    "id": "go-interview_物理内存、虚拟内存和共享内存_008",
    "text": "**VIRT (Virtual Memory)**：150,000 KB，表示进程使用的虚拟内存总量，包括物理内存和所有映射的文件、共享内存等。",
    "answer": "**VIRT (Virtual Memory)**：150,000 KB，表示进程使用的虚拟内存总量，包括物理内存和所有映射的文件、共享内存等。",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "虚拟内存",
      "进程内存",
      "物理内存",
      "文件映射",
      "共享内存"
    ],
    "followup_points": [
      "1. 在这个150,000 KB的虚拟内存总量中，实际占用的物理内存（RES/SIZE）和共享内存（SHR）分别是多少？它们的比例如何？",
      "2. 如果虚拟内存中包含大量映射的文件（如mmap的文件），这些文件是活跃使用的还是仅作为后备存储？是否有办法进一步优化这部分内存的使用？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/物理内存、虚拟内存和共享内存.md",
    "code_examples": []
  },
  {
    "id": "go-interview_物理内存、虚拟内存和共享内存_009",
    "text": "**RES (Resident Memory)**：30,000 KB，表示实际占用的物理内存量，不包括交换空间中的内容。",
    "answer": "**RES (Resident Memory)**：30,000 KB，表示实际占用的物理内存量，不包括交换空间中的内容。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "物理内存",
      "内存占用",
      "RES",
      "交换空间",
      "内存管理"
    ],
    "followup_points": [
      "1. RES值在进程生命周期中是否会动态变化？哪些操作会导致其显著增加或减少？",
      "2. 如果RES远大于进程实际需要的内存量，可能由哪些原因导致？如何排查优化？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/物理内存、虚拟内存和共享内存.md",
    "code_examples": []
  },
  {
    "id": "go-interview_物理内存、虚拟内存和共享内存_010",
    "text": "**SHR (Shared Memory)**：5,000 KB，表示进程所使用的共享内存量，这部分内存可能会被其他进程共享。",
    "answer": "**SHR (Shared Memory)**：5,000 KB，表示进程所使用的共享内存量，这部分内存可能会被其他进程共享。",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "共享内存",
      "进程间通信",
      "内存共享",
      "内存管理",
      "SHR"
    ],
    "followup_points": [
      "1. 这5,000 KB的共享内存具体是通过哪种机制（如System V共享内存、POSIX共享内存等）创建的？",
      "2. 这些共享内存是否被多个进程同时访问，是否存在并发访问的同步机制（如锁、信号量等）？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/物理内存、虚拟内存和共享内存.md",
    "code_examples": []
  },
  {
    "id": "go-interview_物理内存、虚拟内存和共享内存_011",
    "text": "**共享内存** 是多个进程可以共享的内存区域，用于进程间通信和数据共享。",
    "answer": "**共享内存** 是多个进程可以共享的内存区域，用于进程间通信和数据共享。 这些信息帮助我们理解系统资源的使用情况，并有助于进行性能分析和优化。",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "共享内存",
      "进程间通信",
      "数据共享",
      "系统资源",
      "性能优化"
    ],
    "followup_points": [
      "1. 在实际应用中，共享内存的同步机制是如何实现的，比如使用信号量或互斥锁来避免数据竞争？",
      "2. 共享内存相比其他进程间通信方式（如管道、消息队列）有哪些优缺点，分别在什么场景下更适合使用？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/物理内存、虚拟内存和共享内存.md",
    "code_examples": []
  },
  {
    "id": "go-interview_分布式id算法_000",
    "text": "**41位时间戳**：通常是从一个固定时间（Twitter的起始时间）开始计算的毫秒数，支持长达69年的时间跨度。",
    "answer": "**41位时间戳**：通常是从一个固定时间（Twitter的起始时间）开始计算的毫秒数，支持长达69年的时间跨度。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "分布式ID",
      "雪花算法",
      "时间戳",
      "毫秒精度",
      "时间跨度"
    ],
    "followup_points": [
      "1. 为什么选择41位时间戳而不是其他位数（如64位）来设计Twitter的时间戳？",
      "2. 在69年的时间跨度内，41位时间戳如何保证唯一性，尤其是在高并发场景下？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/分布式id算法.md",
    "code_examples": []
  },
  {
    "id": "go-interview_分布式id算法_001",
    "text": "**号段模式**：Leaf使用数据库来生成一段连续的ID范围，分配给不同的应用实例。每个实例拿到一个ID段后，在段内本地递增生成ID。生成完一个段后，再去数据库申请新的ID段。",
    "answer": "**号段模式**：Leaf使用数据库来生成一段连续的ID范围，分配给不同的应用实例。每个实例拿到一个ID段后，在段内本地递增生成ID。生成完一个段后，再去数据库申请新的ID段。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "号段模式",
      "数据库",
      "ID生成",
      "本地递增",
      "分布式ID"
    ],
    "followup_points": [
      "1. 在号段模式中，如果某个应用实例在生成完当前ID段后，短时间内频繁向数据库申请新的ID段，如何避免对数据库造成过大压力？",
      "2. 当Leaf服务重启或故障恢复时，如何确保未使用完的ID段能够被重新利用，避免ID重复生成或浪费？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/分布式id算法.md",
    "code_examples": []
  },
  {
    "id": "go-interview_分布式id算法_002",
    "text": "**Snowflake模式**：Leaf中直接实现了Twitter的Snowflake算法，按时间戳生成ID。",
    "answer": "**Snowflake模式**：Leaf中直接实现了Twitter的Snowflake算法，按时间戳生成ID。",
    "category": "algorithm",
    "difficulty": 2,
    "tags": [
      "Snowflake算法",
      "分布式ID生成",
      "时间戳",
      "Leaf",
      "Twitter"
    ],
    "followup_points": [
      "1. 在Leaf中实现Snowflake算法时，是如何处理时钟回拨问题的？",
      "2. Snowflake生成的ID在分布式环境下如何保证全局唯一性？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/分布式id算法.md",
    "code_examples": []
  },
  {
    "id": "go-interview_分布式id算法_003",
    "text": "**增加了容错机制：** 在时钟回拨时，UidGenerator会引入一定的容错策略，如阻塞等待、自动回滚。",
    "answer": "**增加了容错机制：** 在时钟回拨时，UidGenerator会引入一定的容错策略，如阻塞等待、自动回滚。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "时钟回拨",
      "容错机制",
      "阻塞等待",
      "自动回滚",
      "UidGenerator"
    ],
    "followup_points": [
      "1. 在时钟回拨场景下，阻塞等待和自动回滚这两种容错策略的具体触发条件和选择逻辑是什么？",
      "2. 阻塞等待策略的超时时间如何设置？如果长时间阻塞仍未解决时钟回拨问题，系统是否有兜底机制？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/分布式id算法.md",
    "code_examples": []
  },
  {
    "id": "go-interview_分布式id算法_004",
    "text": "如果需要有序ID并希望系统稳定，Snowflake 及其变种（如百度的 UidGenerator）则是常见选择。",
    "answer": "如果需要有序ID并希望系统稳定，Snowflake 及其变种（如百度的 UidGenerator）则是常见选择。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "Snowflake",
      "UidGenerator",
      "有序ID",
      "系统稳定",
      "ID生成"
    ],
    "followup_points": [
      "1. 在选择 Snowflake 或其变种时，如何根据业务场景的具体需求（如QPS、ID长度、机器数量等）来评估和选择最适合的方案？",
      "2. Snowflake 及其变种在分布式环境下，如何解决时钟回拨问题，并确保ID生成的稳定性和唯一性？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/分布式id算法.md",
    "code_examples": []
  },
  {
    "id": "go-interview_分布式id算法_005",
    "text": "对于有数据库或缓存支持的场景，可以考虑Leaf的号段模式或Redis的自增方式。",
    "answer": "对于有数据库或缓存支持的场景，可以考虑Leaf的号段模式或Redis的自增方式。 每种算法各有优劣，选择时需根据系统的性能需求、可扩展性和维护成本等方面进行权衡。",
    "category": "redis",
    "difficulty": 2,
    "tags": [
      "分布式ID生成",
      "Leaf号段模式",
      "Redis自增",
      "性能权衡",
      "可扩展性"
    ],
    "followup_points": [
      "1. 在Leaf的号段模式中，如果号段耗尽但数据库或缓存出现故障，系统有哪些容错机制来保证ID生成的连续性和可用性？",
      "2. Redis自增方式在高并发场景下可能面临哪些性能瓶颈（如网络延迟、Redis单线程限制等），是否有优化方案来提升其吞吐量？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/分布式id算法.md",
    "code_examples": []
  },
  {
    "id": "go-interview_互斥锁_000",
    "text": "### 面试中的常见问题",
    "answer": "1. **互斥锁与读写锁的区别？** - 互斥锁是独占锁，任何线程都不能同时访问资源。 - 读写锁允许多个线程同时读取，但写操作是独占的。",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "互斥锁",
      "读写锁",
      "线程同步",
      "锁机制",
      "并发控制"
    ],
    "followup_points": [
      "1. 在什么场景下会选择使用读写锁而不是互斥锁？",
      "2. 读写锁在写操作频繁时可能存在性能问题，如何优化或避免这种情况？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/互斥锁.md",
    "code_examples": []
  },
  {
    "id": "go-interview_抢占分布式锁时_000",
    "text": "结合这些策略，可以提高分布式锁的稳定性，减少因长时间执行而导致的锁过期问题。你想深入了解某个策略吗？",
    "answer": "结合这些策略，可以提高分布式锁的稳定性，减少因长时间执行而导致的锁过期问题。你想深入了解某个策略吗？",
    "category": "system-design",
    "difficulty": 3,
    "tags": [
      "分布式锁",
      "锁过期",
      "锁续期",
      "稳定性",
      "长时间任务"
    ],
    "followup_points": [
      "1. 在使用锁续约机制时，如何避免续约失败导致的锁提前释放问题？",
      "2. 对于长时间执行的任务，除了锁续约，还有哪些策略可以优化任务执行流程以减少锁持有时间？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Theory/抢占分布式锁时.md",
    "code_examples": []
  },
  {
    "id": "go-interview_基本数据类型，以及底层数据结构_001",
    "text": "**底层数据结构**：",
    "answer": "- **SDS（Simple Dynamic String）**：Redis 的字符串是基于 SDS 实现的动态字符串。 - 支持动态扩容，避免频繁的内存分配。 - 额外维护了字符串长度，支持高效的长度获取操作。",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "SDS",
      "动态字符串",
      "动态扩容",
      "内存分配",
      "长度维护"
    ],
    "followup_points": [
      "1. SDS 在扩容时是如何进行内存管理的？是否涉及内存碎片问题？",
      "2. SDS 与传统 C 字符串（以 `\\0` 结尾）相比，在哪些场景下能显著提升性能？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/基本数据类型，以及底层数据结构.md",
    "code_examples": []
  },
  {
    "id": "go-interview_基本数据类型，以及底层数据结构_002",
    "text": "**底层数据结构**：",
    "answer": "- **ZipList（压缩列表）**：当字段数量较少且字段和值较小时使用，节省内存。 - **HashTable（哈希表）**：当字段数量或字段值较大时使用，支持快速查询。",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "ZipList",
      "HashTable",
      "底层数据结构",
      "内存优化",
      "快速查询"
    ],
    "followup_points": [
      "1. 当 ZipList 和 HashTable 之间进行转换时，触发转换的具体阈值是什么？这些阈值是如何配置或调整的？",
      "2. 在 HashTable 中，当发生哈希冲突时，Redis 采用了什么解决策略，对查询性能有何影响？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/基本数据类型，以及底层数据结构.md",
    "code_examples": []
  },
  {
    "id": "go-interview_基本数据类型，以及底层数据结构_003",
    "text": "**底层数据结构**：",
    "answer": "- **ZipList（压缩列表）**：当列表元素较少且每个元素较小时使用，节省内存。 - **LinkedList（双向链表）**：当列表元素较多或元素较大时使用，支持快速插入和删除。",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "ZipList",
      "LinkedList",
      "底层数据结构",
      "内存优化",
      "快速插入删除"
    ],
    "followup_points": [
      "1. ZipList 和 LinkedList 在 Redis 中的切换阈值是如何确定的？是否可以手动调整？",
      "2. 当 ZipList 转换为 LinkedList 时，数据是如何迁移的？是否存在性能开销？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/基本数据类型，以及底层数据结构.md",
    "code_examples": []
  },
  {
    "id": "go-interview_基本数据类型，以及底层数据结构_004",
    "text": "**底层数据结构**：",
    "answer": "- **IntSet（整数集合）**：当集合中的元素全是整数且数量较少时使用，节省内存。 - **HashTable（哈希表）**：当集合元素较多或包含非整数时使用，支持快速查询。",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "IntSet",
      "HashTable",
      "数据结构",
      "内存优化",
      "快速查询"
    ],
    "followup_points": [
      "1. IntSet在什么情况下会从整数集合升级为哈希表？具体的触发条件是什么？",
      "2. 哈希表在Redis中是如何解决哈希冲突的？是否采用了链地址法或开放寻址法？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/基本数据类型，以及底层数据结构.md",
    "code_examples": []
  },
  {
    "id": "go-interview_基本数据类型，以及底层数据结构_005",
    "text": "**底层数据结构**：",
    "answer": "- **ZipList（压缩列表）**：当集合元素较少且分数较小时使用，节省内存。 - **SkipList（跳表）**：当集合元素较多或分数较大时使用，支持快速范围查询和排序。",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "ZipList",
      "SkipList",
      "数据结构",
      "内存优化",
      "快速查询"
    ],
    "followup_points": [
      "1. 在什么具体场景下，Redis 会从 ZipList 切换到 SkipList？切换的阈值是如何配置的？",
      "2. SkipList 的多层结构如何影响其查询性能？与平衡树（如红黑树）相比，SkipList 在实现和性能上有哪些优势？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/基本数据类型，以及底层数据结构.md",
    "code_examples": []
  },
  {
    "id": "go-interview_redis扩容方式和触发方式_000",
    "text": "**方式**：将数据按某种规则（比如 key 的哈希值）分片，分别存储到多个 Redis 实例上。常见的方式包括一致性哈希（Consistent Hashing）和哈希槽（如 Redis Cluster 的 16384 个哈希槽）。",
    "answer": "**方式**：将数据按某种规则（比如 key 的哈希值）分片，分别存储到多个 Redis 实例上。常见的方式包括一致性哈希（Consistent Hashing）和哈希槽（如 Redis Cluster 的 16384 个哈希槽）。",
    "category": "redis",
    "difficulty": 2,
    "tags": [
      "数据分片",
      "一致性哈希",
      "哈希槽",
      "Redis Cluster",
      "分布式存储"
    ],
    "followup_points": [
      "1. 一致性哈希和哈希槽在数据迁移和扩容时，各自的优缺点是什么？",
      "2. 在哈希槽分片中，如果某个实例故障，如何确保数据的高可用性和一致性？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/redis扩容方式和触发方式.md",
    "code_examples": []
  },
  {
    "id": "go-interview_redis扩容方式和触发方式_001",
    "text": "**触发**：当单个 Redis 实例的容量或性能达到瓶颈时，可以通过分片将数据分布到多台 Redis 实例上。",
    "answer": "**触发**：当单个 Redis 实例的容量或性能达到瓶颈时，可以通过分片将数据分布到多台 Redis 实例上。",
    "category": "redis",
    "difficulty": 1,
    "tags": [
      "Redis分片",
      "性能瓶颈",
      "容量扩展",
      "数据分布",
      "集群架构"
    ],
    "followup_points": [
      "1. 在确定单个 Redis 实例达到容量或性能瓶颈时，通常会通过哪些具体指标（如内存使用率、QPS、延迟等）来评估，以及这些指标的阈值是如何设定的？",
      "2. 分片方案中，数据分片策略（如哈希取模、一致性哈希等）的选择对后续的扩展性和运维复杂度有哪些影响，如何根据业务场景权衡？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/redis扩容方式和触发方式.md",
    "code_examples": []
  },
  {
    "id": "go-interview_redis扩容方式和触发方式_002",
    "text": "**实现**：在 Redis Cluster 模式下，数据会被自动分布在多个节点上，扩容时可以新增节点，将部分哈希槽迁移到新的节点上。",
    "answer": "**实现**：在 Redis Cluster 模式下，数据会被自动分布在多个节点上，扩容时可以新增节点，将部分哈希槽迁移到新的节点上。",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "Redis Cluster",
      "数据分片",
      "哈希槽",
      "扩容",
      "节点迁移"
    ],
    "followup_points": [
      "1. 在 Redis Cluster 中，哈希槽的具体分配算法是什么？如何确保数据在节点间均匀分布？",
      "2. 迁移哈希槽的过程中，如何保证服务的高可用性？是否会出现数据不一致的情况？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/redis扩容方式和触发方式.md",
    "code_examples": []
  },
  {
    "id": "go-interview_redis扩容方式和触发方式_003",
    "text": "**方式**：增加 Redis 服务器的 CPU、内存或网络带宽，从而提升 Redis 实例的处理能力。",
    "answer": "**方式**：增加 Redis 服务器的 CPU、内存或网络带宽，从而提升 Redis 实例的处理能力。",
    "category": "redis",
    "difficulty": 1,
    "tags": [
      "Redis扩容",
      "垂直扩展",
      "硬件升级",
      "CPU优化",
      "内存扩展"
    ],
    "followup_points": [
      "1. 在增加 CPU、内存或网络带宽时，如何根据当前 Redis 的性能瓶颈（如 CPU 使用率、内存碎片率、网络延迟等）来确定优先提升哪一项资源？",
      "2. 如果通过增加资源后 Redis 性能提升不明显，可能存在哪些潜在问题（如数据结构设计不合理、持久化策略影响、大 Key 问题等），应如何排查和优化？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/redis扩容方式和触发方式.md",
    "code_examples": []
  },
  {
    "id": "go-interview_redis扩容方式和触发方式_004",
    "text": "**实现**：通常需要升级硬件或在云环境中使用更大的实例规格，Redis 本身并不需要特别的配置改变。",
    "answer": "**实现**：通常需要升级硬件或在云环境中使用更大的实例规格，Redis 本身并不需要特别的配置改变。",
    "category": "redis",
    "difficulty": 1,
    "tags": [
      "硬件升级",
      "云实例规格",
      "Redis配置",
      "性能优化",
      "扩容策略"
    ],
    "followup_points": [
      "1. 在升级硬件或云实例规格时，有哪些具体的性能指标（如内存、CPU、IOPS）需要重点考虑，以确保满足Redis的扩展需求？",
      "2. 除了硬件升级，是否有软件层面的优化策略（如Redis配置参数调整、数据结构优化）可以配合硬件升级，进一步提升性能和资源利用率？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/redis扩容方式和触发方式.md",
    "code_examples": []
  },
  {
    "id": "go-interview_redis扩容方式和触发方式_005",
    "text": "**方式**：Redis Cluster 通过哈希槽（hash slots）分配 key 到不同的节点，集群中的每个节点负责处理一部分哈希槽。当需要扩容时，可以通过新增节点，将部分哈希槽重新分配给新的节点。",
    "answer": "**方式**：Redis Cluster 通过哈希槽（hash slots）分配 key 到不同的节点，集群中的每个节点负责处理一部分哈希槽。当需要扩容时，可以通过新增节点，将部分哈希槽重新分配给新的节点。",
    "category": "redis",
    "difficulty": 2,
    "tags": [
      "Redis Cluster",
      "哈希槽",
      "数据分片",
      "扩容",
      "节点分配"
    ],
    "followup_points": [
      "1. 在哈希槽重新分配的过程中，如何确保数据的一致性和服务的可用性？",
      "2. 哈希槽的分配策略（如哈希算法、槽范围划分）是否会影响集群的负载均衡和性能？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/redis扩容方式和触发方式.md",
    "code_examples": []
  },
  {
    "id": "go-interview_redis扩容方式和触发方式_006",
    "text": "**触发**：当现有 Redis Cluster 节点负载过高或存储容量不足时，可以通过增加新的节点来分担压力。",
    "answer": "**触发**：当现有 Redis Cluster 节点负载过高或存储容量不足时，可以通过增加新的节点来分担压力。",
    "category": "redis",
    "difficulty": 2,
    "tags": [
      "Redis Cluster",
      "负载均衡",
      "扩容",
      "节点管理",
      "容量规划"
    ],
    "followup_points": [
      "1. 在增加新节点后，如何确保数据在节点间的重新分布是均匀的，避免某些节点仍然负载过高？",
      "2. 当新节点加入后，Redis Cluster 的主从复制和故障转移机制需要做哪些调整来保证高可用性？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/redis扩容方式和触发方式.md",
    "code_examples": []
  },
  {
    "id": "go-interview_redis扩容方式和触发方式_007",
    "text": "**节点健康检查**：扩容时应确保新加入的节点稳定且配置正确，否则可能导致集群异常。",
    "answer": "**节点健康检查**：扩容时应确保新加入的节点稳定且配置正确，否则可能导致集群异常。 通过这些方式，Redis 可以在单机容量不足时灵活扩展到多个节点，提升整体处理能力和存储容量。",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "集群扩容",
      "节点健康检查",
      "配置管理",
      "集群稳定性",
      "高可用性"
    ],
    "followup_points": [
      "1. 具体采用哪些健康检查指标（如 CPU、内存、网络延迟、Redis 服务状态等）来验证新节点的稳定性？",
      "2. 在扩容过程中，如何自动化执行健康检查流程，以及未通过检查时的回滚或重试机制是怎样的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/redis扩容方式和触发方式.md",
    "code_examples": []
  },
  {
    "id": "go-interview_缓存穿透、击穿、雪崩、预热、更新、降级_000",
    "text": "**布隆过滤器**：在缓存前使用布隆过滤器检查请求的数据是否存在。布隆过滤器能有效拦截不存在的数据请求，从而避免对数据库的无效查询。",
    "answer": "**布隆过滤器**：在缓存前使用布隆过滤器检查请求的数据是否存在。布隆过滤器能有效拦截不存在的数据请求，从而避免对数据库的无效查询。",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "布隆过滤器",
      "缓存",
      "数据库查询优化",
      "数据存在性检查",
      "无效请求拦截"
    ],
    "followup_points": [
      "1. 布隆过滤器的误判率如何影响整体系统的性能，以及在实际应用中如何平衡误判率和内存占用？",
      "2. 当布隆过滤器中需要动态添加或删除元素时，如何处理其不可删除的特性，以及有哪些替代方案或优化策略？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/缓存穿透、击穿、雪崩、预热、更新、降级.md",
    "code_examples": []
  },
  {
    "id": "go-interview_缓存穿透、击穿、雪崩、预热、更新、降级_001",
    "text": "**互斥锁**：在缓存过期的情况下，使用互斥锁确保只有一个请求去数据库查询数据，其他请求等待数据加载完成后再从缓存中获取数据。",
    "answer": "**互斥锁**：在缓存过期的情况下，使用互斥锁确保只有一个请求去数据库查询数据，其他请求等待数据加载完成后再从缓存中获取数据。",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "互斥锁",
      "缓存过期",
      "数据库查询",
      "请求等待",
      "缓存更新"
    ],
    "followup_points": [
      "1. 互斥锁的实现方式有哪些（如Redis的SETNX、数据库锁等），各自的优缺点是什么？",
      "2. 如果等待请求过多，长时间阻塞可能导致系统性能下降，如何优化这种等待场景（如设置超时、异步加载等）？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/缓存穿透、击穿、雪崩、预热、更新、降级.md",
    "code_examples": []
  },
  {
    "id": "go-interview_缓存穿透、击穿、雪崩、预热、更新、降级_002",
    "text": "**写回模式**：先更新缓存，异步更新数据库。这样可以减少数据库的写入压力，但可能存在数据不一致的风险。",
    "answer": "**写回模式**：先更新缓存，异步更新数据库。这样可以减少数据库的写入压力，但可能存在数据不一致的风险。",
    "category": "redis",
    "difficulty": 2,
    "tags": [
      "缓存策略",
      "数据一致性",
      "异步更新",
      "写回模式",
      "数据库写入压力"
    ],
    "followup_points": [
      "1. 在写回模式中，如果异步更新数据库失败，你会采取哪些措施来保证数据最终一致性？",
      "2. 如何处理并发场景下，缓存更新和数据库更新顺序不一致导致的数据不一致问题？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/缓存穿透、击穿、雪崩、预热、更新、降级.md",
    "code_examples": []
  },
  {
    "id": "go-interview_缓存穿透、击穿、雪崩、预热、更新、降级_003",
    "text": "**熔断机制**：当缓存服务出现异常时，快速切换到备用处理流程，以避免缓存故障导致系统整体不可用。",
    "answer": "**熔断机制**：当缓存服务出现异常时，快速切换到备用处理流程，以避免缓存故障导致系统整体不可用。 通过理解和应用这些缓存优化策略，可以有效提高系统的性能和稳定性。",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "缓存",
      "熔断机制",
      "系统稳定性",
      "故障切换",
      "性能优化"
    ],
    "followup_points": [
      "1. 在熔断机制触发后，系统如何判断缓存服务是否恢复正常，从而决定是否重新切换回主流程？",
      "2. 熔断机制在切换到备用处理流程时，是否会对备用服务的性能或可用性产生影响？如何避免备用服务成为新的瓶颈？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/缓存穿透、击穿、雪崩、预热、更新、降级.md",
    "code_examples": []
  },
  {
    "id": "go-interview_redis如何判断Key是否存在_000",
    "text": "Redis 中判断 Key 是否存在的原理依赖于 Redis 的底层数据结构和哈希表的实现。当你使用 `EXISTS` 命令时，Redis 会在其内部的数据结构中查找相应的 key。具体原理如下：",
    "answer": "Redis 中判断 Key 是否存在的原理依赖于 Redis 的底层数据结构和哈希表的实现。当你使用 `EXISTS` 命令时，Redis 会在其内部的数据结构中查找相应的 key。具体原理如下：",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "Redis底层数据结构",
      "哈希表实现",
      "Key查找机制",
      "EXISTS命令",
      "哈希冲突处理"
    ],
    "followup_points": [
      "1. Redis 底层数据结构中哈希表的实现细节是什么？例如，哈希冲突如何解决，扩容机制是怎样的？",
      "2. 在高并发场景下，`EXISTS` 命令的性能如何保障？是否存在锁竞争或优化的机制？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/redis如何判断Key是否存在.md",
    "code_examples": []
  },
  {
    "id": "go-interview_String数据结构sds_000",
    "text": "**动态扩容**：SDS 支持动态扩展，当字符串长度需要增加时，SDS 可以自动调整空间大小，无需手动管理内存。",
    "answer": "**动态扩容**：SDS 支持动态扩展，当字符串长度需要增加时，SDS 可以自动调整空间大小，无需手动管理内存。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "动态扩容",
      "内存管理",
      "自动调整空间大小",
      "字符串长度扩展",
      "无需手动管理内存"
    ],
    "followup_points": [
      "1. SDS 动态扩容的具体策略是什么？是每次扩容固定增加一定大小，还是采用类似指数增长的方式（如翻倍）？",
      "2. 在扩容过程中，SDS 如何保证数据的安全性？是否涉及内存拷贝，如何优化频繁扩容带来的性能开销？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/String数据结构sds.md",
    "code_examples": []
  },
  {
    "id": "go-interview_String数据结构sds_001",
    "text": "**二进制安全**：SDS 不会对字符串内容做任何假设，它可以存储任意二进制数据，而不仅仅是以 `\\0` 结尾的字符数组。",
    "answer": "**二进制安全**：SDS 不会对字符串内容做任何假设，它可以存储任意二进制数据，而不仅仅是以 `\\0` 结尾的字符数组。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "二进制安全",
      "字符串处理",
      "数据结构",
      "内存管理",
      "C语言"
    ],
    "followup_points": [
      "1. SDS 如何确保在存储和操作二进制数据时不会误判 `\\0` 的位置，从而避免数据截断？",
      "2. 在 SDS 的实现中，是如何通过元数据（如长度字段）来支持二进制数据的正确处理和高效内存管理的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/String数据结构sds.md",
    "code_examples": []
  },
  {
    "id": "go-interview_String数据结构sds_002",
    "text": "**常数时间获取长度**：SDS 会在内部记录字符串的长度，所以获取字符串长度的操作是 O(1) 的，而 C 字符串需要遍历整个字符数组来计算长度（O(n)）。",
    "answer": "**常数时间获取长度**：SDS 会在内部记录字符串的长度，所以获取字符串长度的操作是 O(1) 的，而 C 字符串需要遍历整个字符数组来计算长度（O(n)）。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "SDS",
      "字符串长度",
      "时间复杂度 O(1)",
      "C 字符串",
      "时间复杂度 O(n)"
    ],
    "followup_points": [
      "1. SDS 在记录长度时，是否还需要考虑字符编码（如 UTF-8）对长度计算的影响？如果字符串包含多字节字符，SDS 如何确保长度记录的准确性？",
      "2. 在 SDS 的实现中，长度信息是如何存储的？如果字符串频繁修改（如 append 操作），SDS 如何高效更新长度信息以保持 O(1) 的时间复杂度？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/String数据结构sds.md",
    "code_examples": []
  },
  {
    "id": "go-interview_String数据结构sds_003",
    "text": "**预分配空间和惰性空间释放**：SDS 在扩展时会预分配一些额外的空间，以减少频繁的内存分配和复制操作。此外，当 SDS 缩短字符串时，它并不会立即释放多余的内存空间，而是保留起来以备后用。",
    "answer": "**预分配空间和惰性空间释放**：SDS 在扩展时会预分配一些额外的空间，以减少频繁的内存分配和复制操作。此外，当 SDS 缩短字符串时，它并不会立即释放多余的内存空间，而是保留起来以备后用。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "内存预分配",
      "惰性释放",
      "空间优化",
      "内存管理",
      "字符串操作"
    ],
    "followup_points": [
      "1. SDS 在预分配空间时，是如何决定预分配大小的？是否有固定的增长策略或公式？",
      "2. SDS 在惰性释放空间后，这些未释放的内存空间是否有最大上限？如果长时间未使用，是否会触发自动释放机制？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/String数据结构sds.md",
    "code_examples": []
  },
  {
    "id": "go-interview_String数据结构sds_004",
    "text": "**buf**：实际保存字符串数据的地方。",
    "answer": "**buf**：实际保存字符串数据的地方。 例如，一个长度为 5 的字符串 `\"hello\"`，对应的 SDS 结构可能是这样的：",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "SDS",
      "字符串",
      "缓冲区",
      "数据结构",
      "内存管理"
    ],
    "followup_points": [
      "1. 在 SDS 结构中，`buf` 字段是如何动态扩展的？当字符串长度超过当前分配的空间时，Redis 会采取什么策略来重新分配 `buf` 的大小？",
      "2. SDS 的 `buf` 字段除了存储字符串数据，是否还存储了额外的元信息（如长度标识）？这些元信息如何帮助 SDS 提升字符串操作的性能？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/String数据结构sds.md",
    "code_examples": []
  },
  {
    "id": "go-interview_String数据结构sds_005",
    "text": "`buf` = \"hello\\0\"（注意 `buf` 并不是传统意义上的以 `\\0` 结尾的字符串，只是恰好有 `\\0` 用来方便处理）",
    "answer": "`buf` = \"hello\\0\"（注意 `buf` 并不是传统意义上的以 `\\0` 结尾的字符串，只是恰好有 `\\0` 用来方便处理）",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "字符串处理",
      "空字符处理",
      "缓冲区",
      "内存表示",
      "C语言特性"
    ],
    "followup_points": [
      "1. 如果 `buf` 不是以 `\\0` 结尾的传统字符串，那么在处理它时需要注意哪些潜在的问题或边界情况？",
      "2. 如果 `buf` 的内容需要被传递给一个期望以 `\\0` 结尾的字符串函数，应该如何安全地处理或转换？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/String数据结构sds.md",
    "code_examples": []
  },
  {
    "id": "go-interview_String数据结构sds_006",
    "text": "**空间预分配**：当 SDS 需要扩展时，它不仅仅只分配所需的内存，还会预分配额外的空间。具体的策略是：",
    "answer": "- 如果 SDS 当前长度小于 1MB，那么扩容时会分配与当前长度相同的额外空间，即如果扩展后的长度是 `N`，那么实际分配的总空间是 `2N`。 - 如果 SDS 当前长度大于等于 1MB，那么每次扩展只额外分配 1MB 的空间。 这种策略能够有效减少频繁的内存分配操作，提升字符串操作的效率。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "内存预分配",
      "动态扩容策略",
      "内存管理",
      "SDS (Simple Dynamic String)",
      "空间分配优化"
    ],
    "followup_points": [
      "1. 在 SDS 的预分配策略中，如果当前长度小于 1MB，分配的额外空间与当前长度相同，这种线性增长的策略是否会在某些场景下导致内存浪费？例如，当字符串长度频繁在接近 1MB 的阈值附近波动时。",
      "2. 对于 SDS 的预分配策略，是否考虑过内存碎片化的影响？特别是在频繁扩容和缩容的场景下，预分配的额外空间是否可能加剧内存碎片问题，以及 Redis 是如何优化这一点的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/String数据结构sds.md",
    "code_examples": []
  },
  {
    "id": "go-interview_String数据结构sds_007",
    "text": "**惰性空间释放**：当字符串缩短时，SDS 并不会立即释放多余的内存空间，而是将这些空间保留起来，以便下次扩展时直接使用。这种策略避免了频繁的内存分配和释放操作，提高了内存使用的效率。",
    "answer": "**惰性空间释放**：当字符串缩短时，SDS 并不会立即释放多余的内存空间，而是将这些空间保留起来，以便下次扩展时直接使用。这种策略避免了频繁的内存分配和释放操作，提高了内存使用的效率。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "惰性空间释放",
      "内存管理",
      "内存分配",
      "内存释放",
      "性能优化"
    ],
    "followup_points": [
      "1. 在什么情况下，SDS 会触发对惰性释放的多余内存空间的实际回收操作？",
      "2. 如果字符串持续缩短但后续不再扩展，惰性释放的内存是否会无限累积？如何避免内存浪费？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Redis/String数据结构sds.md",
    "code_examples": []
  },
  {
    "id": "go-interview_超卖问题_000",
    "text": "### 面试中的常见问题",
    "answer": "1. **悲观锁和乐观锁的区别？** - 悲观锁：假设会发生并发冲突，操作前加锁，性能较低但安全性高。 - 乐观锁：假设不会发生并发冲突，操作后校验版本号，性能较高但需要重试机制。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "悲观锁",
      "乐观锁",
      "并发控制",
      "版本号机制",
      "重试机制"
    ],
    "followup_points": [
      "1. 在什么场景下你会选择使用悲观锁而不是乐观锁？请结合具体业务场景说明。",
      "2. 乐观锁的重试机制如何设计才能避免无限循环或性能问题？请举例说明你的优化思路。"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Case/超卖问题.md",
    "code_examples": []
  },
  {
    "id": "go-interview_读写锁的实现及底层原理_000",
    "text": "**w**：表示写锁的状态和数量。写锁是互斥的，也就是说，同时只能有一个 Goroutine 获得写锁。",
    "answer": "**w**：表示写锁的状态和数量。写锁是互斥的，也就是说，同时只能有一个 Goroutine 获得写锁。",
    "category": "go",
    "difficulty": 1,
    "tags": [
      "Go并发",
      "互斥锁",
      "写锁",
      "Goroutine",
      "锁状态"
    ],
    "followup_points": [
      "1. 如果写锁是互斥的，为什么需要记录\"数量\"而不是简单的布尔值表示状态？",
      "2. 在写锁释放时，是如何确保只有一个 Goroutine 能成功获取锁，而其他等待的 Goroutine 不会被错误唤醒？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Go/读写锁的实现及底层原理.md",
    "code_examples": []
  },
  {
    "id": "go-interview_读写锁的实现及底层原理_001",
    "text": "**RLock**：获取读锁。",
    "answer": "1. 如果当前没有 Goroutine 持有写锁，则 `readerCount` 增加，允许当前 Goroutine 获得读锁。 2. 如果有 Goroutine 持有写锁，则当前 Goroutine 被阻塞，直到写锁被释放。",
    "category": "go",
    "difficulty": 1,
    "tags": [
      "RLock",
      "读锁",
      "写锁",
      "Goroutine",
      "readerCount"
    ],
    "followup_points": [
      "1. 当多个 Goroutine 同时尝试获取读锁时，`readerCount` 的增加操作是否需要加锁？为什么？",
      "2. 如果当前 Goroutine 已经持有读锁，再次尝试获取读锁时，`readerCount` 会如何处理？是否存在重入性？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Go/读写锁的实现及底层原理.md",
    "code_examples": []
  },
  {
    "id": "go-interview_读写锁的实现及底层原理_002",
    "text": "**RUnlock**：释放读锁。",
    "answer": "1. `readerCount` 减少，当最后一个读锁被释放时，检查是否有等待写锁的 Goroutine。如果有，则唤醒其中一个。",
    "category": "go",
    "difficulty": 1,
    "tags": [
      "读写锁",
      "Goroutine调度",
      "锁状态管理",
      "锁竞争与唤醒",
      "原子操作"
    ],
    "followup_points": [
      "1. 当 `readerCount` 减少到 0 时，如何确保唤醒的写锁 Goroutine 是公平的，避免写锁饥饿？",
      "2. 如果多个写锁 Goroutine 同时在等待，唤醒策略是什么（如 FIFO、随机或其他）？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Go/读写锁的实现及底层原理.md",
    "code_examples": []
  },
  {
    "id": "go-interview_读写锁的实现及底层原理_003",
    "text": "**Lock**：获取写锁。",
    "answer": "1. 检查是否有其他 Goroutine 持有读锁或写锁，如果有，当前 Goroutine 被阻塞。 2. 否则，标记写锁已被持有，并阻止其他 Goroutine 获得读锁或写锁。",
    "category": "go",
    "difficulty": 1,
    "tags": [
      "写锁",
      "阻塞",
      "锁状态检查",
      "Goroutine",
      "互斥"
    ],
    "followup_points": [
      "1. 如果当前 Goroutine 已经持有读锁，尝试获取写锁时会阻塞自己吗？为什么？",
      "2. 写锁被阻塞时，Goroutine 是如何被唤醒的？唤醒的条件是什么？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Go/读写锁的实现及底层原理.md",
    "code_examples": []
  },
  {
    "id": "go-interview_读写锁的实现及底层原理_004",
    "text": "**Unlock**：释放写锁。",
    "answer": "1. 解除写锁标记，检查是否有等待的读锁或写锁 Goroutine，并根据优先级唤醒合适的 Goroutine。",
    "category": "go",
    "difficulty": 1,
    "tags": [
      "锁机制",
      "写锁释放",
      "Goroutine调度",
      "锁优先级",
      "唤醒机制"
    ],
    "followup_points": [
      "1. 在检查等待的锁时，如何确定读锁和写锁的优先级？是否有特定的策略或配置选项？",
      "2. 唤醒 Goroutine 的具体机制是什么？是直接调度到运行队列，还是通过某种条件通知机制？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Go/读写锁的实现及底层原理.md",
    "code_examples": []
  },
  {
    "id": "go-interview_读写锁的实现及底层原理_005",
    "text": "写锁是通过修改 `w` 来实现的。如果 `w` 是负数，表示当前已经有 Goroutine 持有写锁，此时新的写操作会被阻塞。",
    "answer": "写锁是通过修改 `w` 来实现的。如果 `w` 是负数，表示当前已经有 Goroutine 持有写锁，此时新的写操作会被阻塞。",
    "category": "go",
    "difficulty": 2,
    "tags": [
      "Go并发",
      "互斥锁",
      "写锁实现",
      "锁状态判断",
      "Goroutine阻塞"
    ],
    "followup_points": [
      "1. 如果 `w` 是负数时，新的写操作被阻塞，那么具体是通过什么机制（如 channel、sync.Mutex 或自旋）来实现的阻塞？",
      "2. 当写锁被释放时，`w` 的值是如何恢复的？是否有其他机制（如等待队列）来唤醒被阻塞的写操作？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Go/读写锁的实现及底层原理.md",
    "code_examples": []
  },
  {
    "id": "go-interview_读写锁的实现及底层原理_006",
    "text": "读锁的释放通过减少 `readerCount` 来实现。如果 `readerCount` 变为 0，且有写锁在等待，写操作会被唤醒。",
    "answer": "读锁的释放通过减少 `readerCount` 来实现。如果 `readerCount` 变为 0，且有写锁在等待，写操作会被唤醒。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "读锁释放",
      "readerCount",
      "写锁唤醒",
      "锁竞争",
      "读写锁机制"
    ],
    "followup_points": [
      "1. 当 `readerCount` 从 1 减少到 0 时，具体是通过什么机制（如条件变量、信号量或原子操作）来唤醒等待的写锁？",
      "2. 如果多个写锁同时等待，当 `readerCount` 变为 0 时，唤醒策略是怎样的（如公平性、FIFO 或优先级）？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Go/读写锁的实现及底层原理.md",
    "code_examples": []
  },
  {
    "id": "go-interview_读写锁的实现及底层原理_007",
    "text": "在 `sync.RWMutex` 中，不支持锁的升级（即持有读锁时尝试获取写锁）和降级（即持有写锁时尝试获取读锁）。这是为了避免死锁。",
    "answer": "在 `sync.RWMutex` 中，不支持锁的升级（即持有读锁时尝试获取写锁）和降级（即持有写锁时尝试获取读锁）。这是为了避免死锁。",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "sync.RWMutex",
      "锁升级",
      "锁降级",
      "死锁",
      "并发控制"
    ],
    "followup_points": [
      "1. 能否举例说明锁升级或降级可能导致的典型死锁场景？",
      "2. 如果业务场景确实需要锁的升级或降级，有哪些替代方案可以实现类似功能？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Go/读写锁的实现及底层原理.md",
    "code_examples": []
  },
  {
    "id": "go-interview_读写锁的实现及底层原理_008",
    "text": "如果一个 Goroutine 持有读锁后又尝试获取写锁，会导致死锁，因为写锁的获取会等待所有读锁释放，而读锁的释放在等待写锁的获取，这样两个操作互相等待。",
    "answer": "如果一个 Goroutine 持有读锁后又尝试获取写锁，会导致死锁，因为写锁的获取会等待所有读锁释放，而读锁的释放在等待写锁的获取，这样两个操作互相等待。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Goroutine",
      "死锁",
      "读写锁",
      "锁升级",
      "互斥等待"
    ],
    "followup_points": [
      "1. 在实际开发中，如何避免这种 Goroutine 持有读锁后又尝试获取写锁导致的死锁问题？有哪些常见的编程模式或最佳实践可以预防这种情况？",
      "2. 如果多个 Goroutine 同时持有读锁，其中一个尝试获取写锁，此时写锁的等待机制具体是如何实现的？底层是如何保证读锁的顺序释放和写锁的优先获取的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Go/读写锁的实现及底层原理.md",
    "code_examples": []
  },
  {
    "id": "go-interview_读写锁的实现及底层原理_009",
    "text": "**读多写少**：`sync.RWMutex` 适用于读操作远多于写操作的场景，这样可以提高并发性能。",
    "answer": "**读多写少**：`sync.RWMutex` 适用于读操作远多于写操作的场景，这样可以提高并发性能。",
    "category": "system-design",
    "difficulty": 1,
    "tags": [
      "sync.RWMutex",
      "读多写少",
      "并发性能",
      "Go语言",
      "锁机制"
    ],
    "followup_points": [
      "1. 如果写操作虽然少，但单个写操作耗时较长，是否会对读操作的并发性能产生显著影响？如何优化这种场景？",
      "2. 在使用 `sync.RWMutex` 时，如果读操作之间也存在竞争（例如需要修改共享数据），是否需要进一步细化锁的粒度？如何设计更高效的并发控制策略？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Go/读写锁的实现及底层原理.md",
    "code_examples": []
  },
  {
    "id": "go-interview_读写锁的实现及底层原理_010",
    "text": "频繁的读写锁竞争可能会导致 Goroutine 被频繁阻塞和唤醒，影响性能。因此，需要根据实际场景选择合适的锁类型。",
    "answer": "频繁的读写锁竞争可能会导致 Goroutine 被频繁阻塞和唤醒，影响性能。因此，需要根据实际场景选择合适的锁类型。 读写锁提供了一种有效的方式来管理共享资源的并发访问，特别是在读操作远多于写操作的情况下。理解其底层原理有助于更好地利用其优势，同时避免常见的陷阱。",
    "category": "go",
    "difficulty": 2,
    "tags": [
      "并发锁",
      "读写锁 (RWMutex)",
      "Goroutine 调度",
      "锁竞争",
      "性能优化"
    ],
    "followup_points": [
      "1. 在实际场景中，如何量化读写锁的竞争程度，从而判断是否需要切换到其他锁类型（如互斥锁或分段锁）？",
      "2. 除了读写锁和互斥锁，还有哪些替代方案（如 sync.Map、原子操作或无锁数据结构）可以优化高并发场景下的性能，它们的适用场景分别是什么？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Go/读写锁的实现及底层原理.md",
    "code_examples": []
  },
  {
    "id": "go-interview_GPM调度模型_000",
    "text": "**Goroutine** 是Go语言中用于并发执行的轻量级线程，每个Goroutine都有自己的栈和上下文信息。",
    "answer": "**Goroutine** 是Go语言中用于并发执行的轻量级线程，每个Goroutine都有自己的栈和上下文信息。",
    "category": "go",
    "difficulty": 1,
    "tags": [
      "并发",
      "Goroutine",
      "轻量级线程",
      "栈",
      "上下文信息"
    ],
    "followup_points": [
      "1. Goroutine的栈大小是如何动态调整的？调整过程中是否涉及内存分配或释放的开销？",
      "2. 当多个Goroutine同时访问共享资源时，Go语言提供了哪些同步机制来避免竞争条件？这些机制各自的适用场景是什么？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Go/GPM调度模型.md",
    "code_examples": []
  },
  {
    "id": "go-interview_GPM调度模型_001",
    "text": "**P** 是处理Goroutine的调度器的上下文，每个P包含一个本地运行队列（Local Run Queue），用于存储需要运行的Goroutine。",
    "answer": "**P** 是处理Goroutine的调度器的上下文，每个P包含一个本地运行队列（Local Run Queue），用于存储需要运行的Goroutine。",
    "category": "go",
    "difficulty": 2,
    "tags": [
      "Goroutine",
      "调度器",
      "上下文",
      "本地运行队列",
      "P"
    ],
    "followup_points": [
      "1. 当本地运行队列满时，新的Goroutine会被如何处理？是放入全局运行队列还是其他P的本地队列？",
      "2. 本地运行队列的调度策略是什么？是FIFO（先进先出）还是其他优先级机制？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Go/GPM调度模型.md",
    "code_examples": []
  },
  {
    "id": "go-interview_GPM调度模型_002",
    "text": "**M** 代表操作系统的线程，负责执行Goroutine。一个M一次只能执行一个Goroutine。",
    "answer": "**M** 代表操作系统的线程，负责执行Goroutine。一个M一次只能执行一个Goroutine。",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "操作系统线程",
      "Goroutine",
      "GMP模型",
      "线程调度",
      "并发执行"
    ],
    "followup_points": [
      "1. 当一个M正在执行Goroutine时，如果该Goroutine因系统调用（如文件I/O）阻塞，会发生什么？M会如何处理这个阻塞的Goroutine？",
      "2. Go运行时如何管理多个M（操作系统线程）与大量Goroutine之间的映射关系？是否存在M的复用或创建策略？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Go/GPM调度模型.md",
    "code_examples": []
  },
  {
    "id": "go-interview_GPM调度模型_003",
    "text": "**调度器工作机制**：Goroutine创建后会被放入P的本地队列，P会从该队列中选择Goroutine，并将其分配给M执行。如果本地队列为空，P可以从全局运行队列或其他P的队列中窃取任务。",
    "answer": "**调度器工作机制**：Goroutine创建后会被放入P的本地队列，P会从该队列中选择Goroutine，并将其分配给M执行。如果本地队列为空，P可以从全局运行队列或其他P的队列中窃取任务。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Goroutine调度",
      "P本地队列",
      "全局运行队列",
      "工作窃取",
      "M线程绑定"
    ],
    "followup_points": [
      "1. 当P从其他P的本地队列窃取任务时，采用什么样的窃取策略（如工作窃取算法）来减少锁竞争和提升效率？",
      "2. 在多核环境下，如果多个P同时尝试从全局运行队列或其他P的队列中窃取任务，调度器如何处理并发冲突和确保任务分配的公平性？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Go/GPM调度模型.md",
    "code_examples": []
  },
  {
    "id": "go-interview_GPM调度模型_004",
    "text": "**工作窃取机制**：如果一个P的本地队列为空，而另一个P的本地队列中有多个Goroutine，前者可以从后者中窃取任务，从而保持系统的高效利用率。",
    "answer": "**工作窃取机制**：如果一个P的本地队列为空，而另一个P的本地队列中有多个Goroutine，前者可以从后者中窃取任务，从而保持系统的高效利用率。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "并发",
      "调度",
      "Goroutine",
      "工作窃取",
      "任务队列"
    ],
    "followup_points": [
      "1. 工作窃取机制中，窃取任务时如何避免竞争条件，确保线程安全？",
      "2. 窃取任务的策略是随机选择目标P的队列，还是遵循特定规则（如优先窃取负载较轻的P）？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Go/GPM调度模型.md",
    "code_examples": []
  },
  {
    "id": "go-interview_GPM调度模型_005",
    "text": "**阻塞与调度**：当M执行的Goroutine阻塞（例如I/O操作）时，M会释放当前的P并等待P重新分配任务，从而避免资源浪费。",
    "answer": "**阻塞与调度**：当M执行的Goroutine阻塞（例如I/O操作）时，M会释放当前的P并等待P重新分配任务，从而避免资源浪费。",
    "category": "go",
    "difficulty": 2,
    "tags": [
      "Goroutine调度",
      "M与P关系",
      "阻塞处理",
      "资源管理",
      "任务分配"
    ],
    "followup_points": [
      "1. 当M释放P后，Goroutine的阻塞状态如何被跟踪和管理？",
      "2. 如果阻塞的Goroutine恢复后，原来的M和P是否还能重新绑定？如果无法绑定，调度器会如何处理这种情况？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docs/Go/GPM调度模型.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_000",
    "text": "[3.7.3](https://github.com/QingWei-Li/docsify/compare/v3.7.2...v3.7.3) (2017-05-22)",
    "answer": "# * **render:** find => filter ([eca3368](https://github.com/QingWei-Li/docsify/commit/eca3368))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "render",
      "filter",
      "commit",
      "git",
      "docsify"
    ],
    "followup_points": [
      "1. 在这个版本更新中，`render` 方法的 `find` 到 `filter` 的改动具体解决了什么性能问题或逻辑优化需求？",
      "2. `eca3368` 提交中提到的改动是否对文档渲染的兼容性或边缘情况产生了影响，是否有相关的测试覆盖？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_001",
    "text": "[3.7.1](https://github.com/QingWei-Li/docsify/compare/v3.7.0...v3.7.1) (2017-05-19)",
    "answer": "# * docsify-updated is undefined ([b2b4742](https://github.com/QingWei-Li/docsify/commit/b2b4742)) # [3.7.0](https://github.com/QingWei-Li/docsify/compare/v3.6.6...v3.7.0) (2017-05-16) # * add docsify-updated, close [#158](https://github.com/QingWei-Li/docsify/issues/158) ([d2be5ae](https://github.com/QingWei-Li/docsify/commit/d2be5ae)) * add externalLinkTarget, close [#149](https://github.com/QingWei-Li/docsify/issues/149) ([2d73285](https://github.com/QingWei-Li/docsify/commit/2d73285))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "版本控制",
      "Git",
      "docsify",
      "更新时间",
      "Markdown"
    ],
    "followup_points": [
      "1. 在 v3.7.0 中新增的 `docsify-updated` 功能是如何工作的，它解决了 issue #158 中提到的什么具体问题？",
      "2. 从 v3.7.0 到 v3.7.1 的修复中，`docsify-updated` 未定义的问题是如何发生的，修复的核心逻辑是什么？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_002",
    "text": "[3.6.6](https://github.com/QingWei-Li/docsify/compare/v3.6.5...v3.6.6) (2017-05-06)",
    "answer": "# * support query string for the search, fixed [#156](https://github.com/QingWei-Li/docsify/issues/156) ([da75d70](https://github.com/QingWei-Li/docsify/commit/da75d70))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "URL查询参数",
      "前端搜索功能",
      "Git版本控制",
      "GitHub Issue跟踪",
      "docsify框架"
    ],
    "followup_points": [
      "1. 在实现搜索查询字符串支持时，是如何处理特殊字符和编码问题的？",
      "2. 该修复对搜索性能是否有影响，是否做了相关的优化措施？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_003",
    "text": "[3.6.5](https://github.com/QingWei-Li/docsify/compare/v3.6.4...v3.6.5) (2017-04-28)",
    "answer": "# * **util:** fix crash, fixed [#154](https://github.com/QingWei-Li/docsify/issues/154) ([51832d3](https://github.com/QingWei-Li/docsify/commit/51832d3))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "util",
      "bug修复",
      "版本控制",
      "GitHub",
      "commit"
    ],
    "followup_points": [
      "1. 这个修复具体解决了什么场景下的崩溃问题？",
      "2. 修复前后的代码逻辑变化是什么？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_004",
    "text": "[3.6.4](https://github.com/QingWei-Li/docsify/compare/v3.6.3...v3.6.4) (2017-04-28)",
    "answer": "# * **util:** correctly clean up duplicate slashes, fixed [#153](https://github.com/QingWei-Li/docsify/issues/153) ([76c041a](https://github.com/QingWei-Li/docsify/commit/76c041a))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "util",
      "字符串处理",
      "路径处理",
      "代码修复",
      "版本控制"
    ],
    "followup_points": [
      "1. 在修复重复斜杠清理问题时，具体遇到了哪些技术挑战或边界情况需要处理？",
      "2. 这个修复对性能或现有功能是否产生了其他潜在影响，是否有相关的回归测试？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_005",
    "text": "[3.6.3](https://github.com/QingWei-Li/docsify/compare/v3.6.2...v3.6.3) (2017-04-25)",
    "answer": "# * **external-script:** script attrs ([2653849](https://github.com/QingWei-Li/docsify/commit/2653849))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "external-script",
      "script-attrs",
      "commit",
      "version-control",
      "github-api"
    ],
    "followup_points": [
      "1. 这次更新中提到的 \"script attrs\" 具体支持了哪些新的属性或功能？",
      "2. 在实现 \"external-script\" 的 script attrs 功能时，遇到了哪些技术挑战或需要特别注意的兼容性问题？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_006",
    "text": "[3.6.2](https://github.com/QingWei-Li/docsify/compare/v3.6.0...v3.6.2) (2017-04-12)",
    "answer": "# * **event:** Collapse the sidebar when click outside element in the small screen ([9b7e5f5](https://github.com/QingWei-Li/docsify/commit/9b7e5f5)) * **external-script:** detect more than one script dom, fixed [#146](https://github.com/QingWei-Li/docsify/issues/146) ([94d6603](https://github.com/QingWei-Li/docsify/commit/94d6603)) # [3.6.0](https://github.com/QingWei-Li/docsify/compare/v3.5.2...v3.6.0) (2017-04-09) # * **render:** add mergeNavbar option, close [#125](https://github.com/QingWei-Li/docsify/issues/125), [#124](https://github.com/QingWei-Li/docsify/issues/124) ([#145](https://github.com/QingWei-Li/docsify/issues/145)) ([9220523](https://github.com/QingWei-Li/docsify/commit/9220523))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "event",
      "external-script",
      "DOM操作",
      "响应式设计",
      "版本控制"
    ],
    "followup_points": [
      "1. 在小屏幕下点击外部元素折叠侧边栏的具体实现逻辑是什么？是否考虑了不同设备屏幕尺寸的适配问题？",
      "2. 针对\"external-script\"检测多个脚本DOM的修复，具体解决了哪些兼容性问题？修复后对页面性能或加载速度是否有影响？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_007",
    "text": "[3.5.1](https://github.com/QingWei-Li/docsify/compare/v3.5.0...v3.5.1) (2017-03-25)",
    "answer": "# * .md file extension regex ([594299f](https://github.com/QingWei-Li/docsify/commit/594299f)) # [3.5.0](https://github.com/QingWei-Li/docsify/compare/v3.4.4...v3.5.0) (2017-03-25) # * adjust display on small screens ([bf35471](https://github.com/QingWei-Li/docsify/commit/bf35471)) * navbar labels for German ([b022aaf](https://github.com/QingWei-Li/docsify/commit/b022aaf)) # * **route:** auto remove .md extension ([8f11653](https://github.com/QingWei-Li/docsify/commit/8f11653))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "版本控制",
      "正则表达式",
      "响应式设计",
      "前端开发",
      "Git提交"
    ],
    "followup_points": [
      "1. 这个版本中关于.md文件扩展名正则表达式的具体改进是什么？",
      "2. 调整小屏幕显示的具体实现方式和考虑因素有哪些？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_008",
    "text": "[3.4.4](https://github.com/QingWei-Li/docsify/compare/v3.4.3...v3.4.4) (2017-03-17)",
    "answer": "# * **search:** fix input style ([2d6a51b](https://github.com/QingWei-Li/docsify/commit/2d6a51b))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Git版本控制",
      "Commit提交",
      "代码审查",
      "前端样式修复",
      "Markdown文档"
    ],
    "followup_points": [
      "1. 这次修改具体解决了什么输入样式问题？修改前后的样式差异是什么？",
      "2. 这个修复是否涉及跨浏览器兼容性处理？如果有，是如何处理的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_009",
    "text": "[3.4.2](https://github.com/QingWei-Li/docsify/compare/v3.4.1...v3.4.2) (2017-03-11)",
    "answer": "# * **emojify:** add no-emoji option ([3aef37a](https://github.com/QingWei-Li/docsify/commit/3aef37a))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Git版本控制",
      "Commit提交",
      "GitHub链接",
      "Emoji处理",
      "功能选项"
    ],
    "followup_points": [
      "1. 在实现 `no-emoji` 选项时，是如何处理配置项与现有 emoji 解析逻辑的兼容性的？",
      "2. 添加该选项后，对性能或渲染流程产生了哪些具体优化或影响？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_010",
    "text": "[3.4.1](https://github.com/QingWei-Li/docsify/compare/v3.4.0...v3.4.1) (2017-03-10)",
    "answer": "# * **dom:** Disable the dom cache when vue is present, fixed [#119](https://github.com/QingWei-Li/docsify/issues/119) ([b9a7275](https://github.com/QingWei-Li/docsify/commit/b9a7275)) # [3.4.0](https://github.com/QingWei-Li/docsify/compare/v3.3.0...v3.4.0) (2017-03-09) # * **zoom-image:** add plugin ([50fa6fc](https://github.com/QingWei-Li/docsify/commit/50fa6fc)) # [3.3.0](https://github.com/QingWei-Li/docsify/compare/v3.2.0...v3.3.0) (2017-03-07) # [3.2.0](https://github.com/QingWei-Li/docsify/compare/v3.1.2...v3.2.0) (2017-02-28) # * **fetch:** load sidebar and navbar for parent path, fixed [#100](https://github.com/QingWei-Li/docsify/issues/100) ([f3fc596](https://github.com/QingWei-Li/docsify/commit/f3fc596)) * **render:** Toc rendering error, fixed [#106](https://github.com/QingWei-Li/docsify/issues/106) ([0d59ee9](https://github.com/QingWei-Li/docsify/commit/0d59ee9)) # * **search:** Localization for no data tip, close [#103](https://github.com/QingWei-Li/docsify/issues/103) ([d3c9fbd](https://github.com/QingWei-Li/docsify/commit/d3c9fbd))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "dom",
      "vue",
      "缓存",
      "插件",
      "图片缩放"
    ],
    "followup_points": [
      "1. 在 Vue 环境下禁用 DOM 缓存的具体原因是什么？是否与 Vue 的响应式系统或虚拟 DOM 机制存在冲突？",
      "2. 该修复（commit b9a7275）是否解决了所有相关的性能问题或潜在副作用？是否有后续优化或回滚的案例？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_011",
    "text": "[3.1.1](https://github.com/QingWei-Li/docsify/compare/v3.1.0...v3.1.1) (2017-02-24)",
    "answer": "# * **render:** custom cover background image ([8f9bf29](https://github.com/QingWei-Li/docsify/commit/8f9bf29)) * **search:** don't search nameLink, fixed [#102](https://github.com/QingWei-Li/docsify/issues/102) ([507d9e8](https://github.com/QingWei-Li/docsify/commit/507d9e8)) * **tpl:** extra character, fixed [#101](https://github.com/QingWei-Li/docsify/issues/101) ([d67d25f](https://github.com/QingWei-Li/docsify/commit/d67d25f)) # [3.1.0](https://github.com/QingWei-Li/docsify/compare/v3.0.5...v3.1.0) (2017-02-22) # * **search:** incorrect anchor link, fixed [#90](https://github.com/QingWei-Li/docsify/issues/90) ([b8a3d8f](https://github.com/QingWei-Li/docsify/commit/b8a3d8f)) * **sw:** update white list ([f2975a5](https://github.com/QingWei-Li/docsify/commit/f2975a5)) # * **emoji:** add emoji plugin ([855c450](https://github.com/QingWei-Li/docsify/commit/855c450))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "render",
      "search",
      "tpl",
      "commit",
      "version-control"
    ],
    "followup_points": [
      "1. 在实现自定义封面背景图片功能时，是如何处理不同设备屏幕尺寸下的图片适配问题的？",
      "2. 针对“不搜索nameLink”的修复，是否考虑过未来可能需要扩展搜索范围的情况，是否有相应的扩展机制设计？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_012",
    "text": "[3.0.5](https://github.com/QingWei-Li/docsify/compare/v3.0.4...v3.0.5) (2017-02-21)",
    "answer": "# * **event:** highlight sidebar when clicked, fixed [#86](https://github.com/QingWei-Li/docsify/issues/86) ([2a1157a](https://github.com/QingWei-Li/docsify/commit/2a1157a)) * **gen-tree:** cache toc list, fixed [#88](https://github.com/QingWei-Li/docsify/issues/88) ([3394ebb](https://github.com/QingWei-Li/docsify/commit/3394ebb)) * **layout.css:** loading style ([42b2dba](https://github.com/QingWei-Li/docsify/commit/42b2dba)) # * **pwa:** add sw.js ([f7111b5](https://github.com/QingWei-Li/docsify/commit/f7111b5))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "event",
      "sidebar",
      "highlight",
      "toc",
      "cache"
    ],
    "followup_points": [
      "1. 在实现 sidebar 高亮功能时，是如何处理点击事件与现有路由导航逻辑的冲突的？",
      "2. gen-tree 模块缓存 TOC 列表的具体实现方式是什么？是否考虑了缓存失效的场景？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_013",
    "text": "[3.0.4](https://github.com/QingWei-Li/docsify/compare/v3.0.3...v3.0.4) (2017-02-20)",
    "answer": "# * **render:** disable rendering sub list when loadSidebar is false ([35dd2e1](https://github.com/QingWei-Li/docsify/commit/35dd2e1)) * **render:** execute script ([780c1e5](https://github.com/QingWei-Li/docsify/commit/780c1e5))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "render",
      "loadSidebar",
      "sub list",
      "execute script",
      "commit"
    ],
    "followup_points": [
      "1. 当 `loadSidebar` 为 `false` 时，禁用子列表渲染的具体实现逻辑是什么？",
      "2. 执行脚本（execute script）功能的触发条件和上下文是怎样的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_014",
    "text": "[3.0.2](https://github.com/QingWei-Li/docsify/compare/v3.0.1...v3.0.2) (2017-02-19)",
    "answer": "# * **compiler:** link ([3b127a1](https://github.com/QingWei-Li/docsify/commit/3b127a1)) * **search:** add lazy input ([bf593a7](https://github.com/QingWei-Li/docsify/commit/bf593a7))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "compiler",
      "search",
      "lazy input",
      "link",
      "commit hash"
    ],
    "followup_points": [
      "1. 在compiler的link功能优化中，具体解决了哪些之前版本存在的链接相关问题？",
      "2. search模块的lazy input实现采用了什么防抖或节流机制，以平衡性能与用户体验？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_015",
    "text": "[3.0.1](https://github.com/QingWei-Li/docsify/compare/v3.0.0...v3.0.1) (2017-02-19)",
    "answer": "# * **route:** empty alias ([cd99b52](https://github.com/QingWei-Li/docsify/commit/cd99b52)) # [3.0.0](https://github.com/QingWei-Li/docsify/compare/v2.4.3...v3.0.0) (2017-02-19) # * **compiler:** link ([c7e09c3](https://github.com/QingWei-Li/docsify/commit/c7e09c3)) * **render:** support html file ([7b6a2ac](https://github.com/QingWei-Li/docsify/commit/7b6a2ac)) * **search:** escape html ([fcb66e8](https://github.com/QingWei-Li/docsify/commit/fcb66e8)) * **search:** fix default config ([2efd859](https://github.com/QingWei-Li/docsify/commit/2efd859)) # * **front-matter:** add front matter[WIP] ([dbb9278](https://github.com/QingWei-Li/docsify/commit/dbb9278)) * **render:** add auto header ([b7768b1](https://github.com/QingWei-Li/docsify/commit/b7768b1)) * **search:** Localization for search placeholder, close [#80](https://github.com/QingWei-Li/docsify/issues/80) ([2351c3e](https://github.com/QingWei-Li/docsify/commit/2351c3e)) * **themes:** add loading info ([86594a3](https://github.com/QingWei-Li/docsify/commit/86594a3))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "route",
      "compiler",
      "render",
      "html file",
      "link"
    ],
    "followup_points": [
      "1. 在3.0.1版本中修复的\"route: empty alias\"问题，具体是如何影响路由解析的？",
      "2. 3.0.0版本中新增的\"compiler: link\"功能，与之前版本相比在链接处理逻辑上有何改进？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_016",
    "text": "[2.4.2](https://github.com/QingWei-Li/docsify/compare/v2.4.1...v2.4.2) (2017-02-14)",
    "answer": "# * **index:** load file path error ([dc536a3](https://github.com/QingWei-Li/docsify/commit/dc536a3))",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Git版本控制",
      "GitHub提交记录",
      "docsify文档工具",
      "文件路径处理",
      "版本差异比较"
    ],
    "followup_points": [
      "1. 在这次修复中，具体的文件路径错误是如何发生的？",
      "2. 修复后的代码是如何确保文件路径正确加载的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_017",
    "text": "[2.4.1](https://github.com/QingWei-Li/docsify/compare/v2.4.0...v2.4.1) (2017-02-13)",
    "answer": "# * **index:** cover page ([dd0c84b](https://github.com/QingWei-Li/docsify/commit/dd0c84b)) # [2.4.0](https://github.com/QingWei-Li/docsify/compare/v2.3.0...v2.4.0) (2017-02-13) # * **hook:** add doneEach ([c6f7602](https://github.com/QingWei-Li/docsify/commit/c6f7602)) # [2.3.0](https://github.com/QingWei-Li/docsify/compare/v2.2.1...v2.3.0) (2017-02-13) # * **event:** has no effect on a FF mobile browser, fixed [#67](https://github.com/QingWei-Li/docsify/issues/67) ([0ff36c2](https://github.com/QingWei-Li/docsify/commit/0ff36c2)) * **render:** custom marked renderer ([bf559b4](https://github.com/QingWei-Li/docsify/commit/bf559b4)) * **render:** fix render link ([a866744](https://github.com/QingWei-Li/docsify/commit/a866744)) * **render:** image url ([6f87529](https://github.com/QingWei-Li/docsify/commit/6f87529)) * **render:** render link ([38ea660](https://github.com/QingWei-Li/docsify/commit/38ea660)) * **src:** fix route ([324301a](https://github.com/QingWei-Li/docsify/commit/324301a)) * **src:** get alias ([784173e](https://github.com/QingWei-Li/docsify/commit/784173e)) * **src:** get alias ([ce99a04](https://github.com/QingWei-Li/docsify/commit/ce99a04)) * **themes:** fix navbar style ([fa54b52](https://github.com/QingWei-Li/docsify/commit/fa54b52)) * **themes:** update navbar style ([4864d1b](https://github.com/QingWei-Li/docsify/commit/4864d1b)) # * **hook:** support custom plugin ([9e81a59](https://github.com/QingWei-Li/docsify/commit/9e81a59)) * **src:** add alias feature ([24412cd](https://github.com/QingWei-Li/docsify/commit/24412cd)) * **src:** dynamic title and fix sidebar style ([6b30eb6](https://github.com/QingWei-Li/docsify/commit/6b30eb6))",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Git版本控制",
      "GitHub比较功能",
      "Commit提交",
      "Release版本管理",
      "Markdown封面页"
    ],
    "followup_points": [
      "1. 在实现 cover page 功能时，是如何处理不同页面之间的路由和状态管理的？",
      "2. `doneEach` hook 的设计初衷是什么？在实际项目中，它通常被用于哪些场景？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_018",
    "text": "[2.2.1](https://github.com/QingWei-Li/docsify/compare/v2.2.0...v2.2.1) (2017-02-11)",
    "answer": "# * **event:** scroll active sidebar ([50f5fc2](https://github.com/QingWei-Li/docsify/commit/50f5fc2)) * **search:** crash when not content, fixed [#68](https://github.com/QingWei-Li/docsify/issues/68) ([9d3cc89](https://github.com/QingWei-Li/docsify/commit/9d3cc89)) * **search:** not work in mobile ([3941304](https://github.com/QingWei-Li/docsify/commit/3941304)) # [2.2.0](https://github.com/QingWei-Li/docsify/compare/v2.1.0...v2.2.0) (2017-02-09) # * **plugins:** add Google Analytics plugin ([#66](https://github.com/QingWei-Li/docsify/issues/66)) ([ac61bb0](https://github.com/QingWei-Li/docsify/commit/ac61bb0)) # [2.1.0](https://github.com/QingWei-Li/docsify/compare/v2.0.3...v2.1.0) (2017-02-09) # * render name ([12e2479](https://github.com/QingWei-Li/docsify/commit/12e2479)) * **vue.css:** update sidebar style ([fc140ef](https://github.com/QingWei-Li/docsify/commit/fc140ef)) # * add search, close [#43](https://github.com/QingWei-Li/docsify/issues/43) ([eb5ff3e](https://github.com/QingWei-Li/docsify/commit/eb5ff3e))",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "event",
      "scroll",
      "search",
      "mobile",
      "bugfix"
    ],
    "followup_points": [
      "1. 关于\"scroll active sidebar\"功能，具体是如何实现滚动时激活对应侧边栏项的？使用了什么技术方案或监听机制？",
      "2. 针对\"search not work in mobile\"的问题，修复后的方案是如何适配移动端搜索逻辑的？是否涉及事件监听或DOM操作的调整？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_019",
    "text": "[2.0.3](https://github.com/QingWei-Li/docsify/compare/v2.0.2...v2.0.3) (2017-02-07)",
    "answer": "# * css var polyfill ([8cd386a](https://github.com/QingWei-Li/docsify/commit/8cd386a)) * css var polyfill ([cbaee21](https://github.com/QingWei-Li/docsify/commit/cbaee21)) * rendering emojis ([8c7e4d7](https://github.com/QingWei-Li/docsify/commit/8c7e4d7))",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "CSS变量",
      "Polyfill",
      "渲染",
      "Emoji",
      "版本控制"
    ],
    "followup_points": [
      "1. 在引入CSS变量polyfill时，遇到了哪些兼容性挑战，是如何解决的？",
      "2. 实现emoji渲染功能时，是否考虑了性能优化或不同渲染引擎的差异？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_020",
    "text": "[2.0.2](https://github.com/QingWei-Li/docsify/compare/v2.0.1...v2.0.2) (2017-02-05)",
    "answer": "# * button style in cover page ([4470855](https://github.com/QingWei-Li/docsify/commit/4470855))",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "CSS样式",
      "前端开发",
      "版本控制",
      "Git提交",
      "Markdown渲染"
    ],
    "followup_points": [
      "1. 这个 commit 修改了封面页中 `*` 按钮的样式，具体是哪些 CSS 属性发生了变化？",
      "2. 当时用户反馈或 issue 中提到的主要问题是什么，促使这次样式调整？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_021",
    "text": "[2.0.1](https://github.com/QingWei-Li/docsify/compare/v2.0.0...v2.0.1) (2017-02-05)",
    "answer": "# [2.0.0](https://github.com/QingWei-Li/docsify/compare/v1.10.5...v2.0.0) (2017-02-05) # * customize the theme color ([5cc9f05](https://github.com/QingWei-Li/docsify/commit/5cc9f05))",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "版本控制",
      "Git",
      "GitHub",
      "更新日志",
      "主题定制"
    ],
    "followup_points": [
      "1. 在自定义主题颜色的实现过程中，遇到了哪些技术挑战或兼容性问题？",
      "2. 主题颜色的自定义功能是否支持动态切换，或者需要重新加载页面？用户反馈中是否有相关的使用体验优化建议？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_022",
    "text": "[1.10.1](https://github.com/QingWei-Li/docsify/compare/v1.10.0...v1.10.1) (2017-01-25)",
    "answer": "# [1.10.0](https://github.com/QingWei-Li/docsify/compare/v1.9.0...v1.10.0) (2017-01-25) # [1.9.0](https://github.com/QingWei-Li/docsify/compare/v1.8.0...v1.9.0) (2017-01-24) # [1.8.0](https://github.com/QingWei-Li/docsify/compare/v1.7.4...v1.8.0) (2017-01-24)",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Git版本控制",
      "GitHub Releases",
      "Changelog管理",
      "Semantic Versioning",
      "docsify框架"
    ],
    "followup_points": [
      "1. 在这个版本更新中，是否解决了之前版本存在的性能或兼容性问题？",
      "2. 相较于1.9.0版本，1.10.1版本的更新是否针对特定用户反馈进行了优化？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_023",
    "text": "[1.7.1](https://github.com/QingWei-Li/docsify/compare/v1.7.0...v1.7.1) (2017-01-12)",
    "answer": "# [1.7.0](https://github.com/QingWei-Li/docsify/compare/v1.6.1...v1.7.0) (2017-01-12)",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Git",
      "版本控制",
      "GitHub",
      "Release Notes",
      "Changelog"
    ],
    "followup_points": [
      "1. 在这个版本更新中，具体修复了哪些关键问题？",
      "2. 这个版本的更新对用户的使用体验或功能有哪些实际影响？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_024",
    "text": "[1.6.1](https://github.com/QingWei-Li/docsify/compare/v1.6.0...v1.6.1) (2017-01-10)",
    "answer": "# [1.6.0](https://github.com/QingWei-Li/docsify/compare/v1.5.2...v1.6.0) (2017-01-10)",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Git",
      "版本控制",
      "GitHub",
      "Release Notes",
      "Changelog"
    ],
    "followup_points": [
      "1. 在1.6.0到1.6.1的更新中，具体修复了哪些问题或改进了哪些功能？",
      "2. 这次更新是否涉及性能优化或兼容性调整？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_025",
    "text": "[1.5.1](https://github.com/QingWei-Li/docsify/compare/v1.5.0...v1.5.1) (2017-01-09)",
    "answer": "# [1.5.0](https://github.com/QingWei-Li/docsify/compare/v1.4.3...v1.5.0) (2017-01-04) # * Markdown parser is configurable, [#42](https://github.com/QingWei-Li/docsify/issues/42) ([8b1000a](https://github.com/QingWei-Li/docsify/commit/8b1000a))",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Markdown parser",
      "版本控制",
      "Git commit",
      "GitHub issues",
      "GitHub compare"
    ],
    "followup_points": [
      "1. 在实现 Markdown parser 可配置化的过程中，遇到了哪些技术挑战或权衡？",
      "2. 用户可以通过哪些具体方式配置 Markdown parser，支持哪些自定义选项或扩展？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_026",
    "text": "[1.4.1](https://github.com/QingWei-Li/docsify/compare/v1.4.0...v1.4.1) (2016-12-31)",
    "answer": "# [1.4.0](https://github.com/QingWei-Li/docsify/compare/v1.3.5...v1.4.0) (2016-12-31)",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Git",
      "版本控制",
      "GitHub",
      "Release Notes",
      "Changelog"
    ],
    "followup_points": [
      "1. 在从 v1.4.0 升级到 v1.4.1 的过程中，是否有遇到任何兼容性问题或需要特别注意的变更点？",
      "2. v1.4.1 版本中修复的问题是否对现有用户的使用习惯或文档结构产生了影响？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_027",
    "text": "[1.3.1](https://github.com/QingWei-Li/docsify/compare/v1.3.0...v1.3.1) (2016-12-22)",
    "answer": "# [1.3.0](https://github.com/QingWei-Li/docsify/compare/v1.2.0...v1.3.0) (2016-12-21) # [1.2.0](https://github.com/QingWei-Li/docsify/compare/v1.1.7...v1.2.0) (2016-12-20)",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Git版本控制",
      "GitHub比较功能",
      "Markdown格式",
      "Release版本管理",
      "Changelog更新日志"
    ],
    "followup_points": [
      "1. 在1.3.1版本中，是否有针对1.3.0版本发布后收集到的用户反馈进行修复或优化？",
      "2. 从1.3.0到1.3.1的更新周期较短，是否遇到了紧急问题需要快速迭代？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_028",
    "text": "[1.1.1](https://github.com/QingWei-Li/docsify/compare/v1.1.0...v1.1.1) (2016-12-17)",
    "answer": "# [1.1.0](https://github.com/QingWei-Li/docsify/compare/v1.0.3...v1.1.0) (2016-12-16)",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Git版本控制",
      "GitHub比较功能",
      "Markdown链接语法",
      "Release版本管理",
      "语义化版本号"
    ],
    "followup_points": [
      "1. 在这个版本更新中，具体修复了哪些关键问题或优化了哪些性能瓶颈？",
      "2. 从 v1.1.0 到 v1.1.1 的更新周期较短，是否遇到了紧急的 bug 或用户反馈？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_029",
    "text": "[1.0.1](https://github.com/QingWei-Li/docsify/compare/v1.0.0...v1.0.1) (2016-12-08)",
    "answer": "# [1.0.0](https://github.com/QingWei-Li/docsify/compare/v0.7.0...v1.0.0) (2016-12-08) # [0.7.0](https://github.com/QingWei-Li/docsify/compare/v0.6.1...v0.7.0) (2016-11-30)",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Git",
      "版本控制",
      "GitHub",
      "Release Notes",
      "Changelog"
    ],
    "followup_points": [
      "1. 在1.0.1版本中，具体修复了哪些问题或优化了哪些功能？",
      "2. 从1.0.0到1.0.1的更新间隔较短，是否遇到了紧急的bug修复需求？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_030",
    "text": "[0.6.1](https://github.com/QingWei-Li/docsify/compare/v0.6.0...v0.6.1) (2016-11-29)",
    "answer": "# [0.6.0](https://github.com/QingWei-Li/docsify/compare/v0.5.0...v0.6.0) (2016-11-29) # [0.5.0](https://github.com/QingWei-Li/docsify/compare/v0.4.2...v0.5.0) (2016-11-28)",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Git版本控制",
      "GitHub比较功能",
      "语义化版本号",
      "发布日志",
      "代码变更追踪"
    ],
    "followup_points": [
      "1. 在v0.6.0到v0.6.1的更新中，是否有任何关键修复或改进是针对性能优化的？",
      "2. v0.5.0版本中引入的新功能，在后续的v0.6.0或v0.6.1版本中是否有进一步的调整或反馈？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_031",
    "text": "[0.4.1](https://github.com/QingWei-Li/docsify/compare/v0.4.0...v0.4.1) (2016-11-28)",
    "answer": "# [0.4.0](https://github.com/QingWei-Li/docsify/compare/v0.3.1...v0.4.0) (2016-11-27) # * custom sidebar, [#4](https://github.com/QingWei-Li/docsify/issues/4) ([#5](https://github.com/QingWei-Li/docsify/issues/5)) ([37e7984](https://github.com/QingWei-Li/docsify/commit/37e7984))",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "版本控制",
      "Git",
      "GitHub",
      "Commit",
      "Pull Request"
    ],
    "followup_points": [
      "1. 在实现自定义侧边栏功能时，主要的技术挑战是什么？",
      "2. 自定义侧边栏功能的实现是否对项目的性能或用户体验产生了显著影响？如果有，具体体现在哪些方面？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_032",
    "text": "[0.3.1](https://github.com/QingWei-Li/docsify/compare/v0.3.0...v0.3.1) (2016-11-27)",
    "answer": "# [0.3.0](https://github.com/QingWei-Li/docsify/compare/v0.2.1...v0.3.0) (2016-11-27)",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Git",
      "版本控制",
      "GitHub",
      "Release Notes",
      "Changelog"
    ],
    "followup_points": [
      "1. 在这个版本更新中，具体修复了哪些关键问题或优化了哪些核心功能？",
      "2. 版本号从 0.3.0 升级到 0.3.1，是否遵循了语义化版本规范（SemVer）？如果是，这次更新属于补丁版本（Patch）的原因是什么？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_HISTORY_033",
    "text": "[0.2.1](https://github.com/QingWei-Li/docsify/compare/v0.2.0...v0.2.1) (2016-11-26)",
    "answer": "# [0.2.0](https://github.com/QingWei-Li/docsify/compare/v0.1.0...v0.2.0) (2016-11-26) # [0.1.0](https://github.com/QingWei-Li/docsify/compare/v0.0.5...v0.1.0) (2016-11-26)",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Git版本控制",
      "GitHub比较功能",
      "语义化版本号",
      "Release管理",
      "变更日志"
    ],
    "followup_points": [
      "1. 在这个版本更新中，主要修复了哪些具体问题或改进了哪些功能？",
      "2. 从 v0.1.0 到 v0.2.0 的迭代过程中，团队是如何决定优先级和开发方向的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/HISTORY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CONTRIBUTING_000",
    "text": "Introduction",
    "answer": "First, thank you for considering contributing to docsify! It's people like you that make the open source community such a great community! 😊 We welcome any type of contribution, not only code. You can help with - **QA**: file bug reports, the more details you can give the better (e.g. screenshots with the console open) - **Marketing**: writing blog posts, howto's, printing stickers, ... - **Community**: presenting the project at meetups, organizing a dedicated meetup for the local community, ... - **Code**: take a look at the [open issues](issues). Even if you can't write code, commenting on them, showing that you care about a given issue matters. It helps us triage them. - **Money**: we welcome financial contributions in full transparency on our [open collective](https://opencollective.com/docsify).",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "开源贡献",
      "文档贡献",
      "QA测试",
      "社区协作",
      "问题报告"
    ],
    "followup_points": [
      "1. 除了 QA 和代码贡献外，还有哪些非代码类型的贡献方式可以在 docsify 社区中参与？",
      "2. 对于新贡献者，社区是否有特定的引导流程或文档来帮助他们快速上手，比如如何有效提交 bug 报告或参与文档改进？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CONTRIBUTING.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CONTRIBUTING_001",
    "text": "Your First Contribution",
    "answer": "Working on your first Pull Request? You can learn how from this *free* series, [How to Contribute to an Open Source Project on GitHub](https://app.egghead.io/playlists/how-to-contribute-to-an-open-source-project-on-github).",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Open Source",
      "GitHub",
      "Pull Request",
      "Contribution",
      "Developer Onboarding"
    ],
    "followup_points": [
      "1. 在完成第一个 Pull Request 的过程中，您遇到过哪些具体的挑战，以及是如何解决的？",
      "2. 除了推荐的系列教程，您还通过哪些资源或实践来提升自己在开源项目中的贡献能力？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CONTRIBUTING.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CONTRIBUTING_002",
    "text": "Submitting code",
    "answer": "Any code change should be submitted as a pull request. The description should explain what the code does and give steps to execute it. The pull request should also contain tests.",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "代码提交",
      "Pull Request",
      "代码审查",
      "测试覆盖",
      "执行步骤"
    ],
    "followup_points": [
      "1. 在提交代码时，如果遇到紧急修复或小改动，是否会考虑简化流程？如果有，具体是如何平衡效率与代码质量的？",
      "2. 对于 pull request 中的测试部分，是否有覆盖率要求？如果有，通常是如何确保测试覆盖到关键逻辑的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CONTRIBUTING.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CONTRIBUTING_003",
    "text": "Code review process",
    "answer": "The bigger the pull request, the longer it will take to review and merge. Try to break down large pull requests in smaller chunks that are easier to review and merge. It is also always helpful to have some context for your pull request. What was the purpose? Why does it matter to you?",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "Code Review",
      "Pull Request",
      "Code Quality",
      "Team Collaboration",
      "Change Management"
    ],
    "followup_points": [
      "1. 在团队中，通常如何定义\"大\"和\"小\"的pull request，有没有具体的代码行数或功能模块划分标准？",
      "2. 除了拆分PR和提供上下文，团队是否有其他机制（如自动化工具或checklist）来优化Code review的效率和质量？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CONTRIBUTING.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CONTRIBUTING_004",
    "text": "Financial contributions",
    "answer": "We also welcome financial contributions in full transparency on our [open collective](https://opencollective.com/docsify). Anyone can file an expense. If the expense makes sense for the development of the community, it will be \"merged\" in the ledger of our open collective by the core contributors and the person who filed the expense will be reimbursed.",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "开源社区治理",
      "财务透明度",
      "Open Collective",
      "费用报销流程",
      "核心贡献者权限"
    ],
    "followup_points": [
      "1. How do core contributors determine if an expense \"makes sense for the development of the community\"? Are there specific criteria or a voting process involved?",
      "2. What measures are in place to ensure transparency and accountability for financial contributions, especially regarding how funds are tracked and reported to the community?"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CONTRIBUTING.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_000",
    "text": "[4.13.1](https://github.com/docsifyjs/docsify/compare/v4.13.0...v4.13.1) (2023-06-24)",
    "answer": "# * enhancement of isExternal ([#2093](https://github.com/docsifyjs/docsify/issues/2093)) ([6a7d15b](https://github.com/docsifyjs/docsify/commit/6a7d15b1d5b93e19d3cf9a328cdbf5f1a166b5bd)) * fix cross-origin links in history router mode ([#1967](https://github.com/docsifyjs/docsify/issues/1967)) ([2312fee](https://github.com/docsifyjs/docsify/commit/2312feef459211a8bcdcbf9164a9ffe051609b70)) * genIndex error for search ([#1933](https://github.com/docsifyjs/docsify/issues/1933)) ([68d8735](https://github.com/docsifyjs/docsify/commit/68d873587c29d694ece466177984aa5fd739dd4b)) # [4.13.0](https://github.com/docsifyjs/docsify/compare/v4.12.4...v4.13.0) (2022-10-26) # * cornerExternalLinkTarget config. ([#1814](https://github.com/docsifyjs/docsify/issues/1814)) ([54cc5f9](https://github.com/docsifyjs/docsify/commit/54cc5f939b9499ae56604f589eef4e3f1c13cdc5)) * correctly fix missing +1, -1 ([#1722](https://github.com/docsifyjs/docsify/issues/1722)) ([719dcbe](https://github.com/docsifyjs/docsify/commit/719dcbea5cb0c8b0835f8e9fc473b094feecb7ec)) * Coverpage when content > viewport height ([#1744](https://github.com/docsifyjs/docsify/issues/1744)) ([301b516](https://github.com/docsifyjs/docsify/commit/301b5169613e95765eda335a4b21d0f9f9cbbbfd)), closes [#381](https://github.com/docsifyjs/docsify/issues/381) * filter null node first. ([#1909](https://github.com/docsifyjs/docsify/issues/1909)) ([d27af3d](https://github.com/docsifyjs/docsify/commit/d27af3dd09a882fce4f1e2774065de57a3501858)) * fix docsify-ignore in seach title. ([#1872](https://github.com/docsifyjs/docsify/issues/1872)) ([9832805](https://github.com/docsifyjs/docsify/commit/9832805681cc6099e9c78deecf6dc0c6fb61fd9b)) * fix search with no content. ([#1878](https://github.com/docsifyjs/docsify/issues/1878)) ([9b74744](https://github.com/docsifyjs/docsify/commit/9b74744299ece0108573a142e5a2e949dc569254)) * Ignore emoji shorthand codes in URIs ([#1847](https://github.com/docsifyjs/docsify/issues/1847)) ([3c9b3d9](https://github.com/docsifyjs/docsify/commit/3c9b3d9702bb05a5ff45a4ce4233e144cf1ebecb)), closes [#1823](https://github.com/docsifyjs/docsify/issues/1823) * Legacy bugs (styles, site plugin error, and dev server error) ([#1743](https://github.com/docsifyjs/docsify/issues/1743)) ([fa6df6d](https://github.com/docsifyjs/docsify/commit/fa6df6d58487ec294e22be04ac159dfb5745bd66)) * package.json & package-lock.json to reduce vulnerabilities ([#1756](https://github.com/docsifyjs/docsify/issues/1756)) ([2dc5b12](https://github.com/docsifyjs/docsify/commit/2dc5b12b715e3ad1922a6401e3fd9837a99ef9c0)) * packages/docsify-server-renderer/package.json & packages/docsify-server-renderer/package-lock.json to reduce vulnerabilities ([#1715](https://github.com/docsifyjs/docsify/issues/1715)) ([c1227b2](https://github.com/docsifyjs/docsify/commit/c1227b22cb8a3fb6c362ca8ac109082ab2251cc3)) # * Emoji build ([#1766](https://github.com/docsifyjs/docsify/issues/1766)) ([ba5ee26](https://github.com/docsifyjs/docsify/commit/ba5ee26f00e957b58173f96b1901f6ffd3d8e5f5)) * Native emoji w/ image-based fallbacks and improved parsing ([#1746](https://github.com/docsifyjs/docsify/issues/1746)) ([35002c9](https://github.com/docsifyjs/docsify/commit/35002c92b762f0d12e51582d7de7914fa380596a)), closes [#779](https://github.com/docsifyjs/docsify/issues/779) * Plugin error handling ([#1742](https://github.com/docsifyjs/docsify/issues/1742)) ([63b2535](https://github.com/docsifyjs/docsify/commit/63b2535a45a98945ec897277f4fbddec2ddba887))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "isExternal",
      "cross-origin",
      "history router",
      "link handling",
      "enhancement"
    ],
    "followup_points": [
      "1. 在修复跨域链接问题时，具体遇到了哪些技术挑战，以及是如何解决跨域资源访问限制的？",
      "2. 针对 `isExternal` 的增强是否涉及对现有链接解析逻辑的重构，以及如何确保向后兼容性？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_001",
    "text": "[4.12.2](https://github.com/docsifyjs/docsify/compare/v4.12.1...v4.12.2) (2022-01-06)",
    "answer": "# * Add escapeHtml for search ([#1551](https://github.com/docsifyjs/docsify/issues/1551)) ([c24f7f6](https://github.com/docsifyjs/docsify/commit/c24f7f6f0b87a87f6dd3755f69eb0969ebb029c9)) * allow also \" inside of an embed ([ec16e4a](https://github.com/docsifyjs/docsify/commit/ec16e4a9d5718ac4f4c25bb3dcaea3b7551372e0)) * buble theme missing generic fallback font ([#1568](https://github.com/docsifyjs/docsify/issues/1568)) ([37d9f0e](https://github.com/docsifyjs/docsify/commit/37d9f0e1214276e93b2a11ed87390aafa1bdbcec)) * Cannot read property 'classList' of null ([#1527](https://github.com/docsifyjs/docsify/issues/1527)) ([d6df2b8](https://github.com/docsifyjs/docsify/commit/d6df2b85a99371bb9a87402a10dd515bb734182e)), closes [/github.com/docsifyjs/docsify/pull/1527#issuecomment-793455105](https://github.com//github.com/docsifyjs/docsify/pull/1527/issues/issuecomment-793455105) * Cannot read property 'tagName' of null ([#1655](https://github.com/docsifyjs/docsify/issues/1655)) ([c3cdadc](https://github.com/docsifyjs/docsify/commit/c3cdadc37137edcd9e219359973902d2fc8b66ff)), closes [#1154](https://github.com/docsifyjs/docsify/issues/1154) [/github.com/docsifyjs/docsify/blob/develop/src/core/router/history/html5.js#L25-L27](https://github.com//github.com/docsifyjs/docsify/blob/develop/src/core/router/history/html5.js/issues/L25-L27) [/github.com/docsifyjs/docsify/blob/develop/src/core/router/history/hash.js#L47-L49](https://github.com//github.com/docsifyjs/docsify/blob/develop/src/core/router/history/hash.js/issues/L47-L49) * upgrade debug from 4.3.2 to 4.3.3 ([#1692](https://github.com/docsifyjs/docsify/issues/1692)) ([40e7749](https://github.com/docsifyjs/docsify/commit/40e77490c68b4143c75dfaebcd0b7f640581306b)) * Upgrade docsify from 4.12.0 to 4.12.1 ([#1544](https://github.com/docsifyjs/docsify/issues/1544)) ([d607f6d](https://github.com/docsifyjs/docsify/commit/d607f6d71c35b50f586806a832f65061f5e3427e)) * upgrade dompurify from 2.2.6 to 2.2.7 ([#1552](https://github.com/docsifyjs/docsify/issues/1552)) ([407e4d4](https://github.com/docsifyjs/docsify/commit/407e4d4f3de78bebd639a3fdae751f8045728e57)) * Upgrade dompurify from 2.2.6 to 2.2.7 ([#1553](https://github.com/docsifyjs/docsify/issues/1553)) ([93c48f3](https://github.com/docsifyjs/docsify/commit/93c48f3d615d95dba550a0e95df6b545d68c3593)) * upgrade dompurify from 2.2.7 to 2.2.8 ([#1577](https://github.com/docsifyjs/docsify/issues/1577)) ([0dd44cc](https://github.com/docsifyjs/docsify/commit/0dd44cc828cc54f7c3b776d45b32925b66cae499)) * upgrade dompurify from 2.2.7 to 2.3.0 ([#1619](https://github.com/docsifyjs/docsify/issues/1619)) ([66303fe](https://github.com/docsifyjs/docsify/commit/66303fec4c7115621e556ad742cfac9d19f26bd9)) * upgrade dompurify from 2.2.8 to 2.2.9 ([#1600](https://github.com/docsifyjs/docsify/issues/1600)) ([baf5a8a](https://github.com/docsifyjs/docsify/commit/baf5a8a4962656d8be8f714283064d2ea10c7e14)) * upgrade dompurify from 2.2.9 to 2.3.0 ([#1616](https://github.com/docsifyjs/docsify/issues/1616)) ([b07fa3c](https://github.com/docsifyjs/docsify/commit/b07fa3cc8323e63dd7b105c7e29b2e1914f5c117)) * upgrade dompurify from 2.3.0 to 2.3.1 ([#1635](https://github.com/docsifyjs/docsify/issues/1635)) ([5ac8237](https://github.com/docsifyjs/docsify/commit/5ac8237cc76e19ca2b373a1a1da6eb4a4da6d8b2)) * upgrade dompurify from 2.3.1 to 2.3.2 ([#1647](https://github.com/docsifyjs/docsify/issues/1647)) ([ff6acfa](https://github.com/docsifyjs/docsify/commit/ff6acfa7623a7db8b00d62c51a9c3037215c4888)) * upgrade node-fetch from 2.6.1 to 2.6.2 ([#1641](https://github.com/docsifyjs/docsify/issues/1641)) ([6ee1c14](https://github.com/docsifyjs/docsify/commit/6ee1c142769a6442aa8c1523ab215106707fa7fc)) * upgrade node-fetch from 2.6.2 to 2.6.4 ([#1649](https://github.com/docsifyjs/docsify/issues/1649)) ([6f81034](https://github.com/docsifyjs/docsify/commit/6f81034ba6a7a6b64ccf1acd2d1fc73761f70a63)) * upgrade node-fetch from 2.6.4 to 2.6.5 ([#1654](https://github.com/docsifyjs/docsify/issues/1654)) ([d16e657](https://github.com/docsifyjs/docsify/commit/d16e657f708777e8377d8e158b50b4010623282d)) * upgrade node-fetch from 2.6.5 to 2.6.6 ([#1668](https://github.com/docsifyjs/docsify/issues/1668)) ([cefe3f8](https://github.com/docsifyjs/docsify/commit/cefe3f87e697a6c54a74d601df2eeb331fcd8933))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "HTML转义",
      "搜索功能",
      "安全漏洞修复",
      "Markdown嵌入",
      "版本控制"
    ],
    "followup_points": [
      "1. 在实现 `escapeHtml` 功能时，具体是如何处理搜索结果中的 HTML 字符的？是否考虑了所有可能的 XSS 攻击向量？",
      "2. 关于允许 `\"` 在嵌入内容中出现，是出于什么场景的考虑？这个改动是否会影响现有的嵌入功能的安全性或兼容性？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_002",
    "text": "[4.12.1](https://github.com/docsifyjs/docsify/compare/v4.12.0...v4.12.1) (2021-03-07)",
    "answer": "# * isExternal check with malformed URL + tests ([#1510](https://github.com/docsifyjs/docsify/issues/1510)) ([ff2a66f](https://github.com/docsifyjs/docsify/commit/ff2a66f12752471277fe81a64ad6c4b2c08111fe)), closes [#1477](https://github.com/docsifyjs/docsify/issues/1477) [#1126](https://github.com/docsifyjs/docsify/issues/1126) [#1489](https://github.com/docsifyjs/docsify/issues/1489) * Replace ES6 usage for IE11 compatibility ([#1500](https://github.com/docsifyjs/docsify/issues/1500)) ([a0f61b2](https://github.com/docsifyjs/docsify/commit/a0f61b2af72cb888ea5b635021a5c9da6beb7ac5)) * theme switcher in IE11 ([#1502](https://github.com/docsifyjs/docsify/issues/1502)) ([8cda078](https://github.com/docsifyjs/docsify/commit/8cda07891afeb1ea6e198d2a600f205357ab4b89)) * Upgrade docsify from 4.11.6 to 4.12.0 ([#1518](https://github.com/docsifyjs/docsify/issues/1518)) ([47cd86c](https://github.com/docsifyjs/docsify/commit/47cd86c8f196a241fc23720e3addfe95d4c973cd)) # * Support search when there is no title ([#1519](https://github.com/docsifyjs/docsify/issues/1519)) ([bc37268](https://github.com/docsifyjs/docsify/commit/bc3726853fb2d1f9241927ea0317970ab0c8a2f2)) # - Fix missing carbon ([#1501](https://github.com/docsifyjs/docsify/issues/1501)) - Change Gitter to Discord throughout project ([#1507](https://github.com/docsifyjs/docsify/issues/1507)) - Add test cases on isExternal ([#1515](https://github.com/docsifyjs/docsify/issues/1515)) # [4.12.0](https://github.com/docsifyjs/docsify/compare/v4.11.6...v4.12.0) (2021-02-08) # * add missing argument for highlighting code ([#1365](https://github.com/docsifyjs/docsify/issues/1365)) ([f35bf99](https://github.com/docsifyjs/docsify/commit/f35bf99d9c762774e328b30347707e62eb8e6f63)) * Can't search homepage content ([#1391](https://github.com/docsifyjs/docsify/issues/1391)) ([25bc9b7](https://github.com/docsifyjs/docsify/commit/25bc9b7eb7e878a6a50ed5f91d33d6a75f9811b0)) * Cannot read property 'startsWith' of undefined ([#1358](https://github.com/docsifyjs/docsify/issues/1358)) ([9351729](https://github.com/docsifyjs/docsify/commit/9351729634b52db0e7e241bed7784fbcd5c39fe0)) * Cannot read property level of undefined ([#1357](https://github.com/docsifyjs/docsify/issues/1357)) ([4807e58](https://github.com/docsifyjs/docsify/commit/4807e58cb994de83f063cb82d2b4a695f29378c8)) * cannot search list content ([#1361](https://github.com/docsifyjs/docsify/issues/1361)) ([8d17dcb](https://github.com/docsifyjs/docsify/commit/8d17dcbe68048d654e62adb01a3925e39a8e0c44)) * duplicate search content when `/README` or `/` exists in the sidebar ([#1403](https://github.com/docsifyjs/docsify/issues/1403)) ([7c3bf98](https://github.com/docsifyjs/docsify/commit/7c3bf98df869188d5956ed1a331f7048b6eba441)) * package.json & package-lock.json to reduce vulnerabilities ([#1419](https://github.com/docsifyjs/docsify/issues/1419)) ([69b6907](https://github.com/docsifyjs/docsify/commit/69b6907c864dbcdf1fe5c75f51a80e6ae6ec279d)) * packages/docsify-server-renderer/package.json & packages/docsify-server-renderer/package-lock.json to reduce vulnerabilities ([#1389](https://github.com/docsifyjs/docsify/issues/1389)) ([62cd35e](https://github.com/docsifyjs/docsify/commit/62cd35ee8345270aab7a48bc761db007d54a0f48)) * packages/docsify-server-renderer/package.json & packages/docsify-server-renderer/package-lock.json to reduce vulnerabilities ([#1418](https://github.com/docsifyjs/docsify/issues/1418)) ([58fbca0](https://github.com/docsifyjs/docsify/commit/58fbca00ebd12f636c213d386761df9ebfb2bd4c)) * Prevent loading remote content via URL hash ([#1489](https://github.com/docsifyjs/docsify/issues/1489)) ([14ce7f3](https://github.com/docsifyjs/docsify/commit/14ce7f3d862ac79fc7d9d316cb2e057d50e1b506)), closes [#1477](https://github.com/docsifyjs/docsify/issues/1477) [#1126](https://github.com/docsifyjs/docsify/issues/1126) * search on homepage test ([#1398](https://github.com/docsifyjs/docsify/issues/1398)) ([ee550d0](https://github.com/docsifyjs/docsify/commit/ee550d0c51f222851854c7cd7e9e6f76e26eb6f4)) * search titles containing ignored characters ([#1395](https://github.com/docsifyjs/docsify/issues/1395)) ([a2ebb21](https://github.com/docsifyjs/docsify/commit/a2ebb2192ac73211a8924111d736df9574abf61b)) * sidebar active class and expand don't work as expect when use \"space\" in markdown filename ([#1454](https://github.com/docsifyjs/docsify/issues/1454)) ([dcf5a64](https://github.com/docsifyjs/docsify/commit/dcf5a644eb6a2eef65fb940f3407c12828a679bc)), closes [#1032](https://github.com/docsifyjs/docsify/issues/1032) * sidebar horizontal scroll bar ([#1362](https://github.com/docsifyjs/docsify/issues/1362)) ([b480822](https://github.com/docsifyjs/docsify/commit/b480822286c66b478e5a7a9b2c82a10b99c69121)) * sidebar title error ([#1360](https://github.com/docsifyjs/docsify/issues/1360)) ([2100fc3](https://github.com/docsifyjs/docsify/commit/2100fc318b009c6e448e48ffff6a693f1988916c)) * slugs are still broken when headings contain html ([#1443](https://github.com/docsifyjs/docsify/issues/1443)) ([76c5e68](https://github.com/docsifyjs/docsify/commit/76c5e685d75ee6df9acc0a7cf92d5daa138c3240)) * the sidebar links to another site. ([#1336](https://github.com/docsifyjs/docsify/issues/1336)) ([c9d4f7a](https://github.com/docsifyjs/docsify/commit/c9d4f7abc94a2cbc4bb558013775df380c1c8376)) * title error when sidebar link exists with html tag ([#1404](https://github.com/docsifyjs/docsify/issues/1404)) ([8ccc202](https://github.com/docsifyjs/docsify/commit/8ccc20225104376af2e5df6757c4dbd58c0e758e)), closes [#1408](https://github.com/docsifyjs/docsify/issues/1408) * Unable to navigate on server without default index support ([#1372](https://github.com/docsifyjs/docsify/issues/1372)) ([759ffac](https://github.com/docsifyjs/docsify/commit/759ffac992b19dbb05b92114ec5620d3bb180d0d)) * upgrade debug from 4.1.1 to 4.3.0 ([#1390](https://github.com/docsifyjs/docsify/issues/1390)) ([ae45b32](https://github.com/docsifyjs/docsify/commit/ae45b3201ba03303a2feb5a347b18fda818a569a)) * upgrade debug from 4.3.0 to 4.3.1 ([#1446](https://github.com/docsifyjs/docsify/issues/1446)) ([bc3350f](https://github.com/docsifyjs/docsify/commit/bc3350f6e6bfe670c95569b4e9c51321f5c7dbb9)) * upgrade debug from 4.3.1 to 4.3.2 ([#1463](https://github.com/docsifyjs/docsify/issues/1463)) ([df21153](https://github.com/docsifyjs/docsify/commit/df21153ab5e841ad89707e07c68a04873a2f3fe8)) * upgrade docsify from 4.11.4 to 4.11.6 ([#1373](https://github.com/docsifyjs/docsify/issues/1373)) ([c2d12ed](https://github.com/docsifyjs/docsify/commit/c2d12ed27fe86b0c5cd690b4d8a22bf06d2a90b9)) * upgrade dompurify from 2.0.17 to 2.1.0 ([#1397](https://github.com/docsifyjs/docsify/issues/1397)) ([1863d8e](https://github.com/docsifyjs/docsify/commit/1863d8edb70da234bf7f211986ba71706351682f)) * upgrade dompurify from 2.1.0 to 2.1.1 ([#1402](https://github.com/docsifyjs/docsify/issues/1402)) ([8cf9fd8](https://github.com/docsifyjs/docsify/commit/8cf9fd8150bd67709c68d8dfe4dc881624583ac8)) * upgrade dompurify from 2.2.2 to 2.2.3 ([#1457](https://github.com/docsifyjs/docsify/issues/1457)) ([720d909](https://github.com/docsifyjs/docsify/commit/720d9091c8e571d6c891426983f54d9c94739182)) * upgrade dompurify from 2.2.2 to 2.2.6 ([#1483](https://github.com/docsifyjs/docsify/issues/1483)) ([eee9507](https://github.com/docsifyjs/docsify/commit/eee9507d435459ae8e68e1112bb58a63b2f58530)) * upgrade dompurify from 2.2.3 to 2.2.6 ([#1482](https://github.com/docsifyjs/docsify/issues/1482)) ([7adad57](https://github.com/docsifyjs/docsify/commit/7adad57df1b7efa469b0cde37f788c36dc27cf8b)) * upgrade marked from 1.2.4 to 1.2.9 ([#1486](https://github.com/docsifyjs/docsify/issues/1486)) ([716a7fa](https://github.com/docsifyjs/docsify/commit/716a7fa777a1eee66964977e1d4405cff3275c53)) * upgrade prismjs from 1.21.0 to 1.22.0 ([#1415](https://github.com/docsifyjs/docsify/issues/1415)) ([0806f48](https://github.com/docsifyjs/docsify/commit/0806f48531b6cb5e6a395c12ab88f0b59281bbf8)) * upgrade prismjs from 1.22.0 to 1.23.0 ([#1481](https://github.com/docsifyjs/docsify/issues/1481)) ([5f29cde](https://github.com/docsifyjs/docsify/commit/5f29cde84c7b74d70c34e3f1f43c479f1bba670d)) * Use legacy-compatible methods for IE11 ([#1495](https://github.com/docsifyjs/docsify/issues/1495)) ([06cbebf](https://github.com/docsifyjs/docsify/commit/06cbebfc0d34726f4a7102a7dc9020520f3a7f86)) # * search ignore diacritical marks ([#1434](https://github.com/docsifyjs/docsify/issues/1434)) ([8968a74](https://github.com/docsifyjs/docsify/commit/8968a744cea5910057ba59ef690316722a35b341)) * Add Jest + Playwright Testing ([#1276](https://github.com/docsifyjs/docsify/issues/1276)) * Add Vue components, mount options, global options, and v3 support ([#1409](https://github.com/docsifyjs/docsify/issues/1409))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "URL验证",
      "外部链接检测",
      "安全处理",
      "测试用例",
      "Git版本控制"
    ],
    "followup_points": [
      "1. 在修复 malformed URL 的 isExternal 检查时，具体遇到了哪些边界情况或特殊格式的 URL 需要额外处理？",
      "2. 新增的测试用例主要覆盖了哪些 malformed URL 场景，是否有典型的反面案例可以分享？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_003",
    "text": "[4.11.6](https://github.com/docsifyjs/docsify/compare/v4.11.5...v4.11.6) (2020-08-22)",
    "answer": "# * Add patch for {docsify-ignore} and {docsify-ignore-all} ([ce31607](https://github.com/docsifyjs/docsify/commit/ce316075e033afdbeb43ce01e284a29fe1870e38))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Git版本控制",
      "代码补丁(Patch)",
      "Markdown语法扩展",
      "docsify-ignore指令",
      "GitHub提交记录"
    ],
    "followup_points": [
      "1. 在实现 `{docsify-ignore}` 和 `{docsify-ignore-all}` 功能时，是如何处理文档中嵌套结构的忽略逻辑的？",
      "2. `{docsify-ignore-all}` 与 `{docsify-ignore}` 在具体实现上是否存在性能差异，特别是在处理大型文档时？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_004",
    "text": "[4.11.5](https://github.com/docsifyjs/docsify/compare/v4.11.4...v4.11.5) (2020-08-21)",
    "answer": "# * Russian language link error ([#1270](https://github.com/docsifyjs/docsify/issues/1270)) ([2a52460](https://github.com/docsifyjs/docsify/commit/2a52460a59448abaf681046fbc5dca642285ae1f)) * {docsify-updated} in the sample code is parsed into time ([#1321](https://github.com/docsifyjs/docsify/issues/1321)) ([2048610](https://github.com/docsifyjs/docsify/commit/2048610aacd4e3c6a592f4247834a726c7ca33fb)) * Add error handling for missing dependencies (fixes [#1210](https://github.com/docsifyjs/docsify/issues/1210)) ([#1232](https://github.com/docsifyjs/docsify/issues/1232)) ([3673001](https://github.com/docsifyjs/docsify/commit/3673001a24cb24c57454f9bc7619de49d2c3a044)) * after setting the background image, the button is obscured ([#1234](https://github.com/docsifyjs/docsify/issues/1234)) ([34d918f](https://github.com/docsifyjs/docsify/commit/34d918f9973bdb8e893248853e3ef7e803d4c253)) * convert {docsify-ignore} and {docsify-ignore-all} to HTML comments ([#1318](https://github.com/docsifyjs/docsify/issues/1318)) ([90d283d](https://github.com/docsifyjs/docsify/commit/90d283d340502456a5d8495df596bb4a02ceb39b)) * fallback page should use path not file location ([#1301](https://github.com/docsifyjs/docsify/issues/1301)) ([2bceabc](https://github.com/docsifyjs/docsify/commit/2bceabcb8e623570540493e2f1d956adf45c99e7)) * Fix search error when exist translations documents ([#1300](https://github.com/docsifyjs/docsify/issues/1300)) ([b869019](https://github.com/docsifyjs/docsify/commit/b8690199006366e86084e9e018def7b9b8f46512)) * gitignore was ignoring folders in src, so VS Code search results or file fuzzy finder were not working, etc ([d4c9247](https://github.com/docsifyjs/docsify/commit/d4c9247b87c0a2701683ed1a17383cfb451cf609)) * packages/docsify-server-renderer/package.json & packages/docsify-server-renderer/package-lock.json to reduce vulnerabilities ([#1250](https://github.com/docsifyjs/docsify/issues/1250)) ([d439bac](https://github.com/docsifyjs/docsify/commit/d439bac93f479d0480799880538fc3104e54c907)) * search can not search the table header ([#1256](https://github.com/docsifyjs/docsify/issues/1256)) ([3f03e78](https://github.com/docsifyjs/docsify/commit/3f03e78418993d8e9a4f5062e10dc79c3753389e)) * Search plugin: matched text is replaced with search text ([#1298](https://github.com/docsifyjs/docsify/issues/1298)) ([78775b6](https://github.com/docsifyjs/docsify/commit/78775b6ee73102cc5ac71c0ee2b392c5f4f6f4f8)) * the uncaught typeerror when el is null ([#1308](https://github.com/docsifyjs/docsify/issues/1308)) ([952f4c9](https://github.com/docsifyjs/docsify/commit/952f4c921b7a6a558c500ca6b105582d39ad36a2)) * Updated docs with instructions for installing specific version (fixes [#780](https://github.com/docsifyjs/docsify/issues/780)) ([#1225](https://github.com/docsifyjs/docsify/issues/1225)) ([b90c948](https://github.com/docsifyjs/docsify/commit/b90c948090e89fa778279c95060dbd7668285658)) * upgrade medium-zoom from 1.0.5 to 1.0.6 ([3beaa66](https://github.com/docsifyjs/docsify/commit/3beaa6666b78518f1ffaa37f6942f3cb08fef896)) * upgrade tinydate from 1.2.0 to 1.3.0 ([#1341](https://github.com/docsifyjs/docsify/issues/1341)) ([59d090f](https://github.com/docsifyjs/docsify/commit/59d090fe9096bc03e259c166634bb75bb2623f85)) # * **search:** add pathNamespaces option ([d179dde](https://github.com/docsifyjs/docsify/commit/d179dde1c71acdcbe66cb762377b123926c55bf2)) * Add title to sidebar links ([#1286](https://github.com/docsifyjs/docsify/issues/1286)) ([667496b](https://github.com/docsifyjs/docsify/commit/667496b85d99b168255f58e60a6bfe902cc6ee03))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Git版本控制",
      "GitHub Issues",
      "Markdown解析",
      "代码片段处理",
      "国际化(i18n)"
    ],
    "followup_points": [
      "1. 这个修复具体解决了俄语链接中的什么错误？是链接显示问题还是点击跳转问题？",
      "2. 针对`{docsify-updated}`被错误解析为时间的问题，修复方案是如何区分普通花括号内容和特殊标记的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_005",
    "text": "[4.11.4](https://github.com/docsifyjs/docsify/compare/v4.11.3...v4.11.4) (2020-06-18)",
    "answer": "# * consistent location of search result ([e9dd2de](https://github.com/docsifyjs/docsify/commit/e9dd2de384b81619aae2bcbf92f52721cb76a177)) * cover overlapping sidebar by removing z-index ([0bf03f5](https://github.com/docsifyjs/docsify/commit/0bf03f58103037d100b1635cf3989c8d3672b4ba)) * cross-origin url cannot be redirected when \"externalLinkTarget\" is set to \"_self\" and \"routerMode\" is set to \"history\". ([#1062](https://github.com/docsifyjs/docsify/issues/1062)) ([fd2cec6](https://github.com/docsifyjs/docsify/commit/fd2cec6bd66c46d6957811fefae4c615c3052a4f)), closes [#1046](https://github.com/docsifyjs/docsify/issues/1046) [#1046](https://github.com/docsifyjs/docsify/issues/1046) [#1046](https://github.com/docsifyjs/docsify/issues/1046) * default html img resize if no height included ([#1065](https://github.com/docsifyjs/docsify/issues/1065)) ([9ff4d06](https://github.com/docsifyjs/docsify/commit/9ff4d0677304bc190e7bd9e89bbbdc64895197fa)) * fixed target and rel issue (fixes [#1183](https://github.com/docsifyjs/docsify/issues/1183)) ([3d662a5](https://github.com/docsifyjs/docsify/commit/3d662a5bf71bbfef077cfbc478df241d794f55a0)) * Inconsistent search and body rendering ([dcb0aae](https://github.com/docsifyjs/docsify/commit/dcb0aaea99efbd68175f1d1aeb5076b6dde9801e)) * rendering cover width bug ([717991c](https://github.com/docsifyjs/docsify/commit/717991c90cf709f4da91fe32610129de6529266b)) * search does not find the contents of the table ([#1198](https://github.com/docsifyjs/docsify/issues/1198)) ([31010e4](https://github.com/docsifyjs/docsify/commit/31010e4979b3d3ab4bd247a09c4ac5fd1405eaa8)) * The search error after setting the ID in the title ([#1159](https://github.com/docsifyjs/docsify/issues/1159)) ([6e554f8](https://github.com/docsifyjs/docsify/commit/6e554f8ebd3d4a2c5c7e4f66cff3dfe2b6aa1e31)) * upgrade docsify from 4.10.2 to 4.11.2 ([60b7f89](https://github.com/docsifyjs/docsify/commit/60b7f89b373b0d48ec8406a51eddeaed8126696d)) # * added html sanitizer for remote rendering ([#1128](https://github.com/docsifyjs/docsify/issues/1128)) ([714ef29](https://github.com/docsifyjs/docsify/commit/714ef29afe779a6db5c4761ebaacdfc70ee2d8dd)) * update src/core/index.js to export all global APIs, deprecate old globals in favor of a single global DOCSIFY, and add tests for this ([7e002bf](https://github.com/docsifyjs/docsify/commit/7e002bf939d7837843908417b5445b4f8d36c1cd)) # * Revert \"Updated docs site dark and light mode with switch and redesigned search bar using docsify-darklight-theme\" (#1207) ([26cb940](https://github.com/docsifyjs/docsify/commit/26cb940b51d34ee584b8425012a336f38a4abd76)), closes [#1207](https://github.com/docsifyjs/docsify/issues/1207) [#1182](https://github.com/docsifyjs/docsify/issues/1182)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "CSS定位",
      "z-index",
      "跨域资源共享",
      "版本控制",
      "前端框架"
    ],
    "followup_points": [
      "1. 在实现搜索结果位置一致性时，具体遇到了哪些布局兼容性问题，是如何解决的？",
      "2. 移除侧边栏 z-index 后，是否遇到过与其他元素（如弹窗、下拉菜单）的层级冲突？如何处理？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_006",
    "text": "[4.11.3](https://github.com/docsifyjs/docsify/compare/v4.11.2...v4.11.3) (2020-03-24)",
    "answer": "# * fix: digit issue with sidebar (complete REVERT to old method) ([154abf5](https://github.com/docsifyjs/docsify/commit/154abf59a6153e84b018fcdffa86892776d6da7d))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Git版本控制",
      "代码提交规范",
      "Bug修复",
      "代码回滚",
      "前端项目维护"
    ],
    "followup_points": [
      "1. 这次修复中提到的\"digit issue with sidebar\"具体是指什么数字相关的问题，以及它如何影响侧边栏的显示或功能？",
      "2. 为什么选择完全回退到旧方法而不是采用新的修复方案？旧方法是否存在其他潜在的问题或限制？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_007",
    "text": "[4.11.2](https://github.com/docsifyjs/docsify/compare/v4.11.1...v4.11.2) (2020-03-09)",
    "answer": "# * fixed rendering of color in coverpage issue ([406670c](https://github.com/docsifyjs/docsify/commit/406670c3d619a627142900fd45019fb8ce00f60a))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "前端渲染",
      "CSS样式",
      "版本控制",
      "Git提交",
      "文档生成"
    ],
    "followup_points": [
      "1. 在修复 coverpage 颜色渲染问题时，具体遇到了哪些技术挑战或兼容性问题？",
      "2. 这个修复是否引入了任何新的 API 或配置选项，或者对现有用户的使用方式有潜在影响？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_008",
    "text": "[4.11.1](https://github.com/docsifyjs/docsify/compare/v4.11.0...v4.11.1) (2020-03-09)",
    "answer": "# [4.11.0](https://github.com/docsifyjs/docsify/compare/v4.10.2...v4.11.0) (2020-03-09) # * emojis in titles not working correctly and update ([#1016](https://github.com/docsifyjs/docsify/issues/1016)) ([b3d9b96](https://github.com/docsifyjs/docsify/commit/b3d9b966dfbb6f456c2c457da1d2a366e85d9190)) * searching table content ([6184e50](https://github.com/docsifyjs/docsify/commit/6184e502629932ca71fdd0a1b10150d118f5a7c8)) * stage modified files as part of pre-commit hook ([#985](https://github.com/docsifyjs/docsify/issues/985)) ([5b77b0f](https://github.com/docsifyjs/docsify/commit/5b77b0f628f056b7ebb6d0b617561d19964516a2)) * config initialization and coercion ([#861](https://github.com/docsifyjs/docsify/pull/861)) * strip indent when embedding code fragment ([#996](https://github.com/docsifyjs/docsify/pull/996)) * Ensure autoHeader dom result is similar to parsed H1 ([#811](https://github.com/docsifyjs/docsify/pull/811)) * upgrade docsify from 4.9.4 to 4.10.2 ([#1054](https://github.com/docsifyjs/docsify/issues/1054)) ([78290b2](https://github.com/docsifyjs/docsify/commit/78290b21038a3ae09c4c7438bd89b14ca4c02805)) * upgrade medium-zoom from 1.0.4 to 1.0.5 ([39ebd73](https://github.com/docsifyjs/docsify/commit/39ebd73021290439180878cae32e663b9e60e214)) * upgrade prismjs from 1.17.1 to 1.19.0 ([9981c43](https://github.com/docsifyjs/docsify/commit/9981c4361ad690d0ed32cf1fb5b48cc5b9f770bb)) # * configure pre-commit hook ([#983](https://github.com/docsifyjs/docsify/issues/983)) ([eea41a1](https://github.com/docsifyjs/docsify/commit/eea41a1207c46533ea9c6c59d82e2c94aa4dd70e)) * Add a prepare script. ([efbea24](https://github.com/docsifyjs/docsify/commit/efbea24de71f2287993b52ed1cef1a2dd6a53f81)) * added capability to add css class and id to images + links + refactoring ([#820](https://github.com/docsifyjs/docsify/issues/820)) ([724ac02](https://github.com/docsifyjs/docsify/commit/724ac024ddfc28e93d8b5dd909e722747286fa00)) * added dark mode to docs closes [#1031](https://github.com/docsifyjs/docsify/issues/1031) ([dc43d3c](https://github.com/docsifyjs/docsify/commit/dc43d3c512c2f04750e76176c25ece626ae7fe2a)) * new option `hideSidebar` ([#1026](https://github.com/docsifyjs/docsify/issues/1026)) ([b7547f1](https://github.com/docsifyjs/docsify/commit/b7547f151e928b3a0eb6a94b2af36023da4fa877)) * new option `topMargin` ([#1045](https://github.com/docsifyjs/docsify/pull/1045)) ([8faee03](https://github.com/docsifyjs/docsify/pull/1024/commits/b53ea1e304d3a2782b125c1d8711295d88faee03)) # * update docs for the `name` config option ([#992](https://github.com/docsifyjs/docsify/pull/992)) * about cache ([#854](https://github.com/docsifyjs/docsify/pull/854)) * removed FOSSA badge * documented `__colon__` tip ([#1025](https://github.com/docsifyjs/docsify/pull/1025)) # * Migrate relative links to absolute in embedded markdown ([#867](https://github.com/docsifyjs/docsify/pull/867)) * smarter scroll behavior ([#744](https://github.com/docsifyjs/docsify/pull/744)) * improve basic layout style ([#884](https://github.com/docsifyjs/docsify/pull/884)) * There are currently {three=>four} themes available. ([#892](https://github.com/docsifyjs/docsify/pull/892)) * Added a redirect for images to show up in Amplify ([#918](https://github.com/docsifyjs/docsify/pull/918)) * removed the escaping of the name of sidebar ([#991](https://github.com/docsifyjs/docsify/pull/991)) * Eslint fixes for v4x ([#989](https://github.com/docsifyjs/docsify/pull/989)) * added github Actions for CI ([#1000](https://github.com/docsifyjs/docsify/pull/1000)) * Add a prepare script. ([#1010](https://github.com/docsifyjs/docsify/pull/1010)) * chore(GH-action): using ubuntu 16 and removed node 8 from CI * chore: add config ([#1014](https://github.com/docsifyjs/docsify/pull/1014)) * chore(stale): added enhancement label to exemptlabels * chore(stale): added bug label to exemptlabels * .markdown-section max-width 800px to 80% ([#1017](https://github.com/docsifyjs/docsify/pull/1017)) * changed the CDN from unpkg to jsDelivr #1020 ([#1022](https://github.com/docsifyjs/docsify/pull/1022)) * migrate CI to github, refactore CI and npm scripts, linting fixes ([#1023](https://github.com/docsifyjs/docsify/pull/1023)) * chore(readme): added CI badges and fixed the logo issue * added new linter config ([#1028](https://github.com/docsifyjs/docsify/pull/1028))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Git版本控制",
      "GitHub Issues",
      "Markdown解析",
      "Emoji支持",
      "Changelog分析"
    ],
    "followup_points": [
      "1. 在修复标题中 emojis 显示问题的过程中，具体遇到了哪些技术挑战或兼容性问题？",
      "2. 除了修复 emojis 问题外，此次更新是否对其他功能（如渲染性能、Markdown 解析逻辑）产生了影响？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_009",
    "text": "[4.10.2](https://github.com/docsifyjs/docsify/compare/v4.10.0...v4.10.2) (2019-12-16)",
    "answer": "# [4.10.0](https://github.com/docsifyjs/docsify/compare/v4.9.4...v4.10.0) (2019-12-16) # * fixed security alert for chokidar(update dep) ([a62b037](https://github.com/docsifyjs/docsify/commit/a62b037becb36941c11c8eab6e4d83df8db85af3)) * npm audit issues ([#934](https://github.com/docsifyjs/docsify/issues/934)) ([615205c](https://github.com/docsifyjs/docsify/commit/615205cfdb7aea8f37a1ec5dd928105eeef56357)) * package security alerts ([f5f1561](https://github.com/docsifyjs/docsify/commit/f5f15619f1a239d6ce12a2f83ad8817352a3352b)) * security alerts of cssnano ([d7d5c8f](https://github.com/docsifyjs/docsify/commit/d7d5c8f302d7c18dbb32e982202a07b73badf6f6))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "npm",
      "版本控制",
      "安全漏洞",
      "依赖管理",
      "Git提交"
    ],
    "followup_points": [
      "1. 在修复 chokidar 安全漏洞的过程中，具体发现了哪些潜在的安全风险，这些风险可能对用户造成什么影响？",
      "2. 针对 npm audit 报告的问题，除了更新依赖外，是否还采取了其他措施（如代码重构、权限调整）来彻底解决或缓解这些漏洞？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_010",
    "text": "[4.9.2](https://github.com/docsifyjs/docsify/compare/v4.9.1...v4.9.2) (2019-04-21)",
    "answer": "# * re-render gitalk when router changed ([11ea1f8](https://github.com/docsifyjs/docsify/commit/11ea1f8)) # * allows relative path, fixed [#590](https://github.com/docsifyjs/docsify/issues/590) ([31654f1](https://github.com/docsifyjs/docsify/commit/31654f1))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "前端路由",
      "组件重渲染",
      "相对路径处理",
      "Gitalk集成",
      "版本控制"
    ],
    "followup_points": [
      "1. 在 re-render gitalk 时，是如何处理路由变化时的状态保持和性能优化的？",
      "2. 支持相对路径后，对文档的解析和渲染逻辑做了哪些具体调整，是否引入了新的兼容性问题？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_011",
    "text": "[4.9.1](https://github.com/docsifyjs/docsify/compare/v4.9.0...v4.9.1) (2019-02-21)",
    "answer": "# * github assets url ([#774](https://github.com/docsifyjs/docsify/issues/774)) ([140bf10](https://github.com/docsifyjs/docsify/commit/140bf10)) # [4.9.0](https://github.com/docsifyjs/docsify/compare/v4.8.6...v4.9.0) (2019-02-19) # * task list rendering (Fix [#749](https://github.com/docsifyjs/docsify/issues/749)) ([#757](https://github.com/docsifyjs/docsify/issues/757)) ([69ef489](https://github.com/docsifyjs/docsify/commit/69ef489)) * upgrade npm-run-all ([049726e](https://github.com/docsifyjs/docsify/commit/049726e)) # * **search-plugin:** add namespace option ([#706](https://github.com/docsifyjs/docsify/issues/706)) ([28beff8](https://github.com/docsifyjs/docsify/commit/28beff8)) * Add new theme \"dolphin\" ([#735](https://github.com/docsifyjs/docsify/issues/735)) ([c3345ba](https://github.com/docsifyjs/docsify/commit/c3345ba)) * Provide code fragments feature ([#748](https://github.com/docsifyjs/docsify/issues/748)) ([1447c8a](https://github.com/docsifyjs/docsify/commit/1447c8a))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Git版本控制",
      "GitHub仓库管理",
      "Release版本发布",
      "Commit提交记录",
      "Issue问题追踪"
    ],
    "followup_points": [
      "1. 这个版本更新中提到的 \"github assets url\" 具体解决了什么问题，对用户使用 docsify 时有哪些实际影响？",
      "2. 在 task list rendering 的修复中，是否还存在其他未解决的 related issues 或后续优化的空间？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_012",
    "text": "[4.8.6](https://github.com/docsifyjs/docsify/compare/v4.8.5...v4.8.6) (2018-11-12)",
    "answer": "# * IE10 compatibility ([#691](https://github.com/docsifyjs/docsify/issues/691)) ([4db8cd6](https://github.com/docsifyjs/docsify/commit/4db8cd6))",
    "category": "network",
    "difficulty": 5,
    "tags": [
      "浏览器兼容性",
      "IE10",
      "版本更新",
      "前端开发",
      "Git Commit"
    ],
    "followup_points": [
      "1. 在实现IE10兼容性时，主要解决了哪些具体的兼容性问题？",
      "2. 针对IE10的兼容性修复，是否引入了额外的polyfill或条件注释，这些方案对其他浏览器版本有何影响？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_013",
    "text": "[4.8.5](https://github.com/docsifyjs/docsify/compare/v4.8.4...v4.8.5) (2018-11-02)",
    "answer": "# * expose version info for Docsify, fixed [#641](https://github.com/docsifyjs/docsify/issues/641) ([aa719e3](https://github.com/docsifyjs/docsify/commit/aa719e3))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "版本管理",
      "Git",
      "版本发布",
      "问题追踪",
      "代码提交"
    ],
    "followup_points": [
      "1. 这个版本更新中提到的\"expose version info for Docsify\"具体是如何实现的，是通过新增API接口还是修改了现有的配置方式？",
      "2. 修复的[#641](https://github.com/docsifyjs/docsify/issues/641) issue中，用户反馈的具体问题是什么？这个修复对开发者使用Docsify时有哪些实际影响或改进？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_014",
    "text": "[4.8.4](https://github.com/docsifyjs/docsify/compare/v4.8.3...v4.8.4) (2018-11-01)",
    "answer": "# * **cover:** Compatible with legacy styles, fixed [#677](https://github.com/docsifyjs/docsify/issues/677) ([#678](https://github.com/docsifyjs/docsify/issues/678)) ([1a945d4](https://github.com/docsifyjs/docsify/commit/1a945d4))",
    "category": "network",
    "difficulty": 5,
    "tags": [
      "Git版本控制",
      "GitHub Issues",
      "CSS兼容性",
      "前端样式修复",
      "代码提交"
    ],
    "followup_points": [
      "1. 这个版本修复的 `cover` 兼容性问题具体影响了哪些旧版本的浏览器或样式规范？",
      "2. 提到的 issue #677 中，用户反馈的具体样式问题是什么，以及修复方案是如何解决该问题的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_015",
    "text": "[4.8.3](https://github.com/docsifyjs/docsify/compare/v4.8.2...v4.8.3) (2018-11-01)",
    "answer": "Fix the last release files has the old version marked...",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "版本控制",
      "Git",
      "发布管理",
      "版本号更新",
      "文件版本标记"
    ],
    "followup_points": [
      "1. 具体是哪些文件中的旧版本标记被错误地保留了？",
      "2. 这个问题是否会影响用户在使用旧版本文档时的版本识别或功能体验？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_016",
    "text": "[4.8.2](https://github.com/docsifyjs/docsify/compare/v4.8.1...v4.8.2) (2018-11-01)",
    "answer": "# - cover button style, fixed [#670](https://github.com/docsifyjs/docsify/issues/670), fixed [#665](https://github.com/docsifyjs/docsify/issues/665) ([#675](https://github.com/docsifyjs/docsify/issues/675)) ([fcd1087](https://github.com/docsifyjs/docsify/commit/fcd1087)) - update match regex ([#669](https://github.com/docsifyjs/docsify/issues/669)) ([2edf47e](https://github.com/docsifyjs/docsify/commit/2edf47e)) - use copy of cached value ([#668](https://github.com/docsifyjs/docsify/issues/668)) ([5fcf210](https://github.com/docsifyjs/docsify/commit/5fcf210)) - **compiler:** import prism-markup-templating, fixed [#672](https://github.com/docsifyjs/docsify/issues/672) ([#676](https://github.com/docsifyjs/docsify/issues/676)) ([fdd8826](https://github.com/docsifyjs/docsify/commit/fdd8826)) # - add heading config id ([#671](https://github.com/docsifyjs/docsify/issues/671)) ([ab19b13](https://github.com/docsifyjs/docsify/commit/ab19b13))",
    "category": "network",
    "difficulty": 5,
    "tags": [
      "CSS样式",
      "Git版本控制",
      "正则表达式",
      "问题追踪",
      "代码提交"
    ],
    "followup_points": [
      "1. 在修复 cover button style 的过程中，具体遇到了哪些样式兼容性问题，是如何解决的？",
      "2. 更新 match regex 的改动对文档搜索功能有哪些具体影响，是否有性能或准确性的优化？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_017",
    "text": "[4.8.1](https://github.com/docsifyjs/docsify/compare/v4.8.0...v4.8.1) (2018-10-31)",
    "answer": "# - ssr package dep, fixed [#605](https://github.com/docsifyjs/docsify/issues/605) ([2bc880d](https://github.com/docsifyjs/docsify/commit/2bc880d)) - **compiler:** extra quotes for codeblock ([4f588e0](https://github.com/docsifyjs/docsify/commit/4f588e0)) - **compiler:** prevent render of html code in paragraph, fixed [#663](https://github.com/docsifyjs/docsify/issues/663) ([d35059d](https://github.com/docsifyjs/docsify/commit/d35059d)) # - upgrade PrismJS, fixed [#534](https://github.com/docsifyjs/docsify/issues/534) ([4805cb5](https://github.com/docsifyjs/docsify/commit/4805cb5)) # [4.8.0](https://github.com/docsifyjs/docsify/compare/v4.7.1...v4.8.0) (2018-10-31) # - Cache TOC for later usage in the case of cached file html ([#649](https://github.com/docsifyjs/docsify/issues/649)) ([9e86017](https://github.com/docsifyjs/docsify/commit/9e86017)) - improve external script plugin ([#632](https://github.com/docsifyjs/docsify/issues/632)) ([50c2434](https://github.com/docsifyjs/docsify/commit/50c2434)) - missing variable declaration ([#660](https://github.com/docsifyjs/docsify/issues/660)) ([1ce37bd](https://github.com/docsifyjs/docsify/commit/1ce37bd)) - Remove target for mailto links ([#652](https://github.com/docsifyjs/docsify/issues/652)) ([18f0f03](https://github.com/docsifyjs/docsify/commit/18f0f03)) - Update getAllPath query selector ([#653](https://github.com/docsifyjs/docsify/issues/653)) ([f6f4e32](https://github.com/docsifyjs/docsify/commit/f6f4e32)) - Update vue.styl ([#634](https://github.com/docsifyjs/docsify/issues/634)) ([bf060be](https://github.com/docsifyjs/docsify/commit/bf060be)) # - Add docsify version to $window.docsify object ([#641](https://github.com/docsifyjs/docsify/issues/641)) ([94bc415](https://github.com/docsifyjs/docsify/commit/94bc415)), closes [#521](https://github.com/docsifyjs/docsify/issues/521) - **compiler:** support embedded mermaid ([#629](https://github.com/docsifyjs/docsify/issues/629)) ([42ea8af](https://github.com/docsifyjs/docsify/commit/42ea8af)) - Add hideOtherSidebarContent option ([#661](https://github.com/docsifyjs/docsify/issues/661)) ([4a23c4a](https://github.com/docsifyjs/docsify/commit/4a23c4a)) - Allow base64, external, and relative logo values ([#642](https://github.com/docsifyjs/docsify/issues/642)) ([0a0802a](https://github.com/docsifyjs/docsify/commit/0a0802a)), closes [#577](https://github.com/docsifyjs/docsify/issues/577) - upgrade marked to 0.5.x, fixed [#645](https://github.com/docsifyjs/docsify/issues/645), close [#644](https://github.com/docsifyjs/docsify/issues/644) ([#662](https://github.com/docsifyjs/docsify/issues/662)) ([a39b214](https://github.com/docsifyjs/docsify/commit/a39b214))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "SSR",
      "编译器",
      "代码块",
      "HTML渲染",
      "依赖管理"
    ],
    "followup_points": [
      "1. 在修复 ssr package 依赖问题时，具体遇到了哪些兼容性挑战，是如何解决的？",
      "2. 针对 codeblock 额外引号和 HTML 代码渲染的修复，compiler 层面做了哪些优化，如何确保不影响其他渲染逻辑？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_018",
    "text": "[4.7.1](https://github.com/docsifyjs/docsify/compare/v4.7.0...v4.7.1) (2018-08-30)",
    "answer": "# [4.7.0](https://github.com/QingWei-Li/docsify/compare/v4.6.9...v4.7.0) (2018-06-29) # - alldow addition content in sidebar, fix [#518](https://github.com/QingWei-Li/docsify/issues/518), fix 539 ([#543](https://github.com/QingWei-Li/docsify/issues/543)) ([04b36b0](https://github.com/QingWei-Li/docsify/commit/04b36b0)) - async install config, fixed [#425](https://github.com/QingWei-Li/docsify/issues/425) ([e4e011c](https://github.com/QingWei-Li/docsify/commit/e4e011c)) - loading embed files synchronously, fixed [#525](https://github.com/QingWei-Li/docsify/issues/525), fixed [#527](https://github.com/QingWei-Li/docsify/issues/527) ([#544](https://github.com/QingWei-Li/docsify/issues/544)) ([feea7f9](https://github.com/QingWei-Li/docsify/commit/feea7f9)) - path include chinese character cause hilight bug ([#556](https://github.com/QingWei-Li/docsify/issues/556)) ([a5f333a](https://github.com/QingWei-Li/docsify/commit/a5f333a)) # - add logo option, [#264](https://github.com/QingWei-Li/docsify/issues/264) ([#541](https://github.com/QingWei-Li/docsify/issues/541)) ([ee72dd0](https://github.com/QingWei-Li/docsify/commit/ee72dd0)) - add unpkg field, close [#531](https://github.com/QingWei-Li/docsify/issues/531) ([#558](https://github.com/QingWei-Li/docsify/issues/558)) ([5c0de0a](https://github.com/QingWei-Li/docsify/commit/5c0de0a)) - support image resizing, resolve [#508](https://github.com/QingWei-Li/docsify/issues/508) ([#545](https://github.com/QingWei-Li/docsify/issues/545)) ([3a7ad62](https://github.com/QingWei-Li/docsify/commit/3a7ad62))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "版本控制",
      "Git",
      "GitHub",
      "Markdown",
      "文档生成"
    ],
    "followup_points": [
      "1. 在修复 issue #518 和 #539 的过程中，具体遇到了哪些技术难点，是如何解决的？",
      "2. \"all addition content in sidebar\" 这一功能改进是否带来了性能上的影响，如果有，是如何优化的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_019",
    "text": "[4.6.10](https://github.com/QingWei-Li/docsify/compare/v4.6.9...v4.6.10) (2018-03-25)",
    "answer": "# - async install config, fixed [#425](https://github.com/QingWei-Li/docsify/issues/425) ([e4e011c](https://github.com/QingWei-Li/docsify/commit/e4e011c))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "异步安装",
      "配置管理",
      "版本控制",
      "Git提交",
      "问题修复"
    ],
    "followup_points": [
      "1. 这个异步安装配置的具体实现方式是什么？",
      "2. 该修复解决了 issue #425 中的哪些具体问题？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_020",
    "text": "[4.6.9](https://github.com/QingWei-Li/docsify/compare/v4.6.8...v4.6.9) (2018-03-10)",
    "answer": "# - upgrade medium-zoom, fixed [#417](https://github.com/QingWei-Li/docsify/issues/417) ([6a3d69a](https://github.com/QingWei-Li/docsify/commit/6a3d69a))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "版本控制",
      "Git",
      "依赖管理",
      "Bug修复",
      "API更新"
    ],
    "followup_points": [
      "1. 这次 medium-zoom 的升级具体解决了哪些问题或带来了哪些新功能？",
      "2. issue #417 中描述的具体问题是什么，以及这个修复如何影响用户体验？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_021",
    "text": "[4.6.8](https://github.com/QingWei-Li/docsify/compare/v4.6.7...v4.6.8) (2018-03-06)",
    "answer": "# - resolve path of image and embed files, fixed [#412](https://github.com/QingWei-Li/docsify/issues/412) ([bfd0d18](https://github.com/QingWei-Li/docsify/commit/bfd0d18))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "路径解析",
      "文件处理",
      "版本控制",
      "问题修复",
      "Git提交"
    ],
    "followup_points": [
      "1. 这个版本更新中提到的\"resolve path of image and embed files\"具体解决了哪些路径解析问题？",
      "2. 修复的 [#412](https://github.com/QingWei-Li/docsify/issues/412) issue 中，用户反馈的具体场景和问题表现是什么？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_022",
    "text": "[4.6.7](https://github.com/QingWei-Li/docsify/compare/v4.6.6...v4.6.7) (2018-03-03)",
    "answer": "# - layout css, fixed [#409](https://github.com/QingWei-Li/docsify/issues/409) ([aeb692e](https://github.com/QingWei-Li/docsify/commit/aeb692e))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "CSS",
      "Layout",
      "Fixed",
      "Git",
      "Version Control"
    ],
    "followup_points": [
      "1. 这个修复具体解决了 layout css 中哪些固定定位的问题？",
      "2. 提交 [aeb692e](https://github.com/QingWei-Li/docsify/commit/aeb692e) 的代码变更是否对其他布局或组件产生了影响？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_023",
    "text": "[4.6.5](https://github.com/QingWei-Li/docsify/compare/v4.6.4...v4.6.5) (2018-03-03)",
    "answer": "# - **navbar:** Now Navbar isn't append to DOM when loadNavbar is falsy ([#407](https://github.com/QingWei-Li/docsify/issues/407)) ([0933445](https://github.com/QingWei-Li/docsify/commit/0933445)) # - **config:** Add 404 page options. ([#406](https://github.com/QingWei-Li/docsify/issues/406)) ([9b3b445](https://github.com/QingWei-Li/docsify/commit/9b3b445))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "DOM操作",
      "配置管理",
      "版本控制",
      "前端框架",
      "错误处理"
    ],
    "followup_points": [
      "1. 当 `loadNavbar` 设置为 `falsy` 时，Navbar 不再被追加到 DOM，这对页面的初始加载性能有何具体影响？",
      "2. 新增的 404 页面选项支持哪些自定义配置，是否可以动态修改 404 页面的内容或样式？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_024",
    "text": "[4.6.4](https://github.com/QingWei-Li/docsify/compare/v4.6.3...v4.6.4) (2018-03-01)",
    "answer": "# - **render:** Disable markdown parsing when the file is an HTML ([#403](https://github.com/QingWei-Li/docsify/issues/403)) ([278a75e](https://github.com/QingWei-Li/docsify/commit/278a75e)) # - **fetch:** Add fallback languages configuration. ([#402](https://github.com/QingWei-Li/docsify/issues/402)) ([ecc0e04](https://github.com/QingWei-Li/docsify/commit/ecc0e04))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Markdown解析",
      "HTML渲染",
      "fetch请求",
      "国际化",
      "版本控制"
    ],
    "followup_points": [
      "1. 在禁用HTML文件的markdown解析后，docsify如何处理混合了markdown和HTML内容的文件？",
      "2. 添加fallback languages配置后，如果用户未明确指定语言，docsify的回退逻辑是怎样的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_025",
    "text": "[4.6.3](https://github.com/QingWei-Li/docsify/compare/v4.6.2...v4.6.3) (2018-02-15)",
    "answer": "# - **hook:** beforeEach don\\'t work, fixed [#393](https://github.com/QingWei-Li/docsify/issues/393) ([6a09059](https://github.com/QingWei-Li/docsify/commit/6a09059))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "hook",
      "beforeEach",
      "路由钩子",
      "版本控制",
      "Git提交"
    ],
    "followup_points": [
      "1. 在修复 `beforeEach` 钩子不工作的问题时，具体遇到了哪些技术难点或挑战？",
      "2. 该修复是否引入了任何潜在的兼容性问题或副作用，如何确保向后兼容性？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_026",
    "text": "[4.6.2](https://github.com/QingWei-Li/docsify/compare/v4.6.1...v4.6.2) (2018-02-14)",
    "answer": "# - **embed:** broken in IE, fixed [#389](https://github.com/QingWei-Li/docsify/issues/389), fixed [#391](https://github.com/QingWei-Li/docsify/issues/391) ([45a7464](https://github.com/QingWei-Li/docsify/commit/45a7464)) - **embed:** init value ([890a7bf](https://github.com/QingWei-Li/docsify/commit/890a7bf))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "浏览器兼容性",
      "JavaScript",
      "前端框架",
      "版本控制",
      "问题修复"
    ],
    "followup_points": [
      "1. 能否详细说明embed功能在IE中具体出现了哪些问题，以及这些问题是如何影响用户体验的？",
      "2. 在修复embed功能的过程中，团队是否遇到过其他兼容性挑战？如果有，是如何解决的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_027",
    "text": "[4.6.1](https://github.com/QingWei-Li/docsify/compare/v4.6.0...v4.6.1) (2018-02-12)",
    "answer": "# - **embed** compatible ssr ([dc0c3ce](https://github.com/QingWei-Li/docsify/commit/dc0c3ce)) - **embed** async fetch embed files, fixed [#387](https://github.com/QingWei-Li/docsify/issues/387) # [4.6.0](https://github.com/QingWei-Li/docsify/compare/v4.5.9...v4.6.0) (2018-02-11) # - **search:** custom clear button, fixed [#271](https://github.com/QingWei-Li/docsify/issues/271) ([864aa18](https://github.com/QingWei-Li/docsify/commit/864aa18)) - **search:** escape special characters for search, fixed [#369](https://github.com/QingWei-Li/docsify/issues/369) ([9755439](https://github.com/QingWei-Li/docsify/commit/9755439)) - build config ([342438f](https://github.com/QingWei-Li/docsify/commit/342438f)) - button style for coverpage, fixed [#362](https://github.com/QingWei-Li/docsify/issues/362) ([85428ef](https://github.com/QingWei-Li/docsify/commit/85428ef)) - dropdown scroll style, fixed [#346](https://github.com/QingWei-Li/docsify/issues/346) ([c4d83f2](https://github.com/QingWei-Li/docsify/commit/c4d83f2)) - highlight homepage link, fixed [#304](https://github.com/QingWei-Li/docsify/issues/304) ([f960c19](https://github.com/QingWei-Li/docsify/commit/f960c19)) - homepage link ([e097f88](https://github.com/QingWei-Li/docsify/commit/e097f88)) - onlyCover ([033be4f](https://github.com/QingWei-Li/docsify/commit/033be4f)) - ssr compatible embedd ([ebc10c4](https://github.com/QingWei-Li/docsify/commit/ebc10c4)) - ssr coverpage, fixed [#273](https://github.com/QingWei-Li/docsify/issues/273) ([9e824a4](https://github.com/QingWei-Li/docsify/commit/9e824a4)) # - click sidebar menu add collapse and expand, close [#294](https://github.com/QingWei-Li/docsify/issues/294) ([5e161a1](https://github.com/QingWei-Li/docsify/commit/5e161a1)) - **compiler:** support embedded file as code block, close [#134](https://github.com/QingWei-Li/docsify/issues/134) ([761ccc2](https://github.com/QingWei-Li/docsify/commit/761ccc2)) - **compiler:** support embedded markdown, html, video, etc files, close [#383](https://github.com/QingWei-Li/docsify/issues/383), close [#333](https://github.com/QingWei-Li/docsify/issues/333) ([524f52f](https://github.com/QingWei-Li/docsify/commit/524f52f)) - **cover:** add onlyCover option, close [#382](https://github.com/QingWei-Li/docsify/issues/382) ([b265fdd](https://github.com/QingWei-Li/docsify/commit/b265fdd)) - **fetch:** add requestHeaders option, fixed [#336](https://github.com/QingWei-Li/docsify/issues/336) ([54ab4c9](https://github.com/QingWei-Li/docsify/commit/54ab4c9)) - **render:** add ext option for custom file extenstion, close [#340](https://github.com/QingWei-Li/docsify/issues/340) ([248aa72](https://github.com/QingWei-Li/docsify/commit/248aa72)) - **render:** mutilple coverpage, close [#315](https://github.com/QingWei-Li/docsify/issues/315) ([f68ddf5](https://github.com/QingWei-Li/docsify/commit/f68ddf5))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "SSR",
      "embed",
      "async",
      "fetch",
      "compatibility"
    ],
    "followup_points": [
      "1. 在实现 embed 组件兼容 SSR 的过程中，遇到了哪些主要的技术挑战，是如何解决的？",
      "2. 针对 embed 组件异步加载文件的优化，对整体性能（如首屏加载时间、资源加载顺序）带来了哪些具体提升？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_028",
    "text": "[4.5.9](https://github.com/QingWei-Li/docsify/compare/v4.5.8...v4.5.9) (2018-02-07)",
    "answer": "# - upgrade marked ([4157173](https://github.com/QingWei-Li/docsify/commit/4157173))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "版本控制",
      "Git",
      "Markdown解析",
      "依赖管理",
      "升级策略"
    ],
    "followup_points": [
      "1. 这次 marked 版本升级具体解决了哪些性能或功能问题？",
      "2. 升级 marked 后是否引入了不兼容的 API 变更，需要开发者额外注意？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_029",
    "text": "[4.5.8](https://github.com/QingWei-Li/docsify/compare/v4.5.6...v4.5.8) (2018-02-07)",
    "answer": "# - cover style, fixed [#381](https://github.com/QingWei-Li/docsify/issues/381) ([368754e](https://github.com/QingWei-Li/docsify/commit/368754e)) - updated deps ([#337](https://github.com/QingWei-Li/docsify/issues/337)) ([a12d393](https://github.com/QingWei-Li/docsify/commit/a12d393))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "CSS样式",
      "版本控制",
      "依赖管理",
      "Git提交",
      "GitHub问题追踪"
    ],
    "followup_points": [
      "1. 关于 cover style 的修复，具体解决了哪些样式问题？是否涉及响应式布局或兼容性调整？",
      "2. 更新依赖（updated deps）主要涉及哪些第三方库？这些更新是否带来了性能优化或安全改进？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_030",
    "text": "[4.5.7](https://github.com/QingWei-Li/docsify/compare/v4.5.6...v4.5.7) (2017-12-29)",
    "answer": "# - add navigation plugin, closed [#180](https://github.com/QingWei-Li/docsify/issues/180) ([f78be4c](https://github.com/QingWei-Li/docsify/commit/f78be4c))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Git版本控制",
      "GitHub Pull Request",
      "GitHub Issue",
      "Changelog管理",
      "插件开发"
    ],
    "followup_points": [
      "1. 在实现导航插件时，主要解决了哪些用户痛点或需求？",
      "2. 导航插件的实现过程中，是否遇到了技术难点，是如何解决的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_031",
    "text": "[4.5.6](https://github.com/QingWei-Li/docsify/compare/v4.5.3...v4.5.6) (2017-12-14)",
    "answer": "# - **style:** increase the tap targets of menu button, fixed [#325](https://github.com/QingWei-Li/docsify/issues/325) ([888f217](https://github.com/QingWei-Li/docsify/commit/888f217))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "CSS",
      "UI/UX",
      "前端开发",
      "GitHub",
      "版本控制"
    ],
    "followup_points": [
      "1. 在优化菜单按钮的 tap targets 时，具体采用了哪些设计策略或技术手段来提升可点击区域？",
      "2. 针对 issue #325 中提到的 tap targets 问题，用户反馈的主要痛点是什么？优化后是否通过数据或用户测试验证了改进效果？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_032",
    "text": "[4.5.5](https://github.com/QingWei-Li/docsify/compare/v4.5.4...v4.5.5) (2017-11-30)",
    "answer": "# - disqus plugin issue ([#318](https://github.com/QingWei-Li/docsify/issues/318)) ([041b33e](https://github.com/QingWei-Li/docsify/commit/041b33e)), closes [#317](https://github.com/QingWei-Li/docsify/issues/317)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Git版本控制",
      "GitHub Issues管理",
      "Commit提交",
      "插件开发",
      "问题修复"
    ],
    "followup_points": [
      "1. 这个disqus插件issue的具体表现是什么？用户在使用时遇到了哪些问题？",
      "2. 修复commit（041b33e）中具体修改了哪些代码？是否涉及插件的核心逻辑或配置方式？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_033",
    "text": "[4.5.4](https://github.com/QingWei-Li/docsify/compare/v4.5.2...v4.5.4) (2017-11-29)",
    "answer": "# - **compiler:** task lists style, fixed [#215](https://github.com/QingWei-Li/docsify/issues/215) ([e43ded4](https://github.com/QingWei-Li/docsify/commit/e43ded4)) # - add gitalk plugin ([#306](https://github.com/QingWei-Li/docsify/issues/306)) ([9208e64](https://github.com/QingWei-Li/docsify/commit/9208e64))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "compiler",
      "task lists",
      "gitalk plugin",
      "commit",
      "version control"
    ],
    "followup_points": [
      "1. 关于 compiler 中 task lists style 的修复，具体解决了哪些样式问题，对用户体验有哪些提升？",
      "2. 新增的 gitalk 插件主要解决了什么需求，与其他评论插件相比有哪些优势或特点？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_034",
    "text": "[4.5.3](https://github.com/QingWei-Li/docsify/compare/v4.5.2...v4.5.3) (2017-11-11)",
    "answer": "# - add gitalk plugin ([#306](https://github.com/QingWei-Li/docsify/issues/306)) ([9208e64](https://github.com/QingWei-Li/docsify/commit/9208e64))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Git插件",
      "版本控制",
      "功能更新",
      "第三方集成",
      "GitHub集成"
    ],
    "followup_points": [
      "1. 在实现 gitalk 插件的过程中，遇到了哪些技术挑战或兼容性问题？",
      "2. gitalk 插件的集成对 docsify 的性能或用户体验产生了哪些具体影响？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_035",
    "text": "[4.5.2](https://github.com/QingWei-Li/docsify/compare/v4.5.1...v4.5.2) (2017-11-09)",
    "answer": "# - github task lists, close [#215](https://github.com/QingWei-Li/docsify/issues/215) ([#305](https://github.com/QingWei-Li/docsify/issues/305)) ([d486eef](https://github.com/QingWei-Li/docsify/commit/d486eef))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "GitHub",
      "版本控制",
      "任务列表",
      "Issue跟踪",
      "Git提交"
    ],
    "followup_points": [
      "1. 实现GitHub任务列表功能时，遇到的主要技术挑战是什么？",
      "2. 该功能对Markdown语法有哪些扩展或限制，如何确保与标准Markdown的兼容性？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_036",
    "text": "[4.5.1](https://github.com/QingWei-Li/docsify/compare/v4.5.0...v4.5.1) (2017-11-07)",
    "answer": "# - fetch files with the query params, fixed [#303](https://github.com/QingWei-Li/docsify/issues/303) ([2a2ed96](https://github.com/QingWei-Li/docsify/commit/2a2ed96)) # [4.5.0](https://github.com/QingWei-Li/docsify/compare/v4.4.1...v4.5.0) (2017-11-04) # - add disqus plugin, closed [#123](https://github.com/QingWei-Li/docsify/issues/123) ([fd7d4e0](https://github.com/QingWei-Li/docsify/commit/fd7d4e0))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "fetch",
      "query params",
      "plugin",
      "disqus",
      "version control"
    ],
    "followup_points": [
      "1. 在 fetch files with the query params 的功能中，具体解决了哪些与查询参数相关的文件获取问题？",
      "2. 添加 disqus 插件后，是否支持自定义配置选项，例如 disqus 短名称或评论页面筛选？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_037",
    "text": "[4.4.1](https://github.com/QingWei-Li/docsify/compare/v4.4.0...v4.4.1) (2017-10-31)",
    "answer": "# - {docsify-ignore-all} and {docsify-ignore} bug ([#299](https://github.com/QingWei-Li/docsify/issues/299)) ([cc98f56](https://github.com/QingWei-Li/docsify/commit/cc98f56)) - zoom image plugin issue, fixed [#187](https://github.com/QingWei-Li/docsify/issues/187) ([#300](https://github.com/QingWei-Li/docsify/issues/300)) ([fa772cf](https://github.com/QingWei-Li/docsify/commit/fa772cf)) # [4.4.0](https://github.com/QingWei-Li/docsify/compare/v4.3.15...v4.4.0) (2017-10-30) # - sidebar style issue on firefox, fixed [#184](https://github.com/QingWei-Li/docsify/issues/184) ([#297](https://github.com/QingWei-Li/docsify/issues/297)) ([36bfc9d](https://github.com/QingWei-Li/docsify/commit/36bfc9d)) # - add helper for disabled link, fixed [#295](https://github.com/QingWei-Li/docsify/issues/295) ([#296](https://github.com/QingWei-Li/docsify/issues/296)) ([4ad96f3](https://github.com/QingWei-Li/docsify/commit/4ad96f3))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "docsify",
      "版本更新",
      "bug修复",
      "插件",
      "Markdown语法"
    ],
    "followup_points": [
      "1. 能否详细说明 `{docsify-ignore-all}` 和 `{docsify-ignore}` 这两个标签的具体使用场景和区别？",
      "2. 关于 zoom image 插件的修复，是否会影响其他依赖图片功能的插件或自定义配置？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_038",
    "text": "[4.3.15](https://github.com/QingWei-Li/docsify/compare/v4.3.14...v4.3.15) (2017-10-20)",
    "answer": "# - scroll active sidebar ([a2b8eae](https://github.com/QingWei-Li/docsify/commit/a2b8eae))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "前端路由",
      "DOM操作",
      "事件监听",
      "滚动行为",
      "锚点定位"
    ],
    "followup_points": [
      "1. 在实现滚动激活侧边栏功能时，是如何判断当前滚动位置的？",
      "2. 该功能是否支持自定义滚动阈值或激活规则？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_039",
    "text": "[4.3.14](https://github.com/QingWei-Li/docsify/compare/v4.3.13...v4.3.14) (2017-10-20)",
    "answer": "# - codesponsor style ([ab68268](https://github.com/QingWei-Li/docsify/commit/ab68268))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Git版本控制",
      "代码提交",
      "代码审查",
      "开源项目",
      "Markdown解析"
    ],
    "followup_points": [
      "1. 在这个版本更新中，codesponsor style 的具体实现细节是什么？",
      "2. 这个更新对用户体验或项目文档展示有哪些实际影响？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_040",
    "text": "[4.3.13](https://github.com/QingWei-Li/docsify/compare/v4.3.12...v4.3.13) (2017-10-17)",
    "answer": "# - duplicate results in search fixed [#257](https://github.com/QingWei-Li/docsify/issues/257) ([#284](https://github.com/QingWei-Li/docsify/issues/284)) ([3476f6f](https://github.com/QingWei-Li/docsify/commit/3476f6f)) # - make whole search result clickable ([#285](https://github.com/QingWei-Li/docsify/issues/285)) ([1b91227](https://github.com/QingWei-Li/docsify/commit/1b91227))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "前端开发",
      "版本控制",
      "Git",
      "问题追踪",
      "用户界面交互"
    ],
    "followup_points": [
      "1. 在修复搜索结果重复问题时，具体遇到了哪些技术挑战，是如何解决的？",
      "2. 将整个搜索结果设置为可点击是出于什么考虑，对用户体验有哪些提升？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_041",
    "text": "[4.3.12](https://github.com/QingWei-Li/docsify/compare/v4.3.11...v4.3.12) (2017-10-15)",
    "answer": "# - incorrect active link ([#281](https://github.com/QingWei-Li/docsify/issues/281)) ([a3ab379](https://github.com/QingWei-Li/docsify/commit/a3ab379))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "前端路由",
      "DOM操作",
      "版本控制",
      "Git",
      "Bug修复"
    ],
    "followup_points": [
      "1. 这个修复具体解决了active link显示不正确的什么场景或问题？",
      "2. commit a3ab379 中的代码改动是如何实现active link逻辑修正的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_042",
    "text": "[4.3.11](https://github.com/QingWei-Li/docsify/compare/v4.3.10...v4.3.11) (2017-10-15)",
    "answer": "# - broken links to same page heading, fix [#278](https://github.com/QingWei-Li/docsify/issues/278), fix [#279](https://github.com/QingWei-Li/docsify/issues/279) ([91d6337](https://github.com/QingWei-Li/docsify/commit/91d6337))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "broken-links",
      "page-heading",
      "issue-fixing",
      "git-commit",
      "markdown-rendering"
    ],
    "followup_points": [
      "1. 这个版本修复的\"broken links to same page heading\"具体表现为哪些问题场景？",
      "2. 修复过程中是否涉及锚点生成逻辑或路由机制的变更？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_043",
    "text": "[4.3.10](https://github.com/QingWei-Li/docsify/compare/v4.3.9...v4.3.10) (2017-10-12)",
    "answer": "# - link render issue after page refreshing ([#276](https://github.com/QingWei-Li/docsify/issues/276)) ([abd885e](https://github.com/QingWei-Li/docsify/commit/abd885e))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "前端路由",
      "页面刷新",
      "链接渲染",
      "DOM操作",
      "版本控制"
    ],
    "followup_points": [
      "1. 这个链接渲染问题在页面刷新后具体表现为哪些异常现象？",
      "2. 修复该问题的 commit ([abd885e](https://github.com/QingWei-Li/docsify/commit/abd885e)) 主要修改了哪些核心代码逻辑？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_044",
    "text": "[4.3.9](https://github.com/QingWei-Li/docsify/compare/v4.3.8...v4.3.9) (2017-10-11)",
    "answer": "# - scroll issue in IE ([#275](https://github.com/QingWei-Li/docsify/issues/275)) ([3e94cb6](https://github.com/QingWei-Li/docsify/commit/3e94cb6))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "浏览器兼容性",
      "滚动处理",
      "前端Bug修复",
      "版本控制",
      "Git提交"
    ],
    "followup_points": [
      "1. 在修复 IE 滚动问题的过程中，遇到了哪些具体的技术挑战？",
      "2. 这个修复是否影响了其他浏览器的兼容性，如果有，是如何处理的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_045",
    "text": "[4.3.8](https://github.com/QingWei-Li/docsify/compare/v4.3.7...v4.3.8) (2017-10-07)",
    "answer": "# - **slugify:** GitHub compatible heading links, fixed [#272](https://github.com/QingWei-Li/docsify/issues/272) ([9b4e666](https://github.com/QingWei-Li/docsify/commit/9b4e666))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "slugify",
      "GitHub兼容",
      "heading links",
      "版本控制",
      "issue修复"
    ],
    "followup_points": [
      "1. 在实现 GitHub compatible heading links 的过程中，遇到了哪些技术难点或兼容性问题？",
      "2. 该修复对文档生成的性能或用户体验产生了哪些具体影响？是否需要额外的配置或注意事项？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_046",
    "text": "[4.3.7](https://github.com/QingWei-Li/docsify/compare/v4.3.6...v4.3.7) (2017-10-02)",
    "answer": "# - **slugify:** GitHub compatible heading links, fixed [#267](https://github.com/QingWei-Li/docsify/issues/267) ([c195d2d](https://github.com/QingWei-Li/docsify/commit/c195d2d))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "slugify",
      "GitHub兼容",
      "heading links",
      "版本控制",
      "issue修复"
    ],
    "followup_points": [
      "1. 这个 `slugify` 功能具体是如何实现 GitHub 兼容的标题链接的？",
      "2. 修复 [#267](https://github.com/QingWei-Li/docsify/issues/267) 时遇到了哪些技术难点，如何解决的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_047",
    "text": "[4.3.6](https://github.com/QingWei-Li/docsify/compare/v4.3.5...v4.3.6) (2017-09-21)",
    "answer": "# - style for codesponsor plugin ([08afec7](https://github.com/QingWei-Li/docsify/commit/08afec7))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Git版本控制",
      "GitHub提交记录",
      "代码审查",
      "前端样式",
      "插件集成"
    ],
    "followup_points": [
      "1. 在实现 codesponsor plugin 的样式时，主要考虑了哪些设计要点或用户体验因素？",
      "2. 该样式更新是否针对特定的赞助商插件功能进行了优化，还是为了整体文档展示效果的统一？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_048",
    "text": "[4.3.5](https://github.com/QingWei-Li/docsify/compare/v4.3.4...v4.3.5) (2017-09-20)",
    "answer": "# - missed symbol ([#254](https://github.com/QingWei-Li/docsify/issues/254)) ([6c702d3](https://github.com/QingWei-Li/docsify/commit/6c702d3)) # - **plugin:** add codesponsor plugin ([46ac4c3](https://github.com/QingWei-Li/docsify/commit/46ac4c3))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Git版本控制",
      "GitHub Issue管理",
      "GitHub Commit",
      "插件开发",
      "Markdown解析"
    ],
    "followup_points": [
      "1. 关于\"missed symbol\"的修复，具体是哪个符号被遗漏了？它对文档渲染有什么影响？",
      "2. 新增的codesponsor插件是如何工作的？它能为项目带来什么实际价值或收益？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_049",
    "text": "[4.3.4](https://github.com/QingWei-Li/docsify/compare/v4.3.3...v4.3.4) (2017-09-07)",
    "answer": "# - scroll position issue, fixed [#234](https://github.com/QingWei-Li/docsify/issues/234) ([388ed3d](https://github.com/QingWei-Li/docsify/commit/388ed3d))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "scroll position",
      "issue tracking",
      "version control",
      "git commit",
      "bug fix"
    ],
    "followup_points": [
      "1. 在修复滚动位置问题（issue #234）时，具体遇到了哪些技术难点或挑战？",
      "2. 修复方案（commit 388ed3d）中是否涉及对路由机制或DOM操作的优化，是否可能引入其他潜在问题？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_050",
    "text": "[4.3.3](https://github.com/QingWei-Li/docsify/compare/v4.3.2...v4.3.3) (2017-09-06)",
    "answer": "# - **buble.css:** tweaks code block style, fixed [#249](https://github.com/QingWei-Li/docsify/issues/249) ([9d43051](https://github.com/QingWei-Li/docsify/commit/9d43051)) # - add doc for react and vue demo box plugin ([#247](https://github.com/QingWei-Li/docsify/issues/247)) ([f0aca19](https://github.com/QingWei-Li/docsify/commit/f0aca19))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "CSS样式",
      "代码块",
      "文档生成",
      "版本控制",
      "插件开发"
    ],
    "followup_points": [
      "1. 在修复代码块样式的问题中，具体遇到了哪些样式兼容性挑战，以及是如何解决的？",
      "2. 为react和vue demo box插件添加文档时，是否考虑了不同版本框架的适配情况，以及文档中是否包含了具体的集成示例？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_051",
    "text": "[4.3.2](https://github.com/QingWei-Li/docsify/compare/v4.3.1...v4.3.2) (2017-09-01)",
    "answer": "# - sidebar highlight ([f82f419](https://github.com/QingWei-Li/docsify/commit/f82f419)) # - add Edit on github plugin (thanks [@njleonzhang](https://github.com/njleonzhang)) ([a0e1ea8](https://github.com/QingWei-Li/docsify/commit/a0e1ea8))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Git版本控制",
      "GitHub提交记录",
      "Markdown语法",
      "插件系统",
      "侧边栏功能"
    ],
    "followup_points": [
      "1. 在实现侧边栏高亮功能时，是如何处理动态路由或嵌套路由的高亮逻辑的？",
      "2. Edit on github插件的设计初衷是什么，它如何与docsify的文档生成流程集成，以及是否支持自定义编辑链接的模板？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_052",
    "text": "[4.3.1](https://github.com/QingWei-Li/docsify/compare/v4.2.9...v4.3.1) (2017-08-30)",
    "answer": "# - **markdown:** supports mermaid [#137](https://github.com/QingWei-Li/docsify/issues/137) ([f4800e0](https://github.com/QingWei-Li/docsify/commit/f4800e0)) # [4.3.0](https://github.com/QingWei-Li/docsify/compare/v4.2.9...v4.3.0) (2017-08-17) # - **markdown:** supports mermaid [#137](https://github.com/QingWei-Li/docsify/issues/137) ([f4800e0](https://github.com/QingWei-Li/docsify/commit/f4800e0))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "markdown",
      "mermaid",
      "版本控制",
      "GitHub",
      "docsify"
    ],
    "followup_points": [
      "1. 在支持 mermaid 功能的过程中，团队是如何处理不同浏览器兼容性问题的？",
      "2. 实现 mermaid 支持时，是否遇到过性能优化方面的挑战，比如渲染大型图表时的效率问题？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_053",
    "text": "[4.2.9](https://github.com/QingWei-Li/docsify/compare/v4.2.8...v4.2.9) (2017-08-15)",
    "answer": "# - ensure document ready before init Docsify [#233](https://github.com/QingWei-Li/docsify/issues/233)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "DOM操作",
      "事件监听",
      "JavaScript执行时机",
      "文档加载",
      "初始化流程"
    ],
    "followup_points": [
      "1. 在这个修复中，具体是通过什么机制来确保文档 ready 的？是使用了 DOMContentLoaded 事件还是其他方法？",
      "2. 修复前后的初始化流程发生了哪些变化？这个修复解决了哪些具体的问题或潜在风险？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_054",
    "text": "[4.2.8](https://github.com/QingWei-Li/docsify/compare/v4.2.7...v4.2.8) (2017-08-10)",
    "answer": "# - **compiler:** support for setting target attribute for link, fixed [#230](https://github.com/QingWei-Li/docsify/issues/230) ([7f270f9](https://github.com/QingWei-Li/docsify/commit/7f270f9))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "compiler",
      "link",
      "target attribute",
      "issue fix",
      "commit hash"
    ],
    "followup_points": [
      "1. 在实现 link 的 target 属性支持时，是如何处理不同场景下的默认值和用户自定义值的冲突的？",
      "2. 该修复是否考虑了 SEO 或无障碍访问（a11y）方面的优化，比如对 target=\"_blank\" 的 rel 属性自动添加 \"noopener noreferrer\"？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_055",
    "text": "[4.2.7](https://github.com/QingWei-Li/docsify/compare/v4.2.4...v4.2.7) (2017-08-05)",
    "answer": "# - **release:** release shell ([628e211](https://github.com/QingWei-Li/docsify/commit/628e211)) - **style:** nowrap => pre-wrap, fixed [#228](https://github.com/QingWei-Li/docsify/issues/228) ([a88252c](https://github.com/QingWei-Li/docsify/commit/a88252c))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Git版本控制",
      "Release管理",
      "CSS样式调整",
      "代码提交规范",
      "Issue追踪"
    ],
    "followup_points": [
      "1. 这个release shell脚本的主要功能和实现逻辑是什么？",
      "2. nowrap改为pre-wrap的样式调整具体解决了什么显示问题，对用户体验有哪些影响？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_056",
    "text": "[4.2.6](https://github.com/QingWei-Li/docsify/compare/v4.2.4...v4.2.6) (2017-07-27)",
    "answer": "# - **css:** hide the nav when the content has not yet been loaded ([1fa1619](https://github.com/QingWei-Li/docsify/commit/1fa1619)) - **release:** release shell ([628e211](https://github.com/QingWei-Li/docsify/commit/628e211))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "CSS",
      "版本发布",
      "前端开发",
      "用户体验",
      "Git提交"
    ],
    "followup_points": [
      "1. 在实现\"hide the nav when the content has not yet been loaded\"这一功能时，具体采用了哪些CSS技术或方法来确保导航栏的隐藏效果？",
      "2. 在\"release shell\"这一commit中，所谓的\"shell\"具体指的是什么？它是否与docsify的初始化或基础渲染逻辑相关？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_057",
    "text": "[4.2.4](https://github.com/QingWei-Li/docsify/compare/v4.2.2...v4.2.4) (2017-07-26)",
    "answer": "# - **render:** Remove getRootNode to be compatible with the lower version of Chrome, fixed [#225](https://github.com/QingWei-Li/docsify/issues/225) ([b8dd346](https://github.com/QingWei-Li/docsify/commit/b8dd346))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "DOM操作",
      "浏览器兼容性",
      "版本控制",
      "Git",
      "前端渲染"
    ],
    "followup_points": [
      "1. 为什么要移除 `getRootNode` 方法，它与 Chrome 低版本的具体兼容性问题是什么？",
      "2. 移除 `getRootNode` 后，docsify 是如何确保在低版本 Chrome 中仍然正常工作的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_058",
    "text": "[4.2.3](https://github.com/QingWei-Li/docsify/compare/v4.2.2...v4.2.3) (2017-07-26)",
    "answer": "# - **search:** Supports the max depth of the search headline, fixed [#223](https://github.com/QingWei-Li/docsify/issues/223), resolve [#129](https://github.com/QingWei-Li/docsify/issues/129) ([b7b589b](https://github.com/QingWei-Li/docsify/commit/b7b589b))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "search",
      "max depth",
      "headline",
      "bug fix",
      "version control"
    ],
    "followup_points": [
      "1. 这个版本更新中提到的“搜索功能最大深度”具体是如何定义和实现的？",
      "2. 修复的 issue #223 和 #129 分别涉及了搜索功能的哪些具体问题，以及这些问题对用户体验产生了哪些影响？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_059",
    "text": "[4.2.2](https://github.com/QingWei-Li/docsify/compare/v4.2.1...v4.2.2) (2017-07-24)",
    "answer": "# - style rerender due to setting themeColor ([17ff3d1](https://github.com/QingWei-Li/docsify/commit/17ff3d1))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "前端性能优化",
      "CSS样式重渲染",
      "主题色动态切换",
      "Git版本控制",
      "代码提交分析"
    ],
    "followup_points": [
      "1. 这次 style rerender 问题的具体表现是什么？",
      "2. 修复方案中 `themeColor` 的设置逻辑是如何优化的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_060",
    "text": "[4.2.1](https://github.com/QingWei-Li/docsify/compare/v4.2.0...v4.2.1) (2017-07-19)",
    "answer": "- give the navbar some line-height (#216) - Remove unnecessary moduleName option from rollup config for plugins (#209) # [4.2.0](https://github.com/QingWei-Li/docsify/compare/v4.1.14...v4.2.0) (2017-07-10) # - not found page ([9af8559](https://github.com/QingWei-Li/docsify/commit/9af8559)) # - alias option supports regexp, resolve [#183](https://github.com/QingWei-Li/docsify/issues/183) ([c4aa22c](https://github.com/QingWei-Li/docsify/commit/c4aa22c)) - ignore to compiled link, fixed [#203](https://github.com/QingWei-Li/docsify/issues/203) ([#204](https://github.com/QingWei-Li/docsify/issues/204)) ([2e00f4c](https://github.com/QingWei-Li/docsify/commit/2e00f4c))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "CSS样式",
      "版本控制",
      "构建工具",
      "错误处理",
      "路由配置"
    ],
    "followup_points": [
      "1. 在版本4.2.1中，为navbar添加line-height的具体原因是什么？是否解决了特定的显示问题或提升了用户体验？",
      "2. 版本4.2.0中引入的\"not found page\"功能是如何实现的？是否支持自定义404页面的内容和样式？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_061",
    "text": "[4.1.14](https://github.com/QingWei-Li/docsify/compare/v4.1.13...v4.1.14) (2017-06-24)",
    "answer": "# - get file path, fixed jrappen/sublime-distractionless/commit/81bfadd391428823191cc03eca956a2312e04d13#commitcomment-22427070 ([e8117e5](https://github.com/QingWei-Li/docsify/commit/e8117e5)), closes [jrappen/sublime-distractionless/commit/81bfadd391428823191cc03eca956a2312e04d13#commitcomment-22427070](https://github.com/jrappen/sublime-distractionless/commit/81bfadd391428823191cc03eca956a2312e04d13/issues/commitcomment-22427070) # - add context attribute, fixed [#191](https://github.com/QingWei-Li/docsify/issues/191) ([ce0e9ac](https://github.com/QingWei-Li/docsify/commit/ce0e9ac))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Git版本控制",
      "代码提交",
      "问题修复",
      "文件路径处理",
      "GitHub Issue"
    ],
    "followup_points": [
      "1. 这个修复具体解决了什么文件路径相关的问题？",
      "2. 在修复之前，用户在使用时遇到了哪些具体的错误或异常行为？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_062",
    "text": "[4.1.12](https://github.com/QingWei-Li/docsify/compare/v4.1.11...v4.1.12) (2017-06-03)",
    "answer": "# - **render:** subtitle in side bar shows undefined, fixed [#182](https://github.com/QingWei-Li/docsify/issues/182) ([d087d57](https://github.com/QingWei-Li/docsify/commit/d087d57))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "render",
      "sidebar",
      "subtitle",
      "undefined",
      "issue fix"
    ],
    "followup_points": [
      "1. 这个修复具体解决了什么场景下副标题显示 undefined 的问题？",
      "2. 修复中提到的 commit (d087d57) 主要修改了哪些代码逻辑？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_063",
    "text": "[4.1.11](https://github.com/QingWei-Li/docsify/compare/v4.1.10...v4.1.11) (2017-06-02)",
    "answer": "# - **compiler:** force reset toc when rendering sidebar fixed [#181](https://github.com/QingWei-Li/docsify/issues/181) ([ccf4c7c](https://github.com/QingWei-Li/docsify/commit/ccf4c7c)) - **render:** autoHeader does not work ([1304d2e](https://github.com/QingWei-Li/docsify/commit/1304d2e))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "compiler",
      "render",
      "toc",
      "sidebar",
      "autoHeader"
    ],
    "followup_points": [
      "1. 在修复 `force reset toc when rendering sidebar fixed` 的问题时，具体遇到了哪些技术挑战，为什么会导致 TOC 需要强制重置？",
      "2. 针对 `autoHeader does not work` 的修复，是否考虑了向后兼容性？如果有兼容性问题，是如何处理的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_064",
    "text": "[4.1.10](https://github.com/QingWei-Li/docsify/compare/v4.1.9...v4.1.10) (2017-06-02)",
    "answer": "# - **hash:** hash routing crashes when url has querystring ([6d48ce1](https://github.com/QingWei-Li/docsify/commit/6d48ce1))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "hash routing",
      "URL querystring",
      "前端路由",
      "JavaScript",
      "Git commit"
    ],
    "followup_points": [
      "1. 这个 hash routing 在处理带 querystring 的 URL 时具体会出现什么样的崩溃现象？",
      "2. 修复方案中是如何解决 querystring 导致的 hash routing 问题的？是否涉及 URL 解析或路由匹配逻辑的调整？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_065",
    "text": "[4.1.9](https://github.com/QingWei-Li/docsify/compare/v4.1.8...v4.1.9) (2017-05-31)",
    "answer": "# - can't render toc on first load ([d9b487e](https://github.com/QingWei-Li/docsify/commit/d9b487e)) - **lifecycle:** continue to handle data ([955d3d5](https://github.com/QingWei-Li/docsify/commit/955d3d5)) - **render:** broken name link, fixed [#167](https://github.com/QingWei-Li/docsify/issues/167) ([91b66a5](https://github.com/QingWei-Li/docsify/commit/91b66a5))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "lifecycle",
      "render",
      "toc",
      "data handling",
      "name link"
    ],
    "followup_points": [
      "1. 在修复\"can't render toc on first load\"的问题时，具体遇到了哪些技术挑战，导致首次加载时无法正确渲染目录？",
      "2. 针对\"broken name link\"的修复（[#167](https://github.com/QingWei-Li/docsify/issues/167)），是否需要用户额外配置或依赖特定条件才能生效？修复后是否引入了新的兼容性问题？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_066",
    "text": "[4.1.8](https://github.com/QingWei-Li/docsify/compare/v4.1.7...v4.1.8) (2017-05-31)",
    "answer": "# - auto replace version ([22b50f0](https://github.com/QingWei-Li/docsify/commit/22b50f0)) - update edit button demo ([ec887c1](https://github.com/QingWei-Li/docsify/commit/ec887c1)) # - add edit button demo ([a64cee1](https://github.com/QingWei-Li/docsify/commit/a64cee1)) - add edit button demo, close [#162](https://github.com/QingWei-Li/docsify/issues/162) ([036fdac](https://github.com/QingWei-Li/docsify/commit/036fdac))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Git版本控制",
      "Commit提交",
      "代码仓库管理",
      "版本更新",
      "功能迭代"
    ],
    "followup_points": [
      "1. 这个版本中的“auto replace version”功能具体是如何实现的，解决了什么问题？",
      "2. “update edit button demo”和“add edit button demo”这两个commit之间是否存在功能迭代，用户反馈是否影响了后续的优化方向？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_067",
    "text": "[4.1.7](https://github.com/QingWei-Li/docsify/compare/v4.1.6...v4.1.7) (2017-05-30)",
    "answer": "# - **ssr:** clean files ([0014895](https://github.com/QingWei-Li/docsify/commit/0014895))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "ssr",
      "git",
      "版本控制",
      "commit",
      "文件清理"
    ],
    "followup_points": [
      "1. 在这次更新中，具体清理了哪些类型的文件，这些文件的存在对项目有什么影响？",
      "2. 这次文件清理操作是否引入了任何向后兼容性问题，或者对用户的使用方式提出了新的要求？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_068",
    "text": "[4.1.6](https://github.com/QingWei-Li/docsify/compare/v4.1.5...v4.1.6) (2017-05-30)",
    "answer": "# - **ssr:** add debug ([6b9e092](https://github.com/QingWei-Li/docsify/commit/6b9e092))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "SSR",
      "调试",
      "版本控制",
      "Git提交",
      "前端框架"
    ],
    "followup_points": [
      "1. 在这个 SSR 调试功能中，具体增加了哪些调试信息或工具，它们是如何帮助开发者排查问题的？",
      "2. 这个调试功能是否会影响生产环境的性能？如果有影响，是否可以通过配置来控制其启用或禁用？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_069",
    "text": "[4.1.5](https://github.com/QingWei-Li/docsify/compare/v4.1.4...v4.1.5) (2017-05-30)",
    "answer": "# - **ssr:** missing package ([6db8c9e](https://github.com/QingWei-Li/docsify/commit/6db8c9e))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "SSR",
      "版本控制",
      "Git",
      "包管理",
      "问题修复"
    ],
    "followup_points": [
      "1. 这个缺失的包具体是哪个，它对 SSR 功能有什么关键作用？",
      "2. 在发现这个问题后，团队是如何定位和修复这个缺失包的？有没有遇到其他相关的依赖问题？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_070",
    "text": "[4.1.4](https://github.com/QingWei-Li/docsify/compare/v4.1.3...v4.1.4) (2017-05-30)",
    "answer": "# - **ssr:** file path ([79a83bc](https://github.com/QingWei-Li/docsify/commit/79a83bc))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "ssr",
      "file path",
      "git commit",
      "version comparison",
      "docsify"
    ],
    "followup_points": [
      "1. 这次 SSR 相关的文件路径修改具体解决了哪些问题或优化了哪些功能？",
      "2. 这次修改对 SSR 的渲染逻辑或性能是否有影响，是否需要额外的配置调整？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_071",
    "text": "[4.1.3](https://github.com/QingWei-Li/docsify/compare/v4.1.2...v4.1.3) (2017-05-30)",
    "answer": "# - update babel config ([9825db4](https://github.com/QingWei-Li/docsify/commit/9825db4))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Babel",
      "版本控制",
      "Git",
      "配置更新",
      "代码提交"
    ],
    "followup_points": [
      "1. 这次 babel 配置更新的具体改动是什么？",
      "2. 这次更新是否带来了性能提升或兼容性改进？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_072",
    "text": "[4.1.2](https://github.com/QingWei-Li/docsify/compare/v4.1.1...v4.1.2) (2017-05-30)",
    "answer": "# - update babel config ([80dba19](https://github.com/QingWei-Li/docsify/commit/80dba19))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Babel",
      "版本控制",
      "Git",
      "配置更新",
      "代码提交"
    ],
    "followup_points": [
      "1. 这次 Babel 配置更新的具体改动是什么？",
      "2. 这次更新解决了哪些兼容性问题或带来了哪些性能优化？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_073",
    "text": "[4.1.1](https://github.com/QingWei-Li/docsify/compare/v4.1.0...v4.1.1) (2017-05-30)",
    "answer": "# - build for ssr package ([4cb20a5](https://github.com/QingWei-Li/docsify/commit/4cb20a5)) - remove history mode ([0e74e6c](https://github.com/QingWei-Li/docsify/commit/0e74e6c)) # [4.1.0](https://github.com/QingWei-Li/docsify/compare/v4.0.2...v4.1.0) (2017-05-30)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "SSR",
      "版本控制",
      "Git",
      "构建流程",
      "前端框架"
    ],
    "followup_points": [
      "1. 在这次更新中移除 history 模式是出于什么考虑？是否遇到了相关的技术挑战或用户反馈问题？",
      "2. 新增的 SSR（服务端渲染）包支持，当时是如何权衡开发成本和实际使用场景的？是否考虑过向后兼容性？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_074",
    "text": "[4.0.2](https://github.com/QingWei-Li/docsify/compare/v4.0.1...v4.0.2) (2017-05-30)",
    "answer": "# - basePath for history mode ([fc1cd3f](https://github.com/QingWei-Li/docsify/commit/fc1cd3f))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "前端路由",
      "历史模式",
      "路径配置",
      "版本控制",
      "Git提交"
    ],
    "followup_points": [
      "1. 在实现 basePath 功能时，是如何处理不同环境（如开发、生产）下的路径配置差异的？",
      "2. basePath 功能的引入对现有项目的迁移是否有兼容性考虑？如果有，具体是如何处理的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_CHANGELOG_075",
    "text": "[4.0.1](https://github.com/QingWei-Li/docsify/compare/v4.0.0...v4.0.1) (2017-05-29)",
    "answer": "# - **ssr:** remove context ([4626157](https://github.com/QingWei-Li/docsify/commit/4626157)) - lint ([b764b6e](https://github.com/QingWei-Li/docsify/commit/b764b6e)) # [4.0.0](https://github.com/QingWei-Li/docsify/compare/v3.7.3...v4.0.0) (2017-05-29) # - **render:** init event in ssr ([eba1c98](https://github.com/QingWei-Li/docsify/commit/eba1c98)) - lint ([1f4514d](https://github.com/QingWei-Li/docsify/commit/1f4514d)) # - finish ssr ([3444884](https://github.com/QingWei-Li/docsify/commit/3444884)) - init ocsify-server-renderer ([6dea685](https://github.com/QingWei-Li/docsify/commit/6dea685)) - support history mode ([f095eb8](https://github.com/QingWei-Li/docsify/commit/f095eb8))",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "ssr",
      "render",
      "context",
      "event",
      "lint"
    ],
    "followup_points": [
      "1. 在这次更新中移除 context 的具体原因是什么？",
      "2. 初始化 ssr 事件时遇到了哪些技术挑战，是如何解决的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/CHANGELOG.md",
    "code_examples": []
  },
  {
    "id": "go-interview_SECURITY_000",
    "text": "Full paths of source file(s) related to the manifestation of the issue",
    "answer": "Full paths of source file(s) related to the manifestation of the issue",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "source file paths",
      "issue manifestation",
      "file location",
      "code analysis",
      "debugging"
    ],
    "followup_points": [
      "1. Could you provide an example of a specific source file path that is related to the manifestation of the issue, and explain how it contributes to the problem?",
      "2. Are there any additional source files or directories that might indirectly influence the manifestation of the issue, even if they are not directly mentioned in the full paths?"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/SECURITY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_SECURITY_001",
    "text": "The location of the affected source code (tag/branch/commit or direct URL)",
    "answer": "The location of the affected source code (tag/branch/commit or direct URL)",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "source_code_location",
      "git_version_control",
      "commit_identification",
      "branch_management",
      "url_direct_access"
    ],
    "followup_points": [
      "1. How did you determine the specific tag/branch/commit or direct URL for the affected source code?",
      "2. Are there any related commits or branches that might also be impacted by this change?"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/SECURITY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_SECURITY_002",
    "text": "Any special configuration required to reproduce the issue",
    "answer": "Any special configuration required to reproduce the issue",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "Bug Reproduction",
      "Configuration Management",
      "Issue Analysis",
      "Troubleshooting",
      "Environment Setup"
    ],
    "followup_points": [
      "1. Could you provide specific examples of the configurations that are necessary to trigger the issue?",
      "2. Are there any default settings that need to be modified, or are additional dependencies required to reproduce the problem?"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/SECURITY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_SECURITY_003",
    "text": "Impact of the issue, including how an attacker might exploit the issue",
    "answer": "Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly. Thank you in advance.",
    "category": "system",
    "difficulty": 3,
    "tags": [
      "漏洞影响",
      "攻击向量",
      "漏洞利用",
      "威胁分析",
      "安全评估"
    ],
    "followup_points": [
      "1. Could you provide a specific example of an attack scenario that exploits this issue, including the steps an attacker might take?",
      "2. What are the potential consequences (e.g., data breach, service disruption, financial loss) if this issue is exploited successfully?"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/SECURITY.md",
    "code_examples": []
  },
  {
    "id": "go-interview_README_002",
    "text": "Quick start",
    "answer": "Look at [this tutorial](https://docsify.js.org/#/quickstart) [![Edit 307qqv236](https://codesandbox.io/static/img/play-codesandbox.svg)](https://codesandbox.io/s/307qqv236)",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "docsify",
      "快速开始",
      "教程",
      "在线编辑",
      "CodeSandbox"
    ],
    "followup_points": [
      "1. 在快速入门教程中，您认为最关键的第一步是什么？为什么？",
      "2. 教程中提到的 CodeSandbox 集成，在实际项目中您会如何选择本地开发环境与在线开发环境的结合方式？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/README.md",
    "code_examples": []
  },
  {
    "id": "go-interview_README_004",
    "text": "Similar projects",
    "answer": "| Project | Description | | ------------------------------------------------ | ---------------------------------------- | | [docute](https://github.com/egoist/docute) | 📜 Effortlessly documentation done right | | [docpress](https://github.com/docpress/docpress) | Documentation website generator |",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Documentation Generator",
      "Static Site Generator",
      "Open Source Project",
      "GitHub Project",
      "Markdown-based Documentation"
    ],
    "followup_points": [
      "1. 在选择这两个相似项目（docute 和 docpress）时，主要基于哪些关键维度进行对比评估？它们各自的核心优势和适用场景有何不同？",
      "2. 这些项目在技术实现（如构建工具、模板引擎、数据管理方式）或生态集成（如插件系统、主题定制）方面，有哪些值得借鉴或改进的设计思路？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/README.md",
    "code_examples": []
  },
  {
    "id": "go-interview_README_005",
    "text": "Contributing",
    "answer": "# You can use Gitpod (a free online VS Code-like IDE) for contributing. With a single click it'll launch a workspace and automatically: - clone the docsify repo. - install the dependencies. - start `npm run dev`. So that you can start straight away. [![Open in Gitpod](https://gitpod.io/button/open-in-gitpod.svg)](https://gitpod.io/#https://github.com/docsifyjs/docsify) - Fork it! - Create your feature branch: `git checkout -b my-new-feature` - Commit your changes: `git add . && git commit -m 'Add some feature'` - Push to the branch: `git push origin my-new-feature` - Submit a pull request",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Gitpod",
      "IDE",
      "Git",
      "npm",
      "开发环境配置"
    ],
    "followup_points": [
      "1. 除了 Gitpod 之外，是否有其他推荐的本地开发环境配置方式？",
      "2. 在使用 Gitpod 进行协作时，如何处理多人同时修改同一文件的情况？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/README.md",
    "code_examples": []
  },
  {
    "id": "go-interview_README_008",
    "text": "Contributors",
    "answer": "This project exists thanks to all the people who contribute. [[Contribute](CONTRIBUTING.md)].",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "开源项目",
      "贡献指南",
      "社区协作",
      "项目维护",
      "开发者参与"
    ],
    "followup_points": [
      "1. How do you onboard new contributors to ensure they understand the project's contribution guidelines and workflow?",
      "2. What specific roles or types of contributions (e.g., code, documentation, issue triage) are most valuable to the project's success?"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/README.md",
    "code_examples": []
  },
  {
    "id": "go-interview_README_009",
    "text": "Special Thanks",
    "answer": "A preview of Docsify's PR and develop branch is Powered by",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "Docsify",
      "PR",
      "develop branch",
      "preview",
      "Powered by"
    ],
    "followup_points": [
      "1. Docsify的PR和develop分支预览功能是如何实现的？",
      "2. \"Powered by\"的具体展示形式和背后是否有品牌合作或推广考量？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/README.md",
    "code_examples": []
  },
  {
    "id": "go-interview_vue_000",
    "text": "Template syntax",
    "answer": "Vue [template syntax](https://vuejs.org/v2/guide/syntax.html) is used to create dynamic content. With no additional configuration, this syntax offers several useful features like support for [JavaScript expressions](https://vuejs.org/v2/guide/syntax.html#Using-JavaScript-Expressions) and Vue [directives](https://vuejs.org/v2/guide/syntax.html#Directives) for loops and conditional rendering. Text for GitHub Item {{ i }} 2 + 2 = {{ 2 + 2 }} [View output on GitHub](https://github.com/docsifyjs/docsify/blob/develop/docs/vue.md#template-syntax) Vue content becomes more interesting when [data](#data), [computed properties](#computed-properties), [methods](#methods), and [lifecycle hooks](#lifecycle-hooks) are used. These options can be specified as [global options](#global-options) or within DOM [mounts](#mounts) and [components](#components). # {{ message }} Text for GitHub [View output on GitHub](https://github.com/docsifyjs/docsify/blob/develop/docs/vue.md#data) # Good {{ timeOfDay }}! # Say Hello # {{ image.title }}",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Vue",
      "template syntax",
      "JavaScript expressions",
      "directives"
    ],
    "followup_points": [
      "1. 在Vue模板中，JavaScript表达式的使用有哪些限制或需要注意的地方？",
      "2. Vue模板语法中的指令（如v-if、v-for）与普通JavaScript表达式在底层实现机制上有何不同？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/vue.md",
    "code_examples": [
      {
        "code": "<!-- Hide in docsify, show elsewhere (e.g. GitHub) -->\n<p v-if=\"false\">Text for GitHub</p>\n\n<!-- Sequenced content (i.e. loop)-->\n<ul>\n  <li v-for=\"i in 3\">Item {{ i }}</li>\n</ul>\n\n<!-- JavaScript expressions -->\n<p>2 + 2 = {{ 2 + 2 }}</p>",
        "language": "markdown"
      },
      {
        "code": "{\n  data() {\n    return {\n      message: 'Hello, World!'\n    };\n  }\n}",
        "language": "js"
      },
      {
        "code": "<!-- Show message in docsify, show \"{{ message }}\" elsewhere (e.g. GitHub)  -->\n{{ message }}\n\n<!-- Show message in docsify, hide elsewhere (e.g. GitHub)  -->\n<p v-text=\"message\"></p>\n\n<!-- Show message in docsify, show text elsewhere (e.g. GitHub)  -->\n<p v-text=\"message\">Text for GitHub</p>",
        "language": "markdown"
      },
      {
        "code": "{\n  computed: {\n    timeOfDay() {\n      const date = new Date();\n      const hours = date.getHours();\n\n      if (hours < 12) {\n        return 'morning';\n      }\n      else if (hours < 18) {\n        return 'afternoon';\n      }\n      else {\n        return 'evening'\n      }\n    }\n  },\n}",
        "language": "js"
      },
      {
        "code": "Good {{ timeOfDay }}!",
        "language": "markdown"
      },
      {
        "code": "{\n  data() {\n    return {\n      message: 'Hello, World!'\n    };\n  },\n  methods: {\n    hello() {\n      alert(this.message);\n    }\n  },\n}",
        "language": "js"
      },
      {
        "code": "<button @click=\"hello\">Say Hello</button>",
        "language": "markdown"
      },
      {
        "code": "{\n  data() {\n    return {\n      images: null,\n    };\n  },\n  created() {\n    fetch('https://api.domain.com/')\n      .then(response => response.json())\n      .then(data => (this.images = data))\n      .catch(err => console.log(err));\n  }\n}\n\n// API response:\n// [\n//   { title: 'Image 1', url: 'https://domain.com/1.jpg' },\n//   { title: 'Image 2', url: 'https://domain.com/2.jpg' },\n//   { title: 'Image 3', url: 'https://domain.com/3.jpg' },\n// ];",
        "language": "js"
      },
      {
        "code": "<div style=\"display: flex;\">\n  <figure style=\"flex: 1;\">\n    <img v-for=\"image in images\" :src=\"image.url\" :title=\"image.title\">\n    <figcaption>{{ image.title }}</figcaption>\n  </figure>\n</div>",
        "language": "markdown"
      }
    ]
  },
  {
    "id": "go-interview_vue_001",
    "text": "Global options",
    "answer": "Use `vueGlobalOptions` to specify [Vue options](https://vuejs.org/v2/api/#Options-Data) for use with Vue content not explicitly mounted with [vueMounts](#mounts), [vueComponents](#components), or a [markdown script](#markdown-script). Changes to global `data` will persist and be reflected anywhere global references are used. - {{ count }} + Notice the behavior when multiple global counters are rendered: - {{ count }} + Changes made to one counter affect the both counters. This is because both instances reference the same global `count` value. Now, navigate to a new page and return to this section to see how changes made to global data persist between page loads.",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Vue 全局配置",
      "vueGlobalOptions",
      "Vue 选项",
      "数据持久化",
      "Vue 内容挂载"
    ],
    "followup_points": [
      "1. `vueGlobalOptions` 中的 `data` 如何与其他局部组件的 `data` 发生冲突或合并？",
      "2. 如果在 `vueGlobalOptions` 中定义了 `computed` 或 `methods`，它们是否可以在所有 Vue 内容中直接访问，还是需要额外配置？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/vue.md",
    "code_examples": [
      {
        "code": "window.$docsify = {\n  vueGlobalOptions: {\n    data() {\n      return {\n        count: 0,\n      };\n    },\n  },\n};",
        "language": "js"
      },
      {
        "code": "<p>\n  <button @click=\"count -= 1\">-</button>\n  {{ count }}\n  <button @click=\"count += 1\">+</button>\n</p>",
        "language": "markdown"
      }
    ]
  },
  {
    "id": "go-interview_vue_003",
    "text": "Components",
    "answer": "Use `vueComponents` to create and register global [Vue components](https://vuejs.org/v2/guide/components.html). Components are specified using the component name as the key with an object containing Vue options as the value. Component `data` is unique for each instance and will not persist as users navigate the site.",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Vue组件",
      "全局组件注册",
      "组件实例数据",
      "组件选项对象",
      "Vue生命周期"
    ],
    "followup_points": [
      "1. 在 `vueComponents` 中注册全局组件时，如何处理组件之间的依赖关系和循环引用问题？",
      "2. 如果需要在多个 Vue 应用实例中共享或隔离全局组件，有哪些最佳实践或配置选项？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/vue.md",
    "code_examples": [
      {
        "code": "window.$docsify = {\n  vueComponents: {\n    'button-counter': {\n      template: `\n        <button @click=\"count += 1\">\n          You clicked me {{ count }} times\n        </button>\n      `,\n      data() {\n        return {\n          count: 0,\n        };\n      },\n    },\n  },\n};",
        "language": "js"
      },
      {
        "code": "<button-counter></button-counter>\n<button-counter></button-counter>",
        "language": "markdown"
      }
    ]
  },
  {
    "id": "go-interview_vue_004",
    "text": "Markdown script",
    "answer": "Vue content can mounted using a `` tag in your markdown pages. !> Only the first `` tag in a markdown file is executed. If you wish to mount multiple Vue instances using a script tag, all instances must be mounted within the first script tag in your markdown.",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "Vue",
      "Markdown",
      "script tag",
      "mounting",
      "single instance limitation"
    ],
    "followup_points": [
      "1. 如果需要在同一个 markdown 文件中执行多个 Vue 实例，除了将它们放在第一个 `<script>` 标签内，是否有其他推荐的实现方式或最佳实践？",
      "2. 当第一个 `<script>` 标签中的 Vue 实例较多时，是否存在性能或维护上的潜在问题，如果有，如何优化？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/vue.md",
    "code_examples": [
      {
        "code": "<!-- Vue 2.x  -->\n<script>\n  new Vue({\n    el: '#example',\n    // Options...\n  });\n</script>",
        "language": "html"
      },
      {
        "code": "<!-- Vue 3.x  -->\n<script>\n  Vue.createApp({\n    // Options...\n  }).mount('#example');\n</script>",
        "language": "html"
      }
    ]
  },
  {
    "id": "go-interview_vue_005",
    "text": "Technical Notes",
    "answer": "- Docsify processes Vue content in the following order on each page load: 1. Execute markdown `` 1. Register global `vueComponents` 1. Mount `vueMounts` 1. Auto-mount unmounted `vueComponents` 1. Auto-mount unmounted Vue template syntax using `vueGlobalOptions` - When auto-mounting Vue content, docsify will mount each top-level element in your markdown that contains template syntax or a component. For example, in the following HTML the top-level ``, ``, and `` elements will be mounted. - Docsify will not mount an existing Vue instance or an element that contains an existing Vue instance. - Docsify will automatically destroy/unmount all Vue instances it creates before each page load.",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "Vue组件",
      "Markdown处理",
      "组件挂载",
      "全局选项",
      "自动挂载"
    ],
    "followup_points": [
      "1. 在 Docsify 处理 Vue 内容的顺序中，为什么 `vueMounts` 的执行优先级高于 `vueComponents` 的自动挂载？",
      "2. `vueGlobalOptions` 在自动挂载未挂载的 Vue 模板语法时，具体是如何影响组件的渲染行为的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/vue.md",
    "code_examples": [
      {
        "code": "<p>{{ foo }}</p>\n  <my-component />\n  <div>\n    <span>{{ bar }}</span>\n    <some-other-component />\n  </div>",
        "language": "html"
      }
    ]
  },
  {
    "id": "go-interview__sidebar_000",
    "text": "Getting started",
    "answer": "- [Quick start](quickstart.md) - [Writing more pages](more-pages.md) - [Custom navbar](custom-navbar.md) - [Cover page](cover.md)",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "文档结构",
      "快速入门",
      "页面编写",
      "导航栏定制",
      "封面页设计"
    ],
    "followup_points": [
      "1. 在 Quick start 中，用户最常遇到的初始配置问题是什么？",
      "2. Custom navbar 支持哪些动态交互功能（如下拉菜单、响应式适配）？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/_sidebar.md",
    "code_examples": []
  },
  {
    "id": "go-interview__sidebar_001",
    "text": "Customization",
    "answer": "- [Configuration](configuration.md) - [Themes](themes.md) - [List of Plugins](plugins.md) - [Write a Plugin](write-a-plugin.md) - [Markdown configuration](markdown.md) - [Language highlighting](language-highlight.md) - [Emoji](emoji.md)",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "Configuration",
      "Themes",
      "Plugins",
      "Markdown",
      "Language Highlighting"
    ],
    "followup_points": [
      "1. 在这些定制化选项中，哪一项是用户反馈中使用频率最高的？",
      "2. 对于插件开发，是否有提供详细的API文档或示例代码来帮助新开发者快速上手？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/_sidebar.md",
    "code_examples": []
  },
  {
    "id": "go-interview_helpers_000",
    "text": "Important content",
    "answer": "Important content like: is rendered as: !> **Time** is money, my friend!",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "Markdown语法",
      "HTML转义",
      "文本格式化",
      "特殊字符处理",
      "内容渲染"
    ],
    "followup_points": [
      "1. 为什么选择使用 `!>` 来标记重要内容，而不是其他常见的标记方式（如 `*` 或 `**`）？",
      "2. 在实际应用中，如何确保重要内容的渲染效果符合用户的预期或设计规范？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/helpers.md",
    "code_examples": [
      {
        "code": "!> **Time** is money, my friend!",
        "language": "markdown"
      }
    ]
  },
  {
    "id": "go-interview_helpers_001",
    "text": "General tips",
    "answer": "General tips like: are rendered as: ?> _TODO_ unit test",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "PHP",
      "HTML",
      "Unit Testing",
      "Code Rendering",
      "TODO Comments"
    ],
    "followup_points": [
      "1. 您提到\"unit test\"，能否具体说明在项目中是如何实施单元测试的？例如使用的测试框架、覆盖率目标以及如何确保测试用例的质量？",
      "2. 对于\"General tips\"中的其他未提及点（如代码规范、性能优化等），您认为哪些是最容易被忽视但又至关重要的，为什么？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/helpers.md",
    "code_examples": [
      {
        "code": "?> _TODO_ unit test",
        "language": "markdown"
      }
    ]
  },
  {
    "id": "go-interview_helpers_002",
    "text": "Ignore to compile link",
    "answer": "Sometimes we will use some other relative path for the link, and we have to tell docsify that we don't need to compile this link. For example: It will be compiled to `link` and will load `/demo/README.md`. Maybe you want to jump to `/demo/index.html`. Now you can do that You will get `link`html. Do not worry, you can still set the title for the link.",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "docsify",
      "编译链接",
      "相对路径",
      "markdown链接",
      "HTML链接"
    ],
    "followup_points": [
      "1. 除了使用 `ignore` 属性外，还有其他方式可以避免 docsify 编译特定链接吗？",
      "2. 如果链接指向的是外部资源（如 CDN 链接），是否也需要使用 `ignore` 属性来防止编译？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/helpers.md",
    "code_examples": [
      {
        "code": "[link](/demo/)",
        "language": "md"
      },
      {
        "code": "[link](/demo/ ':ignore')",
        "language": "md"
      },
      {
        "code": "[link](/demo/ ':ignore title')\n\n<a href=\"/demo/\" title=\"title\">link</a>",
        "language": "md"
      }
    ]
  },
  {
    "id": "go-interview_helpers_003",
    "text": "GitHub Task Lists",
    "answer": "- [ ] foo - bar - [x] baz - [] bam <~ not working - [ ] bim - [ ] lim",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "Markdown语法",
      "GitHub任务列表",
      "复选框",
      "任务状态",
      "列表格式"
    ],
    "followup_points": [
      "1. 您提到 \"not working\"，能否具体描述一下您遇到的问题现象和期望的正确行为是什么？",
      "2. 在实际使用中，您是如何处理 Task List 的状态更新（如 `[ ]` 和 `[x]`）的？是通过手动编辑还是借助工具/脚本？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/helpers.md",
    "code_examples": [
      {
        "code": "- [ ] foo\n- bar\n- [x] baz\n- [] bam <~ not working\n  - [ ] bim\n  - [ ] lim",
        "language": "md"
      }
    ]
  },
  {
    "id": "go-interview_helpers_005",
    "text": "Markdown in html tag",
    "answer": "You need to insert a space between the html and markdown content. This is useful for rendering markdown content in the details element. Self-assessment (Click to expand) - Abc - Abc Markdown content can also be wrapped in html tags. - Abc - Abc",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "Markdown渲染",
      "HTML标签",
      "空格处理",
      "details元素",
      "内容嵌套"
    ],
    "followup_points": [
      "1. 除了在 `<details>` 元素中，这种在 HTML 标签后插入空格的方式在其他 HTML 标签（如 `<div>`、`<section>`）中渲染 Markdown 时是否同样适用？",
      "2. 如果 HTML 标签和 Markdown 内容之间没有插入空格，常见的渲染错误或浏览器兼容性问题有哪些？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/helpers.md",
    "code_examples": [
      {
        "code": "<details>\n<summary>Self-assessment (Click to expand)</summary>\n\n- Abc\n- Abc\n\n</details>",
        "language": "markdown"
      },
      {
        "code": "<div style='color: red'>\n\n- listitem\n- listitem\n- listitem\n\n</div>",
        "language": "markdown"
      }
    ]
  },
  {
    "id": "go-interview_plugins_000",
    "text": "Full text search",
    "answer": "By default, the hyperlink on the current page is recognized and the content is saved in `localStorage`. You can also specify the path to the files. This plugin ignores diacritical marks when performing a full text search (e.g., \"cafe\" will also match \"café\"). Legacy browsers like IE11 require the following [String.normalize()](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/normalize) polyfill to ignore diacritical marks:",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Full text search",
      "localStorage",
      "diacritical marks",
      "hyperlink",
      "path to files"
    ],
    "followup_points": [
      "1. How does the plugin handle updates to the content in `localStorage` when the source files change dynamically?",
      "2. What are the performance implications of ignoring diacritical marks during full-text search, especially for large datasets?"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/plugins.md",
    "code_examples": [
      {
        "code": "<script>\n  window.$docsify = {\n    search: 'auto', // default\n\n    search: [\n      '/',            // => /README.md\n      '/guide',       // => /guide.md\n      '/get-started', // => /get-started.md\n      '/zh-cn/',      // => /zh-cn/README.md\n    ],\n\n    // complete configuration parameters\n    search: {\n      maxAge: 86400000, // Expiration time, the default one day\n      paths: [], // or 'auto'\n      placeholder: 'Type to search',\n\n      // Localization\n      placeholder: {\n        '/zh-cn/': '搜索',\n        '/': 'Type to search',\n      },\n\n      noData: 'No Results!',\n\n      // Localization\n      noData: {\n        '/zh-cn/': '找不到结果',\n        '/': 'No Results',\n      },\n\n      // Headline depth, 1 - 6\n      depth: 2,\n\n      hideOtherSidebarContent: false, // whether or not to hide other sidebar content\n\n      // To avoid search index collision\n      // between multiple websites under the same domain\n      namespace: 'website-1',\n\n      // Use different indexes for path prefixes (namespaces).\n      // NOTE: Only works in 'auto' mode.\n      //\n      // When initialiazing an index, we look for the first path from the sidebar.\n      // If it matches the prefix from the list, we switch to the corresponding index.\n      pathNamespaces: ['/zh-cn', '/ru-ru', '/ru-ru/v1'],\n\n      // You can provide a regexp to match prefixes. In this case,\n      // the matching substring will be used to identify the index\n      pathNamespaces: /^(\\/(zh-cn|ru-ru))?(\\/(v1|v2))?/,\n    },\n  };\n</script>\n<script src=\"//cdn.jsdelivr.net/npm/docsify/lib/docsify.min.js\"></script>\n<script src=\"//cdn.jsdelivr.net/npm/docsify/lib/plugins/search.min.js\"></script>",
        "language": "html"
      },
      {
        "code": "<script src=\"//polyfill.io/v3/polyfill.min.js?features=String.prototype.normalize\"></script>",
        "language": "html"
      }
    ]
  },
  {
    "id": "go-interview_plugins_001",
    "text": "Google Analytics",
    "answer": "Install the plugin and configure the track id. Configure by `data-ga`.",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "Google Analytics",
      "插件安装",
      "配置追踪ID",
      "data-ga属性",
      "网站分析工具"
    ],
    "followup_points": [
      "1. 在配置 `data-ga` 属性时，具体需要设置哪些关键参数（如事件类别、操作、标签等）来确保数据追踪的准确性？",
      "2. 如果网站同时存在多个需要追踪的交互元素（如按钮、链接、表单），如何通过 `data-ga` 属性区分不同元素的追踪逻辑，避免数据混淆？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/plugins.md",
    "code_examples": [
      {
        "code": "<script>\n  window.$docsify = {\n    ga: 'UA-XXXXX-Y',\n  };\n</script>\n<script src=\"//cdn.jsdelivr.net/npm/docsify/lib/docsify.min.js\"></script>\n<script src=\"//cdn.jsdelivr.net/npm/docsify/lib/plugins/ga.min.js\"></script>",
        "language": "html"
      },
      {
        "code": "<script src=\"//cdn.jsdelivr.net/npm/docsify/lib/docsify.min.js\" data-ga=\"UA-XXXXX-Y\"></script>\n<script src=\"//cdn.jsdelivr.net/npm/docsify/lib/plugins/ga.min.js\"></script>",
        "language": "html"
      }
    ]
  },
  {
    "id": "go-interview_plugins_003",
    "text": "External Script",
    "answer": "If the script on the page is an external one (imports a js file via `src` attribute), you'll need this plugin to make it work.",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "External Script",
      "JavaScript",
      "src attribute",
      "Plugin",
      "Import"
    ],
    "followup_points": [
      "1. 除了通过 `src` 属性引入的外部脚本，该插件是否还支持其他方式加载的外部脚本（如动态创建的 `script` 标签或通过模块系统加载的脚本）？",
      "2. 如果页面中同时存在内联脚本和外部脚本，该插件是否会优先处理外部脚本，或者两者会以何种顺序执行？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/plugins.md",
    "code_examples": [
      {
        "code": "<script src=\"//cdn.jsdelivr.net/npm/docsify/lib/plugins/external-script.min.js\"></script>",
        "language": "html"
      }
    ]
  },
  {
    "id": "go-interview_plugins_004",
    "text": "Zoom image",
    "answer": "Medium's image zoom. Based on [medium-zoom](https://github.com/francoischalifour/medium-zoom). Exclude the special image",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "image zoom",
      "medium-zoom",
      "JavaScript",
      "DOM manipulation",
      "event handling"
    ],
    "followup_points": [
      "1. 如何判断和排除\"特殊图像\"，具体是哪些类型的图像需要被排除？",
      "2. 在使用 medium-zoom 时，是否遇到过性能或兼容性问题，是如何优化的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/plugins.md",
    "code_examples": [
      {
        "code": "<script src=\"//cdn.jsdelivr.net/npm/docsify/lib/plugins/zoom-image.min.js\"></script>",
        "language": "html"
      },
      {
        "code": "![](image.png ':no-zoom')",
        "language": "markdown"
      }
    ]
  },
  {
    "id": "go-interview_plugins_005",
    "text": "Edit on github",
    "answer": "Add `Edit on github` button on every pages. Provided by [@njleonzhang](https://github.com/njleonzhang), see this [document](https://github.com/njleonzhang/docsify-edit-on-github)",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "前端开发",
      "GitHub集成",
      "文档网站",
      "插件使用",
      "UI组件"
    ],
    "followup_points": [
      "1. 这个 `Edit on github` 按钮的具体实现方式是怎样的？是直接引入了某个第三方库，还是需要手动配置 GitHub 仓库的相关信息？",
      "2. 添加这个按钮后，是否会对页面的加载性能或用户体验产生明显影响？如果有，是如何优化的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/plugins.md",
    "code_examples": []
  },
  {
    "id": "go-interview_plugins_006",
    "text": "Demo code with instant preview and jsfiddle integration",
    "answer": "With this plugin, sample code can be rendered on the page instantly, so that the readers can see the preview immediately. When readers expand the demo box, the source code and description are shown there. if they click the button `Try in Jsfiddle`, `jsfiddle.net` will be open with the code of this sample, which allow readers to revise the code and try on their own. [Vue](https://njleonzhang.github.io/docsify-demo-box-vue/) and [React](https://njleonzhang.github.io/docsify-demo-box-react/) are both supported.",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "代码预览",
      "即时渲染",
      "Jsfiddle集成",
      "交互设计",
      "插件开发"
    ],
    "followup_points": [
      "1. How does the plugin handle different code languages (e.g., HTML, CSS, JavaScript) in the instant preview, and are there any limitations?",
      "2. What happens if the code in the demo contains external dependencies (e.g., libraries or APIs) – how does the integration with jsfiddle ensure those dependencies are loaded correctly?"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/plugins.md",
    "code_examples": []
  },
  {
    "id": "go-interview_plugins_007",
    "text": "Copy to Clipboard",
    "answer": "Add a simple `Click to copy` button to all preformatted code blocks to effortlessly allow users to copy example code from your docs. Provided by [@jperasmus](https://github.com/jperasmus) See [here](https://github.com/jperasmus/docsify-copy-code/blob/master/README.md) for more details.",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "Clipboard API",
      "DOM 操作",
      "事件处理",
      "前端交互",
      "代码高亮"
    ],
    "followup_points": [
      "1. 这个功能在移动端或触摸设备上的用户体验如何优化？",
      "2. 是否支持自定义复制按钮的样式或触发方式（如双击代码块复制）？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/plugins.md",
    "code_examples": [
      {
        "code": "<script src=\"//cdn.jsdelivr.net/npm/docsify-copy-code/dist/docsify-copy-code.min.js\"></script>",
        "language": "html"
      }
    ]
  },
  {
    "id": "go-interview_plugins_009",
    "text": "Pagination",
    "answer": "Pagination for docsify. By [@imyelo](https://github.com/imyelo) Click [here](https://github.com/imyelo/docsify-pagination#readme) to get more information.",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "docsify",
      "pagination",
      "JavaScript",
      "GitHub",
      "前端开发"
    ],
    "followup_points": [
      "1. 在 docsify 的分页插件中，如何自定义分页的样式或行为？",
      "2. 该分页插件是否支持动态内容加载，比如基于 API 返回的数据进行分页？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/plugins.md",
    "code_examples": [
      {
        "code": "<script src=\"//cdn.jsdelivr.net/npm/docsify/lib/docsify.min.js\"></script>\n<script src=\"//cdn.jsdelivr.net/npm/docsify-pagination/dist/docsify-pagination.min.js\"></script>",
        "language": "html"
      }
    ]
  },
  {
    "id": "go-interview_language-highlight_000",
    "text": "Markup - `markup`, `html`, `xml`, `svg`, `mathml`, `ssml`, `atom`, `rss`",
    "answer": "Markup - `markup`, `html`, `xml`, `svg`, `mathml`, `ssml`, `atom`, `rss`",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "markup",
      "html",
      "xml",
      "svg",
      "mathml"
    ],
    "followup_points": [
      "1. 这些标记语言中，哪些是专门用于特定领域（如数学、语音合成）的，它们与通用标记语言（如HTML、XML）的主要区别是什么？",
      "2. 在实际项目中，你会如何选择使用XML而不是JSON（或其他数据格式）来存储或传输结构化数据？请结合具体场景说明。"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/language-highlight.md",
    "code_examples": []
  },
  {
    "id": "go-interview_configuration_002",
    "text": "autoHeader",
    "answer": "- Type: `Boolean` - Default: `false` If `loadSidebar` and `autoHeader` are both enabled, for each link in `_sidebar.md`, prepend a header to the page before converting it to HTML. See [#78](https://github.com/docsifyjs/docsify/issues/78).",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Type",
      "Boolean",
      "Default",
      "loadSidebar",
      "autoHeader"
    ],
    "followup_points": [
      "1. 如果 `autoHeader` 和 `loadSidebar` 同时启用，当 `_sidebar.md` 中的链接指向不存在的页面时，是否会自动生成对应的 header？",
      "2. `autoHeader` 生成的 header 默认样式或层级是否可以自定义，比如通过 CSS 或配置项调整？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/configuration.md",
    "code_examples": [
      {
        "code": "window.$docsify = {\n  loadSidebar: true,\n  autoHeader: true,\n};",
        "language": "js"
      }
    ]
  },
  {
    "id": "go-interview_configuration_004",
    "text": "catchPluginErrors",
    "answer": "- Type: `Boolean` - Default: `true` Determines if Docsify should handle uncaught _synchronous_ plugin errors automatically. This can prevent plugin errors from affecting docsify's ability to properly render live site content.",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "Error Handling",
      "Plugin System",
      "Synchronous Execution",
      "Configuration",
      "Default Value"
    ],
    "followup_points": [
      "1. 当 `catchPluginErrors` 设置为 `false` 时，未捕获的插件错误会如何影响 Docsify 的渲染流程？",
      "2. 如果多个插件同时抛出同步错误，`catchPluginErrors` 的处理机制是否会区分错误优先级或记录详细的错误来源？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/configuration.md",
    "code_examples": []
  },
  {
    "id": "go-interview_configuration_005",
    "text": "cornerExternalLinkTarget",
    "answer": "- Type: `String` - Default: `'_blank'` Target to open external link at the top right corner. Default `'_blank'` (new window/tab)",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "Type",
      "String",
      "Default",
      "External link",
      "Target"
    ],
    "followup_points": [
      "1. 如果用户希望在新窗口中打开外部链接，但不想使用默认的 `_blank`，还有哪些可选的值？",
      "2. 除了 `'_blank'`，是否支持其他目标属性（如 `'_self'`、`'_parent'` 或 `'_top'`）？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/configuration.md",
    "code_examples": [
      {
        "code": "window.$docsify = {\n  cornerExternalLinkTarget: '_self', // default: '_blank'\n};",
        "language": "js"
      }
    ]
  },
  {
    "id": "go-interview_configuration_008",
    "text": "executeScript",
    "answer": "- Type: `Boolean` - Default: `null` Execute the script on the page. Only parses the first script tag ([demo](themes)). If Vue is detected, this is `true` by default. ```markdown",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "executeScript",
      "Vue",
      "script_tag",
      "Boolean",
      "default_value"
    ],
    "followup_points": [
      "1. 如果页面中存在多个 script 标签，`executeScript` 是否会按顺序执行所有标签，还是仅执行第一个匹配的标签？",
      "2. 当 Vue 被检测到时，`executeScript` 默认为 `true`，那么这个检测机制是基于 Vue 的特定属性、全局变量还是其他特征？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/configuration.md",
    "code_examples": [
      {
        "code": "window.$docsify = {\n  executeScript: true,\n};",
        "language": "js"
      }
    ]
  },
  {
    "id": "go-interview_configuration_009",
    "text": "This is test",
    "answer": "console.log(2333) ``` Note that if you are running an external script, e.g. an embedded jsfiddle demo, make sure to include the [external-script](plugins.md?id=external-script) plugin.",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "console.log",
      "external-script",
      "plugins",
      "embedded-jsfiddle",
      "demo"
    ],
    "followup_points": [
      "1. 在什么场景下需要使用 external-script 插件来加载外部脚本？",
      "2. 如果 external-script 插件加载失败，有哪些常见的排查方法？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/configuration.md",
    "code_examples": []
  },
  {
    "id": "go-interview_configuration_011",
    "text": "externalLinkRel",
    "answer": "- Type: `String` - Default: `'noopener'` Default `'noopener'` (no opener) prevents the newly opened external page (when [externalLinkTarget](#externallinktarget) is `'_blank'`) from having the ability to control our page. No `rel` is set when it's not `'_blank'`. See [this post](https://mathiasbynens.github.io/rel-noopener/) for more information about why you may want to use this option.",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "externalLinkRel",
      "noopener",
      "security",
      "rel attribute",
      "externalLinkTarget"
    ],
    "followup_points": [
      "1. 如果 `externalLinkTarget` 不是 `'_blank'`，是否完全不需要设置 `rel` 属性？有没有其他场景下建议手动指定 `rel` 值？",
      "2. 在安全性方面，除了 `'noopener'`，是否还有其他值得推荐的 `rel` 值（如 `'noreferrer'`）？它们之间的安全性和性能影响有何区别？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/configuration.md",
    "code_examples": [
      {
        "code": "window.$docsify = {\n  externalLinkRel: '', // default: 'noopener'\n};",
        "language": "js"
      }
    ]
  },
  {
    "id": "go-interview_configuration_012",
    "text": "externalLinkTarget",
    "answer": "- Type: `String` - Default: `'_blank'` Target to open external links inside the markdown. Default `'_blank'` (new window/tab)",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "Type",
      "String",
      "Default",
      "externalLinkTarget",
      "markdown"
    ],
    "followup_points": [
      "1. 如果用户希望某些外部链接在当前标签页打开，应该如何配置 `externalLinkTarget` 来覆盖默认行为？",
      "2. `externalLinkTarget` 是否支持动态配置（例如基于路径或条件判断）？如果支持，具体如何实现？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/configuration.md",
    "code_examples": [
      {
        "code": "window.$docsify = {\n  externalLinkTarget: '_self', // default: '_blank'\n};",
        "language": "js"
      }
    ]
  },
  {
    "id": "go-interview_configuration_013",
    "text": "fallbackLanguages",
    "answer": "- Type: `Array` List of languages that will fallback to the default language when a page is requested and it doesn't exist for the given locale. Example: - try to fetch the page of `/de/overview`. If this page exists, it'll be displayed. - then try to fetch the default page `/overview` (depending on the default language). If this page exists, it'll be displayed. - then display the 404 page.",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "i18n",
      "localization",
      "fallback",
      "locale",
      "array"
    ],
    "followup_points": [
      "1. 当 fallbackLanguages 数组中包含多个语言时，系统会按照什么顺序尝试回退？",
      "2. 如果 fallbackLanguages 中的语言页面也不存在，是否会继续回退到默认语言，还是直接报错？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/configuration.md",
    "code_examples": [
      {
        "code": "window.$docsify = {\n  fallbackLanguages: ['fr', 'de'],\n};",
        "language": "js"
      }
    ]
  },
  {
    "id": "go-interview_configuration_014",
    "text": "formatUpdated",
    "answer": "- Type: `String|Function` We can display the file update date through **{docsify-updated}** variable. And format it by `formatUpdated`. See https://github.com/lukeed/tinydate#patterns",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "docsify-updated",
      "formatUpdated",
      "String|Function",
      "tinydate",
      "patterns"
    ],
    "followup_points": [
      "1. 如果 `formatUpdated` 设置为一个函数，该函数会接收什么参数，并且应该如何返回格式化后的日期字符串？",
      "2. 在使用 `{docsify-updated}` 变量时，如果未设置 `formatUpdated`，默认的日期格式是什么样的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/configuration.md",
    "code_examples": [
      {
        "code": "window.$docsify = {\n  formatUpdated: '{MM}/{DD} {HH}:{mm}',\n\n  formatUpdated: function (time) {\n    // ...\n\n    return time;\n  },\n};",
        "language": "js"
      }
    ]
  },
  {
    "id": "go-interview_configuration_015",
    "text": "hideSidebar",
    "answer": "- Type : `Boolean` - Default: `true` This option will completely hide your sidebar and won't render any content on the side.",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "Boolean",
      "Default",
      "Option",
      "Sidebar",
      "Render"
    ],
    "followup_points": [
      "1. 当 `hideSidebar` 设置为 `false` 时，sidebar 的默认渲染行为或配置是什么样的？",
      "2. 如果 sidebar 被隐藏后，是否支持通过某种动态方式（如事件、API 或状态变化）重新显示它？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/configuration.md",
    "code_examples": [
      {
        "code": "window.$docsify = {\n  hideSidebar: true,\n};",
        "language": "js"
      }
    ]
  },
  {
    "id": "go-interview_configuration_017",
    "text": "loadNavbar",
    "answer": "- Type: `Boolean|String` - Default: `false` Loads navbar from the Markdown file `_navbar.md` if **true**, else loads it from the path specified.",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "Type",
      "Boolean",
      "String",
      "Default",
      "Markdown file"
    ],
    "followup_points": [
      "1. 如果指定路径加载导航栏，该路径是相对于当前文档还是项目根目录？",
      "2. 当 `loadNavbar` 为 `true` 时，`_navbar.md` 文件需要遵循特定的格式或结构要求吗？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/configuration.md",
    "code_examples": [
      {
        "code": "window.$docsify = {\n  // load from _navbar.md\n  loadNavbar: true,\n\n  // load from nav.md\n  loadNavbar: 'nav.md',\n};",
        "language": "js"
      }
    ]
  },
  {
    "id": "go-interview_configuration_018",
    "text": "loadSidebar",
    "answer": "- Type: `Boolean|String` - Default: `false` Loads sidebar from the Markdown file `_sidebar.md` if **true**, else loads it from the path specified.",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "Type",
      "Boolean",
      "String",
      "Default",
      "Markdown"
    ],
    "followup_points": [
      "1. 当 `loadSidebar` 设置为 `true` 时，`_sidebar.md` 文件的具体格式和配置要求是什么？",
      "2. 如果 `loadSidebar` 设置为自定义路径（如 `'./custom/sidebar.md'`），该路径的解析规则和优先级是怎样的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/configuration.md",
    "code_examples": [
      {
        "code": "window.$docsify = {\n  // load from _sidebar.md\n  loadSidebar: true,\n\n  // load from summary.md\n  loadSidebar: 'summary.md',\n};",
        "language": "js"
      }
    ]
  },
  {
    "id": "go-interview_configuration_022",
    "text": "mergeNavbar",
    "answer": "- Type: `Boolean` - Default: `false` Navbar will be merged with the sidebar on smaller screens.",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "- Navbar",
      "- Sidebar",
      "- Responsive Design",
      "- Boolean Type",
      "- Default Value"
    ],
    "followup_points": [
      "1. 当 `mergeNavbar` 设置为 `true` 时，Navbar 和 Sidebar 的具体合并逻辑是怎样的？是否会有样式上的调整或交互上的变化？",
      "2. 在哪些具体的屏幕尺寸下会触发 Navbar 和 Sidebar 的合并，这个阈值是否可以自定义？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/configuration.md",
    "code_examples": [
      {
        "code": "window.$docsify = {\n  mergeNavbar: true,\n};",
        "language": "js"
      }
    ]
  },
  {
    "id": "go-interview_configuration_025",
    "text": "nativeEmoji",
    "answer": "- Type: `Boolean` - Default: `false` Render emoji shorthand codes using GitHub-style emoji images or platform-native emoji characters. GitHub-style images when `false`: Platform-native characters when `true`: 😄︎ 🥳︎ 😂︎ 👍︎ 👎︎ To render shorthand codes as text, replace `:` characters with the `&colon;` HTML entity. &colon;100&colon;",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "emoji渲染",
      "布尔类型配置",
      "GitHub风格",
      "平台原生字符",
      "HTML实体编码"
    ],
    "followup_points": [
      "1. 当 `nativeEmoji` 设置为 `true` 时，平台-native emoji 字符在不同操作系统或设备上的显示效果是否存在差异？",
      "2. 如果用户输入的 emoji shorthand code 不存在，当 `nativeEmoji` 为 `false` 时会显示默认的 GitHub 图像，那么设置为 `true` 时会如何处理无效的 shorthand code？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/configuration.md",
    "code_examples": [
      {
        "code": "window.$docsify = {\n  nativeEmoji: true,\n};",
        "language": "js"
      },
      {
        "code": ":smile:\n:partying_face:\n:joy:\n:+1:\n:-1:",
        "language": "markdown"
      },
      {
        "code": "&colon;100&colon;",
        "language": "markdown"
      }
    ]
  },
  {
    "id": "go-interview_configuration_026",
    "text": "noCompileLinks",
    "answer": "- Type: `Array` Sometimes we do not want docsify to handle our links. See [#203](https://github.com/docsifyjs/docsify/issues/203). We can skip compiling of certain links by specifying an array of strings. Each string is converted into to a regular expression (`RegExp`) and the _whole_ href of a link is matched against it.",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "- Array",
      "- Regular Expression",
      "- RegExp",
      "- href",
      "- Link Handling"
    ],
    "followup_points": [
      "1. 如果 `noCompileLinks` 中的正则表达式匹配到多个链接，docsify 会如何处理这些匹配到的链接？",
      "2. 能否提供一个具体的 `noCompileLinks` 配置示例，说明如何跳过特定模式（如外部链接或特定路径）的链接编译？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/configuration.md",
    "code_examples": [
      {
        "code": "window.$docsify = {\n  noCompileLinks: ['/foo', '/bar/.*'],\n};",
        "language": "js"
      }
    ]
  },
  {
    "id": "go-interview_configuration_028",
    "text": "notFoundPage",
    "answer": "- Type: `Boolean` | `String` | `Object` - Default: `false` Display default \"404 - Not found\" message: Load the `_404.md` file: Load the customized path of the 404 page: Load the right 404 page according to the localization: > Note: The options for fallbackLanguages don't work with the `notFoundPage` options.",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "- 404页面配置",
      "- 多语言支持",
      "- 文件加载机制",
      "- 类型检查",
      "- 回退策略"
    ],
    "followup_points": [
      "1. 当 `notFoundPage` 设置为 `Object` 类型时，如何配置多语言 404 页面的路径和对应的语言标识？",
      "2. 如果 `notFoundPage` 设置为自定义路径（如 `/custom-404`），但该路径不存在或加载失败，系统会如何处理回退逻辑？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/configuration.md",
    "code_examples": [
      {
        "code": "window.$docsify = {\n  notFoundPage: false,\n};",
        "language": "js"
      },
      {
        "code": "window.$docsify = {\n  notFoundPage: true,\n};",
        "language": "js"
      },
      {
        "code": "window.$docsify = {\n  notFoundPage: 'my404.md',\n};",
        "language": "js"
      },
      {
        "code": "window.$docsify = {\n  notFoundPage: {\n    '/': '_404.md',\n    '/de': 'de/_404.md',\n  },\n};",
        "language": "js"
      }
    ]
  },
  {
    "id": "go-interview_configuration_030",
    "text": "relativePath",
    "answer": "- Type: `Boolean` - Default: `false` If **true**, links are relative to the current context. For example, the directory structure is as follows: With relative path **enabled** and current URL `http://domain.com/zh-cn/README`, given links will resolve to:",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "relativePath",
      "URL解析",
      "路径解析",
      "布尔类型",
      "默认值"
    ],
    "followup_points": [
      "1. 当 `relativePath` 为 `true` 时，如果当前 URL 是 `http://domain.com/zh-cn/README`，而链接是 `/about`，最终解析的完整路径是什么？",
      "2. 如果 `relativePath` 为 `false`，链接会如何解析？它与 `true` 时的行为有什么本质区别？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/configuration.md",
    "code_examples": [
      {
        "code": ".\n└── docs\n    ├── README.md\n    ├── guide.md\n    └── zh-cn\n        ├── README.md\n        ├── guide.md\n        └── config\n            └── example.md",
        "language": "text"
      },
      {
        "code": "guide.md              => http://domain.com/zh-cn/guide\nconfig/example.md     => http://domain.com/zh-cn/config/example\n../README.md          => http://domain.com/README\n/README.md            => http://domain.com/README",
        "language": "text"
      },
      {
        "code": "window.$docsify = {\n  // Relative path enabled\n  relativePath: true,\n\n  // Relative path disabled (default value)\n  relativePath: false,\n};",
        "language": "js"
      }
    ]
  },
  {
    "id": "go-interview_configuration_032",
    "text": "requestHeaders",
    "answer": "- Type: `Object` Set the request resource headers. Such as setting the cache",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "HTTP请求头",
      "对象类型",
      "缓存控制",
      "资源请求",
      "配置参数"
    ],
    "followup_points": [
      "1. 当设置 `requestHeaders` 时，如果设置的 header 与浏览器默认的 header 冲突，优先级是怎样的？",
      "2. 在跨域请求中，哪些 header 是受浏览器安全策略限制而无法通过 `requestHeaders` 自定义的？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/configuration.md",
    "code_examples": [
      {
        "code": "window.$docsify = {\n  requestHeaders: {\n    'x-token': 'xxx',\n  },\n};",
        "language": "js"
      },
      {
        "code": "window.$docsify = {\n  requestHeaders: {\n    'cache-control': 'max-age=600',\n  },\n};",
        "language": "js"
      }
    ]
  },
  {
    "id": "go-interview_configuration_034",
    "text": "subMaxLevel",
    "answer": "- Type: `Number` - Default: `0` Add table of contents (TOC) in custom sidebar. If you have a link to the homepage in the sidebar and want it to be shown as active when accessing the root url, make sure to update your sidebar accordingly: For more details, see [#1131](https://github.com/docsifyjs/docsify/issues/1131).",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Type",
      "Number",
      "Default",
      "Add table of contents",
      "TOC"
    ],
    "followup_points": [
      "1. 如果 `subMaxLevel` 设置为 0，是否意味着完全禁用目录（TOC）的生成？",
      "2. 当 `subMaxLevel` 设置为大于 0 的值时，目录是否会自动包含所有层级的标题，还是需要额外配置？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/configuration.md",
    "code_examples": [
      {
        "code": "window.$docsify = {\n  subMaxLevel: 2,\n};",
        "language": "js"
      },
      {
        "code": "- Sidebar\n  - [Home](/)\n  - [Another page](another.md)",
        "language": "markdown"
      }
    ]
  },
  {
    "id": "go-interview_configuration_035",
    "text": "themeColor",
    "answer": "- Type: `String` Customize the theme color. Use [CSS3 variables](https://developer.mozilla.org/en-US/docs/Web/CSS/Using_CSS_variables) feature and polyfill in older browsers.",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Type",
      "String",
      "CSS3 variables",
      "Polyfill",
      "Customization"
    ],
    "followup_points": [
      "1. 在使用 CSS3 变量实现主题色时，如何确保在旧浏览器中通过 polyfill 正确渲染？",
      "2. 除了 CSS 变量，是否支持其他主题色配置方式（如动态类名、内联样式）？各自的优缺点是什么？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/configuration.md",
    "code_examples": [
      {
        "code": "window.$docsify = {\n  themeColor: '#3F51B5',\n};",
        "language": "js"
      }
    ]
  },
  {
    "id": "go-interview_configuration_037",
    "text": "vueComponents",
    "answer": "- Type: `Object` Creates and registers global [Vue components](https://vuejs.org/v2/guide/components.html). Components are specified using the component name as the key with an object containing Vue options as the value. Component `data` is unique for each instance and will not persist as users navigate the site.",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Vue组件",
      "全局组件注册",
      "组件选项",
      "组件数据",
      "组件实例"
    ],
    "followup_points": [
      "1. 在 VueComponents 中，如果组件名与现有全局组件名冲突，Vue 会如何处理？",
      "2. 如何动态注册或卸载全局组件，特别是在运行时场景下？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/configuration.md",
    "code_examples": [
      {
        "code": "window.$docsify = {\n  vueComponents: {\n    'button-counter': {\n      template: `\n        <button @click=\"count += 1\">\n          You clicked me {{ count }} times\n        </button>\n      `,\n      data() {\n        return {\n          count: 0,\n        };\n      },\n    },\n  },\n};",
        "language": "js"
      },
      {
        "code": "<button-counter></button-counter>",
        "language": "markdown"
      }
    ]
  },
  {
    "id": "go-interview_configuration_038",
    "text": "vueGlobalOptions",
    "answer": "- Type: `Object` Specifies [Vue options](https://vuejs.org/v2/api/#Options-Data) for use with Vue content not explicitly mounted with [vueMounts](#mounting-dom-elements), [vueComponents](#components), or a [markdown script](#markdown-script). Changes to global `data` will persist and be reflected anywhere global references are used. - {{ count }} +",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "- Vue全局配置",
      "- Vue选项对象",
      "- 数据持久化",
      "- 未挂载Vue实例",
      "- 全局data响应式"
    ],
    "followup_points": [
      "1. 在 `vueGlobalOptions` 中修改全局 `data` 时，如果多个未明确挂载的 Vue 组件共享该数据，如何确保数据变化的响应式同步不会引发意外的副作用或性能问题？",
      "2. 当 `vueGlobalOptions` 与通过 `vueMounts` 或 `vueComponents` 显式配置的 Vue 选项存在冲突时（如 `data` 或 `methods` 重名），Vue 的合并策略是怎样的，优先级如何确定？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/configuration.md",
    "code_examples": [
      {
        "code": "window.$docsify = {\n  vueGlobalOptions: {\n    data() {\n      return {\n        count: 0,\n      };\n    },\n  },\n};",
        "language": "js"
      },
      {
        "code": "<p>\n  <button @click=\"count -= 1\">-</button>\n  {{ count }}\n  <button @click=\"count += 1\">+</button>\n</p>",
        "language": "markdown"
      }
    ]
  },
  {
    "id": "go-interview_more-pages_001",
    "text": "Nested Sidebars",
    "answer": "You may want the sidebar to update after navigation to reflect the current directory. This can be done by adding a `_sidebar.md` file to each folder. `_sidebar.md` is loaded from each level directory. If the current directory doesn't have `_sidebar.md`, it will fall back to the parent directory. If, for example, the current path is `/guide/quick-start`, the `_sidebar.md` will be loaded from `/guide/_sidebar.md`. You can specify `alias` to avoid unnecessary fallback. !> You can create a `README.md` file in a subdirectory to use it as the landing page for the route.",
    "category": "system",
    "difficulty": 3,
    "tags": [
      "文件系统导航",
      "侧边栏配置",
      "嵌套目录结构",
      "动态内容加载",
      "回退机制"
    ],
    "followup_points": [
      "1. 在实现嵌套侧边栏时，如何处理 `_sidebar.md` 文件中路径的相对路径解析，确保在不同层级目录下都能正确导航到目标页面？",
      "2. 如果用户希望在某些特定目录下禁用侧边栏的默认回退机制（即不继承父目录的 `_sidebar.md`），是否有配置方法或自定义逻辑来实现这一需求？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/more-pages.md",
    "code_examples": [
      {
        "code": "<script>\n  window.$docsify = {\n    loadSidebar: true,\n    alias: {\n      '/.*/_sidebar.md': '/_sidebar.md'\n    }\n  }\n</script>",
        "language": "html"
      }
    ]
  },
  {
    "id": "go-interview_more-pages_002",
    "text": "Set Page Titles from Sidebar Selection",
    "answer": "A page's `title` tag is generated from the _selected_ sidebar item name. For better SEO, you can customize the title by specifying a string after the filename.",
    "category": "system",
    "difficulty": 2,
    "tags": [
      "SEO",
      "HTML title tag",
      "Dynamic content generation",
      "Sidebar navigation",
      "URL routing"
    ],
    "followup_points": [
      "1. 如何确保动态生成的页面标题对搜索引擎优化（SEO）最有效？",
      "2. 如果侧边栏选项名称包含特殊字符或过长，是否有机制来处理或限制标题的格式？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/more-pages.md",
    "code_examples": [
      {
        "code": "<!-- docs/_sidebar.md -->\n* [Home](/)\n* [Guide](guide.md \"The greatest guide in the world\")",
        "language": "markdown"
      }
    ]
  },
  {
    "id": "go-interview_more-pages_003",
    "text": "Table of Contents",
    "answer": "Once you've created `_sidebar.md`, the sidebar content is automatically generated based on the headers in the markdown files. A custom sidebar can also automatically generate a table of contents by setting a `subMaxLevel`, compare [subMaxLevel configuration](configuration.md#submaxlevel).",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "Markdown",
      "Sidebar",
      "Table of Contents",
      "Configuration",
      "subMaxLevel"
    ],
    "followup_points": [
      "1. 如果 `subMaxLevel` 设置为 2，但某些 markdown 文件的标题层级超过 2，会如何处理这些超出层级的标题？",
      "2. 在自定义侧边栏中，是否可以手动调整生成的目录顺序，或者仅依赖标题的层级结构？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/more-pages.md",
    "code_examples": [
      {
        "code": "<!-- index.html -->\n\n<script>\n  window.$docsify = {\n    loadSidebar: true,\n    subMaxLevel: 2\n  }\n</script>\n<script src=\"//cdn.jsdelivr.net/npm/docsify/lib/docsify.min.js\"></script>",
        "language": "html"
      }
    ]
  },
  {
    "id": "go-interview_more-pages_004",
    "text": "Ignoring Subheaders",
    "answer": "When `subMaxLevel` is set, each header is automatically added to the table of contents by default. If you want to ignore a specific header, add `` to it. ```markdown # Getting Started",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "Markdown",
      "Subheaders",
      "Table of Contents",
      "Configuration",
      "Syntax"
    ],
    "followup_points": [
      "1. 如果项目中需要批量忽略多个特定层级的子标题，是否有更高效的方法，比如通过配置文件或正则表达式来批量处理，而不是逐个添加 `ignore` 标记？",
      "2. 在忽略子标题后，生成的目录结构是否会保留被忽略标题的层级占位符，还是直接跳过这些标题，这对文档的可读性和导航逻辑有什么影响？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/more-pages.md",
    "code_examples": []
  },
  {
    "id": "go-interview_more-pages_005",
    "text": "Header <!-- {docsify-ignore} -->",
    "answer": "This header won't appear in the sidebar table of contents. markdown # Getting Started",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "docsify-ignore",
      "markdown",
      "header",
      "sidebar",
      "table of contents"
    ],
    "followup_points": [
      "1. 除了 `<!-- {docsify-ignore} -->`，还有哪些其他方式可以控制文档在侧边栏目录中的显示或隐藏？",
      "2. 如果希望在特定层级（如某个章节下）忽略目录生成，而其他层级正常显示，应该如何实现？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/more-pages.md",
    "code_examples": [
      {
        "code": "To ignore all headers on a specific page, you can use `<!-- {docsify-ignore-all} -->` on the first header of the page.",
        "language": ""
      }
    ]
  },
  {
    "id": "go-interview_deploy_000",
    "text": "GitHub Pages",
    "answer": "There are three places to populate your docs for your GitHub repository: - `docs/` folder - main branch - gh-pages branch It is recommended that you save your files to the `./docs` subfolder of the `main` branch of your repository. Then select `main branch /docs folder` as your GitHub Pages source in your repository's settings page. ![GitHub Pages](_images/deploy-github-pages.png) !> You can also save files in the root directory and select `main branch`. You'll need to place a `.nojekyll` file in the deploy location (such as `/docs` or the gh-pages branch)",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "GitHub Pages",
      "docs folder",
      "main branch",
      "gh-pages branch",
      "source configuration"
    ],
    "followup_points": [
      "1. 如果选择 `gh-pages` 分支作为 GitHub Pages 的源，与使用 `main` 分支的 `docs/` 文件夹相比，有哪些具体的优势和适用场景？",
      "2. 当使用 `main` 分支的 `docs/` 文件夹作为源时，如何处理文档的版本控制和发布流程，以确保文档与代码的更新同步？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/deploy.md",
    "code_examples": []
  },
  {
    "id": "go-interview_deploy_001",
    "text": "GitLab Pages",
    "answer": "If you are deploying your master branch, create a `.gitlab-ci.yml` with the following script: ?> The `.public` workaround is so `cp` doesn't also copy `public/` to itself in an infinite loop. !> You can replace script with `- cp -r docs/. public`, if `./docs` is your Docsify subfolder.",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "GitLab CI/CD",
      ".gitlab-ci.yml",
      "Pages部署",
      "静态站点生成",
      "Docsify"
    ],
    "followup_points": [
      "1. 为什么在 `.gitlab-ci.yml` 中需要使用 `.public` 作为中间目录，而不是直接将 `docs/` 内容复制到 `public/`？",
      "2. 如果项目结构复杂（如多语言文档或动态生成内容），如何调整 `.gitlab-ci.yml` 以确保 Pages 正确部署所有必要文件？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/deploy.md",
    "code_examples": [
      {
        "code": "pages:\n  stage: deploy\n  script:\n  - mkdir .public\n  - cp -r * .public\n  - mv .public public\n  artifacts:\n    paths:\n    - public\n  only:\n  - master",
        "language": "YAML"
      }
    ]
  },
  {
    "id": "go-interview_deploy_002",
    "text": "Firebase Hosting",
    "answer": "!> You'll need to install the Firebase CLI using `npm i -g firebase-tools` after signing into the [Firebase Console](https://console.firebase.google.com) using a Google Account. Using a terminal, determine and navigate to the directory for your Firebase Project. This could be `~/Projects/Docs`, etc. From there, run `firebase init` and choose `Hosting` from the menu (use **space** to select, **arrow keys** to change options and **enter** to confirm). Follow the setup instructions. Your `firebase.json` file should look similar to this (I changed the deployment directory from `public` to `site`): Once finished, build the starting template by running `docsify init ./site` (replacing site with the deployment directory you determined when running `firebase init` - public by default). Add/edit the documentation, then run `firebase deploy` from the root project directory.",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "Firebase CLI",
      "Firebase Console",
      "npm",
      "Google Account",
      "Terminal Navigation"
    ],
    "followup_points": [
      "1. 在安装 Firebase CLI 后，如何验证安装是否成功，以及如何检查当前登录的 Google 账户是否正确？",
      "2. 如果项目目录中已经存在 Firebase 相关配置文件（如 `firebase.json`），初始化时需要注意哪些步骤或常见问题？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/deploy.md",
    "code_examples": [
      {
        "code": "{\n  \"hosting\": {\n    \"public\": \"site\",\n    \"ignore\": [\"firebase.json\", \"**/.*\", \"**/node_modules/**\"]\n  }\n}",
        "language": "json"
      }
    ]
  },
  {
    "id": "go-interview_deploy_005",
    "text": "AWS Amplify",
    "answer": "1. Set the routerMode in the Docsify project `index.html` to *history* mode. 2. Login to your [AWS Console](https://aws.amazon.com). 3. Go to the [AWS Amplify Dashboard](https://aws.amazon.com/amplify). 4. Choose the **Deploy** route to setup your project. 5. When prompted, keep the build settings empty if you're serving your docs within the root directory. If you're serving your docs from a different directory, customise your amplify.yml 6. Add the following Redirect rules in their displayed order. Note that the second record is a PNG image where you can change it with any image format you are using. | Source address | Target address | Type | |----------------|----------------|---------------| | /.md | /.md | 200 (Rewrite) | | /.png | /.png | 200 (Rewrite) | | / | /index.html | 200 (Rewrite) |",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "AWS Amplify",
      "前端路由",
      "AWS Console",
      "部署配置",
      "构建设置"
    ],
    "followup_points": [
      "1. 在设置 routerMode 为 history 模式时，如何处理后端 API 的路由冲突问题？",
      "2. 在 AWS Amplify 部署过程中，如果自定义构建设置失败，有哪些常见的排查步骤？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/deploy.md",
    "code_examples": [
      {
        "code": "<script>\n    window.$docsify = {\n      loadSidebar: true,\n      routerMode: 'history'\n    }\n</script>",
        "language": "html"
      },
      {
        "code": "version: 0.1\nfrontend:\n  phases:\n    build:\n      commands:\n        - echo \"Nothing to build\"\n  artifacts:\n    baseDirectory: /docs\n    files:\n      - '**/*'\n  cache:\n    paths: []",
        "language": "yml"
      }
    ]
  },
  {
    "id": "go-interview__navbar_000",
    "text": "Translations",
    "answer": "- [:uk: English](/) - [:cn: 简体中文](/zh-cn/) - [:de: Deutsch](/de-de/) - [:es: Español](/es/) - [:ru: Русский](/ru-ru/)",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "国际化",
      "多语言",
      "URL路由",
      "语言标识符",
      "链接结构"
    ],
    "followup_points": [
      "1. 在选择支持的语言时，主要考虑了哪些因素（如用户需求、市场覆盖度、资源投入等）？",
      "2. 对于新增语言或调整现有语言版本的流程，是否有标准化的规范或工具支持？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/_navbar.md",
    "code_examples": []
  },
  {
    "id": "go-interview__coverpage_000",
    "text": "Multiple themes",
    "answer": "Multiple themes [GitHub](https://github.com/docsifyjs/docsify/) [Getting Started](#docsify)",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "docsify",
      "themes",
      "GitHub",
      "getting-started",
      "multiple-themes"
    ],
    "followup_points": [
      "1. 在实现多主题功能时，如何确保不同主题之间的样式隔离和冲突避免？",
      "2. 多主题切换是否支持动态加载，对页面性能有哪些优化措施？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/_coverpage.md",
    "code_examples": []
  },
  {
    "id": "go-interview_quickstart_000",
    "text": "Initialize",
    "answer": "If you want to write the documentation in the `./docs` subdirectory, you can use the `init` command.",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "Documentation",
      "Initialization",
      "Command-Line Interface",
      "Directory Structure",
      "Subdirectory"
    ],
    "followup_points": [
      "1. 除了 `./docs` 目录，`init` 命令是否支持自定义其他文档目录路径？",
      "2. `init` 命令执行后，会生成哪些默认的文档结构或配置文件？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/quickstart.md",
    "code_examples": [
      {
        "code": "docsify init ./docs",
        "language": "bash"
      }
    ]
  },
  {
    "id": "go-interview_quickstart_001",
    "text": "Writing content",
    "answer": "After the `init` is complete, you can see the file list in the `./docs` subdirectory. - `index.html` as the entry file - `README.md` as the home page - `.nojekyll` prevents GitHub Pages from ignoring files that begin with an underscore You can easily update the documentation in `./docs/README.md`, of course you can add [more pages](more-pages.md).",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "Documentation",
      "File Structure",
      "Static Site Generation",
      "GitHub Pages",
      "Markdown"
    ],
    "followup_points": [
      "1. 在 `./docs` 目录下，除了 `index.html`、`README.md` 和 `.nojekyll` 之外，还有哪些关键文件或目录需要关注？",
      "2. 如果需要自定义 `index.html` 的内容或样式，有哪些推荐的实现方式或注意事项？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/quickstart.md",
    "code_examples": []
  },
  {
    "id": "go-interview_quickstart_002",
    "text": "Preview your site",
    "answer": "Run the local server with `docsify serve`. You can preview your site in your browser on `http://localhost:3000`. ?> For more use cases of `docsify-cli`, head over to the [docsify-cli documentation](https://github.com/docsifyjs/docsify-cli).",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "docsify",
      "本地服务器",
      "命令行工具",
      "端口3000",
      "实时预览"
    ],
    "followup_points": [
      "1. 如果在运行 `docsify serve` 后浏览器无法访问 `http://localhost:3000`，可能的原因有哪些？",
      "2. 除了 `docsify serve`，还有哪些方法可以本地预览 docsify 生成的站点？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/quickstart.md",
    "code_examples": [
      {
        "code": "docsify serve docs",
        "language": "bash"
      }
    ]
  },
  {
    "id": "go-interview_quickstart_003",
    "text": "Manual initialization",
    "answer": "If you don't like `npm` or have trouble installing the tool, you can manually create `index.html`: # ?> Note that in both of the examples below, docsify URLs will need to be manually updated when a new major version of docsify is released (e.g. `v4.x.x` => `v5.x.x`). Check the docsify website periodically to see if a new major version has been released. Specifying a major version in the URL (`@4`) will allow your site will receive non-breaking enhancements (i.e. \"minor\" updates) and bug fixes (i.e. \"patch\" updates) automatically. This is the recommended way to load docsify resources. If you prefer to lock docsify to a specific version, specify the full version after the `@` symbol in the URL. This is the safest way to ensure your site will look and behave the same way regardless of any changes made to future versions of docsify. # If you have Python installed on your system, you can easily use it to run a static server to preview your site.",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "Manual initialization",
      "HTML setup",
      "Version management",
      "CDN usage",
      "Dependency management"
    ],
    "followup_points": [
      "1. 除了手动创建 `index.html`，还有哪些替代方案可以避免使用 `npm` 安装 docsify？",
      "2. 手动更新 docsify 版本时，有哪些最佳实践或工具可以简化版本管理的过程？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/quickstart.md",
    "code_examples": [
      {
        "code": "<!-- index.html -->\n\n<!DOCTYPE html>\n<html>\n  <head>\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" />\n    <meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\n    <meta charset=\"UTF-8\" />\n    <link\n      rel=\"stylesheet\"\n      href=\"//cdn.jsdelivr.net/npm/docsify@4/themes/vue.css\"\n    />\n  </head>\n  <body>\n    <div id=\"app\"></div>\n    <script>\n      window.$docsify = {\n        //...\n      };\n    </script>\n    <script src=\"//cdn.jsdelivr.net/npm/docsify@4\"></script>\n  </body>\n</html>",
        "language": "html"
      },
      {
        "code": "<link rel=\"stylesheet\" href=\"//cdn.jsdelivr.net/npm/docsify@4/themes/vue.css\" />\n<script src=\"//cdn.jsdelivr.net/npm/docsify@4\"></script>",
        "language": "html"
      },
      {
        "code": "<link\n  rel=\"stylesheet\"\n  href=\"//cdn.jsdelivr.net/npm/docsify@4.11.4/themes/vue.css\"\n/>\n<script src=\"//cdn.jsdelivr.net/npm/docsify@4.11.4\"></script>",
        "language": "html"
      },
      {
        "code": "cd docs && python -m SimpleHTTPServer 3000",
        "language": "python2"
      },
      {
        "code": "cd docs && python -m http.server 3000",
        "language": "python3"
      }
    ]
  },
  {
    "id": "go-interview_quickstart_004",
    "text": "Loading dialog",
    "answer": "If you want, you can show a loading dialog before docsify starts to render your documentation: You should set the `data-app` attribute if you changed `el`: Compare [el configuration](configuration.md#el).",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "Loading dialog",
      "data-app attribute",
      "el configuration",
      "docsify initialization",
      "render documentation"
    ],
    "followup_points": [
      "1. 在实际项目中，你遇到过哪些需要自定义 loading dialog 场景？如何根据不同场景调整 loading dialog 的样式和交互逻辑？",
      "2. 如果 loading dialog 需要支持多语言或动态内容（如加载进度、错误提示），你会如何结合 docsify 的生命周期钩子来实现？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/quickstart.md",
    "code_examples": [
      {
        "code": "<!-- index.html -->\n\n<div id=\"app\">Please wait...</div>",
        "language": "html"
      },
      {
        "code": "<!-- index.html -->\n\n<div data-app id=\"main\">Please wait...</div>\n\n<script>\n  window.$docsify = {\n    el: '#main',\n  };\n</script>",
        "language": "html"
      }
    ]
  },
  {
    "id": "go-interview_README_000",
    "text": "What it is",
    "answer": "Docsify generates your documentation website on the fly. Unlike GitBook, it does not generate static html files. Instead, it smartly loads and parses your Markdown files and displays them as a website. To start using it, all you need to do is create an `index.html` and [deploy it on GitHub Pages](deploy.md). See the [Quick start](quickstart.md) guide for more details.",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "Markdown",
      "动态生成",
      "静态网站生成器",
      "GitHub Pages",
      "前端开发"
    ],
    "followup_points": [
      "1. How does Docsify's on-the-fly generation impact the performance and loading speed of the documentation website compared to static site generators like GitBook?",
      "2. What are the key advantages or trade-offs of using Docsify's dynamic parsing approach over static HTML generation for large or frequently updated documentation projects?"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/README.md",
    "code_examples": []
  },
  {
    "id": "go-interview_write-a-plugin_002",
    "text": "Lifecycle Hooks",
    "answer": "Lifecycle hooks are provided via the `hook` argument passed to the plugin function. # Invoked one time when docsify script is initialized. # Invoked one time when the docsify instance has mounted on the DOM. # Invoked on each page load before new markdown is transformed to HTML. For asynchronous tasks, the hook function accepts a `next` callback as a second argument. Call this function with the final `markdown` value when ready. To prevent errors from affecting docsify and other plugins, wrap async code in a `try/catch/finally` block. # Invoked on each page load after new markdown has been transformed to HTML. For asynchronous tasks, the hook function accepts a `next` callback as a second argument. Call this function with the final `html` value when ready. To prevent errors from affecting docsify and other plugins, wrap async code in a `try/catch/finally` block. # Invoked on each page load after new HTML has been appended to the DOM. # Invoked one time after rendering the initial page.",
    "category": "system",
    "difficulty": 2,
    "tags": [
      "Lifecycle Hooks",
      "Plugin Initialization",
      "DOM Mounting",
      "Page Load",
      "Asynchronous Tasks"
    ],
    "followup_points": [
      "1. 在异步任务处理中，如何确保 `hook` 的执行顺序或依赖关系？",
      "2. 除了提到的三个生命周期钩子，docsify 是否还支持其他自定义钩子，如页面卸载或数据更新时的钩子？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/write-a-plugin.md",
    "code_examples": [
      {
        "code": "hook.init(function () {\n  // ...\n});",
        "language": "js"
      },
      {
        "code": "hook.mounted(function () {\n  // ...\n});",
        "language": "js"
      },
      {
        "code": "hook.beforeEach(function (markdown) {\n  // ...\n  return markdown;\n});",
        "language": "js"
      },
      {
        "code": "hook.beforeEach(function (markdown, next) {\n  try {\n    // Async task(s)...\n  } catch (err) {\n    // ...\n  } finally {\n    next(markdown);\n  }\n});",
        "language": "js"
      },
      {
        "code": "hook.afterEach(function (html) {\n  // ...\n  return html;\n});",
        "language": "js"
      },
      {
        "code": "hook.afterEach(function (html, next) {\n  try {\n    // Async task(s)...\n  } catch (err) {\n    // ...\n  } finally {\n    next(html);\n  }\n});",
        "language": "js"
      },
      {
        "code": "hook.doneEach(function () {\n  // ...\n});",
        "language": "js"
      },
      {
        "code": "hook.ready(function () {\n  // ...\n});",
        "language": "js"
      }
    ]
  },
  {
    "id": "go-interview_embed-files_000",
    "text": "Embedded file type",
    "answer": "Currently, file extensions are automatically recognized and embedded in different ways. These types are supported: * **iframe** `.html`, `.htm` * **markdown** `.markdown`, `.md` * **audio** `.mp3` * **video** `.mp4`, `.ogg` * **code** other file extension Of course, you can force the specified type. For example, a Markdown file can be embedded as a code block by setting `:type=code`. You will get: [filename](_media/example.md ':include :type=code')",
    "category": "system",
    "difficulty": 2,
    "tags": [
      "文件类型识别",
      "文件嵌入",
      "iframe嵌入",
      "markdown渲染",
      "多媒体支持"
    ],
    "followup_points": [
      "1. 如何判断系统是否正确识别了文件类型，如果识别错误有哪些手动干预的方式？",
      "2. 对于自定义文件类型，除了强制指定嵌入类型外，是否支持扩展默认支持的文件类型列表？如何操作？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/embed-files.md",
    "code_examples": [
      {
        "code": "[filename](_media/example.md ':include :type=code')",
        "language": "markdown"
      }
    ]
  },
  {
    "id": "go-interview_embed-files_001",
    "text": "Markdown with YAML Front Matter",
    "answer": "When using Markdown, YAML front matter will be stripped from the rendered content. The attributes cannot be used in this case. You will get just the content [filename](_media/example-with-yaml.md ':include')",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "Markdown",
      "YAML Front Matter",
      "内容渲染",
      "文件包含",
      "属性访问"
    ],
    "followup_points": [
      "1. 如果需要在渲染后的内容中使用 YAML front matter 的属性，有哪些替代方案可以实现？",
      "2. 在不同的 Markdown 渲染器（如 Jekyll、Hugo、Hexo 等）中，处理 YAML front matter 的方式是否存在差异？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/embed-files.md",
    "code_examples": [
      {
        "code": "[filename](_media/example-with-yaml.md ':include')",
        "language": "markdown"
      }
    ]
  },
  {
    "id": "go-interview_embed-files_002",
    "text": "Embedded code fragments",
    "answer": "Sometimes you don't want to embed a whole file. Maybe because you need just a few lines but you want to compile and test the file in CI. In your code file you need to surround the fragment between `/// [demo]` lines (before and after the fragment). Alternatively you can use `# Example: [filename](_media/example.js ':include :type=code :fragment=demo')",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "代码片段嵌入",
      "CI编译测试",
      "文档注释标记",
      "代码示例引用",
      "文件片段引用"
    ],
    "followup_points": [
      "1. 在使用 `/// [demo]` 标记代码片段时，如果片段中包含依赖其他文件或外部库的代码，如何确保在 CI 环境中正确编译和测试？",
      "2. 除了 `/// [demo]` 和 `# Example: [filename](_m`，是否有其他更灵活或更高级的代码片段嵌入方式，比如支持动态参数或条件编译？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/embed-files.md",
    "code_examples": [
      {
        "code": "[filename](_media/example.js ':include :type=code :fragment=demo')",
        "language": "markdown"
      }
    ]
  },
  {
    "id": "go-interview_embed-files_003",
    "text": "Tag attribute",
    "answer": "If you embed the file as `iframe`, `audio` and `video`, then you may need to set the attributes of these tags. ?> Note, for the `audio` and `video` types, docsify adds the `controls` attribute by default. When you want add more attributes, the `controls` attribute need to be added manually if need be. [cinwell website](https://cinwell.com ':include :type=iframe width=100% height=400px') Did you see it? You only need to write directly. You can check [MDN](https://developer.mozilla.org/en-US/docs/Web/HTML/Element/iframe) for these attributes.",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "iframe",
      "audio",
      "video",
      "tag attributes",
      "controls attribute"
    ],
    "followup_points": [
      "1. 在 docsify 中，除了 `controls` 属性外，还有哪些常用的 `audio` 和 `video` 标签属性需要手动添加，以及它们的具体作用是什么？",
      "2. 如果需要在 `iframe` 标签中添加自定义属性（如 `sandbox`、`allowfullscreen` 等），是否有特定的配置方法或注意事项？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/embed-files.md",
    "code_examples": [
      {
        "code": "[filename](_media/example.mp4 ':include :type=video controls width=100%')",
        "language": "md"
      },
      {
        "code": "[cinwell website](https://cinwell.com ':include :type=iframe width=100% height=400px')",
        "language": "markdown"
      }
    ]
  },
  {
    "id": "go-interview_embed-files_004",
    "text": "The code block highlight",
    "answer": "Embedding any type of source code file, you can specify the highlighted language or automatically identify. ⬇️ [](_media/example.html ':include :type=code text') ?> How to set highlight? You can see [here](language-highlight.md).",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "代码高亮",
      "嵌入代码",
      "语言识别",
      "Markdown语法",
      "代码块处理"
    ],
    "followup_points": [
      "1. 自动识别代码高亮语言的机制是基于什么规则或算法实现的？",
      "2. 如果指定的语言类型与实际代码不符，系统会如何处理？是否支持手动覆盖或修正？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/embed-files.md",
    "code_examples": [
      {
        "code": "[](_media/example.html ':include :type=code text')",
        "language": "markdown"
      }
    ]
  },
  {
    "id": "go-interview_embed-files_005",
    "text": "Embed a gist",
    "answer": "You can embed a gist as markdown content or as a code block - this is based on the approach at the start of [Embed Files](#embed-files) section, but uses a raw gist URL as the target. ?> **No** plugin or app config change is needed here to make this work. In fact, the \"Embed\" `script` tag that is copied from a gist will _not_ load even if you make plugin or config changes to allow an external script. # Start by viewing a gist on `gist.github.com`. For the purposes of this guide, we use this gist: - https://gist.github.com/anikethsaha/f88893bb563bb7229d6e575db53a8c15 Identify the following items from the gist: Field | Example | Description --- | --- | --- **Username** | `anikethsaha` | The gist's owner. **Gist ID** | `c2bece08f27c4277001f123898d16a7c` | Identifier for the gist. This is fixed for the gist's lifetime. **Filename** | `content.md` | Select a name of a file in the gist. This needed even on a single-file gist for embedding to work. You will need those to build the _raw gist URL_ for the target file. This has the following format: - `https://gist.githubusercontent.com/USERNAME/GIST_ID/raw/FILENAME` Here are two examples based on the sample gist: - https://gist.githubusercontent.com/anikethsaha/f88893bb563bb7229d6e575db53a8c15/raw/content.md - https://gist.githubusercontent.com/anikethsaha/f88893bb563bb7229d6e575db53a8c15/raw/script.js ?> Alternatively, you can get a raw URL directly clicking the _Raw_ button on a gist file. But, if you use that approach, just be sure to **remove** the revision number between `raw/` and the filename so that the URL matches the pattern above instead. Otherwise your embedded gist will **not** show the latest content when the gist is updated. Continue with one of the sections below to embed the gist on a Docsify page. # This is a great way to embed content **seamlessly** in your docs, without sending someone to an external link. This approach is well-suited to reusing a gist of say installation instructions across doc sites of multiple repos. This approach works equally well with a gist owned by your account or by another user. Here is the format: For example: Which renders as: [gist: content.md](https://gist.githubusercontent.com/anikethsaha/f88893bb563bb7229d6e575db53a8c15/raw/content.md ':include') The `LABEL` can be any text you want. It acts as a _fallback_ message if the link is broken - so it is useful to repeat the filename here in case you need to fix a broken link. It also makes an embedded element easy to read at a glance. # The format is the same as the previous section, but with `:type=code` added to the alt text. As with the [Embedded file type](#embedded-file-type) section, the syntax highlighting will be **inferred** from the extension (e.g. `.js` or `.py`), so you can leave the `type` set as `code`. Here is the format: For example: Which renders as: [gist: script.js](https://gist.githubusercontent.com/anikethsaha/f88893bb563bb7229d6e575db53a8c15/raw/script.js ':include :type=code')",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Markdown",
      "Gist",
      "Embed",
      "Code Block",
      "URL"
    ],
    "followup_points": [
      "1. 在嵌入 gist 时，如何处理 gist 中的敏感信息（如 API 密钥或私人数据）？",
      "2. 嵌入 gist 后，是否可以动态更新内容，或者需要手动重新嵌入才能获取最新版本？"
    ],
    "source_repo": "go-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/go-interview/docsify/docs/embed-files.md",
    "code_examples": [
      {
        "code": "[LABEL](https://gist.githubusercontent.com/USERNAME/GIST_ID/raw/FILENAME ':include')",
        "language": "markdown"
      },
      {
        "code": "[gist: content.md](https://gist.githubusercontent.com/anikethsaha/f88893bb563bb7229d6e575db53a8c15/raw/content.md ':include')",
        "language": "markdown"
      },
      {
        "code": "[LABEL](https://gist.githubusercontent.com/USERNAME/GIST_ID/raw/FILENAME ':include :type=code')",
        "language": "markdown"
      },
      {
        "code": "[gist: script.js](https://gist.githubusercontent.com/anikethsaha/f88893bb563bb7229d6e575db53a8c15/raw/script.js ':include :type=code')",
        "language": "markdown"
      }
    ]
  },
  {
    "id": "gopher_q019_000",
    "text": "**在方法内把局部变量指针返回** 局部变量原本应该在栈中分配，在栈中回收。但是由于返回时被外部引用，因此其生命周期大于栈，则溢出。",
    "answer": "**在方法内把局部变量指针返回** 局部变量原本应该在栈中分配，在栈中回收。但是由于返回时被外部引用，因此其生命周期大于栈，则溢出。",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "局部变量指针",
      "栈内存分配",
      "栈内存回收",
      "生命周期",
      "内存溢出"
    ],
    "followup_points": [
      "1. 如何通过动态内存分配（如 `malloc`）来避免局部变量指针返回导致的栈溢出问题？",
      "2. 在 C++ 中，使用 `new` 分配的内存和栈上分配的局部变量在生命周期管理上有何本质区别？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/q019.md",
    "code_examples": []
  },
  {
    "id": "gopher_q019_001",
    "text": "**发送指针或带有指针的值到 channel 中。**  在编译时，是没有办法知道哪个 `goroutine` 会在 `channel` 上接收数据。所以编译器没法知道变量什么时候才会被释放。",
    "answer": "**发送指针或带有指针的值到 channel 中。** 在编译时，是没有办法知道哪个 `goroutine` 会在 `channel` 上接收数据。所以编译器没法知道变量什么时候才会被释放。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Go",
      "channel",
      "指针",
      "内存管理",
      "并发安全"
    ],
    "followup_points": [
      "1. 在实际开发中，你是如何避免因发送指针到 channel 而导致的内存泄漏问题的？有哪些具体的实践或模式可以确保接收方在使用完指针后正确释放资源？",
      "2. 如果 channel 中的指针指向的数据在发送方已经被修改，而接收方还未处理，这种并发访问是否会导致数据竞争？你通常如何确保数据的一致性和安全性？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/q019.md",
    "code_examples": []
  },
  {
    "id": "gopher_q019_002",
    "text": "**在一个切片上存储指针或带指针的值。** 一个典型的例子就是 `[]*string` 。这会导致切片的内容逃逸。尽管其后面的数组可能是在栈上分配的，但其引用的值一定是在堆上。",
    "answer": "**在一个切片上存储指针或带指针的值。** 一个典型的例子就是 `[]*string` 。这会导致切片的内容逃逸。尽管其后面的数组可能是在栈上分配的，但其引用的值一定是在堆上。",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "Go 逃逸分析",
      "Go 切片",
      "Go 指针",
      "Go 内存分配",
      "Go 堆栈"
    ],
    "followup_points": [
      "1. 在实际开发中，如何判断或检测切片中的指针是否发生了逃逸？",
      "2. 如果切片存储的是指针，如何优化内存使用以减少堆分配的开销？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/q019.md",
    "code_examples": []
  },
  {
    "id": "gopher_q019_003",
    "text": "**slice 的背后数组被重新分配了，因为 append 时可能会超出其容量( cap )。** slice 初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。",
    "answer": "**slice 的背后数组被重新分配了，因为 append 时可能会超出其容量( cap )。** slice 初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "slice",
      "append",
      "容量(cap)",
      "内存分配",
      "栈与堆"
    ],
    "followup_points": [
      "1. 在什么具体场景下，编译器会决定将 slice 的初始分配放在堆上而不是栈上？",
      "2. 如果 slice 的初始容量（cap）设置得足够大，是否能完全避免运行时的堆分配？为什么？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/q019.md",
    "code_examples": []
  },
  {
    "id": "gopher_q019_004",
    "text": "**在 interface 类型上调用方法。**  在 interface 类型上调用方法都是动态调度的 —— 方法的真正实现只能在运行时知道。想像一个 io.Reader 类型的变量 r , 调用 r.Read(b) 会使得 r 的值和切片b 的背后存储都逃逸掉，所以会在堆上分配。",
    "answer": "**在 interface 类型上调用方法。** 在 interface 类型上调用方法都是动态调度的 —— 方法的真正实现只能在运行时知道。想像一个 io.Reader 类型的变量 r , 调用 r.Read(b) 会使得 r 的值和切片b 的背后存储都逃逸掉，所以会在堆上分配。",
    "category": "system",
    "difficulty": 3,
    "tags": [
      "interface",
      "动态调度",
      "逃逸分析",
      "堆分配",
      "io.Reader"
    ],
    "followup_points": [
      "1. 在 interface 类型上调用方法时，除了逃逸到堆上，还有哪些性能影响需要注意？",
      "2. 如果 io.Reader 的具体实现是一个结构体指针，其逃逸行为是否会有变化？为什么？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/q019.md",
    "code_examples": []
  },
  {
    "id": "gopher_q019_005",
    "text": "`./main.go:8:10: new(A) escapes to heap` 说明 `new(A)` 逃逸了,符合上述提到的常见情况中的第一种。",
    "answer": "`./main.go:8:10: new(A) escapes to heap` 说明 `new(A)` 逃逸了,符合上述提到的常见情况中的第一种。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "Go逃逸分析",
      "new关键字",
      "内存逃逸",
      "堆分配",
      "编译器优化"
    ],
    "followup_points": [
      "1. 除了第一种情况，还有哪些常见的代码场景会导致变量逃逸到堆？",
      "2. 变量逃逸到堆对程序性能有哪些具体影响？如何优化以减少不必要的逃逸？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/q019.md",
    "code_examples": []
  },
  {
    "id": "gopher_q019_006",
    "text": "`./main.go:14:11: main a.s + \" world\" does not escape` 说明 b 变量没有逃逸，因为它只在方法内存在，会在方法结束时被回收。",
    "answer": "`./main.go:14:11: main a.s + \" world\" does not escape` 说明 b 变量没有逃逸，因为它只在方法内存在，会在方法结束时被回收。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "Go逃逸分析",
      "变量作用域",
      "内存回收",
      "Go编译器",
      "栈内存分配"
    ],
    "followup_points": [
      "1. 如果将 `b` 变量作为返回值返回，它的逃逸行为会如何变化？",
      "2. 在什么情况下，Go 编译器会允许局部变量逃逸到堆上，即使它只在方法内使用？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/q019.md",
    "code_examples": []
  },
  {
    "id": "gopher_q019_007",
    "text": "`./main.go:15:9: b + \"!\" escapes to heap` 说明 c 变量逃逸，通过`fmt.Println(a ...interface{})`打印的变量，都会发生逃逸，感兴趣的朋友可以去查查为什么。",
    "answer": "`./main.go:15:9: b + \"!\" escapes to heap` 说明 c 变量逃逸，通过`fmt.Println(a ...interface{})`打印的变量，都会发生逃逸，感兴趣的朋友可以去查查为什么。 以上操作其实就叫逃逸分析。下篇文章，跟大家聊聊怎么用一个比较trick的方法使变量不逃逸。方便大家在面试官面前秀一波。 >原文",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "Go逃逸分析",
      "fmt.Println逃逸",
      "堆内存分配",
      "栈内存分配",
      "变量生命周期"
    ],
    "followup_points": [
      "1. 除了`fmt.Println`外，还有哪些常见的Go语言操作或函数调用会导致变量逃逸到堆上？",
      "2. 变量逃逸对程序性能有哪些具体影响？在什么情况下我们需要特别关注逃逸问题？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/q019.md",
    "code_examples": []
  },
  {
    "id": "gopher_go-scheduler_000",
    "text": "切换机制：如何把挑选出来的goroutine放到CPU上运行？",
    "answer": "切换机制：如何把挑选出来的goroutine放到CPU上运行？ 对这三大问题的解决构成了调度器的所有工作，因而我们对调度器的分析也必将围绕着它们所展开。 第二章我们已经详细的分析了调度器的初始化以及goroutine的切换机制，本章将重点讨论调度器如何挑选下一个goroutine出来运行的策略问题，而剩下的与调度时机相关的内容我们将在第4～6章进行全面的分析。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Goroutine调度",
      "CPU调度",
      "调度策略",
      "调度时机",
      "上下文切换"
    ],
    "followup_points": [
      "1. 调度器在选择下一个goroutine运行时，具体采用了哪些策略来确保调度的公平性和高效性？",
      "2. 在将goroutine放到CPU上运行的过程中，调度器如何处理与操作系统调度器的交互，以及如何避免不必要的上下文切换开销？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/go-scheduler.md",
    "code_examples": []
  },
  {
    "id": "gopher_go-scheduler_001",
    "text": "第一步，从全局运行队列中寻找goroutine。为了保证调度的公平性，每个工作线程每经过61次调度就需要优先尝试从全局运行队列中找出一个goroutine来运行，这样才能保证位于全局运行队列中的goroutine得到调度的机会。全局运行队列是所有工作线程都可以访问的，所以在访问它之前需要加锁。",
    "answer": "第一步，从全局运行队列中寻找goroutine。为了保证调度的公平性，每个工作线程每经过61次调度就需要优先尝试从全局运行队列中找出一个goroutine来运行，这样才能保证位于全局运行队列中的goroutine得到调度的机会。全局运行队列是所有工作线程都可以访问的，所以在访问它之前需要加锁。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Goroutine调度",
      "全局运行队列",
      "工作线程",
      "调度公平性",
      "锁机制"
    ],
    "followup_points": [
      "1. 为什么选择61次调度作为从全局运行队列中获取goroutine的阈值？这个数字是如何确定的，是否有特定的考量或历史原因？",
      "2. 在多线程竞争全局运行队列锁的场景下，Go调度器采用了哪些策略来减少锁竞争或优化性能？例如是否有锁的细化、无锁设计或其他并发控制机制？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/go-scheduler.md",
    "code_examples": []
  },
  {
    "id": "gopher_go-scheduler_002",
    "text": "第二步，从工作线程本地运行队列中寻找goroutine。如果不需要或不能从全局运行队列中获取到goroutine则从本地运行队列中获取。",
    "answer": "第二步，从工作线程本地运行队列中寻找goroutine。如果不需要或不能从全局运行队列中获取到goroutine则从本地运行队列中获取。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Goroutine调度",
      "工作窃取",
      "本地运行队列",
      "全局运行队列",
      "调度策略"
    ],
    "followup_points": [
      "1. 在什么情况下，工作线程会判断\"不需要或不能从全局运行队列中获取goroutine\"？具体判断条件是什么？",
      "2. 如果本地运行队列为空，但全局运行队列中有goroutine，此时工作线程会采取什么策略来获取goroutine？是否会有优先级调整？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/go-scheduler.md",
    "code_examples": []
  },
  {
    "id": "gopher_go-scheduler_003",
    "text": "第三步，从其它工作线程的运行队列中偷取goroutine。如果上一步也没有找到需要运行的goroutine，则调用findrunnable从其他工作线程的运行队列中偷取goroutine，findrunnable函数在偷取之前会再次尝试从全局运行队列和当前线程的本地运行队列中查找需要运行的goroutine。",
    "answer": "第三步，从其它工作线程的运行队列中偷取goroutine。如果上一步也没有找到需要运行的goroutine，则调用findrunnable从其他工作线程的运行队列中偷取goroutine，findrunnable函数在偷取之前会再次尝试从全局运行队列和当前线程的本地运行队列中查找需要运行的goroutine。 下面我们先来看如何从全局运行队列中获取goroutine。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Goroutine调度",
      "工作窃取",
      "运行队列",
      "全局运行队列",
      "本地运行队列"
    ],
    "followup_points": [
      "1. 在findrunnable函数中，为什么需要再次尝试从全局运行队列和本地运行队列中查找goroutine，而不是直接进行偷取操作？",
      "2. 在从其他工作线程的运行队列中偷取goroutine时，如果多个工作线程同时尝试偷取，是否存在竞争条件？如果有，Go runtime是如何解决这个问题的？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/go-scheduler.md",
    "code_examples": []
  },
  {
    "id": "gopher_go-scheduler_004",
    "text": "位于`atomic.LoadAcq`之后的代码，对内存的读取和写入必须在`atomic.LoadAcq`读取完成后才能执行，编译器和CPU都不能打乱这个顺序；",
    "answer": "位于`atomic.LoadAcq`之后的代码，对内存的读取和写入必须在`atomic.LoadAcq`读取完成后才能执行，编译器和CPU都不能打乱这个顺序；",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "内存屏障",
      "原子操作",
      "内存顺序",
      "编译器优化",
      "CPU乱序执行"
    ],
    "followup_points": [
      "1. 如果在`atomic.LoadAcq`之后插入一个普通的内存读写操作（非原子操作），编译器或CPU是否会违反这个顺序保证？为什么？",
      "2. 在多核CPU场景下，`atomic.LoadAcq`如何确保其他核心的内存写入对当前核心可见？是否涉及缓存一致性协议（如MESI）的交互？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/go-scheduler.md",
    "code_examples": []
  },
  {
    "id": "gopher_go-scheduler_005",
    "text": "当前线程执行`atomic.LoadAcq`时可以读取到其它线程最近一次通过`atomic.CasRel`对同一个变量写入的值，与此同时，位于`atomic.LoadAcq`之后的代码，不管读取哪个内存地址中的值，都可以读取到其它线程中位于atomic.CasRel（对同一个变量操作）之前的代码最近一次对内存的写入。",
    "answer": "当前线程执行`atomic.LoadAcq`时可以读取到其它线程最近一次通过`atomic.CasRel`对同一个变量写入的值，与此同时，位于`atomic.LoadAcq`之后的代码，不管读取哪个内存地址中的值，都可以读取到其它线程中位于atomic.CasRel（对同一个变量操作）之前的代码最近一次对内存的写入。",
    "category": "system",
    "difficulty": 5,
    "tags": [
      "原子操作",
      "内存屏障",
      "内存顺序",
      "Acquire语义",
      "Release语义"
    ],
    "followup_points": [
      "1. 在`atomic.LoadAcq`和`atomic.CasRel`的内存屏障语义中，如何确保跨线程的内存可见性保证不会因为编译器优化或CPU乱序执行而被破坏？",
      "2. 如果多个线程对同一个变量交替执行`atomic.CasRel`和`atomic.LoadAcq`，是否存在潜在的竞争条件或内存可见性失效的场景？如果有，如何避免？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/go-scheduler.md",
    "code_examples": []
  },
  {
    "id": "gopher_go-scheduler_006",
    "text": "位于`atomic.CasRel`之前的代码，对内存的读取和写入必须在`atomic.CasRel`对内存的写入之前完成，编译器和CPU都不能打乱这个顺序；",
    "answer": "位于`atomic.CasRel`之前的代码，对内存的读取和写入必须在`atomic.CasRel`对内存的写入之前完成，编译器和CPU都不能打乱这个顺序；",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "内存屏障",
      "原子操作",
      "内存顺序",
      "编译器优化",
      "CPU乱序执行"
    ],
    "followup_points": [
      "1. 在`atomic.CasRel`之前的代码中，如果存在多个内存读取和写入操作，编译器和CPU是否会保证这些操作之间的相对顺序，还是仅保证它们整体在`atomic.CasRel`的写入之前完成？",
      "2. 如果`atomic.CasRel`之前的代码中包含函数调用或跨goroutine的内存访问，这种顺序保证是否仍然有效，或者是否存在需要额外注意的边界情况？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/go-scheduler.md",
    "code_examples": []
  },
  {
    "id": "gopher_go-scheduler_007",
    "text": "线程执行`atomic.CasRel`完成后其它线程通过`atomic.LoadAcq`读取同一个变量可以读到最新的值，与此同时，位于`atomic.CasRel`之前的代码对内存写入的值，可以被其它线程中位于`atomic.LoadAcq`（对同一个变量操作）之后的代码读取到。",
    "answer": "线程执行`atomic.CasRel`完成后其它线程通过`atomic.LoadAcq`读取同一个变量可以读到最新的值，与此同时，位于`atomic.CasRel`之前的代码对内存写入的值，可以被其它线程中位于`atomic.LoadAcq`（对同一个变量操作）之后的代码读取到。 因为可能有多个线程会并发的修改和读取`runqhead`，以及需要依靠runqhead的值来读取runq数组的元素，所以需要使用atomic.LoadAcq和atomic.CasRel来保证上述语义。 我们可能会问，为什么读取p的runqtail成员不需要使用atomic.LoadAcq或atomic.load？因为runqtail不会被其它线程修改，只会被当前工作线程修改，此时没有人修改它，所以也就不需要使用原子相关的操作。 最后，由`p`的`runq`、`runqhead`和`runqtail`这三个成员组成的这个无锁循环队列非常精妙，我们会在后面的章节对这个循环队列进行分析。",
    "category": "system",
    "difficulty": 3,
    "tags": [
      "atomic",
      "memory_order",
      "memory_barrier",
      "concurrency",
      "sync/atomic"
    ],
    "followup_points": [
      "1. 为什么读取p的runqtail成员不需要使用atomic.LoadAcq或atomic.load，这与runqhead的内存语义有何不同？",
      "2. 如果runqtail的读取不需要原子操作，那么在并发场景下如何确保runqtail的读取不会导致数据竞争或不一致？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/go-scheduler.md",
    "code_examples": []
  },
  {
    "id": "gopher_go-scheduler-base_000",
    "text": "goroutine简介",
    "answer": "goroutine是Go语言实现的用户态线程，主要用来解决操作系统线程太“重”的问题，所谓的太重，主要表现在以下两个方面： - 创建和切换太重：操作系统线程的创建和切换都需要进入内核，而进入内核所消耗的性能代价比较高，开销较大； - 内存使用太重：一方面，为了尽量避免极端情况下操作系统线程栈的溢出，内核在创建操作系统线程时默认会为其分配一个较大的栈内存（虚拟地址空间，内核并不会一开始就分配这么多的物理内存），然而在绝大多数情况下，系统线程远远用不了这么多内存，这导致了浪费；另一方面，栈内存空间一旦创建和初始化完成之后其大小就不能再有变化，这决定了在某些特殊场景下系统线程栈还是有溢出的风险。 而相对的，用户态的goroutine则轻量得多： - goroutine是用户态线程，其创建和切换都在用户代码中完成而无需进入操作系统内核，所以其开销要远远小于系统线程的创建和切换； - goroutine启动时默认栈大小只有2k，这在多数情况下已经够用了，即使不够用，goroutine的栈也会自动扩大，同时，如果栈太大了过于浪费它还能自动收缩，这样既没有栈溢出的风险，也不会造成栈内存空间的大量浪费。 正是因为Go语言中实现了如此轻量级的线程，才使得我们在Go程序中，可以轻易的创建成千上万甚至上百万的goroutine出来并发的执行任务而不用太担心性能和内存等问题。 **注意：** 为了避免混淆，从现在开始，后面出现的所有的线程一词均是指操作系统线程，而goroutine我们不再称之为什么什么线程而是直接使用goroutine这个词。",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "并发编程",
      "用户态线程",
      "Go语言",
      "线程开销",
      "内存管理"
    ],
    "followup_points": [
      "1. goroutine的调度器是如何实现用户态调度的，其调度模型（如GMP模型）具体是如何解决操作系统线程切换开销大的问题的？",
      "2. goroutine的栈是动态伸缩的，能否详细说明其栈增长机制，以及在什么场景下可能会发生栈溢出风险？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/go-scheduler-base.md",
    "code_examples": []
  },
  {
    "id": "gopher_q015_000",
    "text": "golang 并发题目测试",
    "answer": "题目来源： [Go并发编程小测验： 你能答对几道题？](https://colobu.com/2019/04/28/go-concurrency-quizzes/) # - A: 不能编译 - B: 输出 main --> A --> B --> C - C: 输出 main - D: panic # - A: 不能编译 - B: 输出 1 - C: 程序hang住 - D: panic # - A: 不能编译 - B: 无输出，正常退出 - C: 程序hang住 - D: panic # - A: 不能编译 - B: 可以编译，正确实现了单例 - C: 可以编译，有并发问题，f函数可能会被执行多次 - D: 可以编译，但是程序运行会panic # - A: 不能编译 - B: 输出 1, 1 - C: 输出 1, 2 - D: panic # - A: 不能编译 - B: 可以编译，运行时正常，内存稳定 - C: 可以编译，运行时内存可能暴涨 - D: 可以编译，运行时内存先暴涨，但是过一会会回收掉 # - A: 不能编译 - B: 一段时间后总是输出 `#goroutines: 1` - C: 一段时间后总是输出 `#goroutines: 2` - D: panic # - A: 不能编译 - B: 输出 1 - C: 输出 0 - D: panic # - A: 不能编译 - B: 输出 1 - C: 输出 0 - D: panic # - A: 不能编译 - B: 输出 1 - C: 输出 0 - D: panic",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "golang并发",
      "channel",
      "goroutine",
      "sync",
      "race condition"
    ],
    "followup_points": [
      "1. 在第一个题目中，如果将 `defer` 语句移到 `go` 关键字之前，输出结果会发生变化吗？为什么？",
      "2. 第二个题目中，如果将 `ch := make(chan int)` 改为 `ch := make(chan int, 1)`，程序的行为会有什么不同？请解释原因。"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/q015.md",
    "code_examples": [
      {
        "code": "package main\nimport (\n\t\"fmt\"\n\t\"sync\"\n)\nvar mu sync.Mutex\nvar chain string\nfunc main() {\n\tchain = \"main\"\n\tA()\n\tfmt.Println(chain)\n}\nfunc A() {\n\tmu.Lock()\n\tdefer mu.Unlock()\n\tchain = chain + \" --> A\"\n\tB()\n}\nfunc B() {\n\tchain = chain + \" --> B\"\n\tC()\n}\nfunc C() {\n\tmu.Lock()\n\tdefer mu.Unlock()\n\tchain = chain + \" --> C\"\n}",
        "language": "go"
      },
      {
        "code": "package main\nimport (\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n)\nvar mu sync.RWMutex\nvar count int\nfunc main() {\n\tgo A()\n\ttime.Sleep(2 * time.Second)\n\tmu.Lock()\n\tdefer mu.Unlock()\n\tcount++\n\tfmt.Println(count)\n}\nfunc A() {\n\tmu.RLock()\n\tdefer mu.RUnlock()\n\tB()\n}\nfunc B() {\n\ttime.Sleep(5 * time.Second)\n\tC()\n}\nfunc C() {\n\tmu.RLock()\n\tdefer mu.RUnlock()\n}",
        "language": "go"
      },
      {
        "code": "package main\nimport (\n\t\"sync\"\n\t\"time\"\n)\nfunc main() {\n\tvar wg sync.WaitGroup\n\twg.Add(1)\n\tgo func() {\n\t\ttime.Sleep(time.Millisecond)\n\t\twg.Done()\n\t\twg.Add(1)\n\t}()\n\twg.Wait()\n}",
        "language": "go"
      },
      {
        "code": "package doublecheck\nimport (\n\t\"sync\"\n)\ntype Once struct {\n\tm    sync.Mutex\n\tdone uint32\n}\nfunc (o *Once) Do(f func()) {\n\tif o.done == 1 {\n\t\treturn\n\t}\n\to.m.Lock()\n\tdefer o.m.Unlock()\n\tif o.done == 0 {\n\t\to.done = 1\n\t\tf()\n\t}\n}",
        "language": "go"
      },
      {
        "code": "package main\nimport (\n\t\"fmt\"\n\t\"sync\"\n)\ntype MyMutex struct {\n\tcount int\n\tsync.Mutex\n}\nfunc main() {\n\tvar mu MyMutex\n\tmu.Lock()\n\tvar mu2 = mu\n\tmu.count++\n\tmu.Unlock()\n\tmu2.Lock()\n\tmu2.count++\n\tmu2.Unlock()\n\tfmt.Println(mu.count, mu2.count)\n}",
        "language": "go"
      },
      {
        "code": "package main\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"runtime\"\n\t\"sync\"\n\t\"time\"\n)\nvar pool = sync.Pool{New: func() interface{} { return new(bytes.Buffer) }}\nfunc main() {\n\tgo func() {\n\t\tfor {\n\t\t\tprocessRequest(1 << 28) // 256MiB\n\t\t}\n\t}()\n\tfor i := 0; i < 1000; i++ {\n\t\tgo func() {\n\t\t\tfor {\n\t\t\t\tprocessRequest(1 << 10) // 1KiB\n\t\t\t}\n\t\t}()\n\t}\n\tvar stats runtime.MemStats\n\tfor i := 0; ; i++ {\n\t\truntime.ReadMemStats(&stats)\n\t\tfmt.Printf(\"Cycle %d: %dB\\n\", i, stats.Alloc)\n\t\ttime.Sleep(time.Second)\n\t\truntime.GC()\n\t}\n}\nfunc processRequest(size int) {\n\tb := pool.Get().(*bytes.Buffer)\n\ttime.Sleep(500 * time.Millisecond)\n\tb.Grow(size)\n\tpool.Put(b)\n\ttime.Sleep(1 * time.Millisecond)\n}",
        "language": "go"
      },
      {
        "code": "package main\nimport (\n\t\"fmt\"\n\t\"runtime\"\n\t\"time\"\n)\nfunc main() {\n\tvar ch chan int\n\tgo func() {\n\t\tch = make(chan int, 1)\n\t\tch <- 1\n\t}()\n\tgo func(ch chan int) {\n\t\ttime.Sleep(time.Second)\n\t\t<-ch\n\t}(ch)\n\tc := time.Tick(1 * time.Second)\n\tfor range c {\n\t\tfmt.Printf(\"#goroutines: %d\\n\", runtime.NumGoroutine())\n\t}\n}",
        "language": "go"
      },
      {
        "code": "package main\nimport \"fmt\"\nfunc main() {\n\tvar ch chan int\n\tvar count int\n\tgo func() {\n\t\tch <- 1\n\t}()\n\tgo func() {\n\t\tcount++\n\t\tclose(ch)\n\t}()\n\t<-ch\n\tfmt.Println(count)\n}",
        "language": "go"
      },
      {
        "code": "package main\nimport (\n\t\"fmt\"\n\t\"sync\"\n)\nfunc main() {\n\tvar m sync.Map\n\tm.LoadOrStore(\"a\", 1)\n\tm.Delete(\"a\")\n\tfmt.Println(m.Len())\n}",
        "language": "go"
      },
      {
        "code": "package main\nvar c = make(chan int)\nvar a int\nfunc f() {\n\ta = 1\n\t<-c\n}\nfunc main() {\n\tgo f()\n\tc <- 0\n\tprint(a)\n}",
        "language": "go"
      }
    ]
  },
  {
    "id": "gopher_Go 语言 map 如何顺序读取？_000",
    "text": "[Go 语言 map 是并发安全的吗？](https://mp.weixin.qq.com/s/4mDzMdMbunR_p94Du65QOA)",
    "answer": "[Go 语言 map 是并发安全的吗？](https://mp.weixin.qq.com/s/4mDzMdMbunR_p94Du65QOA)",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "Go语言",
      "并发安全",
      "map",
      "数据竞争",
      "sync.Map"
    ],
    "followup_points": [
      "1. 如果在并发场景下需要使用 map，有哪些常见的并发安全实现方式？各自有什么优缺点？",
      "2. Go 1.9 引入的 `sync.Map` 和 `sync.RWMutex` 保护下的 map 在使用场景和性能上有什么区别？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/Go 语言 map 如何顺序读取？.md",
    "code_examples": []
  },
  {
    "id": "gopher_Go 语言 map 如何顺序读取？_001",
    "text": "[Go 语言切片是如何扩容的？](https://mp.weixin.qq.com/s/VVM8nqs4mMGdFyCNJx16_g)",
    "answer": "[Go 语言切片是如何扩容的？](https://mp.weixin.qq.com/s/VVM8nqs4mMGdFyCNJx16_g)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Go语言",
      "切片",
      "扩容机制",
      "内存分配",
      "算法策略"
    ],
    "followup_points": [
      "1. 在切片扩容时，如果新申请的容量超过原容量的两倍，为什么 Go 语言选择直接使用新申请的容量而不是继续按照两倍增长？这种设计背后的考量是什么？",
      "2. 如果在扩容过程中，底层数组的空间不足，Go 语言是如何处理并发安全问题的？是否有锁机制或其他同步手段来避免数据竞争？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/Go 语言 map 如何顺序读取？.md",
    "code_examples": []
  },
  {
    "id": "gopher_Go 语言 map 如何顺序读取？_002",
    "text": "[Go 语言数组和切片的区别](https://mp.weixin.qq.com/s/esaAmAdmV4w3_qjtAzTr4A)",
    "answer": "[Go 语言数组和切片的区别](https://mp.weixin.qq.com/s/esaAmAdmV4w3_qjtAzTr4A)",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "Go语言基础",
      "数组",
      "切片",
      "内存管理",
      "数据结构"
    ],
    "followup_points": [
      "1. 在函数参数传递时，为什么切片比数组更高效，底层实现上有什么差异？",
      "2. 当切片进行扩容时，Go 底层是如何分配新内存并处理旧数据的？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/Go 语言 map 如何顺序读取？.md",
    "code_examples": []
  },
  {
    "id": "gopher_Go 语言 map 如何顺序读取？_003",
    "text": "[Go 语言 new 和 make 关键字的区别](https://mp.weixin.qq.com/s/NBDkI3roHgNgW1iW4e_6cA)",
    "answer": "[Go 语言 new 和 make 关键字的区别](https://mp.weixin.qq.com/s/NBDkI3roHgNgW1iW4e_6cA)",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "Go语言",
      "关键字",
      "new",
      "make",
      "内存分配"
    ],
    "followup_points": [
      "1. 在使用 new 为自定义结构体分配内存时，如果结构体中包含需要初始化的指针类型字段，应该如何确保这些字段被正确初始化？",
      "2. 对于 make 切片时，如果预分配的容量（cap）远大于实际需要的长度（len），会对内存使用和性能产生哪些潜在影响？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/Go 语言 map 如何顺序读取？.md",
    "code_examples": []
  },
  {
    "id": "gopher_Go 语言 map 如何顺序读取？_004",
    "text": "[为什么 Go 不支持 \\[\\]T 转换为 \\[\\]interface](https://mp.weixin.qq.com/s/cwDEgnicK4jkuNpzulU2bw)",
    "answer": "[为什么 Go 不支持 \\[\\]T 转换为 \\[\\]interface](https://mp.weixin.qq.com/s/cwDEgnicK4jkuNpzulU2bw)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Go语言类型系统",
      "接口类型转换",
      "切片类型转换",
      "类型安全",
      "内存布局"
    ],
    "followup_points": [
      "1. 如果 Go 支持 `[]T` 转换为 `[]interface{}`，可能会带来哪些具体的运行时安全问题或性能损耗？",
      "2. 在实际开发中，有哪些场景下开发者会期望 `[]T` 能直接转换为 `[]interface{}`，目前有哪些替代方案可以解决这类需求？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/Go 语言 map 如何顺序读取？.md",
    "code_examples": []
  },
  {
    "id": "gopher_Go 语言 map 如何顺序读取？_005",
    "text": "[为什么 Go 语言 struct 要使用 tags](https://mp.weixin.qq.com/s/L7-TJ-CzYfuVrIBWP7Ebaw)",
    "answer": "[为什么 Go 语言 struct 要使用 tags](https://mp.weixin.qq.com/s/L7-TJ-CzYfuVrIBWP7Ebaw)",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "Go struct tags",
      "序列化与反序列化",
      "JSON 映射",
      "ORM 框架",
      "反射机制"
    ],
    "followup_points": [
      "1. 在使用 struct tags 时，如果 tag 中包含多个键值对（如 `json:\"name,omitempty\" db:\"name\"`），Go 语言是如何解析和处理这些冲突的？有没有优先级或覆盖规则？",
      "2. 除了 `json`、`xml` 等常见标准库的 tag，自定义 tag 的命名规范和最佳实践是什么？如果多个自定义 tag 存在冲突，应该如何避免或解决？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/Go 语言 map 如何顺序读取？.md",
    "code_examples": []
  },
  {
    "id": "gopher_q021_000",
    "text": "说明 `http.Get` 默认使用 `DefaultTransport` 管理连接。",
    "answer": "说明 `http.Get` 默认使用 `DefaultTransport` 管理连接。 DefaultTransport 是干嘛的呢？",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "HTTP客户端",
      "DefaultTransport",
      "连接管理",
      "Go标准库",
      "http.Get"
    ],
    "followup_points": [
      "1. DefaultTransport 的核心配置参数有哪些，这些参数如何影响连接管理？",
      "2. DefaultTransport 如何实现连接池管理，包括最大空闲连接数、连接复用和超时控制？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/q021.md",
    "code_examples": [
      {
        "code": "// It establishes network connections as needed\n// and caches them for reuse by subsequent calls.",
        "language": "go"
      }
    ]
  },
  {
    "id": "gopher_q021_001",
    "text": "`DefaultTransport` 的作用是根据需要建立网络连接并缓存它们以供后续调用重用。",
    "answer": "`DefaultTransport` 的作用是根据需要建立网络连接并缓存它们以供后续调用重用。 那么 `DefaultTransport` 什么时候会建立连接呢？ 接着上面的代码堆栈往下翻 ```go func send(ireq *Request, rt RoundTripper, deadline time.Time)",
    "category": "redis",
    "difficulty": 2,
    "tags": [
      "网络连接管理",
      "连接池",
      "HTTP客户端",
      "Go语言",
      "RoundTripper"
    ],
    "followup_points": [
      "1. `DefaultTransport` 在什么具体场景下会触发建立新连接，而不是直接使用缓存的连接？",
      "2. 如果缓存的连接已经失效（例如超时或服务器关闭），`DefaultTransport` 如何检测并处理这种情况？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/q021.md",
    "code_examples": []
  },
  {
    "id": "gopher_q021_002",
    "text": "一次建立连接，就会启动一个读goroutine和写goroutine。这就是为什么一次`http.Get()`会泄漏两个goroutine的来源。",
    "answer": "一次建立连接，就会启动一个读goroutine和写goroutine。这就是为什么一次`http.Get()`会泄漏两个goroutine的来源。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Go并发",
      "goroutine",
      "HTTP连接",
      "资源泄漏",
      "Go标准库"
    ],
    "followup_points": [
      "1. 在连接关闭时，这两个goroutine是如何被正确回收的？",
      "2. 如果连接因异常情况（如网络中断）断开，这两个goroutine的退出机制是怎样的？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/q021.md",
    "code_examples": []
  },
  {
    "id": "gopher_q021_003",
    "text": "如果执行 earlyCloseFn ，waitForBodyRead 通道输入的是 false，alive 也会是 false，那 readLoop() 这个 goroutine 就会退出。",
    "answer": "如果执行 earlyCloseFn ，waitForBodyRead 通道输入的是 false，alive 也会是 false，那 readLoop() 这个 goroutine 就会退出。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Goroutine生命周期控制",
      "Channel通信机制",
      "布尔值状态管理",
      "函数闭包",
      "并发退出逻辑"
    ],
    "followup_points": [
      "1. 在 earlyCloseFn 被执行时，除了向 waitForBodyRead 通道输入 false，是否还有其他可能导致 readLoop() goroutine 退出的条件或逻辑？",
      "2. 当 readLoop() goroutine 退出后，是否有其他 goroutine 或机制负责清理相关资源（如连接、缓冲区等），或者是否存在资源泄漏的风险？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/q021.md",
    "code_examples": []
  },
  {
    "id": "gopher_q021_004",
    "text": "如果执行 fn ，其中包括正常情况下 body 读完数据抛出 io.EOF 时的 case，waitForBodyRead 通道输入的是 true，那 alive 会是 true，那么 readLoop() 这个 goroutine 就不会退出，同时还顺便执行了 tryPutIdleConn(trace) 。",
    "answer": "如果执行 fn ，其中包括正常情况下 body 读完数据抛出 io.EOF 时的 case，waitForBodyRead 通道输入的是 true，那 alive 会是 true，那么 readLoop() 这个 goroutine 就不会退出，同时还顺便执行了 tryPutIdleConn(trace) 。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Goroutine生命周期管理",
      "通道通信",
      "io.EOF错误处理",
      "连接池管理",
      "HTTP请求处理流程"
    ],
    "followup_points": [
      "1. 在这种情况下，readLoop() goroutine 不退出会导致什么潜在的资源泄漏或性能问题吗？",
      "2. tryPutIdleConn(trace) 被执行后，连接是如何被管理以避免后续重复使用时的状态不一致问题？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/q021.md",
    "code_examples": [
      {
        "code": "// tryPutIdleConn adds pconn to the list of idle persistent connections awaiting\n// a new request.\n// If pconn is no longer needed or not in a good state, tryPutIdleConn returns\n// an error explaining why it wasn't registered.\n// tryPutIdleConn does not close pconn. Use putOrCloseIdleConn instead for that.\nfunc (t *Transport) tryPutIdleConn(pconn *persistConn) error",
        "language": "go"
      }
    ]
  },
  {
    "id": "gopher_q021_005",
    "text": "tryPutIdleConn 将 pconn 添加到等待新请求的空闲持久连接列表中，也就是之前说的连接会复用。",
    "answer": "es.mu.Lock() defer es.mu.Unlock() if es.closed { return nil } es.closed = true if es.earlyCloseFn != nil && es.rerr != io.EOF { return es.earlyCloseFn() // 关闭时执行 earlyCloseFn } err := es.body.Close() return es.condfn(err)",
    "category": "system",
    "difficulty": 2,
    "tags": [
      "互斥锁 (Mutex)",
      "连接复用 (Connection Reuse)",
      "错误处理 (Error Handling)",
      "资源关闭 (Resource Closing)",
      "条件函数 (Conditional Function)"
    ],
    "followup_points": [
      "1. 在 `tryPutIdleConn` 方法中，如果 `es.closed` 为 true，直接返回 nil，这是否意味着连接复用过程中可能会丢失未处理的连接？",
      "2. 方法中调用了 `es.earlyCloseFn`，这个回调函数的具体作用是什么？它在什么场景下会被触发，对连接复用逻辑有何影响？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/q021.md",
    "code_examples": []
  },
  {
    "id": "gopher_q021_006",
    "text": "这个`read`，其实就是 `bodyEOFSignal` 里的",
    "answer": "... n, err = es.body.Read(p) if err != nil { ... // 这里会有一个io.EOF的报错，意思是读完了 err = es.condfn(err) } return if es.fn == nil { return err } err = es.fn(err) // 这了执行了 fn es.fn = nil return err",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "Golang",
      "io.EOF",
      "错误处理",
      "函数指针",
      "条件判断"
    ],
    "followup_points": [
      "1. 在 `err = es.condfn(err)` 这一步，`condfn` 的具体作用是什么？它是否会处理 `io.EOF` 错误，或者只是传递错误？",
      "2. 如果 `es.fn` 不为空，执行 `es.fn(err)` 后将 `es.fn` 置为 `nil`，这种设计是为了避免重复执行吗？是否有其他潜在的场景需要考虑？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/q021.md",
    "code_examples": []
  },
  {
    "id": "gopher_q021_007",
    "text": "上面这个其实就是我们比较收悉的读取 body 里的内容。 ioutil.ReadAll() ,在读完 body 的内容时会执行 fn，也就是此时 readLoop() 里的 waitForBodyRead 通道输入的是 true，alive 也会是 true，那 readLoop() 这个 goroutine 就不会退出，goroutine 会泄露，然后执行 tryPutIdleConn(trace) 把连接放回池子里复用。",
    "answer": "上面这个其实就是我们比较收悉的读取 body 里的内容。 ioutil.ReadAll() ,在读完 body 的内容时会执行 fn，也就是此时 readLoop() 里的 waitForBodyRead 通道输入的是 true，alive 也会是 true，那 readLoop() 这个 goroutine 就不会退出，goroutine 会泄露，然后执行 tryPutIdleConn(trace) 把连接放回池子里复用。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Goroutine泄漏",
      "HTTP连接池",
      "ioutil.ReadAll",
      "readLoop",
      "waitForBodyRead"
    ],
    "followup_points": [
      "1. 在 readLoop() 中，除了 waitForBodyRead 通道输入 true 会导致 goroutine 不退出外，还有哪些其他条件或场景可能造成类似的 goroutine 泄露问题？",
      "2. 当 tryPutIdleConn(trace) 把连接放回池子复用时，是否有机制检测或处理该连接关联的 goroutine 状态，以避免后续操作时出现资源竞争或僵尸连接？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/q021.md",
    "code_examples": []
  },
  {
    "id": "gopher_q021_008",
    "text": "所以结论呼之欲出了，虽然执行了 6 次循环，而且每次都没有执行 Body.Close() ,就是因为执行了ioutil.ReadAll()把内容都读出来了，连接得以复用，因此只泄漏了一个读goroutine和一个写goroutine，最后加上main goroutine，所以答案就是3个goroutine。",
    "answer": "所以结论呼之欲出了，虽然执行了 6 次循环，而且每次都没有执行 Body.Close() ,就是因为执行了ioutil.ReadAll()把内容都读出来了，连接得以复用，因此只泄漏了一个读goroutine和一个写goroutine，最后加上main goroutine，所以答案就是3个goroutine。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Goroutine泄漏",
      "HTTP连接复用",
      "ioutil.ReadAll",
      "Body.Close",
      "Go并发模型"
    ],
    "followup_points": [
      "1. 如果将 `ioutil.ReadAll()` 替换为只读取部分内容的操作（如 `ReadN`），连接复用机制会如何变化，goroutine 泄漏情况是否会有不同？",
      "2. 在连接复用的场景下，HTTP 客户端底层是如何管理连接池的？如果并发请求量增大，是否会影响 goroutine 的泄漏数量？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/q021.md",
    "code_examples": []
  },
  {
    "id": "gopher_q021_009",
    "text": "从另外一个角度说，正常情况下我们的代码都会执行 ioutil.ReadAll()，但如果此时忘了 resp.Body.Close()，确实会导致泄漏。但如果你调用的域名一直是同一个的话，那么只会泄漏一个 读goroutine 和一个写goroutine，这就是为什么代码明明不规范但却看不到明显内存泄漏的原因。",
    "answer": "从另外一个角度说，正常情况下我们的代码都会执行 ioutil.ReadAll()，但如果此时忘了 resp.Body.Close()，确实会导致泄漏。但如果你调用的域名一直是同一个的话，那么只会泄漏一个 读goroutine 和一个写goroutine，这就是为什么代码明明不规范但却看不到明显内存泄漏的原因。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Go",
      "HTTP",
      "ioutil.ReadAll",
      "goroutine",
      "内存泄漏"
    ],
    "followup_points": [
      "1. 如果调用的域名是同一个，为什么只泄漏一个读goroutine和一个写goroutine，而不是每次调用都泄漏新的goroutine？",
      "2. 在实际生产环境中，如何检测和定位这种因未关闭resp.Body而导致的goroutine泄漏问题？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/q021.md",
    "code_examples": []
  },
  {
    "id": "gopher_q021_010",
    "text": "那么问题又来了，为什么上面要特意强调是同一个域名呢？改天，回头，以后有空再说吧。",
    "answer": "那么问题又来了，为什么上面要特意强调是同一个域名呢？改天，回头，以后有空再说吧。 >作者：9號同学 链接：https://juejin.cn/post/6896993332019822605 来源：掘金 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 作者：9號同学 链接：https://juejin.cn/post/6896993332019822605 来源：掘金 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "同源策略",
      "跨域",
      "Cookie",
      "浏览器安全",
      "域名"
    ],
    "followup_points": [
      "1. 如果跨域请求时，目标服务器没有正确配置 CORS 头（比如没有设置 Access-Control-Allow-Origin），浏览器会直接拦截请求还是先发送预检请求（OPTIONS）？",
      "2. 在实际开发中，如果遇到因跨域问题导致的接口调用失败，你会如何排查和解决？请结合具体场景说明。"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/q021.md",
    "code_examples": []
  },
  {
    "id": "gopher_Go 语言 context 都能做什么？_000",
    "text": "`Value()`：返回 key 对应的值。",
    "answer": "`Value()`：返回 key 对应的值。 有四个结构体实现了这个接口，分别是：`emptyCtx`, `cancelCtx`, `timerCtx` 和 `valueCtx`。 其中 `emptyCtx` 是空类型，暴露了两个方法： 一般情况下，会使用 `Background()` 作为根 ctx，然后在其基础上再派生出子 ctx。要是不确定使用哪个 ctx，就使用 `TODO()`。 另外三个也分别暴露了对应的方法：",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "Go Context",
      "接口实现",
      "结构体类型",
      "方法实现",
      "Context 派生"
    ],
    "followup_points": [
      "1. 在 `emptyCtx` 中，为什么需要设计一个空类型，它主要解决了什么问题？",
      "2. `cancelCtx`、`timerCtx` 和 `valueCtx` 在实现 `Value()` 方法时，是如何处理 key 不存在的情况？它们之间是否有优先级或覆盖规则？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/Go 语言 context 都能做什么？.md",
    "code_examples": [
      {
        "code": "func Background() Context\nfunc TODO() Context",
        "language": "go"
      },
      {
        "code": "func WithCancel(parent Context) (ctx Context, cancel CancelFunc)\nfunc WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc)\nfunc WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc)\nfunc WithValue(parent Context, key, val interface{}) Context",
        "language": "go"
      }
    ]
  },
  {
    "id": "gopher_Go 语言 context 都能做什么？_001",
    "text": "[Go 语言 map 如何顺序读取？](https://mp.weixin.qq.com/s/iScSgfpSE2y14GH7JNRJSA)",
    "answer": "[Go 语言 map 如何顺序读取？](https://mp.weixin.qq.com/s/iScSgfpSE2y14GH7JNRJSA)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Go语言",
      "map",
      "数据结构",
      "遍历",
      "有序性"
    ],
    "followup_points": [
      "1. 在 Go 1.12 之前，map 的迭代顺序是随机的，而 Go 1.12 开始引入了随机化迭代顺序的机制，这种随机化设计的目的是什么？它解决了哪些潜在的安全或性能问题？",
      "2. 如果需要在高并发场景下对 map 进行顺序读取，除了使用 `sync.Map` 或加锁的方式，是否有更优化的方案来平衡性能和顺序一致性？例如，是否可以利用 `sync.RWMutex` 结合 `for range` 的特性来实现？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/Go 语言 context 都能做什么？.md",
    "code_examples": []
  },
  {
    "id": "gopher_Go 语言 context 都能做什么？_002",
    "text": "[Go 语言 map 是并发安全的吗？](https://mp.weixin.qq.com/s/4mDzMdMbunR_p94Du65QOA)",
    "answer": "[Go 语言 map 是并发安全的吗？](https://mp.weixin.qq.com/s/4mDzMdMbunR_p94Du65QOA)",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "Go语言",
      "并发安全",
      "map",
      "数据竞争",
      "sync.Map"
    ],
    "followup_points": [
      "1. 除了使用 `sync.Map`，还有哪些常见的并发安全方案可以替代 Go 原生 map，各自的适用场景是什么？",
      "2. 在 Go 1.9 及之后的版本中，原生 map 的读写操作在什么情况下会触发并发安全问题，具体的表现形式有哪些？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/Go 语言 context 都能做什么？.md",
    "code_examples": []
  },
  {
    "id": "gopher_Go 语言 context 都能做什么？_003",
    "text": "[Go 语言切片是如何扩容的？](https://mp.weixin.qq.com/s/VVM8nqs4mMGdFyCNJx16_g)",
    "answer": "[Go 语言切片是如何扩容的？](https://mp.weixin.qq.com/s/VVM8nqs4mMGdFyCNJx16_g)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Go语言",
      "切片",
      "内存分配",
      "扩容策略",
      "append操作"
    ],
    "followup_points": [
      "1. 如果扩容后的容量仍然不足以容纳新元素，Go 会如何处理这种情况？是否会再次触发扩容机制？",
      "2. 在并发场景下，多个 goroutine 同时对同一个切片进行 append 操作，扩容机制是否会导致数据竞争？如何避免？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/Go 语言 context 都能做什么？.md",
    "code_examples": []
  },
  {
    "id": "gopher_Go 语言 context 都能做什么？_004",
    "text": "[Go 语言数组和切片的区别](https://mp.weixin.qq.com/s/esaAmAdmV4w3_qjtAzTr4A)",
    "answer": "[Go 语言数组和切片的区别](https://mp.weixin.qq.com/s/esaAmAdmV4w3_qjtAzTr4A)",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "Go语言基础",
      "数组",
      "切片",
      "内存布局",
      "长度与容量"
    ],
    "followup_points": [
      "1. 在函数参数传递时，数组作为参数和切片作为参数在性能和内存使用上有何区别？",
      "2. 切片的扩容机制具体是如何实现的？扩容时底层数组的变化对性能有什么影响？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/Go 语言 context 都能做什么？.md",
    "code_examples": []
  },
  {
    "id": "gopher_Go 语言 context 都能做什么？_005",
    "text": "[Go 语言 new 和 make 关键字的区别](https://mp.weixin.qq.com/s/NBDkI3roHgNgW1iW4e_6cA)",
    "answer": "[Go 语言 new 和 make 关键字的区别](https://mp.weixin.qq.com/s/NBDkI3roHgNgW1iW4e_6cA)",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "Go语言关键字",
      "内存分配",
      "内置函数",
      "切片",
      "map"
    ],
    "followup_points": [
      "1. 在使用 new 为结构体指针分配内存后，如果结构体中包含需要初始化的切片或 map 字段，是否还需要单独对这些字段进行初始化？为什么？",
      "2. 如果尝试使用 make 为自定义类型（如 type MyInt int）分配内存，编译器会如何处理？这与 new 的行为有何不同？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/Go 语言 context 都能做什么？.md",
    "code_examples": []
  },
  {
    "id": "gopher_Go 语言 context 都能做什么？_006",
    "text": "[为什么 Go 不支持 \\[\\]T 转换为 \\[\\]interface](https://mp.weixin.qq.com/s/cwDEgnicK4jkuNpzulU2bw)",
    "answer": "[为什么 Go 不支持 \\[\\]T 转换为 \\[\\]interface](https://mp.weixin.qq.com/s/cwDEgnicK4jkuNpzulU2bw)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Go语言类型系统",
      "接口类型转换",
      "切片类型转换",
      "类型安全",
      "内存布局"
    ],
    "followup_points": [
      "1. 如果 Go 支持 `[]T` 转换为 `[]interface{}`，可能会在运行时引发哪些具体问题？能否举例说明？",
      "2. 在实际开发中，如果确实需要将 `[]T` 转换为 `[]interface{}`，通常有哪些替代方案？各自的优缺点是什么？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/Go 语言 context 都能做什么？.md",
    "code_examples": []
  },
  {
    "id": "gopher_Go 语言 context 都能做什么？_007",
    "text": "[为什么 Go 语言 struct 要使用 tags](https://mp.weixin.qq.com/s/L7-TJ-CzYfuVrIBWP7Ebaw)",
    "answer": "[为什么 Go 语言 struct 要使用 tags](https://mp.weixin.qq.com/s/L7-TJ-CzYfuVrIBWP7Ebaw)",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "Go语言",
      "Struct",
      "Tags",
      "JSON序列化",
      "反射机制"
    ],
    "followup_points": [
      "1. 在使用 struct tags 进行序列化/反序列化时，如果 tag 中包含特殊字符（如 `json:\"name,omitempty\"` 中的 `,` 和 `omitempty`），Go 是如何解析这些特殊字符并区分不同配置项的？",
      "2. 除了序列化/反序列化，struct tags 在反射（reflection）场景中如何被高效利用？能否举例说明反射中通过 tag 动态获取或设置 struct 字段值的实现细节？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/Go 语言 context 都能做什么？.md",
    "code_examples": []
  },
  {
    "id": "gopher_q014_001",
    "text": "写出以下打印结果，并解释下为什么这么打印的。",
    "answer": "golang 中的切片底层其实使用的是数组。当使用`str1[1:]` 使，`str2` 和 `str1` 底层共享一个数组，这回导致 `str2[1] = \"new\"` 语句影响 `str1`。 而 `append` 会导致底层数组扩容，生成新的数组，因此追加数据后的 `str2` 不会影响 `str1`。 但是为什么对 `str2` 复制后影响的确实 `str1` 的第三个元素呢？这是因为切片 `str2` 是从数组的第二个元素开始，`str2` 索引为 1 的元素对应的是 `str1` 索引为 2 的元素。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "golang切片",
      "切片底层数组",
      "切片共享内存",
      "append扩容",
      "索引偏移"
    ],
    "followup_points": [
      "1. 在切片扩容时，Go 底层是如何决定新数组的容量的？是简单的翻倍还是有其他策略？",
      "2. 如果在 `str2` 上执行 `str2 = append(str2, \"another\")` 后再修改 `str2[1]`，`str1` 会受影响吗？为什么？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/q014.md",
    "code_examples": [
      {
        "code": "package main\nimport (\n    \"fmt\"\n)\nfunc main() {\n    str1 := []string{\"a\", \"b\", \"c\"}\n    str2 := str1[1:]\n    str2[1] = \"new\"\n    fmt.Println(str1)\n    str2 = append(str2, \"z\", \"x\", \"y\")\n    fmt.Println(str1)\n}",
        "language": "go"
      }
    ]
  },
  {
    "id": "gopher_q014_002",
    "text": "下面代码写法有什么问题？",
    "answer": "golang中的`map` 通过`key`获取到的实际上是两个值，第一个是获取到的值，第二个是是否存在该`key`。因此不能直接通过`key`来赋值对象。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "golang",
      "map",
      "key",
      "value",
      "赋值"
    ],
    "followup_points": [
      "1. 如果直接通过`key`赋值对象，会导致什么具体的运行时错误或行为？",
      "2. 在实际开发中，应该如何正确地处理`map`中`key`不存在的情况？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/interview/q014.md",
    "code_examples": [
      {
        "code": "package main\nimport (\n    \"fmt\"\n)\ntype Student struct {\n    Age int\n}\nfunc main() {\n    kv := map[string]Student{\"menglu\": {Age: 21}}\n    kv[\"menglu\"].Age = 22\n    s := []Student{{Age: 21}}\n    s[0].Age = 22\n    fmt.Println(kv, s)\n}",
        "language": "go"
      }
    ]
  },
  {
    "id": "gopher_004-读 Go 源码，可以试试这个工具_000",
    "text": "[Go Error 嵌套到底是怎么实现的？](https://mp.weixin.qq.com/s/nWb-0RTDG1Pg5ZmJZfbEPA)",
    "answer": "[Go Error 嵌套到底是怎么实现的？](https://mp.weixin.qq.com/s/nWb-0RTDG1Pg5ZmJZfbEPA)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Go Error",
      "错误处理",
      "错误包装",
      "错误链",
      "标准库 errors"
    ],
    "followup_points": [
      "1. 在 Go 1.13 之前，如果需要实现 Error 嵌套，通常会采用怎样的方式？这种方式与 Go 1.13 引入的 `fmt.Errorf` 和 `%w` 动词相比，存在哪些明显的优缺点？",
      "2. 当使用 `errors.Unwrap` 解嵌错误时，如果底层错误是多个嵌套层级的错误链，`Unwrap` 的行为是怎样的？它是逐层解嵌直到最底层的错误，还是只解嵌一层？如果需要遍历整个错误链，有哪些常见的实践方法？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/advanced/004-读 Go 源码，可以试试这个工具.md",
    "code_examples": []
  },
  {
    "id": "gopher_004-读 Go 源码，可以试试这个工具_001",
    "text": "[为什么要避免在 Go 中使用 ioutil.ReadAll？](https://mp.weixin.qq.com/s/e2A3ME4vhOK2S3hLEJtPsw)",
    "answer": "[为什么要避免在 Go 中使用 ioutil.ReadAll？](https://mp.weixin.qq.com/s/e2A3ME4vhOK2S3hLEJtPsw)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Go",
      "ioutil.ReadAll",
      "内存管理",
      "性能优化",
      "io.Reader"
    ],
    "followup_points": [
      "1. 在实际项目中，如果遇到必须读取未知大小的数据流时，除了使用 `ioutil.ReadAll`，你会如何设计更安全的读取方案来避免内存耗尽风险？",
      "2. 如果已经使用了 `ioutil.ReadAll`，有哪些监控或优化手段可以及时发现并处理潜在的内存问题？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/advanced/004-读 Go 源码，可以试试这个工具.md",
    "code_examples": []
  },
  {
    "id": "gopher_004-读 Go 源码，可以试试这个工具_002",
    "text": "[如何在 Go 中将 []byte 转换为 io.Reader？](https://mp.weixin.qq.com/s/nFkob92GOs6Gp75pxA5wCQ)",
    "answer": "[如何在 Go 中将 []byte 转换为 io.Reader？](https://mp.weixin.qq.com/s/nFkob92GOs6Gp75pxA5wCQ) 在解决问题的过程中也就对源码更熟悉了。 还有一点要注意的就是，先看整体，再看细节。 在这里推荐给大家一个工具，这个工具可以帮我们梳理出代码的整体结构，我觉得还是挺有用的。是一个开源项目：",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "Go",
      "io.Reader",
      "[]byte",
      "类型转换",
      "接口实现"
    ],
    "followup_points": [
      "1. 在将 []byte 转换为 io.Reader 时，不同实现方式（如 bytes.NewReader、bufio.NewReader 等）的性能差异主要体现在哪些场景？",
      "2. 除了文中提到的工具，还有哪些方法可以帮助梳理 Go 代码的整体结构，特别是在分析标准库源码时？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/advanced/004-读 Go 源码，可以试试这个工具.md",
    "code_examples": []
  },
  {
    "id": "gopher_004-读 Go 源码，可以试试这个工具_003",
    "text": "[开始读 Go 源码了](https://mp.weixin.qq.com/s/iPM-mPOepRuDqkBtcnG1ww)",
    "answer": "[开始读 Go 源码了](https://mp.weixin.qq.com/s/iPM-mPOepRuDqkBtcnG1ww)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Go源码",
      "runtime",
      "内存管理",
      "并发模型",
      "调度器"
    ],
    "followup_points": [
      "1. 在阅读 Go 源码时，你通常会从哪些核心模块或包开始入手？为什么选择这些模块作为切入点？",
      "2. 在阅读源码过程中，你遇到过哪些理解上的难点或容易混淆的概念？是如何解决的？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/advanced/004-读 Go 源码，可以试试这个工具.md",
    "code_examples": []
  },
  {
    "id": "gopher_004-读 Go 源码，可以试试这个工具_004",
    "text": "[推荐三个实用的 Go 开发工具](https://mp.weixin.qq.com/s/3GLMLhegB3wF5_62mpmePA)",
    "answer": "[推荐三个实用的 Go 开发工具](https://mp.weixin.qq.com/s/3GLMLhegB3wF5_62mpmePA)",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Go",
      "开发工具",
      "效率工具",
      "IDE",
      "调试工具"
    ],
    "followup_points": [
      "1. 在推荐这些工具时，是否遇到过团队协作中工具链整合的挑战？如果有，是如何解决的？",
      "2. 除了这三个工具，你认为在 Go 项目中还有哪些容易被忽视但能显著提升效率的小工具？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/advanced/004-读 Go 源码，可以试试这个工具.md",
    "code_examples": []
  },
  {
    "id": "gopher_000-开始读 Go 源码了_000",
    "text": "将自己的阅读心得总结输出。",
    "answer": "将自己的阅读心得总结输出。 可以通过上面的一种或几种方法相结合，然后再不断阅读不断总结，最终找到一个完全适合自己的方法。 下面是我总结的一些标准库及功能介绍：",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "学习方法",
      "知识总结",
      "标准库",
      "功能介绍",
      "持续学习"
    ],
    "followup_points": [
      "1. 您提到“结合多种方法找到适合自己的方式”，能否举例说明您尝试过哪些具体方法，以及它们各自的优缺点是什么？",
      "2. 您总结的标准库及功能介绍是基于哪些阅读材料或实践经验？在总结过程中遇到过哪些理解或应用上的难点？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/advanced/000-开始读 Go 源码了.md",
    "code_examples": []
  },
  {
    "id": "gopher_000-开始读 Go 源码了_001",
    "text": "`fmt`-`io`-`bufio`-`path/filepath`-`flag`：",
    "answer": "- `fmt`：提供格式化输入输出功能。 - `io`：提供基本输入输出功能，大多数是围绕系统功能的封装。 - `bufio`：缓冲输入输出功能的封装。 - `path/filepath`：用来操作在当前系统中的目标文件名路径。 - `flag`：提供对命令行参数的操作。",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "fmt",
      "io",
      "bufio",
      "path/filepath",
      "flag"
    ],
    "followup_points": [
      "1. 在使用 `bufio` 时，缓冲区的默认大小是多少？如果需要处理大文件，是否需要手动调整缓冲区大小以优化性能？",
      "2. `path/filepath` 和 `path` 包的主要区别是什么？在跨平台开发时，为什么推荐使用 `path/filepath` 而不是 `path`？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/advanced/000-开始读 Go 源码了.md",
    "code_examples": []
  },
  {
    "id": "gopher_000-开始读 Go 源码了_002",
    "text": "`strings`-`strconv`-`unicode`-`regexp`-`bytes`：",
    "answer": "- `strings`：提供对字符串的操作。 - `strconv`：提供将字符串转换为基础类型的功能。 - `unicode`：为 unicode 型的字符串提供特殊的功能。 - `regexp`：正则表达式功能。 - `bytes`：提供对字符型分片的操作。 - `index/suffixarray`：子字符串快速查询。",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "strings",
      "strconv",
      "unicode",
      "regexp",
      "bytes"
    ],
    "followup_points": [
      "1. 在 `strings` 包中，哪些函数是区分大小写的，哪些是不区分大小写的？它们在实际应用中如何选择使用？",
      "2. `bytes` 包和 `strings` 包在操作上有哪些相似之处？为什么 Go 语言要同时提供这两个包？它们各自的适用场景是什么？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/advanced/000-开始读 Go 源码了.md",
    "code_examples": []
  },
  {
    "id": "gopher_000-开始读 Go 源码了_003",
    "text": "`math`-`math/cmath`-`math/big`-`math/rand-sort`：",
    "answer": "- `math`：基本的数学函数。 - `math/cmath`：对复数的操作。 - `math/rand`：伪随机数生成。 - `sort`：为数组排序和自定义集合。 - `math/big`：大数的实现和计算。",
    "category": "algorithm",
    "difficulty": 3,
    "tags": [
      "math",
      "math/cmath",
      "math/rand",
      "sort",
      "math/big"
    ],
    "followup_points": [
      "1. 在 `math/rand` 中，如何确保生成的随机数在并发环境下是安全的？",
      "2. `math/big` 支持哪些大数运算，与标准库中的 `int`/`float` 类型相比，性能上有何权衡？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/advanced/000-开始读 Go 源码了.md",
    "code_examples": []
  },
  {
    "id": "gopher_000-开始读 Go 源码了_004",
    "text": "`compress/bzip2`-`/flate`-`/gzip`-`/lzw`-`zlib`：",
    "answer": "- `compress/bzip2`：实现 bzip2 的解压。 - `flate`：实现 deflate 的数据压缩格式，如 RFC 1951 所述。 - `gzip`：实现 gzip 压缩文件的读写。 - `lzw`：Lempel Ziv Welch 压缩数据格式实现。 - `zlib`：实现 zlib 数据压缩格式的读写。",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "compress/bzip2",
      "flate",
      "gzip",
      "lzw",
      "zlib"
    ],
    "followup_points": [
      "1. 在实际项目中，你会如何选择使用 `gzip` 还是 `zlib` 进行数据压缩？它们的主要应用场景和性能差异是什么？",
      "2. `bzip2` 和 `gzip` 在压缩率和压缩速度上通常如何权衡？在哪些场景下你会优先选择 `bzip2` 而不是 `gzip`？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/advanced/000-开始读 Go 源码了.md",
    "code_examples": []
  },
  {
    "id": "gopher_000-开始读 Go 源码了_005",
    "text": "`context`：用来简化对于处理单个请求的多个 goroutine 之间与请求域的数据、取消信号、截止时间等相关操作。",
    "answer": "`context`：用来简化对于处理单个请求的多个 goroutine 之间与请求域的数据、取消信号、截止时间等相关操作。",
    "category": "go",
    "difficulty": 1,
    "tags": [
      "context",
      "goroutine",
      "并发控制",
      "取消信号",
      "截止时间"
    ],
    "followup_points": [
      "1. 在实际项目中，你是如何设计 `context` 的初始化和传递逻辑，以确保数据、取消信号和截止时间能够正确地在多个 goroutine 之间同步？",
      "2. 当 `context` 的取消信号被触发时，你是如何处理 goroutine 的优雅退出，以及如何避免资源泄漏或未完成的操作？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/advanced/000-开始读 Go 源码了.md",
    "code_examples": []
  },
  {
    "id": "gopher_000-开始读 Go 源码了_006",
    "text": "`crypto`-`crypto/md5`-`crypto/sha1`：",
    "answer": "- `crypto`：常用密码常数的集合。 - `crypto/md5`：MD5 加密。 - `crypto/sha1`：SHA1 加密。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "crypto",
      "crypto/md5",
      "crypto/sha1"
    ],
    "followup_points": [
      "1. 在实际应用中，MD5 和 SHA1 加密存在哪些安全风险，为什么现在不推荐使用？",
      "2. 除了 MD5 和 SHA1，Go 的 `crypto` 包还提供了哪些更安全的哈希算法（如 SHA256、SHA512），它们的应用场景有何不同？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/advanced/000-开始读 Go 源码了.md",
    "code_examples": []
  },
  {
    "id": "gopher_000-开始读 Go 源码了_007",
    "text": "`unsafe`：包含了一些打破 Go 语言「类型安全」的命令，一般程序不会使用，可用在 C/C++ 程序的调用中。",
    "answer": "`unsafe`：包含了一些打破 Go 语言「类型安全」的命令，一般程序不会使用，可用在 C/C++ 程序的调用中。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "unsafe",
      "类型安全",
      "C/C++ 调用",
      "Go 语言",
      "打破类型安全"
    ],
    "followup_points": [
      "1. 在使用 `unsafe` 调用 C/C++ 程序时，如何确保内存安全性和避免常见的内存错误（如悬垂指针、内存泄漏）？",
      "2. 除了 C/C++ 调用，`unsafe` 还有哪些典型应用场景？在这些场景中，如何权衡类型安全与性能/灵活性的需求？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/advanced/000-开始读 Go 源码了.md",
    "code_examples": []
  },
  {
    "id": "gopher_000-开始读 Go 源码了_008",
    "text": "`syscall`-`os`-`os/exec`：",
    "answer": "- `syscall`：提供了操作系统底层调用的基本接口。 - `os`：提供给我们一个平台无关性的操作系统功能接口，采用类 Unix 设计，隐藏了不同操作系统间差异，让不同的文件系统和操作系统对象表现一致。 - `os/exec`：提供了运行外部操作系统命令和程序的方式。",
    "category": "system",
    "difficulty": 3,
    "tags": [
      "syscall",
      "os",
      "os/exec"
    ],
    "followup_points": [
      "1. 在 `syscall` 和 `os` 的接口设计中，Go 是如何平衡底层系统调用的直接性和跨平台一致性的？",
      "2. `os/exec` 在执行外部命令时，如何处理不同操作系统的路径分隔符、环境变量差异和命令参数转义？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/advanced/000-开始读 Go 源码了.md",
    "code_examples": []
  },
  {
    "id": "gopher_000-开始读 Go 源码了_009",
    "text": "`encoding/json`-`encoding/xml`-`text/template`：",
    "answer": "- `encoding/json`：读取并解码和写入并编码 JSON 数据。 - `encoding/xml`：简单的 XML1.0 解析器。 - `text/template`：生成像 HTML 一样的数据与文本混合的数据驱动模板。",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "encoding/json",
      "encoding/xml",
      "text/template",
      "数据解析",
      "模板引擎"
    ],
    "followup_points": [
      "1. `encoding/json` 在处理嵌套 JSON 结构时，如何避免常见的解析错误（如类型不匹配或字段缺失）？",
      "2. `text/template` 与 `html/template` 的主要区别是什么，在什么场景下更适合使用 `html/template`？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/advanced/000-开始读 Go 源码了.md",
    "code_examples": []
  },
  {
    "id": "gopher_000-开始读 Go 源码了_010",
    "text": "`net`-`net/http`：",
    "answer": "- `net`：网络数据的基本操作。 - `http`：提供了一个可扩展的 HTTP 服务器和基础客户端，解析 HTTP 请求和回复。",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "net",
      "net/http",
      "HTTP服务器",
      "HTTP客户端",
      "网络数据操作"
    ],
    "followup_points": [
      "1. `net` 包中的 `Dial` 函数在建立网络连接时，如何处理超时和错误？",
      "2. `http` 包的 `ServeMux` 如何实现路由匹配，是否支持正则表达式或自定义匹配规则？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/advanced/000-开始读 Go 源码了.md",
    "code_examples": []
  },
  {
    "id": "gopher_000-开始读 Go 源码了_011",
    "text": "`reflect`：实现通过程序运行时反射，让程序操作任意类型的变量。",
    "answer": "`reflect`：实现通过程序运行时反射，让程序操作任意类型的变量。 这里仅仅列举了一部分标准库，更全面的标准库列表大家可以直接看官网。 那么问题来了，这么多库从何下手呢？ 我这里做一个简单的分类，由于水平有限，只能做一些简单的梳理，然后大家可以结合自己的实际情况来做选择。 有些库涉及到非常专业的知识，投入产出比可能会比较低。比如 `archive`、`compress` 以及 `crypto`，涉及到压缩算法以及加密算法的知识。 有些库属于工具类，比如 `bufio`、`bytes`、`strings`、`path`、`strconv` 等，这些库不涉及领域知识，阅读起来比较容易。 有些库属于与操作系统打交道的，比如 `os`，`net`、`sync` 等，学习这些库需要对操作系统有明确的认识。 `net` 下的很多子包与网络协议相关，比如 `net/http`，涉及 `http` 报文的解析，需要对网络协议比较了解。 如果想要深入了解语言的底层原理，则需要阅读 `runtime` 库。 要想快速入门，并且了解语言的设计理念，建议阅读 `io` 以及 `fmt` 库，阅读后会对接口的设计理解更深。 我已经看了一些源码，虽然过程痛苦，但确实非常有用。前期可能理解起来比较困难，用的时间长一些，但形成固定套路之后，会越来越熟悉，用的时间也会更少，理解也会更深刻。 后续我还会继续总结输出，请大家持续关注，让我们学起来。",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "reflect",
      "runtime",
      "type",
      "interface",
      "value"
    ],
    "followup_points": [
      "1. 在使用 `reflect` 进行反射操作时，如何确保类型安全，避免因反射导致的运行时错误？",
      "2. 反射操作通常比直接调用方法或访问字段更慢，有哪些优化策略可以减少反射带来的性能开销？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/advanced/000-开始读 Go 源码了.md",
    "code_examples": []
  },
  {
    "id": "gopher_000-开始读 Go 源码了_012",
    "text": "[https://github.com/yongxinz/id-maker](https://github.com/yongxinz/id-maker)",
    "answer": "[https://github.com/yongxinz/id-maker](https://github.com/yongxinz/id-maker)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "分布式ID生成",
      "雪花算法",
      "Snowflake",
      "Java",
      "GitHub开源项目"
    ],
    "followup_points": [
      "1. 在ID生成器的实现中，如何处理时钟回拨问题？是否有相应的容错机制？",
      "2. 当前ID生成器是否支持分布式环境下的多节点协同生成？如果有，如何保证ID的唯一性和有序性？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/advanced/000-开始读 Go 源码了.md",
    "code_examples": []
  },
  {
    "id": "gopher_000-开始读 Go 源码了_013",
    "text": "[开源项目｜Go 开发的一款分布式唯一 ID 生成系统](https://mp.weixin.qq.com/s/tCGYTlB4nJH1ClViFQJ6Cw)",
    "answer": "[开源项目｜Go 开发的一款分布式唯一 ID 生成系统](https://mp.weixin.qq.com/s/tCGYTlB4nJH1ClViFQJ6Cw)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "分布式唯一ID",
      "Go",
      "雪花算法",
      "ID生成",
      "开源项目"
    ],
    "followup_points": [
      "1. 该系统在分布式环境下如何保证ID的唯一性和全局有序性？",
      "2. 系统采用了哪些策略来应对高并发场景下的性能瓶颈和延迟问题？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/advanced/000-开始读 Go 源码了.md",
    "code_examples": []
  },
  {
    "id": "gopher_000-开始读 Go 源码了_014",
    "text": "[测试小姐姐问我 gRPC 怎么用，我直接把这篇文章甩给了她](https://mp.weixin.qq.com/s/qdI2JqpMq6t2KN1byHaNCQ)",
    "answer": "[测试小姐姐问我 gRPC 怎么用，我直接把这篇文章甩给了她](https://mp.weixin.qq.com/s/qdI2JqpMq6t2KN1byHaNCQ)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "gRPC",
      "Protocol Buffers",
      "微服务",
      "RPC框架",
      "Go语言"
    ],
    "followup_points": [
      "1. 如果测试小姐姐看完文章后，对 gRPC 的服务端流式调用（Server Streaming）场景有疑问，你会如何结合一个具体的业务案例（如日志推送）来进一步解释其实现原理和注意事项？",
      "2. 在实际项目中，如果测试团队需要验证 gRPC 接口的性能（如并发请求、超时处理），你会推荐哪些测试工具或方法，并如何结合文章中的示例代码进行测试用例设计？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/advanced/000-开始读 Go 源码了.md",
    "code_examples": []
  },
  {
    "id": "gopher_000-开始读 Go 源码了_015",
    "text": "[gRPC，爆赞](https://mp.weixin.qq.com/s/1Xbca4Dv0akonAZerrChgA)",
    "answer": "[gRPC，爆赞](https://mp.weixin.qq.com/s/1Xbca4Dv0akonAZerrChgA)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "gRPC",
      "HTTP/2",
      "Protocol Buffers",
      "RPC框架",
      "微服务通信"
    ],
    "followup_points": [
      "1. 文章中提到gRPC基于HTTP/2协议，能否具体展开说明HTTP/2的多路复用特性如何提升gRPC的并发性能，相比传统HTTP/1.1有哪些核心优势？",
      "2. 在实际项目中，gRPC的流式通信（如客户端流、服务端流、双向流）通常用于哪些场景？能否分享一个你使用流式通信解决具体业务问题的案例？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/advanced/000-开始读 Go 源码了.md",
    "code_examples": []
  },
  {
    "id": "gopher_05-开源项目｜Go 开发的一款分布式唯一 ID 生成系统_000",
    "text": "**pkg**：一些调用的包",
    "answer": "usecase > repository (Postgres) usecase < repository (Postgres)",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "分层架构",
      "依赖注入",
      "仓储模式",
      "领域驱动设计",
      "包管理"
    ],
    "followup_points": [
      "1. 在 usecase 和 repository 之间的依赖方向是如何确定的？是否存在双向依赖的场景？",
      "2. 如果 repository 层需要依赖 usecase 层（例如 repository 需要调用 usecase 的某些方法），这种设计是否合理？如何处理循环依赖问题？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/blog/05-开源项目｜Go 开发的一款分布式唯一 ID 生成系统.md",
    "code_examples": []
  },
  {
    "id": "gopher_05-开源项目｜Go 开发的一款分布式唯一 ID 生成系统_001",
    "text": "[听说，99% 的 Go 程序员都被 defer 坑过](https://mp.weixin.qq.com/s/1T6Z74Wri27Ap8skeJiyWQ)",
    "answer": "[听说，99% 的 Go 程序员都被 defer 坑过](https://mp.weixin.qq.com/s/1T6Z74Wri27Ap8skeJiyWQ)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Go",
      "defer",
      "执行顺序",
      "闭包",
      "参数传递"
    ],
    "followup_points": [
      "1. 在使用 defer 时，如果 defer 语句中涉及函数参数的传递，参数是在 defer 时求值还是执行时求值？请举例说明。",
      "2. 当多个 defer 语句同时存在时，它们的执行顺序是怎样的？这种顺序是否会影响程序的逻辑，特别是在资源释放或错误处理场景下？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/blog/05-开源项目｜Go 开发的一款分布式唯一 ID 生成系统.md",
    "code_examples": []
  },
  {
    "id": "gopher_05-开源项目｜Go 开发的一款分布式唯一 ID 生成系统_002",
    "text": "[测试小姐姐问我 gRPC 怎么用，我直接把这篇文章甩给了她](https://mp.weixin.qq.com/s/qdI2JqpMq6t2KN1byHaNCQ)",
    "answer": "[测试小姐姐问我 gRPC 怎么用，我直接把这篇文章甩给了她](https://mp.weixin.qq.com/s/qdI2JqpMq6t2KN1byHaNCQ)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "gRPC",
      "Protocol Buffers",
      "微服务",
      "RPC框架",
      "HTTP/2"
    ],
    "followup_points": [
      "1. 在实际项目中，你是如何选择使用 gRPC 还是 RESTful API 的？主要考虑哪些因素？",
      "2. 如果 gRPC 服务需要支持跨语言调用（比如前端 JavaScript 调用后端 gRPC 服务），你会如何解决兼容性问题？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/blog/05-开源项目｜Go 开发的一款分布式唯一 ID 生成系统.md",
    "code_examples": []
  },
  {
    "id": "gopher_05-开源项目｜Go 开发的一款分布式唯一 ID 生成系统_003",
    "text": "[gRPC，爆赞](https://mp.weixin.qq.com/s/1Xbca4Dv0akonAZerrChgA)",
    "answer": "[gRPC，爆赞](https://mp.weixin.qq.com/s/1Xbca4Dv0akonAZerrChgA)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "gRPC",
      "RPC框架",
      "HTTP/2",
      "Protocol Buffers",
      "微服务通信"
    ],
    "followup_points": [
      "1. 文章中提到gRPC基于HTTP/2协议，能否具体展开说明HTTP/2的多路复用特性如何帮助gRPC实现高效的双流通信？",
      "2. 在实际项目中，如果gRPC服务面临高并发场景，你会如何结合负载均衡和熔断机制来保障服务的稳定性？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/blog/05-开源项目｜Go 开发的一款分布式唯一 ID 生成系统.md",
    "code_examples": []
  },
  {
    "id": "gopher_05-开源项目｜Go 开发的一款分布式唯一 ID 生成系统_004",
    "text": "[使用 grpcurl 通过命令行访问 gRPC 服务](https://mp.weixin.qq.com/s/GShwcGCopXVmxCKnYf5FhA)",
    "answer": "[使用 grpcurl 通过命令行访问 gRPC 服务](https://mp.weixin.qq.com/s/GShwcGCopXVmxCKnYf5FhA)",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "gRPC",
      "grpcurl",
      "命令行工具",
      "API调试",
      "Protocol Buffers"
    ],
    "followup_points": [
      "1. 在使用 grpcurl 访问需要认证的 gRPC 服务时，除了文中提到的 `-H` 参数传递认证头，还有哪些常见的认证方式（如 TLS、OAuth2、JWT 等）？如何配置这些认证方式？",
      "2. 当 gRPC 服务返回的响应数据结构较复杂时，如何通过 grpcurl 更直观地解析或格式化输出（如使用 `-raw`、` -format json` 或结合 jq 工具）？是否有其他实用技巧可以提升调试效率？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/blog/05-开源项目｜Go 开发的一款分布式唯一 ID 生成系统.md",
    "code_examples": []
  },
  {
    "id": "gopher_05-开源项目｜Go 开发的一款分布式唯一 ID 生成系统_005",
    "text": "[推荐三个实用的 Go 开发工具](https://mp.weixin.qq.com/s/3GLMLhegB3wF5_62mpmePA)",
    "answer": "[推荐三个实用的 Go 开发工具](https://mp.weixin.qq.com/s/3GLMLhegB3wF5_62mpmePA)",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Go开发工具",
      "效率工具",
      "开发工具",
      "实用工具",
      "Go工具"
    ],
    "followup_points": [
      "1. 在推荐的三个工具中，是否有遇到过工具在某些场景下不适用或存在局限性？如果有，是如何解决的？",
      "2. 除了这三个工具，你在实际项目中还使用过哪些提升开发效率的工具？它们各自解决了什么问题？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/blog/05-开源项目｜Go 开发的一款分布式唯一 ID 生成系统.md",
    "code_examples": []
  },
  {
    "id": "gopher_05-开源项目｜Go 开发的一款分布式唯一 ID 生成系统_006",
    "text": "[go-clean-template](https://github.com/evrone/go-clean-template)",
    "answer": "[go-clean-template](https://github.com/evrone/go-clean-template)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Go",
      "Clean Architecture",
      "DDD",
      "gRPC",
      "gorm"
    ],
    "followup_points": [
      "1. 在该模板中，clean architecture 的分层结构具体是如何组织的，各层之间的依赖关系是如何实现的？",
      "2. 模板中是否包含依赖注入（DI）的实现，如果包含，具体使用了哪些工具或机制，如何确保依赖的可测试性？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/blog/05-开源项目｜Go 开发的一款分布式唯一 ID 生成系统.md",
    "code_examples": []
  },
  {
    "id": "gopher_05-开源项目｜Go 开发的一款分布式唯一 ID 生成系统_007",
    "text": "[Leaf——美团点评分布式ID生成系统](https://tech.meituan.com/2017/04/21/mt-leaf.html)",
    "answer": "[Leaf——美团点评分布式ID生成系统](https://tech.meituan.com/2017/04/21/mt-leaf.html)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "分布式ID生成",
      "雪花算法",
      "号段模式",
      "数据库",
      "高可用"
    ],
    "followup_points": [
      "1. Leaf-segment模式中，当数据库中的segment号用尽时，系统是如何保证高可用性的？如果数据库出现故障，是否有降级方案？",
      "2. Leaf-snowflake模式中，时钟回拨问题是如何处理的？除了文中提到的判断时钟回拨并拒绝服务，是否有更优的解决方案来减少对业务的影响？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/blog/05-开源项目｜Go 开发的一款分布式唯一 ID 生成系统.md",
    "code_examples": []
  },
  {
    "id": "gopher_使用 Go 语言实现二叉搜索树_000",
    "text": "`String()`：打印一个树形结构",
    "answer": "key int value Item left *Node //left right *Node //right root *Node lock sync.RWMutex bst.lock.Lock() defer bst.lock.Unlock() n := &Node{key, value, nil, nil} if bst.root == nil { bst.root = n } else { insertNode(bst.root, n) } if newNode.key n.key { return search(n.right, key) } return true bst.lock.Lock() defer bst.lock.Unlock() remove(bst.root, key) if node == nil { return nil } if key node.key { node.right = remove(node.right, key) return node } // key == node.key if node.left == nil && node.right == nil { node = nil return nil } if node.left == nil { node = node.right return node } if node.right == nil { node = node.left return node } leftmostrightside := node.right for { //find smallest value on the right side if leftmostrightside != nil && leftmostrightside.left != nil { leftmostrightside = leftmostrightside.left } else { break } } node.key, node.value = leftmostrightside.key, leftmostrightside.value node.right = remove(node.right, node.key) return node bst.lock.Lock() defer bst.lock.Unlock() fmt.Println(\"------------------------------------------------\") stringify(bst.root, 0) fmt.Println(\"------------------------------------------------\") if n != nil { format := \"\" for i := 0; i < level; i++ { format += \" \" } format += \"---[ \" level++ stringify(n.left, level) fmt.Printf(format+\"%d\\n\", n.key) stringify(n.right, level) }",
    "category": "algorithm",
    "difficulty": 3,
    "tags": [
      "树形结构",
      "递归",
      "二叉搜索树",
      "并发控制",
      "指针"
    ],
    "followup_points": [
      "1. 在实现树形结构打印时，如何处理树的遍历顺序（如前序、中序、后序）对输出结果的影响？",
      "2. 如果树的结构非常庞大或存在深度递归的情况，如何优化打印逻辑以避免栈溢出或性能问题？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/blog/使用 Go 语言实现二叉搜索树.md",
    "code_examples": []
  },
  {
    "id": "gopher_使用 Go 语言实现二叉搜索树_001",
    "text": "[Go 语言 select 都能做什么？](https://mp.weixin.qq.com/s/YyyMzYxMi8I4HEaxzy4c7g)",
    "answer": "[Go 语言 select 都能做什么？](https://mp.weixin.qq.com/s/YyyMzYxMi8I4HEaxzy4c7g)",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "Go语言",
      "select关键字",
      "多路复用",
      "channel通信",
      "并发控制"
    ],
    "followup_points": [
      "1. 在 select 语句中，如果多个 channel 同时满足条件，Go 的 select 语句会选择哪个 case 执行？这种选择是否有确定性的规则？",
      "2. 当 select 语句中没有 default 分支且所有 channel 都未就绪时，程序会阻塞，这种阻塞行为是否会被外部中断（如 context 取消）？如何优雅地处理这种阻塞场景？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/blog/使用 Go 语言实现二叉搜索树.md",
    "code_examples": []
  },
  {
    "id": "gopher_使用 Go 语言实现二叉搜索树_002",
    "text": "[Go 语言 context 都能做什么？](https://mp.weixin.qq.com/s/7IliODEUt3JpEuzL8K_sOg)",
    "answer": "[Go 语言 context 都能做什么？](https://mp.weixin.qq.com/s/7IliODEUt3JpEuzL8K_sOg)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "并发控制",
      "超时控制",
      "取消机制",
      "请求链路传递",
      "goroutine 生命周期管理"
    ],
    "followup_points": [
      "1. 在使用 context 实现超时控制时，如果某个 goroutine 的处理时间超过了设定的超时时间，应该如何优雅地终止该 goroutine，避免资源泄漏？",
      "2. 当一个 context 被取消（如调用 cancel()）后，如何确保所有相关的 goroutine 都能正确接收到取消信号，并执行必要的清理逻辑？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/blog/使用 Go 语言实现二叉搜索树.md",
    "code_examples": []
  },
  {
    "id": "gopher_01-推荐三个实用的 Go 开发工具_000",
    "text": "孙悟空在花果山称王的时候，特意去了一趟东海，在那里淘到了如意金箍棒。因为身为一个山大王，怎么能没有一件趁手的兵器呢？",
    "answer": "孙悟空在花果山称王的时候，特意去了一趟东海，在那里淘到了如意金箍棒。因为身为一个山大王，怎么能没有一件趁手的兵器呢？",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "西游记",
      "孙悟空",
      "东海龙宫",
      "如意金箍棒",
      "兵器"
    ],
    "followup_points": [
      "1. 除了金箍棒，孙悟空在东海还关注了哪些宝物？这些宝物对他后续的修行或战斗有何潜在影响？",
      "2. 孙悟空选择金箍棒作为兵器时，除了“趁手”这一标准，是否还考虑了其他因素（如象征意义、特殊能力等）？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/blog/01-推荐三个实用的 Go 开发工具.md",
    "code_examples": []
  },
  {
    "id": "gopher_05-流程控制，一网打尽_000",
    "text": "在 `if` 之后，条件语句之前可以添加变量初始化语句，使用 `;` 分隔。",
    "answer": "if 7%2 == 0 { fmt.Println(\"7 is even\") } else { fmt.Println(\"7 is odd\") // 7 is odd } if 8%4 == 0 { fmt.Println(\"8 is divisible by 4\") // 8 is divisible by 4 } if num := 9; num < 0 { fmt.Println(num, \"is negative\") } else if num < 10 { fmt.Println(num, \"has 1 digit\") // 9 has 1 digit } else { fmt.Println(num, \"has multiple digits\") }",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "Go语言",
      "条件语句",
      "变量初始化",
      "if-else结构",
      "作用域"
    ],
    "followup_points": [
      "1. 在 `if` 条件语句前添加变量初始化时，该变量的作用域仅限于当前 `if-else` 块内部，这种设计是出于什么考虑？",
      "2. 如果在 `if` 条件语句前初始化的变量与外部作用域的变量同名，Go 语言会如何处理这种情况？是否会导致编译错误或覆盖外部变量？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/sc/05-流程控制，一网打尽.md",
    "code_examples": []
  },
  {
    "id": "gopher_05-流程控制，一网打尽_001",
    "text": "可以不设定条件表达式，在此种情况下，整个 `switch` 结构与多个 `if-else` 的逻辑作用等同；",
    "answer": "可以不设定条件表达式，在此种情况下，整个 `switch` 结构与多个 `if-else` 的逻辑作用等同；",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "switch",
      "if-else",
      "条件表达式",
      "逻辑结构",
      "控制流"
    ],
    "followup_points": [
      "1. 在不设定条件表达式的情况下，`switch` 结构是如何实现与多个 `if-else` 逻辑等同的？具体是通过什么机制或语法特性实现的？",
      "2. 这种无条件表达式的 `switch` 结构在实际开发中是否有典型应用场景？相比传统的 `if-else`，它可能带来哪些优势或局限性？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/sc/05-流程控制，一网打尽.md",
    "code_examples": []
  },
  {
    "id": "gopher_05-流程控制，一网打尽_002",
    "text": "在 `case` 中添加 `fallthrough` 关键字，会继续执行紧跟的下一个 `case`，不需要判断 `case` 的条件语句;",
    "answer": "在 `case` 中添加 `fallthrough` 关键字，会继续执行紧跟的下一个 `case`，不需要判断 `case` 的条件语句;",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "fallthrough",
      "switch-case",
      "控制流",
      "条件判断",
      "关键字"
    ],
    "followup_points": [
      "1. 在什么场景下你会主动使用 `fallthrough` 关键字，而不是直接将多个 `case` 的逻辑合并到一个条件块中？",
      "2. 如果 `fallthrough` 后的 `case` 包含 `break` 语句，程序会如何执行？是否会导致提前退出 `switch` 结构？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/sc/05-流程控制，一网打尽.md",
    "code_examples": []
  },
  {
    "id": "gopher_05-流程控制，一网打尽_003",
    "text": "`switch` 支持 `default` 语句，当所有 `case` 都不满足时，执行 `default` 语句。",
    "answer": "\"fmt\" \"time\" i := 2 fmt.Print(\"write \", i, \" as \") switch i { case 1: fmt.Println(\"one\") case 2: fmt.Println(\"two\") // write 2 as two fallthrough case 3: fmt.Println(\"three\") // three case 4, 5, 6: fmt.Println(\"four, five, six\") } switch num := 9; num { case 1: fmt.Println(\"one\") default: fmt.Println(\"nine\") // nine } switch time.Now().Weekday() { case time.Saturday, time.Sunday: fmt.Println(\"it's the weekend\") default: fmt.Println(\"it's a weekday\") // it's a weekday } t := time.Now() switch { case t.Hour() < 12: fmt.Println(\"it's before noon\") default: fmt.Println(\"it's after noon\") // it's after noon }",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "switch",
      "fallthrough",
      "default",
      "case",
      "multiple_case"
    ],
    "followup_points": [
      "1. 在 `switch` 语句中，`fallthrough` 的作用是什么？它和 `default` 语句的执行顺序有什么关系？",
      "2. 如果 `switch` 语句中既有 `case` 匹配又有 `fallthrough`，`default` 语句是否会被执行？为什么？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/sc/05-流程控制，一网打尽.md",
    "code_examples": []
  },
  {
    "id": "gopher_05-流程控制，一网打尽_004",
    "text": "支持 `continue` 和 `break`。",
    "answer": "\"fmt\" i := 1 // 只有条件 for i <= 3 { fmt.Println(i) i = i + 1 } // 有变量初始化和条件 for j := 7; j <= 9; j++ { fmt.Println(j) } // 死循环 for { fmt.Println(\"loop\") break } // 遍历数组 a := [...]int{10, 20, 30, 40} for i := range a { fmt.Println(i) } for i, v := range a { fmt.Println(i, v) } // 遍历切片 s := []string{\"a\", \"b\", \"c\"} for i := range s { fmt.Println(i) } for i, v := range s { fmt.Println(i, v) } // 遍历字典 m := map[string]int{\"a\": 10, \"b\": 20, \"c\": 30} for k := range m { fmt.Println(k) } for k, v := range m { fmt.Println(k, v) }",
    "category": "go",
    "difficulty": 2,
    "tags": [
      "for循环",
      "break",
      "continue",
      "range",
      "切片"
    ],
    "followup_points": [
      "1. 在死循环的示例中，你使用了 `break` 来终止循环，但如果想无限次执行循环体，应该如何修改代码？",
      "2. 在遍历数组的示例中，`for i := range a` 和 `for i, v := range a` 的区别是什么？如果数组元素是结构体，如何通过 `range` 获取结构体的字段值？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/sc/05-流程控制，一网打尽.md",
    "code_examples": []
  },
  {
    "id": "gopher_05-流程控制，一网打尽_005",
    "text": "只能跳到同级作用域或者上层作用域内，不能跳到内部作用域内。",
    "answer": "\"fmt\" // 跳出循环 for i := 0; ; i++ { if i == 2 { goto L1 } fmt.Println(i) } fmt.Println(\"Done\") // 跳过变量声明，不允许 // goto L2 // j := 1 // L2:",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "goto",
      "作用域",
      "变量声明",
      "循环控制",
      "标签使用规则"
    ],
    "followup_points": [
      "1. 在Go语言中，使用`goto`语句跳转到标签时，如果目标标签位于循环内部但当前作用域外部（如函数级别），编译器会如何处理？是否存在隐式的作用域扩展机制？",
      "2. 如果将`goto L1`修改为跳转到`L2`（即使`L2`在当前作用域内但位于变量声明之后），编译器报错的具体原因是什么？是否与Go的\"先声明后使用\"规则有直接关联？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/sc/05-流程控制，一网打尽.md",
    "code_examples": []
  },
  {
    "id": "gopher_05-流程控制，一网打尽_006",
    "text": "单独使用，用于跳出 `break` 当前所在的 `for`、 `switch`、 `select` 语句的执行;",
    "answer": "单独使用，用于跳出 `break` 当前所在的 `for`、 `switch`、 `select` 语句的执行;",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "break",
      "for",
      "switch",
      "select",
      "控制流"
    ],
    "followup_points": [
      "1. 在嵌套的 `for` 循环中，`break` 默认只会跳出当前层的循环，如果需要跳出多层循环，通常会如何实现？",
      "2. 除了 `for`、`switch` 和 `select` 语句，`break` 是否可以用于跳出其他控制结构（如 `if` 或 `range`）？如果不行，原因是什么？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/sc/05-流程控制，一网打尽.md",
    "code_examples": []
  },
  {
    "id": "gopher_05-流程控制，一网打尽_007",
    "text": "和标签一起使用，用于跳出标签所标识的 `for`、 `switch`、 `select` 语句的执行，可用于跳出多重循环，但标签和 `break` 必须在同一个函数内。",
    "answer": "\"fmt\" // break 跳转到标签处，然后跳过 for 循环 for i := 0; ; i++ { for j := 0; ; j++ { if i >= 2 { break L3 } if j > 4 { break } fmt.Println(i, j) } }",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "break",
      "label",
      "loop",
      "control-flow",
      "goto"
    ],
    "followup_points": [
      "1. 在上述代码中，如果将 `break L3` 改为 `continue L3`，程序的输出会有什么变化？为什么？",
      "2. 如果 `L3` 标签定义在 `for i := 0; ; i++` 循环的外部（例如函数开头），编译器会报错吗？为什么？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/sc/05-流程控制，一网打尽.md",
    "code_examples": []
  },
  {
    "id": "gopher_05-流程控制，一网打尽_008",
    "text": "和标签一起使用，用于跳出标签所标识的 `for` 语句的本次选代，但标签和 `continue` 必须在同一个函数内。",
    "answer": "\"fmt\" // continue 跳转到标签处，然后执行 i++ for i := 0; ; i++ { for j := 0; j 4 { break L4 } if i >= 2 { continue L4 } if j > 4 { continue } fmt.Println(i, j) } }",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "continue",
      "标签",
      "for循环",
      "break",
      "goto"
    ],
    "followup_points": [
      "1. 如果将标签 `L4` 定义在 `for` 循环的外层，而 `continue L4` 仍然在内层循环中使用，程序会如何执行？",
      "2. 在嵌套循环中，如果 `continue` 后的标签对应的是外层循环，而内层循环有未执行的代码，这些代码会被跳过吗？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/sc/05-流程控制，一网打尽.md",
    "code_examples": []
  },
  {
    "id": "gopher_05-流程控制，一网打尽_009",
    "text": "**选择语句：** 对应关键词 `switch`，`case`，`fallthrough` 和 `default`；",
    "answer": "**选择语句：** 对应关键词 `switch`，`case`，`fallthrough` 和 `default`；",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "switch",
      "case",
      "fallthrough",
      "default",
      "选择语句"
    ],
    "followup_points": [
      "1. 在使用 `switch` 语句时，`fallthrough` 的行为和适用场景是什么？",
      "2. `default` 分支在 `switch` 语句中的执行条件是什么？如果所有 `case` 都不匹配，`default` 是否一定会执行？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/sc/05-流程控制，一网打尽.md",
    "code_examples": []
  },
  {
    "id": "gopher_05-流程控制，一网打尽_010",
    "text": "**跳转语句：** 对应关键词 `goto`。",
    "answer": "**跳转语句：** 对应关键词 `goto`。 除此之外，还有 `break` 和 `continue`，都可以搭配循环语句和跳转语句使用。 跳转语句在某些场景下会非常实用，但也很容易出现一些莫名其妙的问题，所以使用起来要更谨慎些。",
    "category": "general",
    "difficulty": 3,
    "tags": [],
    "followup_points": [],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/sc/05-流程控制，一网打尽.md",
    "code_examples": []
  },
  {
    "id": "gopher_11-听说，99% 的 Go 程序员都被 defer 坑过_000",
    "text": "[https://github.com/yongxinz/gopher/tree/main/sc](https://github.com/yongxinz/gopher/tree/main/sc)",
    "answer": "[https://github.com/yongxinz/gopher/tree/main/sc](https://github.com/yongxinz/gopher/tree/main/sc)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Go",
      "并发编程",
      "Channel",
      "Select",
      "Context"
    ],
    "followup_points": [
      "1. 在实现并发安全的计数器时，除了使用互斥锁，你考虑过使用其他并发原语（如 atomic 包）吗？它们的优缺点分别是什么？",
      "2. 如果这个计数器需要支持高并发场景，你会如何优化它的性能？例如，是否有分段锁或无锁数据结构的改进方案？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/sc/11-听说，99% 的 Go 程序员都被 defer 坑过.md",
    "code_examples": []
  },
  {
    "id": "gopher_11-听说，99% 的 Go 程序员都被 defer 坑过_001",
    "text": "[gRPC，爆赞](https://mp.weixin.qq.com/s/1Xbca4Dv0akonAZerrChgA)",
    "answer": "[gRPC，爆赞](https://mp.weixin.qq.com/s/1Xbca4Dv0akonAZerrChgA)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "gRPC",
      "HTTP/2",
      "Protocol Buffers",
      "RPC框架",
      "微服务通信"
    ],
    "followup_points": [
      "1. 文章中提到gRPC相比REST API具有高性能优势，能否具体展开说明gRPC在哪些场景下性能优势最显著，以及这种优势是如何通过HTTP/2和Protocol Buffers实现的？",
      "2. 文章是否探讨了gRPC在微服务架构中的实际落地挑战？比如服务发现、负载均衡、跨语言兼容性等问题，企业在大规模应用时通常如何应对这些挑战？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/sc/11-听说，99% 的 Go 程序员都被 defer 坑过.md",
    "code_examples": []
  },
  {
    "id": "gopher_11-听说，99% 的 Go 程序员都被 defer 坑过_002",
    "text": "[使用 grpcurl 通过命令行访问 gRPC 服务](https://mp.weixin.qq.com/s/GShwcGCopXVmxCKnYf5FhA)",
    "answer": "[使用 grpcurl 通过命令行访问 gRPC 服务](https://mp.weixin.qq.com/s/GShwcGCopXVmxCKnYf5FhA)",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "gRPC",
      "grpcurl",
      "命令行工具",
      "API调试",
      "Protocol Buffers"
    ],
    "followup_points": [
      "1. 当使用 grpcurl 访问需要 TLS 认证的 gRPC 服务时，如果服务端使用了自签名证书，如何正确配置 grpcurl 以避免证书验证失败？",
      "2. 在使用 grpcurl 调用流式 RPC（如服务端流、客户端流或双向流）时，命令行应如何处理和展示持续返回的流数据？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/sc/11-听说，99% 的 Go 程序员都被 defer 坑过.md",
    "code_examples": []
  },
  {
    "id": "gopher_11-听说，99% 的 Go 程序员都被 defer 坑过_003",
    "text": "[推荐三个实用的 Go 开发工具](https://mp.weixin.qq.com/s/3GLMLhegB3wF5_62mpmePA)",
    "answer": "[推荐三个实用的 Go 开发工具](https://mp.weixin.qq.com/s/3GLMLhegB3wF5_62mpmePA)",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "Go",
      "开发工具",
      "效率工具",
      "代码质量",
      "调试工具"
    ],
    "followup_points": [
      "1. 在推荐这三个工具时，它们分别解决了你在 Go 开发中遇到的最具体的痛点是什么？",
      "2. 除了这三个工具，你在实际项目中还尝试过哪些其他工具，为什么最终没有选择它们？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/sc/11-听说，99% 的 Go 程序员都被 defer 坑过.md",
    "code_examples": []
  },
  {
    "id": "gopher_11-听说，99% 的 Go 程序员都被 defer 坑过_004",
    "text": "[被 Docker 日志坑惨了](https://mp.weixin.qq.com/s/3Tkc15dTCEDUAZaZ88pcSQ)",
    "answer": "[被 Docker 日志坑惨了](https://mp.weixin.qq.com/s/3Tkc15dTCEDUAZaZ88pcSQ)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Docker 日志",
      "日志驱动",
      "日志轮转",
      "日志大小限制",
      "日志收集"
    ],
    "followup_points": [
      "1. 文中提到 Docker 日志驱动配置不当会导致磁盘写满，除了默认的 json-file 驱动外，在实际生产环境中，你会如何根据业务场景选择合适的日志驱动（如 syslog、fluentd、journald 等）？需要考虑哪些关键因素？",
      "2. 对于容器日志的收集和持久化，除了文中提到的 ELK/EFK 技术栈，还有哪些常见的日志管理方案（如 Loki + Promtail、Vector + Kafka + ClickHouse 等）？各自的优缺点和适用场景是什么？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/sc/11-听说，99% 的 Go 程序员都被 defer 坑过.md",
    "code_examples": []
  },
  {
    "id": "gopher_11-听说，99% 的 Go 程序员都被 defer 坑过_005",
    "text": "[https://www.jianshu.com/p/63e3d57f285f](https://www.jianshu.com/p/63e3d57f285f)",
    "answer": "[https://www.jianshu.com/p/63e3d57f285f](https://www.jianshu.com/p/63e3d57f285f)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Java并发",
      "线程池",
      "ThreadPoolExecutor",
      "线程安全",
      "锁机制"
    ],
    "followup_points": [
      "1. 在实现\"两数之和\"问题时，如果输入的数组中有重复元素且存在多个有效解，应该如何设计算法来返回所有可能的解？",
      "2. 除了哈希表方法，是否还有其他时间复杂度为O(n)的解法？如果有，请比较它们在空间复杂度和实际运行效率上的差异。"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/sc/11-听说，99% 的 Go 程序员都被 defer 坑过.md",
    "code_examples": []
  },
  {
    "id": "gopher_go-zero 是如何实现令牌桶限流的？_000",
    "text": "生成的令牌放入令牌桶中存放，如果令牌桶满了则多余的令牌会直接丢弃，当请求到达时，会尝试从令牌桶中取令牌，取到了令牌的请求可以执行；",
    "answer": "生成的令牌放入令牌桶中存放，如果令牌桶满了则多余的令牌会直接丢弃，当请求到达时，会尝试从令牌桶中取令牌，取到了令牌的请求可以执行；",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "令牌桶算法",
      "流量控制",
      "限流",
      "速率限制",
      "资源保护"
    ],
    "followup_points": [
      "1. 令牌桶的容量大小和令牌的生成速率是如何设定的？这些参数通常根据什么业务场景或系统负载来调整？",
      "2. 当请求到达时，如果令牌桶中没有足够的令牌，这些请求会如何处理？是直接拒绝、排队等待还是采用其他策略？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/go-zero/go-zero 是如何实现令牌桶限流的？.md",
    "code_examples": []
  },
  {
    "id": "gopher_go-zero 是如何实现令牌桶限流的？_001",
    "text": "如果桶空了，那么尝试取令牌的请求会被直接丢弃。",
    "answer": "如果桶空了，那么尝试取令牌的请求会被直接丢弃。 ![](https://cdn.jsdelivr.net/gh/yongxinz/picb@main/data/tokenlimit.png) 令牌桶算法既能够将所有的请求平均分布到时间区间内，又能接受服务器能够承受范围内的突发请求，因此是目前使用较为广泛的一种限流算法。",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "令牌桶算法",
      "限流",
      "突发请求",
      "请求丢弃",
      "流量控制"
    ],
    "followup_points": [
      "1. 如果桶空了直接丢弃请求，那么对于需要保证可靠性的业务场景（如支付、订单创建），如何优化处理逻辑以避免关键请求丢失？",
      "2. 令牌桶算法中的桶容量和令牌填充速率如何根据业务实际流量特征进行动态调整，以平衡限流效果和资源利用率？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/go-zero/go-zero 是如何实现令牌桶限流的？.md",
    "code_examples": []
  },
  {
    "id": "gopher_go-zero 是如何实现令牌桶限流的？_002",
    "text": "[如何实现计数器限流？](https://mp.weixin.qq.com/s/CTemkZ2aKPCPTuQiDJri0Q)",
    "answer": "[如何实现计数器限流？](https://mp.weixin.qq.com/s/CTemkZ2aKPCPTuQiDJri0Q)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "计数器限流",
      "滑动窗口",
      "令牌桶",
      "漏桶",
      "限流算法"
    ],
    "followup_points": [
      "1. 计数器限流在时间窗口切换的瞬间可能出现双倍请求的问题，如何优化算法来避免这种突刺现象？",
      "2. 在分布式系统中，多个服务实例如何同步计数器的值，确保限流策略的一致性和准确性？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/go-zero/go-zero 是如何实现令牌桶限流的？.md",
    "code_examples": []
  },
  {
    "id": "gopher_go-zero 是如何实现令牌桶限流的？_003",
    "text": "[go-zero 是如何做路由管理的？](https://mp.weixin.qq.com/s/uTJ1En-BXiLvH45xx0eFsA)",
    "answer": "[go-zero 是如何做路由管理的？](https://mp.weixin.qq.com/s/uTJ1En-BXiLvH45xx0eFsA)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "go-zero",
      "路由管理",
      "中间件",
      "HTTP服务",
      "框架设计"
    ],
    "followup_points": [
      "1. 在 go-zero 的路由管理中，如果路由规则发生变更（如新增 API 路径或修改现有路径），框架是如何实现动态更新或热加载的，需要重启服务吗？",
      "2. go-zero 的路由管理中，对于跨域（CORS）、限流、鉴权等中间件是如何与路由规则集成并生效的，中间件的执行顺序是如何控制的？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/go-zero/go-zero 是如何实现令牌桶限流的？.md",
    "code_examples": []
  },
  {
    "id": "gopher_go-zero 是如何实现计数器限流的？_000",
    "text": "如果计数器超过了限制数量，则本窗口内所有的请求都被丢弃当时间到达下一个窗口时，计数器重置。",
    "answer": "如果计数器超过了限制数量，则本窗口内所有的请求都被丢弃当时间到达下一个窗口时，计数器重置。 ![](https://cdn.jsdelivr.net/gh/yongxinz/picb@main/data/periodlimit1.png) 固定窗口计数器是最为简单的算法，但这个算法有时会让通过请求量允许为限制的两倍。 ![](https://cdn.jsdelivr.net/gh/yongxinz/picb@main/data/periodlimit2.png) 考虑如下情况：限制 1 秒内最多通过 5 个请求，在第一个窗口的最后半秒内通过了 5 个请求，第二个窗口的前半秒内又通过了 5 个请求。这样看来就是在 1 秒内通过了 10 个请求。",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "固定窗口计数器",
      "限流算法",
      "计数器重置",
      "请求丢弃",
      "流量控制"
    ],
    "followup_points": [
      "1. 在固定窗口计数器算法中，如何解决窗口边界处请求量可能达到限制两倍的问题？是否有更优的算法（如滑动窗口）来避免这种情况？",
      "2. 如果系统需要实时调整限制数量（如从5个增加到10个），当前算法的计数器重置机制如何适应这种动态变化？是否需要额外的同步机制？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/go-zero/go-zero 是如何实现计数器限流的？.md",
    "code_examples": []
  },
  {
    "id": "gopher_go-zero 是如何实现计数器限流的？_001",
    "text": "如果当前窗口内区间的请求计数总和超过了限制数量，则本窗口内所有的请求都被丢弃。",
    "answer": "如果当前窗口内区间的请求计数总和超过了限制数量，则本窗口内所有的请求都被丢弃。 ![](https://cdn.jsdelivr.net/gh/yongxinz/picb@main/data/periodlimit3.png) 滑动窗口计数器是通过将窗口再细分，并且按照时间滑动，这种算法避免了固定窗口计数器带来的双倍突发请求，但时间区间的精度越高，算法所需的空间容量就越大。",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "滑动窗口算法",
      "请求限流",
      "计数器",
      "突发请求",
      "时间精度"
    ],
    "followup_points": [
      "1. 在滑动窗口计数器算法中，如何确定最优的窗口细分粒度，以平衡时间精度和空间容量之间的关系？",
      "2. 当窗口内请求被丢弃后，是否有机制向客户端返回明确的限流提示（如HTTP 429状态码），以及如何设计合理的重试策略？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/go-zero/go-zero 是如何实现计数器限流的？.md",
    "code_examples": []
  },
  {
    "id": "gopher_go-zero 是如何实现计数器限流的？_002",
    "text": "采用 lua script 做整个窗口计算，保证计算的原子性",
    "answer": "redis.call(\"expire\", KEYS[1], window) return 1 return 2 return 0 // PeriodOption defines the method to customize a PeriodLimit. PeriodOption func(l *PeriodLimit) // A PeriodLimit is used to limit requests during a period of time. PeriodLimit struct { period int // 窗口大小，单位 s quota int // 请求上限 limitStore *redis.Redis keyPrefix string // key 前缀 align bool } opts ...PeriodOption) *PeriodLimit { limiter := &PeriodLimit{ period: period, quota: quota, limitStore: limitStore, keyPrefix: keyPrefix, } for _, opt := range opts { opt(limiter) } return limiter return h.TakeCtx(context.Background(), key) resp, err := h.limitStore.EvalCtx(ctx, periodScript, []string{h.keyPrefix + key}, []string{ strconv.Itoa(h.quota), strconv.Itoa(h.calcExpireSeconds()), }) if err != nil { return Unknown, err } code, ok := resp.(int64) if !ok { return Unknown, ErrUnknownCode } switch code { case internalOverQuota: // 超过上限 return OverQuota, nil case internalAllowed: // 未超过，允许访问 return Allowed, nil case internalHitQuota: // 正好达到限流上限 return HitQuota, nil default: return Unknown, ErrUnknownCode }",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "Redis Lua Script",
      "原子性操作",
      "滑动窗口算法",
      "限流",
      "数据结构设计"
    ],
    "followup_points": [
      "1. 在 Lua 脚本中，如何处理多个 KEYS 和 ARGV 的传递，以确保窗口计算的准确性和原子性？",
      "2. 当 Redis 集群环境下，Lua 脚本的分布式一致性如何保证，以及如何避免因网络分区或节点故障导致的计算异常？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/go-zero/go-zero 是如何实现计数器限流的？.md",
    "code_examples": []
  },
  {
    "id": "gopher_go-zero 是如何实现计数器限流的？_003",
    "text": "[go-zero 是如何做路由管理的？](https://mp.weixin.qq.com/s/uTJ1En-BXiLvH45xx0eFsA)",
    "answer": "[go-zero 是如何做路由管理的？](https://mp.weixin.qq.com/s/uTJ1En-BXiLvH45xx0eFsA)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "go-zero",
      "路由管理",
      "中间件",
      "HTTP服务",
      "框架设计"
    ],
    "followup_points": [
      "1. go-zero 的路由管理中，`restful` 路由和 `rpc` 路由在底层实现上有哪些核心差异？",
      "2. 在动态路由场景下（如基于正则或参数的匹配），go-zero 如何保证路由查找的性能和准确性？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/go-zero/go-zero 是如何实现计数器限流的？.md",
    "code_examples": []
  },
  {
    "id": "gopher_go-zero 是如何做路由管理的？_001",
    "text": "go-zero 路由规则",
    "answer": "在使用 go-zero 开发项目时，定义路由需要遵守如下规则： 1. 路由必须以 `/` 开头 2. 路由节点必须以 `/` 分隔 3. 路由节点中可以包含 `:`，但是 `:` 必须是路由节点的第一个字符，`:` 后面的节点值必须要在结请求体中有 `path tag` 声明，用于接收路由参数 4. 路由节点可以包含字母、数字、下划线、中划线 接下来就让我们深入到源码层面，相信看过源码之后，你就会更懂这些规则的意义了。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "go-zero",
      "路由规则",
      "路由参数",
      "path tag",
      "源码分析"
    ],
    "followup_points": [
      "1. go-zero 路由规则中，`:` 后面的节点值必须要在请求体中有 `path tag` 声明，这个 `path tag` 是否可以自定义名称，还是必须与路由节点名称完全一致？",
      "2. 路由节点中允许包含字母、数字、下划线、中划线，如果路由节点包含其他特殊字符（如 `.`、`?` 等），go-zero 底层是如何处理或校验的？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/go-zero/go-zero 是如何做路由管理的？.md",
    "code_examples": []
  },
  {
    "id": "gopher_go-zero 是如何做路由管理的？_002",
    "text": "go-zero 源码实现",
    "answer": "首先需要说明的是，底层数据结构使用的是二叉搜索树，还不是很了解的同学可以看这篇文章：[使用 Go 语言实现二叉搜索树](https://mp.weixin.qq.com/s/2wYRmG_AiiHYjLDEXg94Ag) # 先看一下节点定义： 重点说一下 `children`，它是一个包含两个元素的数组，元素 `0` 存正常路由键，元素 `1` 存以 `:` 开头的路由键，这些是 url 中的变量，到时候需要替换成实际值。 举一个例子，有这样一个路由 `/api/:user`，那么 `api` 会存在 `children[0]`，`user` 会存在 `children[1]`。 具体可以看看这段代码： # 主要部分代码都已经加了注释，其实这个过程就是树的构建，如果读过之前那篇文章，那这里还是比较好理解的。 # 先来看一段 `match` 代码： 这里有两个参数： - `pat`：路由树中存储的路由 - `token`：实际请求的路由，可能包含参数值 还是刚才的例子 `/api/:user`，如果是 `api`，没有以 `:` 开头，那就不会走 `if` 逻辑。 接下来匹配 `:user` 部分，如果实际请求的 url 是 `/api/zhangsan`，那么会将 `user` 作为 `key`，`zhangsan` 作为 `value` 保存到结果中。 下面是搜索查找代码： 以上就是路由管理的大部分代码，整个文件也就 200 多行，逻辑也并不复杂，通读之后还是很有收获的。 大家如果感兴趣的话，可以找到项目更详细地阅读。也可以关注我，接下来还会分析其他模块的源码。 以上就是本文的全部内容，如果觉得还不错的话欢迎**点赞**，**转发**和**关注**，感谢支持。 *** **推荐阅读：** * [使用 Go 语言实现二叉搜索树](https://mp.weixin.qq.com/s/2wYRmG_AiiHYjLDEXg94Ag) * [HTTP Router 算法演进](https://mp.weixin.qq.com/s/Ec2KyQ1ObyJuAOSvFa5xXg)",
    "category": "network",
    "difficulty": 5,
    "tags": [
      "go-zero",
      "路由",
      "二叉搜索树",
      "数据结构",
      "节点定义"
    ],
    "followup_points": [
      "1. 在 go-zero 的路由实现中，为什么选择二叉搜索树作为底层数据结构，相比其他树结构（如红黑树、AVL树）或哈希表有哪些优势和适用场景？",
      "2. 对于动态路由参数（如 `:user`），go-zero 是如何处理匹配优先级和冲突检测的？当路由规则存在嵌套或重叠时（如 `/api/:user` 和 `/api/user/profile`），底层逻辑如何确保正确匹配？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/go-zero/go-zero 是如何做路由管理的？.md",
    "code_examples": [
      {
        "code": "// core/search/tree.go\n\nconst (\n    colon = ':'\n    slash = '/'\n)\n\ntype (\n    // 节点\n    node struct {\n        item     interface{}\n        children [2]map[string]*node\n    }\n\n    // A Tree is a search tree.\n    Tree struct {\n        root *node\n    }\n)",
        "language": "go"
      },
      {
        "code": "func (nd *node) getChildren(route string) map[string]*node {\n    // 判断路由是不是以 : 开头\n    if len(route) > 0 && route[0] == colon {\n        return nd.children[1]\n    }\n\n    return nd.children[0]\n}",
        "language": "go"
      },
      {
        "code": "// Add adds item to associate with route.\nfunc (t *Tree) Add(route string, item interface{}) error {\n    // 需要路由以 / 开头\n    if len(route) == 0 || route[0] != slash {\n        return errNotFromRoot\n    }\n\n    if item == nil {\n        return errEmptyItem\n    }\n\n    // 把去掉 / 的路由作为参数传入\n    err := add(t.root, route[1:], item)\n    switch err {\n    case errDupItem:\n        return duplicatedItem(route)\n    case errDupSlash:\n        return duplicatedSlash(route)\n    default:\n        return err\n    }\n}\n\n\nfunc add(nd *node, route string, item interface{}) error {\n    if len(route) == 0 {\n        if nd.item != nil {\n            return errDupItem\n        }\n\n        nd.item = item\n        return nil\n    }\n\n    // 继续判断，看看是不是有多个 /\n    if route[0] == slash {\n        return errDupSlash\n    }\n\n    for i := range route {\n        // 判断是不是 /，目的就是去处两个 / 之间的内容\n        if route[i] != slash {\n            continue\n        }\n\n        token := route[:i]\n        \n        // 看看有没有子节点，如果有子节点，就在子节点下面继续添加\n        children := nd.getChildren(token)\n        if child, ok := children[token]; ok {\n            if child != nil {\n                return add(child, route[i+1:], item)\n            }\n\n            return errInvalidState\n        }\n\n        // 没有子节点，那么新建一个\n        child := newNode(nil)\n        children[token] = child\n        return add(child, route[i+1:], item)\n    }\n\n    children := nd.getChildren(route)\n    if child, ok := children[route]; ok {\n        if child.item != nil {\n            return errDupItem\n        }\n\n        child.item = item\n    } else {\n        children[route] = newNode(item)\n    }\n\n    return nil\n}",
        "language": "go"
      },
      {
        "code": "func match(pat, token string) innerResult {\n    if pat[0] == colon {\n        return innerResult{\n            key:   pat[1:],\n            value: token,\n            named: true,\n            found: true,\n        }\n    }\n\n    return innerResult{\n        found: pat == token,\n    }\n}",
        "language": "go"
      },
      {
        "code": "// Search searches item that associates with given route.\nfunc (t *Tree) Search(route string) (Result, bool) {\n    // 第一步先判断是不是 / 开头\n    if len(route) == 0 || route[0] != slash {\n        return NotFound, false\n    }\n\n    var result Result\n    ok := t.next(t.root, route[1:], &result)\n    return result, ok\n}\n\nfunc (t *Tree) next(n *node, route string, result *Result) bool {\n    if len(route) == 0 && n.item != nil {\n        result.Item = n.item\n        return true\n    }\n\n    for i := range route {\n        // 和 add 里同样的提取逻辑\n        if route[i] != slash {\n            continue\n        }\n\n        token := route[:i]\n        return n.forEach(func(k string, v *node) bool {\n            r := match(k, token)\n            if !r.found || !t.next(v, route[i+1:], result) {\n                return false\n            }\n            // 如果 url 中有参数，会把键值对保存到结果中\n            if r.named {\n                addParam(result, r.key, r.value)\n            }\n\n            return true\n        })\n    }\n\n    return n.forEach(func(k string, v *node) bool {\n        if r := match(k, route); r.found && v.item != nil {\n            result.Item = v.item\n            if r.named {\n                addParam(result, r.key, r.value)\n            }\n\n            return true\n        }\n\n        return false\n    })\n}",
        "language": "go"
      }
    ]
  },
  {
    "id": "gopher_为什么说 Go 语言字符串是不可变的？_000",
    "text": "`len`：字符串的长度",
    "answer": "`len`：字符串的长度 所以，当我们定义一个字符串： 那么它在内存中存储是这样的： ![](https://cdn.jsdelivr.net/gh/yongxinz/picb@main/data/string.drawio.png) 当我们在程序中对字符串进行重新赋值时，比如这样： 底层的存储就变成了这样： ![](https://cdn.jsdelivr.net/gh/yongxinz/picb@main/data/string.drawio%20\\(1\\).png) Go 实际上是重新创建了一个 `[]byte{}` 切片，然后让指针指向了新的地址。 更直接一点，我们直接修改字符串中的单个字符，比如： 这样做的话，会直接报错： 如果一定要这么做的话，需要对字符串进行一个转换，转换成 `[]byte` 类型，修改之后再转换回 `string` 类型： 这样就可以了。 以上就是本文的全部内容，如果觉得还不错的话欢迎**点赞**，**转发**和**关注**，感谢支持。",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "字符串不可变性",
      "内存存储",
      "指针重新指向",
      "切片创建",
      "重新赋值"
    ],
    "followup_points": [
      "1. 在Go中，字符串是不可变的，那么当我们重新赋值字符串时，底层是如何处理内存分配和垃圾回收的？",
      "2. 如果字符串被频繁重新赋值，这种重新创建`[]byte`切片的方式会对性能产生什么影响，有没有优化建议？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/whygo/为什么说 Go 语言字符串是不可变的？.md",
    "code_examples": [
      {
        "code": "s := \"Hello World\"",
        "language": "go"
      },
      {
        "code": "s := \"Hello World\"\n\ns = \"Hello AlwaysBeta\"",
        "language": "go"
      },
      {
        "code": "s := \"Hello World\"\ns[0] = 'h'",
        "language": "go"
      },
      {
        "code": "cannot assign to s[0] (strings are immutable)",
        "language": "go"
      },
      {
        "code": "s := \"Hello World\"\nsBytes := []byte(s)\nsBytes[0] = 'h'\ns = string(sBytes)",
        "language": "go"
      }
    ]
  },
  {
    "id": "gopher_为什么说 Go 语言字符串是不可变的？_001",
    "text": "[Go 语言 map 如何顺序读取？](https://mp.weixin.qq.com/s/iScSgfpSE2y14GH7JNRJSA)",
    "answer": "[Go 语言 map 如何顺序读取？](https://mp.weixin.qq.com/s/iScSgfpSE2y14GH7JNRJSA)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Go语言",
      "map",
      "数据结构",
      "遍历",
      "有序读取"
    ],
    "followup_points": [
      "1. 如果在遍历过程中对 map 进行了插入或删除操作，会对遍历顺序产生什么影响？",
      "2. 除了文中提到的 `sort` + `range` 方案，是否有其他更高效的顺序读取方式（例如使用 `sync.Map` 或第三方库）？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/whygo/为什么说 Go 语言字符串是不可变的？.md",
    "code_examples": []
  },
  {
    "id": "gopher_为什么说 Go 语言字符串是不可变的？_002",
    "text": "[Go 语言 map 是并发安全的吗？](https://mp.weixin.qq.com/s/4mDzMdMbunR_p94Du65QOA)",
    "answer": "[Go 语言 map 是并发安全的吗？](https://mp.weixin.qq.com/s/4mDzMdMbunR_p94Du65QOA)",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "Go语言",
      "并发安全",
      "map",
      "数据竞争",
      "sync.Map"
    ],
    "followup_points": [
      "1. 除了使用 `sync.Map`，还有哪些常见的并发安全方案可以替代原生 map，它们各自的适用场景是什么？",
      "2. 如果在并发场景下必须使用原生 map，除了加锁外，还有哪些优化手段可以减少锁竞争或提升性能？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/whygo/为什么说 Go 语言字符串是不可变的？.md",
    "code_examples": []
  },
  {
    "id": "gopher_为什么说 Go 语言字符串是不可变的？_003",
    "text": "[Go 语言切片是如何扩容的？](https://mp.weixin.qq.com/s/VVM8nqs4mMGdFyCNJx16_g)",
    "answer": "[Go 语言切片是如何扩容的？](https://mp.weixin.qq.com/s/VVM8nqs4mMGdFyCNJx16_g)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Go语言",
      "切片",
      "内存分配",
      "扩容策略",
      "append函数"
    ],
    "followup_points": [
      "1. Go 切片扩容时，新分配的底层数组容量是如何计算出来的？具体是按什么规则（如翻倍或固定增长）来确定容量的？",
      "2. 如果切片在扩容后不再使用原来的底层数组，原数组会被垃圾回收吗？Go 是如何管理这种内存回收的？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/whygo/为什么说 Go 语言字符串是不可变的？.md",
    "code_examples": []
  },
  {
    "id": "gopher_为什么说 Go 语言字符串是不可变的？_004",
    "text": "[Go 语言数组和切片的区别](https://mp.weixin.qq.com/s/esaAmAdmV4w3_qjtAzTr4A)",
    "answer": "[Go 语言数组和切片的区别](https://mp.weixin.qq.com/s/esaAmAdmV4w3_qjtAzTr4A)",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "Go语言基础",
      "数组",
      "切片",
      "内存管理",
      "数据结构"
    ],
    "followup_points": [
      "1. 在函数参数传递时，数组是值传递而切片是引用传递，这种差异在实际开发中会对性能产生哪些具体影响？",
      "2. 当切片进行 append 操作导致底层数组扩容时，新数组与原数组的关系是什么？如何避免因扩容导致的内存浪费？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/whygo/为什么说 Go 语言字符串是不可变的？.md",
    "code_examples": []
  },
  {
    "id": "gopher_为什么说 Go 语言字符串是不可变的？_005",
    "text": "[Go 语言 new 和 make 关键字的区别](https://mp.weixin.qq.com/s/NBDkI3roHgNgW1iW4e_6cA)",
    "answer": "[Go 语言 new 和 make 关键字的区别](https://mp.weixin.qq.com/s/NBDkI3roHgNgW1iW4e_6cA)",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "Go语言关键字",
      "内存分配",
      "内置函数",
      "切片",
      "map"
    ],
    "followup_points": [
      "1. 在什么场景下，使用 `new` 分配的内存需要手动初始化，而 `make` 会自动完成初始化？这种自动初始化对性能有何影响？",
      "2. 如果尝试用 `make` 来创建非 slice、map 或 channel 的类型（如自定义结构体），编译器会报什么错误？为什么 Go 语言设计上限制 `make` 只能用于这三种类型？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/whygo/为什么说 Go 语言字符串是不可变的？.md",
    "code_examples": []
  },
  {
    "id": "gopher_为什么说 Go 语言字符串是不可变的？_006",
    "text": "[为什么 Go 不支持 \\[\\]T 转换为 \\[\\]interface](https://mp.weixin.qq.com/s/cwDEgnicK4jkuNpzulU2bw)",
    "answer": "[为什么 Go 不支持 \\[\\]T 转换为 \\[\\]interface](https://mp.weixin.qq.com/s/cwDEgnicK4jkuNpzulU2bw)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Go语言类型系统",
      "接口类型转换",
      "切片类型转换",
      "类型安全",
      "内存布局"
    ],
    "followup_points": [
      "1. 如果 Go 支持 `[]T` 转换为 `[]interface{}`，可能会在运行时引入哪些潜在的性能或内存问题？",
      "2. 在实际开发中，有没有其他替代方案（如类型断言、泛型）可以安全地实现类似 `[]T` 到 `[]interface{}` 的转换，各自的优缺点是什么？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/whygo/为什么说 Go 语言字符串是不可变的？.md",
    "code_examples": []
  },
  {
    "id": "gopher_为什么说 Go 语言字符串是不可变的？_007",
    "text": "[为什么 Go 语言 struct 要使用 tags](https://mp.weixin.qq.com/s/L7-TJ-CzYfuVrIBWP7Ebaw)",
    "answer": "[为什么 Go 语言 struct 要使用 tags](https://mp.weixin.qq.com/s/L7-TJ-CzYfuVrIBWP7Ebaw)",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "Go struct tags",
      "序列化与反序列化",
      "JSON 映射",
      "ORM 框架",
      "反射机制"
    ],
    "followup_points": [
      "1. 在使用 struct tags 进行序列化/反序列化时，如果 tag 中包含特殊字符（如 `json:\"name,omitempty\"` 中的逗号和冒号），Go 的反射机制是如何解析这些特殊字符的？解析过程中是否有性能损耗？",
      "2. 除了 JSON 序列化，struct tags 在其他场景（如数据库 ORM 框架、RPC 协议、模板渲染等）中是否有不同的设计考量？不同框架对 tag 的解析规则是否存在冲突或兼容性问题？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/whygo/为什么说 Go 语言字符串是不可变的？.md",
    "code_examples": []
  },
  {
    "id": "gopher_为什么 Go 语言 struct 要使用 tags_000",
    "text": "struct tags 的使用",
    "answer": "struct tags 使用还是很广泛的，特别是在 json 序列化，或者是数据库 ORM 映射方面。 在定义上，它以 `key:value` 的形式出现，跟在 struct 字段后面，除此之外，还有以下几点需要注意： # 在声明 struct tag 时，使用反引号 `` ` `` 包围 tag 的值，可以防止转义字符的影响，使 tag 更容易读取和理解。例如： # 在 struct tag 中，应该避免使用空格，特别是在 tag 名称和 tag 值之间。使用空格可能会导致编码或解码错误，并使代码更难以维护。例如： # 在 struct 中，应该避免重复使用同一个 tag 名称。如果重复使用同一个 tag 名称，编译器可能会无法识别 tag，从而导致编码或解码错误。例如： # 为了使 struct tag 更加标准化和易于维护，应该使用一些标准化的 tag 名称。 例如，对于序列化和反序列化，可以使用 `json`、`xml`、`yaml` 等；对于数据库操作，可以使用 `db`。 其中，`Password` 字段后面的 `-` 表示忽略该字段，也就是说该字段不会被序列化或反序列化。 # 如果一个字段需要指定多个 tag 值，可以使用 `,` 将多个 tag 值分隔开。例如： 其中 `omitempty` 表示如果该字段值为空，则不序列化该字段。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "struct tags",
      "json 序列化",
      "数据库 ORM 映射",
      "tag 值转义",
      "tag 命名规范"
    ],
    "followup_points": [
      "1. 在 JSON 序列化和数据库 ORM 映射中，struct tag 的具体作用机制是什么？能否举例说明不同 tag 如何影响数据的转换过程？",
      "2. 如果 struct 中重复使用同一个 tag 名称，会导致什么问题？是否有实际场景下需要重复使用 tag 的情况，以及如何处理？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/whygo/为什么 Go 语言 struct 要使用 tags.md",
    "code_examples": [
      {
        "code": "type User struct {\n    ID    int    `json:\"id\" db:\"id\"`\n    Name  string `json:\"name\" db:\"name\"`\n    Email string `json:\"email\" db:\"email\"`\n}",
        "language": "go"
      },
      {
        "code": "// 不规范的写法\ntype User struct {\n    ID    int    `json: \"id\" db: \"id\"`\n    Name  string `json: \"name\" db: \"name\"`\n    Email string `json: \"email\" db: \"email\"`\n}\n\n// 规范的写法\ntype User struct {\n    ID    int    `json:\"id\" db:\"id\"`\n    Name  string `json:\"name\" db:\"name\"`\n    Email string `json:\"email\" db:\"email\"`\n}",
        "language": "go"
      },
      {
        "code": "// 不规范的写法\ntype User struct {\n    ID    int    `json:\"id\" db:\"id\"`\n    Name  string `json:\"name\" db:\"name\"`\n    Email string `json:\"email\" db:\"name\"`\n}\n\n// 规范的写法\ntype User struct {\n    ID    int    `json:\"id\" db:\"id\"`\n    Name  string `json:\"name\" db:\"name\"`\n    Email string `json:\"email\" db:\"email\"`\n}",
        "language": "go"
      },
      {
        "code": "type User struct {\n    ID       int    `json:\"id\" db:\"id\"`\n    Name     string `json:\"name\" db:\"name\"`\n    Password string `json:\"-\" db:\"password\"` // 忽略该字段\n    Email    string `json:\"email\" db:\"email\"`\n}",
        "language": "go"
      },
      {
        "code": "type User struct {\n    ID        int    `json:\"id\" db:\"id\"`\n    Name      string `json:\"name\" db:\"name\"`\n    Email     string `json:\"email,omitempty\" db:\"email,omitempty\"`\n}",
        "language": "go"
      }
    ]
  },
  {
    "id": "gopher_为什么 Go 语言 struct 要使用 tags_001",
    "text": "struct tags 的原理",
    "answer": "Go 的反射库提供了一些方法，可以让我们在程序运行时获取和解析结构体标签。 介绍这些方法之前，先来看看 `reflect.StructField` ，它是描述结构体字段的数据类型。定义如下： 结构体中还有一些其他字段，被我省略了，只保留了和本文相关的。 在结构体的反射中，我们经常使用 `reflect.TypeOf` 获取类型信息，然后使用 `Type.Field` 或 `Type.FieldByName()` 获取结构体字段的 `reflect.StructField`，然后根据 `StructField` 中的信息做进一步处理。 例如，可以通过 `StructField.Tag.Get` 方法获取结构体字段的标签值。 下面看一段代码： 运行以上代码，输出结果如下：",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "Go反射",
      "StructField",
      "Tag.Get",
      "结构体标签",
      "运行时解析"
    ],
    "followup_points": [
      "1. 在使用 `reflect.StructField.Tag.Get` 获取标签值时，如果标签不存在或值为空，返回的结果是什么？如何区分这两种情况？",
      "2. 结构体标签的解析规则是怎样的？例如，标签中包含 `key:\"value\"` 和 `key:\"value,opt1,opt2\"` 时，如何正确解析出 `value` 和选项？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/whygo/为什么 Go 语言 struct 要使用 tags.md",
    "code_examples": [
      {
        "code": "type StructField struct {\n    Name      string      // 字段名\n    Type      Type        // 字段类型\n    Tag       StructTag   // 字段标签\n}",
        "language": "go"
      },
      {
        "code": "package main\n\nimport (\n    \"fmt\"\n    \"reflect\"\n)\n\ntype User struct {\n    Name string `json:\"name\"`\n    Age  int    `json:\"age\"`\n}\n\ntype Manager struct {\n    Title string `json:\"title\"`\n    User\n}\n\nfunc main() {\n    m := Manager{Title: \"Manager\", User: User{Name: \"Alice\", Age: 25}}\n\n    mt := reflect.TypeOf(m)\n\n    // 获取 User 字段的 reflect.StructField\n    userField, _ := mt.FieldByName(\"User\")\n    fmt.Println(\"Field 'User' exists:\", userField.Name, userField.Type)\n\n    // 获取 User.Name 字段的 reflect.StructField\n    nameField, _ := userField.Type.FieldByName(\"Name\")\n    tag := nameField.Tag.Get(\"json\")\n    fmt.Println(\"User.Name tag:\", tag)\n}",
        "language": "go"
      },
      {
        "code": "Field 'User' exists: User {string int}\nUser.Name tag: \"name\"",
        "language": "go"
      }
    ]
  },
  {
    "id": "gopher_为什么 Go 语言 struct 要使用 tags_002",
    "text": "struct tags 的优势",
    "answer": "使用 struct tag 的主要优势之一是可以在**运行时通过反射来访问和操作 struct 中的字段**。 比如在 Go Web 开发中，常常需要将 HTTP 请求中的参数绑定到一个 struct 中。这时，我们可以使用 struct tag 指定每个字段对应的参数名称、验证规则等信息。在接收到 HTTP 请求时，就可以使用反射机制读取这些信息，并根据信息来验证参数是否合法。 另外，在将 struct 序列化为 JSON 或者其他格式时，我们也可以使用 struct tag 来指定每个字段在序列化时的名称和规则。 此外，使用 struct tag 还可以提高代码的**可读性**和**可维护性**。在一个大型的项目中，struct 中的字段通常会包含很多不同的元信息，比如数据库中的表名、字段名、索引、验证规则等等。 如果没有 struct tag，我们可能需要将这些元信息放在注释中或者在代码中进行硬编码。这样会让代码变得难以维护和修改。而使用 struct tag 可以将这些元信息与 struct 字段紧密关联起来，使代码更加清晰和易于维护。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "反射",
      "序列化",
      "代码可读性",
      "代码可维护性",
      "HTTP参数绑定"
    ],
    "followup_points": [
      "1. 在使用反射访问 struct tag 时，如何处理 tag 中包含特殊字符或需要转义的情况？",
      "2. 除了 HTTP 参数绑定和 JSON 序列化，struct tag 还有哪些常见的应用场景？能否举例说明？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/whygo/为什么 Go 语言 struct 要使用 tags.md",
    "code_examples": []
  },
  {
    "id": "gopher_为什么 Go 语言 struct 要使用 tags_003",
    "text": "常用的 struct tags",
    "answer": "在 Go 的官方 wiki 中，有一个常用的 struct tags 的库的列表，我复制在下面了，感兴趣的同学可以看看源码，再继续深入学习。 Tag | Documentation ----------|--------------- xml | https://pkg.go.dev/encoding/xml json | https://pkg.go.dev/encoding/json asn1 | https://pkg.go.dev/encoding/asn1 reform | https://pkg.go.dev/gopkg.in/reform.v1 dynamodb | https://docs.aws.amazon.com/sdk-for-go/api/service/dynamodb/dynamodbattribute/#Marshal bigquery | https://pkg.go.dev/cloud.google.com/go/bigquery datastore | https://pkg.go.dev/cloud.google.com/go/datastore spanner | https://pkg.go.dev/cloud.google.com/go/spanner bson | https://pkg.go.dev/labix.org/v2/mgo/bson, https://pkg.go.dev/go.mongodb.org/mongo-driver/bson/bsoncodec gorm | https://pkg.go.dev/github.com/jinzhu/gorm yaml | https://pkg.go.dev/gopkg.in/yaml.v2 toml | https://pkg.go.dev/github.com/pelletier/go-toml validate | https://github.com/go-playground/validator mapstructure | https://pkg.go.dev/github.com/mitchellh/mapstructure parser | https://pkg.go.dev/github.com/alecthomas/participle protobuf | https://github.com/golang/protobuf db | https://github.com/jmoiron/sqlx url | https://github.com/google/go-querystring feature | https://github.com/nikolaydubina/go-featureprocessing 以上就是本文的全部内容，如果觉得还不错的话欢迎**点赞**，**转发**和**关注**，感谢支持。 *** **参考文章：** - https://github.com/golang/go/wiki/Well-known-struct-tags **推荐阅读：** - [为什么 Go 不支持 []T 转换为 []interface](https://mp.weixin.qq.com/s/cwDEgnicK4jkuNpzulU2bw)",
    "category": "go",
    "difficulty": 1,
    "tags": [
      "struct tags",
      "encoding",
      "json",
      "xml",
      "asn1"
    ],
    "followup_points": [
      "1. 除了官方库中列出的这些 struct tags，你在实际项目中是否使用过或了解过其他第三方库中定义的 struct tags？它们通常用于解决什么特定场景的需求？",
      "2. 在使用 struct tags（如 `json` 或 `xml`）时，你是否遇到过 tag 配置与实际需求不匹配的情况？你是如何调整或解决这些问题的？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/whygo/为什么 Go 语言 struct 要使用 tags.md",
    "code_examples": []
  },
  {
    "id": "gopher_为什么 Go 不支持 []T 转换为 []interface_000",
    "text": "那么，既然是这样的话，我就有一个疑问了，拿出我举一反三的能力。是否可以将 `[]T` 转换为 `[]interface` 呢？",
    "answer": "那么，既然是这样的话，我就有一个疑问了，拿出我举一反三的能力。是否可以将 `[]T` 转换为 `[]interface` 呢？",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "Go类型转换",
      "接口类型",
      "切片类型",
      "类型断言",
      "空接口"
    ],
    "followup_points": [
      "1. 在尝试将 `[]T` 转换为 `[]interface{}` 时，如果 `T` 是一个具体类型（如 `int` 或 `struct`），会遇到什么编译错误或运行时问题？",
      "2. 如果 `T` 本身实现了 `interface{}` 的方法（或本身就是接口类型），是否有特殊的方式可以安全地进行转换？"
    ],
    "source_repo": "gopher",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/gopher/whygo/为什么 Go 不支持 []T 转换为 []interface.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_000",
    "text": "[如何向面试官提问？](https://github.com/yongxinz/InterviewThis)",
    "answer": "[如何向面试官提问？](https://github.com/yongxinz/InterviewThis)",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "面试技巧",
      "沟通能力",
      "求职准备",
      "职业规划",
      "信息获取"
    ],
    "followup_points": [
      "1. 在面试中，如果面试官对某个问题的回答比较模糊或不够具体，有哪些合适的追问方式既能获取有效信息，又不会显得咄咄逼人？",
      "2. 针对不同类型的面试官（如技术面试官、HR面试官、业务部门面试官），提问的侧重点和方式应该如何调整，才能更好地了解岗位和团队的真实情况？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_001",
    "text": "[Python 常考题](https://github.com/yongxinz/backend-interview/tree/master/Python)",
    "answer": "[Python 常考题](https://github.com/yongxinz/backend-interview/tree/master/Python)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Python基础",
      "数据结构与算法",
      "面向对象编程",
      "Python高级特性",
      "Web框架"
    ],
    "followup_points": [
      "1. 在Python中，GIL（全局解释器锁）对多线程性能的具体影响是什么？有没有实际案例可以说明？",
      "2. Python的装饰器（decorator）是如何工作的？能否举一个自定义装饰器的例子，并解释其执行顺序？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_002",
    "text": "[Go 语言 new 和 make 关键字的区别](https://mp.weixin.qq.com/s/NBDkI3roHgNgW1iW4e_6cA)",
    "answer": "[Go 语言 new 和 make 关键字的区别](https://mp.weixin.qq.com/s/NBDkI3roHgNgW1iW4e_6cA)",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "Go语言关键字",
      "内存分配",
      "内置函数",
      "切片",
      "map"
    ],
    "followup_points": [
      "1. 在实际开发中，什么场景下你会选择使用 `new` 而不是 `make`，或者反之？能否举例说明？",
      "2. 如果尝试对 `map` 或 `slice` 使用 `new` 会发生什么？为什么会出现这样的结果？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_003",
    "text": "[Go 语言数组和切片的区别](https://mp.weixin.qq.com/s/esaAmAdmV4w3_qjtAzTr4A)",
    "answer": "[Go 语言数组和切片的区别](https://mp.weixin.qq.com/s/esaAmAdmV4w3_qjtAzTr4A)",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "Go语言基础",
      "数组",
      "切片",
      "内存布局",
      "长度与容量"
    ],
    "followup_points": [
      "1. 在函数参数传递时，数组作为值传递和切片作为引用传递的具体底层实现机制是什么？",
      "2. 当切片进行 append 操作导致容量不足时，Go 底层是如何扩容的？扩容后的新数组与原数组的关系是怎样的？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_004",
    "text": "[Go 语言切片是如何扩容的？](https://mp.weixin.qq.com/s/VVM8nqs4mMGdFyCNJx16_g)",
    "answer": "[Go 语言切片是如何扩容的？](https://mp.weixin.qq.com/s/VVM8nqs4mMGdFyCNJx16_g)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Go语言",
      "切片",
      "内存分配",
      "扩容策略",
      "append函数"
    ],
    "followup_points": [
      "1. 在切片扩容时，如果新申请的容量超过原容量的两倍，为什么 Go 语言会选择直接使用新申请的容量而不是继续按照两倍增长？这种设计背后的考量是什么？",
      "2. 切片扩容时，如果新容量超过 `maxSliceCap`（通常是 1<<63 - 1），Go 语言会如何处理？这种极端情况下的扩容策略有什么潜在问题？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_005",
    "text": "[为什么 Go for-range 的 value 值地址每次都一样？](https://mp.weixin.qq.com/s/OoJ42UVYe72492mRUGtdvA)",
    "answer": "[为什么 Go for-range 的 value 值地址每次都一样？](https://mp.weixin.qq.com/s/OoJ42UVYe72492mRUGtdvA)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Go for-range",
      "range value address",
      "变量复用",
      "内存地址",
      "Go 语言特性"
    ],
    "followup_points": [
      "1. 如果在 for-range 循环中修改 value 的值，会对原始数据结构中的元素产生影响吗？为什么？",
      "2. 对于 map 类型的 for-range 循环，value 的地址是否仍然保持一致？如果不一致，原因是什么？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_006",
    "text": "[Go 语言 map 如何顺序读取？](https://mp.weixin.qq.com/s/iScSgfpSE2y14GH7JNRJSA)",
    "answer": "[Go 语言 map 如何顺序读取？](https://mp.weixin.qq.com/s/iScSgfpSE2y14GH7JNRJSA)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Go语言",
      "map",
      "数据结构",
      "遍历",
      "顺序读取"
    ],
    "followup_points": [
      "1. 如果在遍历过程中动态向 map 中插入新元素，会对遍历顺序产生什么影响？",
      "2. Go 1.12 之前和之后的 map 实现中，遍历顺序的随机性是否有差异？为什么？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_007",
    "text": "[Go 语言 map 是并发安全的吗？](https://mp.weixin.qq.com/s/4mDzMdMbunR_p94Du65QOA)",
    "answer": "[Go 语言 map 是并发安全的吗？](https://mp.weixin.qq.com/s/4mDzMdMbunR_p94Du65QOA)",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "Go语言",
      "map",
      "并发安全",
      "竞态条件",
      "sync.Map"
    ],
    "followup_points": [
      "1. 如果需要在 Go 中实现并发安全的 map，有哪些常用的方案？各自的优缺点是什么？",
      "2. Go 1.9 版本中引入的 `sync.Map` 与使用 `sync.RWMutex` 手动加锁的 map 相比，在什么场景下性能更优？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_008",
    "text": "[Go 语言 select 都能做什么？](https://mp.weixin.qq.com/s/YyyMzYxMi8I4HEaxzy4c7g)",
    "answer": "[Go 语言 select 都能做什么？](https://mp.weixin.qq.com/s/YyyMzYxMi8I4HEaxzy4c7g)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Go语言",
      "select语句",
      "channel通信",
      "多路复用",
      "非阻塞操作"
    ],
    "followup_points": [
      "1. 在 select 语句中，如果多个 case 同时满足条件，Go 的执行顺序是怎样的？是否存在优先级或随机性？",
      "2. select 中的 default 分支在什么场景下使用？如果所有 channel 都阻塞，直接走 default 会带来什么潜在问题？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_009",
    "text": "[Go 语言 context 都能做什么？](https://mp.weixin.qq.com/s/7IliODEUt3JpEuzL8K_sOg)",
    "answer": "[Go 语言 context 都能做什么？](https://mp.weixin.qq.com/s/7IliODEUt3JpEuzL8K_sOg)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "并发控制",
      "超时控制",
      "取消机制",
      "上下文传递",
      "链式调用"
    ],
    "followup_points": [
      "1. 在使用 context.WithTimeout 或 context.WithDeadline 时，如果子 goroutine 未能在截止时间前完成处理，应该如何优雅地终止或清理资源？",
      "2. 当 context 被取消时，如何确保所有相关的 goroutine 都能及时感知到取消信号，避免 goroutine 泄漏？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_010",
    "text": "[为什么说 Go 语言字符串是不可变的？](https://mp.weixin.qq.com/s/AOb6AjKwyTwLeAUou0AU-Q)",
    "answer": "[为什么说 Go 语言字符串是不可变的？](https://mp.weixin.qq.com/s/AOb6AjKwyTwLeAUou0AU-Q)",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "Go语言基础",
      "字符串不可变性",
      "内存安全",
      "并发安全",
      "值类型"
    ],
    "followup_points": [
      "1. 如果需要在 Go 中频繁修改字符串内容，有哪些优化的实践方法？",
      "2. Go 字符串不可变的设计对并发安全有哪些具体影响？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_011",
    "text": "[为 sync.WaitGroup 中Wait函数支持 WaitTimeout 功能.](Go/q013.md)",
    "answer": "[为 sync.WaitGroup 中Wait函数支持 WaitTimeout 功能.](Go/q013.md)",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "sync.WaitGroup",
      "并发控制",
      "超时机制",
      "context.Context",
      "goroutine同步"
    ],
    "followup_points": [
      "1. 在实现 WaitTimeout 功能时，如何处理 WaitGroup 计数器为负数的情况？",
      "2. 如果多个 goroutine 同时调用 WaitTimeout，如何确保并发安全性和正确的超时逻辑？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_012",
    "text": "[小林coding图解 MySQL](https://xiaolincoding.com/mysql/)",
    "answer": "[小林coding图解 MySQL](https://xiaolincoding.com/mysql/)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "MySQL",
      "数据库",
      "索引",
      "事务",
      "锁"
    ],
    "followup_points": [
      "1. 在学习MySQL时，你从\"小林coding图解MySQL\"中印象最深刻的一个知识点是什么？为什么它对你有帮助？",
      "2. 你在学习\"小林coding图解MySQL\"的过程中，是否遇到过难以理解的概念？你是如何通过该资源或其他方式解决的？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_013",
    "text": "[MySQL 常考题](https://github.com/yongxinz/backend-interview/tree/master/MySQL)",
    "answer": "[MySQL 常考题](https://github.com/yongxinz/backend-interview/tree/master/MySQL)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "索引优化",
      "事务与锁",
      "SQL查询优化",
      "存储引擎",
      "数据库设计范式"
    ],
    "followup_points": [
      "1. 在MySQL索引优化中，如果遇到\"索引失效\"的情况，你会从哪些方面进行排查和解决？",
      "2. 针对MySQL的事务隔离级别，能否举例说明不同隔离级别下可能出现的并发问题（如脏读、不可重复读）以及对应的解决方案？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_014",
    "text": "[20 道 MySQL 面试题](https://mp.weixin.qq.com/s/KVnMi45dvuLaRjoxcmpbNw)",
    "answer": "[20 道 MySQL 面试题](https://mp.weixin.qq.com/s/KVnMi45dvuLaRjoxcmpbNw)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "索引优化",
      "事务与锁",
      "SQL查询性能",
      "存储引擎",
      "数据库架构"
    ],
    "followup_points": [
      "1. 对于InnoDB和MyISAM存储引擎的选择，除了文中提到的ACID支持、外键、行级锁等核心差异，能否结合具体业务场景（如高并发写入、频繁查询、数据一致性要求等）举例说明如何进行更精细化的权衡？",
      "2. 在优化SQL查询时，文中提到了索引的使用和EXPLAIN分析，但实际中可能遇到“索引失效”或“索引选择不优”的情况，能否结合具体案例（如隐式类型转换、函数操作、联合索引最左前缀原则失效等）追问排查思路和解决方案？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_015",
    "text": "[看一遍就理解：order by 详解](https://mp.weixin.qq.com/s/h9jWeoyiBGnQLvDrtXqVWw)",
    "answer": "[看一遍就理解：order by 详解](https://mp.weixin.qq.com/s/h9jWeoyiBGnQLvDrtXqVWw)",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "SQL排序",
      "ORDER BY",
      "索引优化",
      "排序算法",
      "执行计划"
    ],
    "followup_points": [
      "1. 在MySQL中，当使用ORDER BY对多列进行排序时，如果两行数据在第一列的排序值相同，MySQL是如何处理第二列排序的？能否举例说明这种多列排序的实际应用场景？",
      "2. 在ORDER BY中使用表达式（如函数、算术运算等）进行排序时，对查询性能有哪些影响？是否有优化建议来减少排序操作的开销？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_016",
    "text": "[小林coding图解 Redis](https://xiaolincoding.com/redis/)",
    "answer": "[小林coding图解 Redis](https://xiaolincoding.com/redis/)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Redis",
      "数据结构",
      "缓存",
      "持久化",
      "面试题"
    ],
    "followup_points": [
      "1. 在学习小林coding的Redis图解内容时，你对哪个具体模块（如数据结构、持久化、集群等）印象最深刻？为什么？",
      "2. 小林coding的图解内容中是否有某个知识点是你之前理解有偏差，通过学习后得到纠正的？具体是什么？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_017",
    "text": "[Redis 常考题](https://github.com/yongxinz/backend-interview/tree/master/Redis)",
    "answer": "[Redis 常考题](https://github.com/yongxinz/backend-interview/tree/master/Redis)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "数据结构",
      "持久化",
      "缓存",
      "高可用",
      "集群"
    ],
    "followup_points": [
      "1. 在Redis的持久化机制中，RDB和AOF各有何优缺点？如果对数据安全性要求极高，你会如何配置Redis的持久化策略？",
      "2. Redis的哨兵模式和集群模式在实现高可用时有何本质区别？如果业务场景需要横向扩展存储容量，你会优先选择哪种模式，为什么？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_018",
    "text": "[Redis 夺命连环 20 问](https://mp.weixin.qq.com/s/PUSpuyh6dOi2zWM6J0-EJA)",
    "answer": "[Redis 夺命连环 20 问](https://mp.weixin.qq.com/s/PUSpuyh6dOi2zWM6J0-EJA)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Redis基础",
      "数据结构",
      "持久化",
      "高可用",
      "缓存策略"
    ],
    "followup_points": [
      "1. 在Redis的持久化机制中，RDB和AOF的混合持久化是如何协同工作的，具体的数据恢复流程是怎样的？",
      "2. Redis集群在处理跨slot的请求时，除了使用`MOVED`和`ASK`重定向，还有哪些优化策略来减少网络开销和提高访问效率？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_019",
    "text": "[Redis的事务满足原子性吗？](https://mp.weixin.qq.com/s/KAdivX9aYK2NgUJsDeKCpA)",
    "answer": "[Redis的事务满足原子性吗？](https://mp.weixin.qq.com/s/KAdivX9aYK2NgUJsDeKCpA)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Redis事务",
      "原子性",
      "MULTI/EXEC",
      "WATCH",
      "乐观锁"
    ],
    "followup_points": [
      "1. Redis事务中MULTI/EXEC/WATCH/DISCARD命令的具体作用和执行机制是什么？",
      "2. 如果事务执行过程中遇到命令语法错误或运行时错误，Redis会如何处理，对原子性有何影响？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_020",
    "text": "[缓存和数据库一致性问题](https://mp.weixin.qq.com/s/4W7vmICGx6a_WX701zxgPQ)",
    "answer": "[缓存和数据库一致性问题](https://mp.weixin.qq.com/s/4W7vmICGx6a_WX701zxgPQ)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "缓存一致性",
      "缓存更新策略",
      "双写一致性",
      "缓存穿透",
      "缓存雪崩"
    ],
    "followup_points": [
      "1. 在采用先更新数据库再更新缓存的策略时，如果更新缓存失败，你会采取哪些补偿机制来保证最终一致性？",
      "2. 对于高并发场景下的缓存穿透、缓存击穿和缓存雪崩问题，除了文中提到的解决方案，还有哪些更细粒度的优化手段？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_021",
    "text": "[深入理解跳表及其在 Redis 中的应用](https://mp.weixin.qq.com/s/ncr0EYG5495_HeCGSJ0z3A)",
    "answer": "[深入理解跳表及其在 Redis 中的应用](https://mp.weixin.qq.com/s/ncr0EYG5495_HeCGSJ0z3A)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "数据结构",
      "跳表",
      "Redis",
      "ZSET",
      "算法复杂度"
    ],
    "followup_points": [
      "1. 在 Redis 的跳表实现中，如果数据量非常大，如何平衡跳表的层级高度与内存占用，避免层级过高导致的内存浪费？",
      "2. Redis 的跳表在并发场景下如何保证数据一致性，是否有锁机制或其他优化策略来减少性能损耗？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_022",
    "text": "[Redis为什么变慢了？一文讲透如何排查Redis性能问题](https://mp.weixin.qq.com/s/Qc4t_-_pL4w8VlSoJhRDcg)",
    "answer": "[Redis为什么变慢了？一文讲透如何排查Redis性能问题](https://mp.weixin.qq.com/s/Qc4t_-_pL4w8VlSoJhRDcg)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Redis性能调优",
      "慢查询分析",
      "命令执行效率",
      "内存管理",
      "持久化机制"
    ],
    "followup_points": [
      "1. 在排查Redis变慢问题时，如何区分是CPU瓶颈、内存瓶颈还是网络瓶颈对性能的影响更大？",
      "2. 当发现Redis存在慢查询时，除了分析命令复杂度和数据结构选择，如何通过`latency-monitor`工具定位具体的延迟来源？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_023",
    "text": "[浅析 Redis 分布式锁解决方案](https://www.infoq.cn/article/dvaaj71f4fbqsxmgvdce)",
    "answer": "[浅析 Redis 分布式锁解决方案](https://www.infoq.cn/article/dvaaj71f4fbqsxmgvdce)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Redis分布式锁",
      "Redisson",
      "Redlock",
      "锁续期",
      "锁释放"
    ],
    "followup_points": [
      "1. 在 Redis 分布式锁中，如果客户端在持有锁期间崩溃，如何确保锁能够被正确释放，避免死锁问题？",
      "2. Redis 分布式锁的续期机制（如 Watchdog）是如何实现的，在高并发场景下续期失败会有什么风险，如何应对？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_024",
    "text": "[MongoDB 常考题](https://github.com/yongxinz/backend-interview/tree/master/MongoDB)",
    "answer": "[MongoDB 常考题](https://github.com/yongxinz/backend-interview/tree/master/MongoDB)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "MongoDB基础",
      "索引",
      "聚合框架",
      "复制与分片",
      "事务与ACID"
    ],
    "followup_points": [
      "1. 在MongoDB中，当查询条件包含多个字段时，如何确保复合索引的正确使用，以及如何分析查询执行计划以验证索引是否被有效利用？",
      "2. MongoDB的复制集架构中，如果主节点发生故障，从节点如何选举新的主节点？选举过程中可能出现哪些问题，以及如何优化选举的可靠性？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_025",
    "text": "[如何设计一个秒杀系统？](https://mp.weixin.qq.com/s/kWqgzMw4qKek7QUfkDSwNg)",
    "answer": "[如何设计一个秒杀系统？](https://mp.weixin.qq.com/s/kWqgzMw4qKek7QUfkDSwNg)",
    "category": "network",
    "difficulty": 5,
    "tags": [
      "高并发",
      "缓存",
      "限流",
      "数据库优化",
      "消息队列"
    ],
    "followup_points": [
      "1. 在秒杀系统中，如何保证库存数据在超高并发下的准确性和一致性，特别是在分布式环境下？",
      "2. 秒杀系统通常需要应对流量洪峰，除了限流和缓存策略，如何设计动态扩容机制来应对突发流量？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_026",
    "text": "[如何设计一个短链服务？](https://mp.weixin.qq.com/s/33lcKX3bLUAC-Mj0VlXa6A)",
    "answer": "[如何设计一个短链服务？](https://mp.weixin.qq.com/s/33lcKX3bLUAC-Mj0VlXa6A)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "URL缩短",
      "哈希算法",
      "高并发",
      "数据库设计",
      "重定向机制"
    ],
    "followup_points": [
      "1. 在短链服务中，如何处理高并发场景下的短码生成和存储压力？",
      "2. 短链服务的短码生成策略有哪些优缺点，如何平衡短码长度、唯一性和生成效率？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_027",
    "text": "[如何设计 Feed 流系统？](https://mp.weixin.qq.com/s/1O5rJtUDOOmlrXt373BaLQ)",
    "answer": "[如何设计 Feed 流系统？](https://mp.weixin.qq.com/s/1O5rJtUDOOmlrXt373BaLQ)",
    "category": "network",
    "difficulty": 5,
    "tags": [
      "Feed流架构",
      "读写分离",
      "Timeline存储",
      "排序算法",
      "缓存策略"
    ],
    "followup_points": [
      "1. 在Feed流系统中，如何处理用户个性化推荐与实时性之间的平衡问题？",
      "2. 当Feed流数据量极大时，如何优化存储和查询性能以避免延迟？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_028",
    "text": "[高并发场景下，红包雨怎么实现？](https://mp.weixin.qq.com/s/q1BPuqFDpdQC_AodeOabsA)",
    "answer": "[高并发场景下，红包雨怎么实现？](https://mp.weixin.qq.com/s/q1BPuqFDpdQC_AodeOabsA)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "高并发",
      "缓存",
      "分布式锁",
      "消息队列",
      "数据库优化"
    ],
    "followup_points": [
      "1. 在红包雨场景中，如何设计红包的分配算法来确保每个红包金额的随机性和公平性，同时避免超发或金额不足的问题？",
      "2. 高并发下，红包领取接口如何进行限流和降级，防止因瞬时流量过大导致系统崩溃，同时保证用户体验？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_029",
    "text": "[18 张图，详解微服务架构](https://mp.weixin.qq.com/s/ApjJcOxEPD3TTRiRW3XtxA)",
    "answer": "[18 张图，详解微服务架构](https://mp.weixin.qq.com/s/ApjJcOxEPD3TTRiRW3XtxA)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "微服务架构",
      "服务拆分",
      "服务治理",
      "API网关",
      "服务通信"
    ],
    "followup_points": [
      "1. 文中提到微服务架构的核心优势是\"独立部署\"和\"技术异构\"，在实际落地中，如何平衡\"技术异构\"带来的团队协作成本与\"独立部署\"带来的效率提升？",
      "2. 文中通过18张图展示了微服务的拆分原则（如DDD领域驱动），但在业务复杂度较高时，如何避免\"过度拆分\"导致的分布式事务、服务治理等问题？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_030",
    "text": "[搞懂异地多活，看这篇就够了](https://mp.weixin.qq.com/s/T6mMDdtTfBuIiEowCpqu6Q)",
    "answer": "[搞懂异地多活，看这篇就够了](https://mp.weixin.qq.com/s/T6mMDdtTfBuIiEowCpqu6Q)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "异地多活",
      "数据一致性",
      "流量调度",
      "容灾架构",
      "分布式事务"
    ],
    "followup_points": [
      "1. 在异地多活架构中，如何解决数据一致性问题和冲突检测，特别是在跨区域写入场景下？",
      "2. 异地多活架构中的流量调度和故障切换机制是如何实现的，如何保证业务连续性和用户体验？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_031",
    "text": "[数据结构与算法常考题](https://github.com/yongxinz/backend-interview/tree/master/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95)",
    "answer": "[数据结构与算法常考题](https://github.com/yongxinz/backend-interview/tree/master/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "数据结构",
      "算法",
      "时间复杂度",
      "空间复杂度",
      "编程题"
    ],
    "followup_points": [
      "1. 在数据结构与算法的面试中，除了常见的排序和查找算法，你认为哪些高级算法（如动态规划、贪心算法或回溯算法）在实际工程中的应用场景最广泛？为什么？",
      "2. 针对GitHub上提到的数据结构与算法常考题，你认为其中哪些题目最能考察候选人的问题分析能力和代码优化能力？请举例说明。"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_032",
    "text": "[系统编程常考题](https://github.com/yongxinz/backend-interview/tree/master/%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B)",
    "answer": "[系统编程常考题](https://github.com/yongxinz/backend-interview/tree/master/%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "系统编程",
      "操作系统",
      "计算机网络",
      "数据结构与算法",
      "C/C++"
    ],
    "followup_points": [
      "1. 在处理系统编程中的并发问题时，如何避免死锁，并请举例说明一种常见的死锁场景及对应的预防策略？",
      "2. 在系统编程中，内存管理是一个关键环节，请问如何检测和解决内存泄漏问题，并分享一种你熟悉的内存调试工具的使用经验？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_033",
    "text": "[网络常考题](https://github.com/yongxinz/backend-interview/tree/master/%E7%BD%91%E7%BB%9C)",
    "answer": "[网络常考题](https://github.com/yongxinz/backend-interview/tree/master/%E7%BD%91%E7%BB%9C)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "TCP/IP",
      "HTTP",
      "DNS",
      "WebSocket",
      "HTTPS"
    ],
    "followup_points": [
      "1. 在TCP三次握手过程中，如果第二次握手（SYN+ACK）的包丢失了，客户端和服务器端会分别发生什么？",
      "2. 在HTTP/2中，多路复用是如何解决HTTP/1.1队头阻塞问题的？如果其中一个流出现阻塞，其他流会受到影响吗？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_034",
    "text": "[既然有 HTTP 协议，为什么还要有 RPC](https://mp.weixin.qq.com/s/eTjsAXEjeSB9BF89xFUktQ)",
    "answer": "[既然有 HTTP 协议，为什么还要有 RPC](https://mp.weixin.qq.com/s/eTjsAXEjeSB9BF89xFUktQ)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "网络协议",
      "通信效率",
      "服务治理",
      "序列化",
      "跨语言调用"
    ],
    "followup_points": [
      "1. 在微服务架构中，如何根据业务场景选择使用 HTTP 还是 RPC？请结合性能、易用性和生态等因素分析。",
      "2. RPC 框架（如 gRPC、Dubbo）通常支持服务发现、负载均衡等功能，这些功能与 HTTP/REST 的 API 网关有哪些异同？如何避免功能重复或架构冗余？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_035",
    "text": "[编程题常考题](https://github.com/yongxinz/backend-interview/tree/master/%E7%BC%96%E7%A8%8B%E9%A2%98)",
    "answer": "[编程题常考题](https://github.com/yongxinz/backend-interview/tree/master/%E7%BC%96%E7%A8%8B%E9%A2%98)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "数据结构与算法",
      "动态规划",
      "递归与回溯",
      "二分查找",
      "哈希表"
    ],
    "followup_points": [
      "1. 在解决这些编程题时，你通常会采用哪些策略来优化时间复杂度和空间复杂度？",
      "2. 针对其中一道题（如两数之和、反转链表等），如果数据规模扩大（例如从10^4到10^6），你的解决方案会有哪些调整或优化？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_000",
    "text": "## MongoDB",
    "answer": "### 1.MongoDB中对多条记录做更新操作命令是什么？ ### 2.MongoDB如何才会拓展到多个shard里？",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "MongoDB更新操作",
      "MongoDB分片",
      "MongoDB水平扩展",
      "MongoDB集群架构",
      "MongoDB数据分片策略"
    ],
    "followup_points": [
      "1. 在使用多条记录更新命令时，如何确保操作的原子性？如果更新过程中出现错误，MongoDB会如何处理已更新的部分数据？",
      "2. 拓展到多个shard时，MongoDB如何选择shard key？选择不当可能导致哪些问题，如何优化shard key的分布？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MongoDB/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_README_004",
    "text": "内存管理与垃圾回收机制",
    "answer": "# # **内存泄漏**指由于疏忽或错误造成程序未能释放已经不再使用的内存。内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，导致在释放该段内存之前就失去了对该段内存的控制，从而造成了内存的浪费。 有`__del__()`函数的对象间的循环引用是导致内存泄露的主凶。不使用一个对象时使用: del object 来删除一个对象的引用计数就可以有效防止内存泄露问题。 通过 Python 扩展模块 gc 来查看不能回收的对象的详细信息。 可以通过 sys.getrefcount(obj) 来获取对象的引用计数，并根据返回值是否为0来判断是否内存泄露。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "内存泄漏",
      "引用计数",
      "循环引用",
      "垃圾回收",
      "sys.getrefcount"
    ],
    "followup_points": [
      "1. 在Python中，`gc`模块除了查看不能回收的对象外，还有哪些常用的方法或机制可以帮助开发者主动管理内存或排查内存泄漏问题？",
      "2. 除了`__del__()`函数导致的循环引用，还有哪些常见的场景或代码模式容易引发内存泄漏，应该如何避免？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Python/README.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_Python 编程题-3_000",
    "text": "画图让抽象问题形象化",
    "answer": "# > 思路一：可以按层次遍历，每一层从右到左 > > 思路二：使用递归 # > 思路：每一圈的开始位置总是坐上角元素[0, 0], [1, 1]...",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "数据结构",
      "算法设计",
      "可视化",
      "递归",
      "层次遍历"
    ],
    "followup_points": [
      "1. 在按层次遍历的思路中，如何确定每一层的边界条件，避免重复或遗漏元素？",
      "2. 递归思路中，如何定义递归终止条件，并确保每一圈（从左上角开始）的元素都被正确处理？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/编程题/Python 编程题-3.md",
    "code_examples": [
      {
        "code": "# coding=utf-8\n\"\"\"\n求二叉树的镜像\n思路一：按层次遍历，每一层从右到左\n思路二：递归遍历\n\"\"\"\nfrom collections import deque\n\n\nclass TreeNode(object):\n    def __init__(self, x):\n        self.val = x\n        self.left = None\n        self.right = None\n\n\nclass Tree(object):\n    def __init__(self):\n        self.root = None\n\n    def construct_tree(self, values=None):\n        if not values:\n            return None\n        self.root = TreeNode(values[0])\n        queue = deque([self.root])\n        leng = len(values)\n        nums = 1\n        while nums < leng:\n            node = queue.popleft()\n            if node:\n                node.left = TreeNode(values[nums]) if values[nums] else None\n                queue.append(node.left)\n                if nums + 1 < leng:\n                    node.right = TreeNode(values[nums + 1]) if values[nums + 1] else None\n                    queue.append(node.right)\n                    nums += 1\n                nums += 1\n\n    def bfs(self):\n        ret = []\n        queue = deque([self.root])\n        while queue:\n            node = queue.popleft()\n            if node:\n                ret.append(node.val)\n                queue.append(node.left)\n                queue.append(node.right)\n        return ret\n\n\ndef mirror_bfs(root):\n    ret = []\n    queue = deque([root])\n    while queue:\n        node = queue.popleft()\n        if node:\n            ret.append(node.val)\n            queue.append(node.right)\n            queue.append(node.left)\n    return ret\n\n\ndef mirror_pre(root):\n    ret = []\n\n    def traversal(root):\n        if root:\n            ret.append(root.val)\n            traversal(root.right)\n            traversal(root.left)\n    traversal(root)\n    return ret\n\n\nif __name__ == '__main__':\n    t = Tree()\n    t.construct_tree([1, 2, 6, 4, 3, 7, 5])\n    print t.bfs()\n    print mirror_bfs(t.root)\n    print mirror_pre(t.root)",
        "language": "python"
      },
      {
        "code": "# coding=utf-8\n\"\"\"\n按从外到里的顺序顺时针打印矩阵\n每一圈的开始位置总是坐上角元素[0, 0], [1, 1]...\n\"\"\"\n\n\ndef print_matrix(matrix):\n    \"\"\"\n    :param matrix: [[]]\n    \"\"\"\n    rows = len(matrix)\n    cols = len(matrix[0]) if matrix else 0\n    start = 0\n    ret = []\n    while start * 2 < rows and start * 2 < cols:\n        print_circle(matrix, start, rows, cols, ret)\n        start += 1\n    print ret\n\n\ndef print_circle(matrix, start, rows, cols, ret):\n    row = rows - start - 1  # 最后一行\n    col = cols - start - 1\n    # left->right\n    for c in range(start, col+1):\n        ret.append(matrix[start][c])\n    # top->bottom\n    if start < row:\n        for r in range(start+1, row+1):\n            ret.append(matrix[r][col])\n    # right->left\n    if start < row and start < col:\n        for c in range(start, col)[::-1]:\n            ret.append(matrix[row][c])\n    # bottom->top\n    if start < row and start < col:\n        for r in range(start+1, row)[::-1]:\n            ret.append(matrix[r][start])\n\n\nif __name__ == '__main__':\n    \"\"\"\n    mat = [[1, 2, 3],\n           [5, 6, 7],\n           [9, 10, 11]]\n    mat = [[]]\n    mat = [[1]]\n    mat = [[1, 2, 3, 4]]\n    mat = [[1], [2], [3], [4]]\n    \"\"\"\n    mat = [[1, 2],\n           [5, 6]]\n    print_matrix(mat)",
        "language": "python"
      }
    ]
  },
  {
    "id": "backend-interview_Python 编程题-3_001",
    "text": "举例让抽象问题具体化",
    "answer": "# > 要求：栈的push，pop，min操作的时间复杂度都是O(1) > > 思路：使用一个辅助栈保存最小值 # > 要求：判断给定的两个序列中，后者是不是前者的弹出序列，给定栈不包含相同值 > > 思路：使用一个辅助栈, 如果辅助栈栈顶元素不等于出栈元素，则从入栈中找改值，直到入栈为空 > 如果最后出栈序列为空，则是入栈的弹出序列值 # > 思路：广度优先搜索，按层次遍历 # > 要求：判断给定的整数数组是不是二叉搜索树的后序遍历序列 > > 整数数组中不包含重复值 > > 整数序列的最后一个值是根结点，然后比根结点小的值是左子树，剩下的是右子树，递归左右子树 # > 要求：输入一棵二叉树和一个值，求从根结点到叶结点的和等于该值的路径 > > 深度优先搜索变形",
    "category": "algorithm",
    "difficulty": 2,
    "tags": [
      "数据结构",
      "栈",
      "队列",
      "二叉树",
      "算法思想"
    ],
    "followup_points": [
      "1. 在使用辅助栈保存最小值的设计中，如何处理空间复杂度与时间复杂度的权衡？如果栈中的元素数量非常大，是否有优化空间？",
      "2. 在判断弹出序列的问题中，如果入栈序列和出栈序列包含重复值，辅助栈的设计需要如何调整？是否会影响时间复杂度？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/编程题/Python 编程题-3.md",
    "code_examples": [
      {
        "code": "# coding=utf-8\n\"\"\"\n包含min函数的栈\n栈的push，pop，min操作的时间复杂度都是O(1)\n使用一个辅助栈保存最小值\n\"\"\"\n\n\nclass MyStack(object):\n\n    def __init__(self):\n        self.stack = []\n        self.min = []\n\n    def push(self, val):\n        self.stack.append(val)\n        if self.min and self.min[-1] < val:\n            self.min.append(self.min[-1])\n        else:\n            self.min.append(val)\n\n    def pop(self):\n        if self.stack:\n            self.min.pop()\n            return self.stack.pop()\n        return None\n\n    def min(self):\n        return self.min[-1] if self.min else None\n\nif __name__ == '__main__':\n    s = MyStack()\n    s.push(2)\n    s.push(1)\n    s.push(3)\n    s.pop()\n    s.push(2)\n    print s.stack\n    print s.min",
        "language": "python"
      },
      {
        "code": "# coding=utf-8\n\"\"\"\n栈的压入弹出序列，判断给定的两个序列中，后者是不是前者的弹出序列\n序列中不存在相同值\n使用一个辅助栈, 如果辅助栈栈顶元素不等于出栈元素，则从入栈中找改值，直到入栈为空\n如果最后出栈序列为空，则是入栈的弹出序列\n\"\"\"\n\n\ndef pop_order(push_stack, pop_stack):\n    if not push_stack or not pop_stack:\n        return False\n    stack = []\n    while pop_stack:\n        pop_val = pop_stack[0]\n        if stack and stack[-1] == pop_val:\n            stack.pop()\n            pop_stack.pop(0)\n        else:\n            while push_stack:\n                if push_stack[0] != pop_val:\n                    stack.append(push_stack.pop(0))\n                else:\n                    push_stack.pop(0)\n                    pop_stack.pop(0)\n                    break\n        if not push_stack:\n            while stack:\n                if stack.pop() != pop_stack.pop(0):\n                    return False\n    if not pop_stack:\n        return True\n    return False\n\n\nif __name__ == '__main__':\n    print pop_order([1, 2, 3], [2, 3, 1])",
        "language": "python"
      },
      {
        "code": "# coding=utf-8\n\"\"\"\n从上往下打印二叉树\n树的广度优先，按层次遍历，使用一个辅助队列就可以\n\"\"\"\n\n\nfrom collections import deque\n\n\nclass TreeNode(object):\n    def __init__(self, x):\n        self.val = x\n        self.left = None\n        self.right = None\n\n\nclass Tree(object):\n    def __init__(self):\n        self.root = None\n\n    def construct_tree(self, values=None):\n        if not values:\n            return None\n        self.root = TreeNode(values[0])\n        queue = deque([self.root])\n        leng = len(values)\n        nums = 1\n        while nums < leng:\n            node = queue.popleft()\n            if node:\n                node.left = TreeNode(values[nums]) if values[nums] else None\n                queue.append(node.left)\n                if nums + 1 < leng:\n                    node.right = TreeNode(values[nums + 1]) if values[nums + 1] else None\n                    queue.append(node.right)\n                    nums += 1\n                nums += 1\n\n    def bfs(self):\n        ret = []\n        queue = deque([self.root])\n        while queue:\n            node = queue.popleft()\n            if node:\n                ret.append(node.val)\n                queue.append(node.left)\n                queue.append(node.right)\n        return ret\n\n\ndef bfs(tree):\n    if not tree:\n        return None\n    stack = [tree]\n    ret = []\n    while stack:\n        node = stack.pop(0)\n        ret.append(node.val)\n        if node.left:\n            stack.append(node.left)\n        if node.right:\n            stack.append(node.right)\n    return ret\n\nif __name__ == '__main__':\n    t = Tree()\n    t.construct_tree([1, 2, 6, 4, 3, 7, 5])\n    print t.bfs()\n    print bfs(t.root)",
        "language": "python"
      },
      {
        "code": "# coding=utf-8\n\"\"\"\n判断给定的整数数组是不是二叉搜索树的后序遍历序列\n整数数组中不包含重复值\n整数序列的最后一个值是根结点，然后比根结点小的值是左子树，剩下的是右子树，递归左右子树\n\"\"\"\n\n\ndef is_post_order(order):\n    length = len(order)\n    if length:\n        root = order[-1]\n        left = 0\n        while order[left] < root:\n            left += 1\n        right = left\n        while right < length - 1:\n            if order[right] < root:\n                return False\n            right += 1\n        left_ret = True if left == 0 else is_post_order(order[:left])\n        right_ret = True if left == right else is_post_order(order[left:right])\n        return left_ret and right_ret\n    return False\n\n\nif __name__ == '__main__':\n    print is_post_order([9, 6, 7])",
        "language": "python"
      },
      {
        "code": "# coding=utf-8\n\"\"\"\n输入一棵二叉树和一个值，求从根结点到叶结点的和等于该值的路径\n深度优先搜索变形\n\"\"\"\n\n\nfrom collections import deque\n\n\nclass TreeNode(object):\n    def __init__(self, x):\n        self.val = x\n        self.left = None\n        self.right = None\n\n\nclass Tree(object):\n    def __init__(self):\n        self.root = None\n\n    def construct_tree(self, values=None):\n        if not values:\n            return None\n        self.root = TreeNode(values[0])\n        queue = deque([self.root])\n        leng = len(values)\n        nums = 1\n        while nums < leng:\n            node = queue.popleft()\n            if node:\n                node.left = TreeNode(values[nums]) if values[nums] else None\n                queue.append(node.left)\n                if nums + 1 < leng:\n                    node.right = TreeNode(values[nums + 1]) if values[nums + 1] else None\n                    queue.append(node.right)\n                    nums += 1\n                nums += 1\n\n\ndef find_path(tree, num):\n    ret = []\n    if not tree:\n        return ret\n    path = [tree]\n    sums = [tree.val]\n\n    def dfs(tree):\n        if tree.left:\n            path.append(tree.left)\n            sums.append(sums[-1]+tree.left.val)\n            dfs(tree.left)\n        if tree.right:\n            path.append(tree.right)\n            sums.append(sums[-1] + tree.right.val)\n            dfs(tree.right)\n        if not tree.left and not tree.right:\n            if sums[-1] == num:\n                ret.append([p.val for p in path])\n        path.pop()\n        sums.pop()\n\n    dfs(tree)\n    return ret\n\n\nif __name__ == '__main__':\n    t = Tree()\n    t.construct_tree([1, 3, 6, 4, 3, 1, 1])\n    print find_path(t.root, 8)",
        "language": "python"
      }
    ]
  },
  {
    "id": "backend-interview_Python 编程题-3_002",
    "text": "分解让复杂问题简单化",
    "answer": "# > 要求：链表中除了指向后一个结点的指针之外，还有一个指针指向任意结点 > > 分为三步完成： > > 一:复制每个结点，并把新结点放在老结点后面，如1->2,复制为1->1->2->2 > > 二:为每个新结点设置other指针 > > 三:把复制后的结点链表拆开 > > 题目设置了复杂链表的实现，测试代码见文件twenth_six.py # > 要求: 将二叉搜索树转化成一个排序的双向链表，只调整树中结点的指向 > > 思路: 中序遍历，根结点的left指向左子树的最后一个(最大)值，right指向右子树的(最小)值 > > 注意: 题目构造了一个普通二叉树用来测试，构造时按照二叉搜索树的顺序输入结点，空结点用None表示，详情见twenty_seven.py # > 要求：求输入字符串的全排列 > > 思路：递归完成，也可以直接使用库函数",
    "category": "algorithm",
    "difficulty": 3,
    "tags": [
      "链表复制",
      "复杂链表",
      "二叉搜索树",
      "双向链表",
      "中序遍历"
    ],
    "followup_points": [
      "1. 在复制复杂链表时，如何确保新结点的other指针指向的是原结点other指针指向结点的新结点，而不是原结点？",
      "2. 在将二叉搜索树转化为双向链表的过程中，如何处理树的根结点，使其正确成为双向链表的表头或表尾？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/编程题/Python 编程题-3.md",
    "code_examples": [
      {
        "code": "# coding=utf-8\n\"\"\"\n复杂链表的复制\n链表中除了指向后一个结点的指针之外，还有一个指针指向任意结点\n分为三步完成：\n一复制每个结点，并把新结点放在老结点后面，如1->2,复制为1->1->2->2\n二为每个新结点设置other指针\n三把复制后的结点链表拆开\n\"\"\"\nimport random\n\n\nclass Node(object):\n\n    def __init__(self, val):\n        self.val = val\n        self.next = None\n        self.other = None\n\n\nclass Solution(object):\n\n    @staticmethod\n    def clone_nodes(head):\n        # 结点复制\n        move = head\n        while move:\n            tmp = Node(move.val)\n            tmp.next = move.next\n            move.next = tmp\n            move = tmp.next\n        return head\n\n    @staticmethod\n    def set_nodes(head):\n        # other指针设置\n        move = head\n        while move:\n            m_next = move.next\n            if move.other:\n                m_next.other = move.other.next\n            move = m_next.next\n        return head\n\n    @staticmethod\n    def reconstruct_nodes(head):\n        # 结点拆分\n        ret = head.next if head else Node\n        move = ret\n        while head:\n            head = move.next\n            if head:\n                move.next = head.next\n                move = move.next\n        return ret\n\n    @staticmethod\n    def clone_link(head):\n        # 结果\n        h = Solution.clone_nodes(head)\n        h = Solution.set_nodes(h)\n        ret = Solution.reconstruct_nodes(h)\n        return ret\n\n    @staticmethod\n    def print_nodes(head):\n        # 打印结点值，结点other的值，用来比较\n        ret = []\n        while head:\n            tmp = [head.val]\n            if head.other:\n                tmp.append(head.other.val)\n            ret.append(tmp)\n            head = head.next\n        print ret\n\n    @staticmethod\n    def construct_nodes(vals):\n        \"\"\"\n        构造一个简单的复杂链表\n        :param vals: list\n        :return: Nodes\n        \"\"\"\n        if not vals:\n            return Node\n        move = head = Node(vals.pop(0))\n        nodes = [None, head]\n        for v in vals:\n            tmp = Node(v)\n            move.next = tmp\n            nodes.append(tmp)\n            move = move.next\n        # print [node.val for node in nodes if node]\n        move = head\n        while move:\n            # 设置other指针为随机结点\n            move.other = random.choice(nodes)\n            move = move.next\n        return head\n\n\nif __name__ == '__main__':\n    link = Solution.construct_nodes([1, 2, 3, 4, 5])\n    Solution.print_nodes(link)\n    test = Solution.clone_link(link)  # 复制\n    Solution.print_nodes(test)",
        "language": "python"
      },
      {
        "code": "# coding=utf-8\n\"\"\"\n将二叉搜索树转化成一个排序的双向链表，只调整树中结点的指向，不用新结点\n中序遍历，根结点的left指向左子树的最后一个(最大)值，right指向右子树的(最小)值\n\"\"\"\n\nfrom collections import deque\n\n\nclass TreeNode(object):\n    def __init__(self, x):\n        self.val = x\n        self.left = None\n        self.right = None\n\n\nclass Tree(object):\n    \"\"\"\n    非二叉搜索树，建树的时候values中的顺序需要注意\n    之后有时间会改成二叉搜索树\n    \"\"\"\n    def __init__(self):\n        self.root = None\n\n    def construct_tree(self, values=None):\n        # 结点值不存在的话，values中用None表示\n        if not values:\n            return None\n        self.root = TreeNode(values[0])\n        queue = deque([self.root])\n        leng = len(values)\n        nums = 1\n        while nums < leng:\n            node = queue.popleft()\n            if node:\n                node.left = TreeNode(values[nums]) if values[nums] else None\n                queue.append(node.left)\n                if nums + 1 < leng:\n                    node.right = TreeNode(values[nums + 1]) if values[nums + 1] else None\n                    queue.append(node.right)\n                    nums += 1\n                nums += 1\n\n    def bfs(self):\n        ret = []\n        queue = deque([self.root])\n        while queue:\n            node = queue.popleft()\n            if node:\n                ret.append(node.val)\n                queue.append(node.left)\n                queue.append(node.right)\n        return ret\n\n\nclass Solution(object):\n\n    @staticmethod\n    def convert(tree):\n        \"\"\"结点转换\"\"\"\n        if not tree:\n            return None\n        p_last = Solution.convert_nodes(tree, None)\n        while p_last and p_last.left:  # 获取链表头结点\n            p_last = p_last.left\n        return p_last\n\n    @staticmethod\n    def convert_nodes(tree, last):\n        if not tree:\n            return None\n        if tree.left:\n            last = Solution.convert_nodes(tree.left, last)\n        if last:\n            last.right = tree\n        tree.left = last\n        last = tree\n        if tree.right:\n            last = Solution.convert_nodes(tree.right, last)\n        return last\n\n    @staticmethod\n    def print_nodes(tree):\n        # 正序链表打印\n        ret = []\n        while tree:\n            tmp = []\n            tmp.append(tree.left.val if tree.left else None)\n            tmp.append(tree.val)\n            tmp.append(tree.right.val if tree.right else None)\n            ret.append(tmp)\n            tree = tree.right\n        print ret\n\nif __name__ == '__main__':\n    r = Tree()\n    # r.construct_tree([2, 1])\n    # r.construct_tree([2, None, 3])\n    # r.construct_tree([2, 1, 3])\n    # r.construct_tree([])\n    r.construct_tree([5, 3, 6, 2, 4, None, 7, 1])\n    t = Solution.convert(r.root)\n    Solution.print_nodes(t)",
        "language": "python"
      },
      {
        "code": "# coding=utf-8\n\"\"\"\n求输入字符串的全排列\n递归完成，也可以直接使用库函数\n\"\"\"\n\nfrom itertools import permutations\n\n\ndef my_permutation(s):\n    str_set = []\n    ret = []  # 最后的结果\n\n    def permutation(string):\n        for i in string:\n            str_tem = string.replace(i, '')\n            str_set.append(i)\n            if len(str_tem) > 0:\n                permutation(str_tem)\n            else:\n                ret.append(''.join(str_set))\n            str_set.pop()\n\n    permutation(s)\n    return ret\n\n\nif __name__ == '__main__':\n    s = 'abc'\n    print my_permutation(s)\n    print [''.join(p) for p in permutations(s)]",
        "language": "python"
      }
    ]
  },
  {
    "id": "backend-interview_README_000",
    "text": "1 台阶问题/斐波那契",
    "answer": "一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法。 第二种记忆方法 第三种方法",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "动态规划",
      "斐波那契数列",
      "递归",
      "记忆化搜索",
      "状态转移方程"
    ],
    "followup_points": [
      "1. 第二种记忆方法具体是指什么？它与传统的记忆化递归相比，在空间复杂度或时间复杂度上有何优化？",
      "2. 第三种方法是否指动态规划的空间优化（如滚动数组）？如果是，请说明如何将空间复杂度从O(n)降至O(1)，并分析其适用场景。"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/编程题/README.md",
    "code_examples": [
      {
        "code": "fib = lambda n: n if n <= 2 else fib(n - 1) + fib(n - 2)",
        "language": "python"
      },
      {
        "code": "def memo(func):\n    cache = {}\n    def wrap(*args):\n        if args not in cache:\n            cache[args] = func(*args)\n        return cache[args]\n    return wrap\n\n\n@memo\ndef fib(i):\n    if i < 2:\n        return 1\n    return fib(i-1) + fib(i-2)",
        "language": "python"
      },
      {
        "code": "def fib(n):\n    a, b = 0, 1\n    for _ in xrange(n):\n        a, b = b, a + b\n    return b",
        "language": "python"
      }
    ]
  },
  {
    "id": "backend-interview_README_004",
    "text": "5 去除列表中的重复元素",
    "answer": "用集合 用字典 用字典并保持顺序 列表推导式 sorted排序并且用列表推导式. l = ['b','c','d','b','c','a','a'] [single.append(i) for i in sorted(l) if i not in single] print single",
    "category": "algorithm",
    "difficulty": 1,
    "tags": [
      "集合",
      "字典",
      "列表推导式",
      "排序",
      "去重"
    ],
    "followup_points": [
      "1. 在使用字典保持顺序的方法中，具体是如何利用字典的特性来去除重复元素并保持原始顺序的？",
      "2. 列表推导式 `[single.append(i) for i in sorted(l) if i not in single]` 中，`single.append(i)` 实际上返回的是 `None`，这种写法是否符合 Python 的最佳实践？是否有更推荐的方式来实现相同的功能？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/编程题/README.md",
    "code_examples": [
      {
        "code": "list(set(l))",
        "language": "python"
      },
      {
        "code": "l1 = ['b','c','d','b','c','a','a']\nl2 = {}.fromkeys(l1).keys()\nprint l2",
        "language": "python"
      },
      {
        "code": "l1 = ['b','c','d','b','c','a','a']\nl2 = list(set(l1))\nl2.sort(key=l1.index)\nprint l2",
        "language": "python"
      },
      {
        "code": "l1 = ['b','c','d','b','c','a','a']\nl2 = []\n[l2.append(i) for i in l1 if not i in l2]",
        "language": "python"
      }
    ]
  },
  {
    "id": "backend-interview_README_005",
    "text": "8 合并两个有序列表",
    "answer": "知乎远程面试要求编程 > 尾递归 > 循环算法 思路： 定义一个新的空列表 比较两个列表的首个元素 小的就插入到新列表里 把已经插入新列表的元素从旧列表删除 直到两个旧列表有一个为空 再把旧列表加到新列表后面 > pop弹出",
    "category": "algorithm",
    "difficulty": 2,
    "tags": [
      "链表合并",
      "双指针",
      "递归",
      "循环算法",
      "列表操作"
    ],
    "followup_points": [
      "1. 如果输入的两个有序列表中存在大量重复元素，算法的时间复杂度和空间复杂度会有什么变化？如何优化？",
      "2. 在使用 pop(0) 操作时，由于 Python 列表的底层实现，每次 pop(0) 的时间复杂度是 O(n)，如何改进算法以避免这个问题？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/编程题/README.md",
    "code_examples": [
      {
        "code": "def _recursion_merge_sort2(l1, l2, tmp):\n    if len(l1) == 0 or len(l2) == 0:\n        tmp.extend(l1)\n        tmp.extend(l2)\n        return tmp\n    else:\n        if l1[0] < l2[0]:\n            tmp.append(l1[0])\n            del l1[0]\n        else:\n            tmp.append(l2[0])\n            del l2[0]\n        return _recursion_merge_sort2(l1, l2, tmp)\n\ndef recursion_merge_sort2(l1, l2):\n    return _recursion_merge_sort2(l1, l2, [])",
        "language": "python"
      },
      {
        "code": "def loop_merge_sort(l1, l2):\n    tmp = []\n    while len(l1) > 0 and len(l2) > 0:\n        if l1[0] < l2[0]:\n            tmp.append(l1[0])\n            del l1[0]\n        else:\n            tmp.append(l2[0])\n            del l2[0]\n    tmp.extend(l1)\n    tmp.extend(l2)\n    return tmp",
        "language": "pyhton"
      },
      {
        "code": "a = [1,2,3,7]\nb = [3,4,5]\n\ndef merge_sortedlist(a,b):\n    c = []\n    while a and b:\n        if a[0] >= b[0]:\n            c.append(b.pop(0))\n        else:\n            c.append(a.pop(0))\n    while a:\n        c.append(a.pop(0))\n    while b:\n        c.append(b.pop(0))\n    return c\nprint merge_sortedlist(a,b)",
        "language": "Python"
      }
    ]
  },
  {
    "id": "backend-interview_README_010",
    "text": "20 前序中序求后序",
    "answer": "推荐: http://blog.csdn.net/hinyunsin/article/details/6315502",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "二叉树遍历",
      "递归算法",
      "前序遍历",
      "中序遍历",
      "后序遍历"
    ],
    "followup_points": [
      "1. 如果前序和中序遍历序列中存在重复元素，你的算法会如何处理？",
      "2. 在递归实现中，如何优化空间复杂度以避免递归栈带来的额外开销？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/编程题/README.md",
    "code_examples": [
      {
        "code": "def rebuild(pre, center):\n    if not pre:\n        return\n    cur = Node(pre[0])\n    index = center.index(pre[0])\n    cur.left = rebuild(pre[1:index + 1], center[:index])\n    cur.right = rebuild(pre[index + 1:], center[index + 1:])\n    return cur\n\ndef deep(root):\n    if not root:\n        return\n    deep(root.left)\n    deep(root.right)\n    print root.data",
        "language": "python"
      }
    ]
  },
  {
    "id": "backend-interview_Python 编程题-4_001",
    "text": "时间效率与空间效率的平衡",
    "answer": "# > 要求：只含有2、3、5因子的数是丑数，求第1500个丑数 > > 思路: 按顺序保存已知的丑数，下一个是已知丑数中某三个数乘以2，3，5中的最小值 # > 要求：求字符串中第一个只出现一次的字符 > > 思路: 使用两个hash，一个记录每个字符穿线的次数，另一个记录每个字符第一次出现的位置 # > 要求：在一个数组中，前面的数字比后面的大，就是一个逆序对，求总数 > > 思路: 归并排序,先把数组依次拆开，然后合并的时候统计逆序对数目，并排序 # > 思路: 先获取到两个链表的长度，然后长的链表先走多的几步，之后一起遍历 > > 文件thirty_seven.py中包含了设置链表公共结点的代码，可以用来测试",
    "category": "algorithm",
    "difficulty": 3,
    "tags": [
      "动态规划",
      "哈希表",
      "分治",
      "双指针",
      "链表"
    ],
    "followup_points": [
      "1. 在丑数问题中，如果内存非常有限，无法存储所有已知的丑数，你会如何优化空间效率？",
      "2. 在逆序对问题中，如果数据规模极大（比如超过10^9），归并排序的空间复杂度会成为瓶颈，你会如何调整算法来平衡时间和空间效率？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/编程题/Python 编程题-4.md",
    "code_examples": [
      {
        "code": "# coding=utf-8\n\"\"\"\n只含有2、3、5因子的数是丑数，求第1500个丑数\n按顺序保存已知的丑数，下一个是已知丑数中某三个数乘以2，3，5中的最小值\n\"\"\"\n\n\nclass Solution(object):\n    def nthUglyNumber(self, n):\n        \"\"\"\n        :type n: int\n        :rtype: int\n        \"\"\"\n        ugly = [1]\n        t2 = t3 = t5 = 0\n        while len(ugly) < n:\n            while ugly[t2] * 2 <= ugly[-1]:\n                t2 += 1\n            while ugly[t3] * 3 <= ugly[-1]:\n                t3 += 1\n            while ugly[t5] * 5 <= ugly[-1]:\n                t5 += 1\n            ugly.append(min(ugly[t2]*2, ugly[t3]*3, ugly[t5]*5))\n        return ugly[-1]\n\n\nif __name__ == '__main__':\n    print Solution().nthUglyNumber(1500)",
        "language": "python"
      },
      {
        "code": "# coding=utf-8\n\"\"\"\n求字符串中第一个只出现一次的字符\n使用两个hash，一个记录每个字符穿线的次数，另一个记录每个字符第一次出现的位置\n\"\"\"\n\n\ndef first_not_repeating_char(string):\n    if not string:\n        return -1\n    count = {}\n    loc = {}\n    for k, s in enumerate(string):\n        count[s] = count[s] + 1 if count.get(s) else 1\n        loc[s] = loc[s] if loc.get(s) else k\n    ret = float('inf')\n    for k in loc.keys():\n        if count.get(k) == 1 and loc[k] < ret:\n            ret = loc[k]\n    return ret\n\nif __name__ == '__main__':\n    test = 'abaccbdse'\n    print first_not_repeating_char(test)",
        "language": "python"
      },
      {
        "code": "# coding=utf-8\n\"\"\"\n在一个数组中，前面的数字比后面的大，就是一个逆序对，求总数\n归并排序,先把数组依次拆开，然后合并的时候统计逆序对数目，并排序\n\"\"\"\nimport copy\n\n\ndef get_inverse_pairs(nums):\n    if not nums:\n        return 0\n    start, end = 0, len(nums) - 1\n    tmp = copy.deepcopy(nums)\n    return inverse_pairs(tmp, start, end)\n\n\ndef inverse_pairs(tmp, start, end):\n    if start == end:  # 递归结束条件\n        return 0\n    mid = (end - start) / 2  # 分别对左右两边递归求值\n    left = inverse_pairs(tmp, start, start+mid)\n    right = inverse_pairs(tmp, start+mid+1, end)\n\n    count = 0  # 本次逆序对数目\n    l_right, r_right = start + mid, end\n    t = []\n    while l_right >= start and r_right >= start + mid + 1:\n        if tmp[l_right] > tmp[r_right]:\n            t.append(tmp[l_right])\n            count += (r_right - mid - start)\n            l_right -= 1\n        else:\n            t.append(tmp[r_right])\n            r_right -= 1\n    while l_right >= start:\n        t.append(tmp[l_right])\n        l_right -= 1\n    while r_right >= start+mid+1:\n        t.append(tmp[r_right])\n        r_right -= 1\n    tmp[start:end+1] = t[::-1]\n    return count + left + right\n\nif __name__ == '__main__':\n    test = [7, 5, 6, 4, 8, 1, 2, 9]\n    print get_inverse_pairs(test)",
        "language": "python"
      },
      {
        "code": "# coding=utf-8\n\"\"\"\n求两个链表的第一个公共结点\n先获取到两个链表的长度，然后长的链表先走多的几步，之后一起遍历\n\"\"\"\n\n\ndef get_first_common_node(link1, link2):\n    if not link1 or not link2:\n        return None\n    length1 = length2 = 0\n    move1, move2 = link1, link2\n    while move1:  # 获取链表长度\n        length1 += 1\n        move1 = move1.next\n    while move2:\n        length2 += 1\n        move2 = move2.next\n    while length1 > length2:  # 长链表先走多的长度\n        length1 -= 1\n        link1 = link1.next\n    while length2 > length1:\n        length2 -= 1\n        link2 = link2.next\n    while link1:  # 链表一起走\n        if link1 == link2:\n            return link1\n        link1, link2 = link1.next, link2.next\n    return None\n\n\nclass ListNode(object):\n    def __init__(self, x):\n        self.val = x\n        self.next = None\n\n\nclass Nodes(object):\n    def __init__(self, values=None):\n        self.nodes = self._set_link(values) if values else None\n\n    def get_link(self):\n        return self.nodes\n\n    def get_tail(self):\n        # 获取尾指针\n        tail = self.nodes\n        while tail.next:\n            tail = tail.next\n        return tail\n\n    def print_self(self):\n        Nodes.print_link(self.nodes)\n\n    @staticmethod\n    def print_link(link=None):\n        count = 1\n        while link:\n            if count == 1:\n                print link.val,\n            elif count % 5 == 0:\n                print '->', link.val\n            else:\n                print '->', link.val,\n            count += 1\n            link = link.next\n        print\n\n    def _set_link(self, values):\n        head = ListNode(0)\n        move = head\n        try:\n            for val in values:\n                tmp = ListNode(val)\n                move.next = tmp\n                move = move.next\n        except Exception as e:\n            print e\n        return head.next\n\nif __name__ == '__main__':\n    t1 = [1, 2, 3, 4]\n    t2 = [5, 6, 7, 8, 12]\n    t3 = [9, 10, 11]\n    node1, node2, common = Nodes(t1), Nodes(t2), Nodes(t3)\n    h1 = node1.get_link()\n    h2 = node2.get_link()\n    h3 = common.get_link()\n    tail1 = node1.get_tail()\n    tail2 = node2.get_tail()\n    tail2.next = h3  # 设置公共链表\n    tail1.next = h3\n    print get_first_common_node(h1, h2)\n    print h3",
        "language": "python"
      }
    ]
  },
  {
    "id": "backend-interview_redis-policy_000",
    "text": "volatile-ttl",
    "answer": "volatile-ttl | maxmemory-policy | 含义 |特性 | | ----- | ----- | ----- | noeviction |不淘汰 |内存超限后写命令会返回错误(如OOM, del命令除外) allkeys-lru |所有key的LRU机制 在|所有key中按照最近最少使用LRU原则剔除key，释放空间 volatile-lru |易失key的LRU |仅以设置过期时间key范围内的LRU(如均为设置过期时间，则不会淘汰) allkeys-random |所有key随机淘汰| 一视同仁，随机 volatile-random |易失Key的随机 |仅设置过期时间key范围内的随机 volatile-ttl |易失key的TTL淘汰| 按最小TTL的key优先淘汰 其中LRU(less recently used)经典淘汰算法在Redis实现中有一定优化设计，来保证内存占用与实际效果的平衡，这也体现了工程应用是空间与时间的平衡性。 > PS：值得注意的，在主从复制模式Replication下，从节点达到maxmemory时不会有任何异常日志信息，但现象为增量数据无法同步至从节点。",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "volatile-ttl",
      "maxmemory-policy",
      "LRU淘汰机制",
      "内存淘汰策略",
      "Redis内存管理"
    ],
    "followup_points": [
      "1. 在volatile-lru策略下，如果所有key都没有设置过期时间，Redis会如何处理内存超限的情况？此时会回退到noeviction策略吗？",
      "2. volatile-ttl策略在淘汰key时，是基于TTL（剩余时间）的什么排序规则（比如优先淘汰TTL最小的key）？这种策略在什么场景下比volatile-lru更适用？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-policy.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-policy_001",
    "text": "图2Approx LRU Redis 3.0 10 samples：Redis 3.0中近似LRU算法(采样值为10)",
    "answer": "图2Approx LRU Redis 3.0 10 samples：Redis 3.0中近似LRU算法(采样值为10)",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "Redis LRU",
      "近似LRU",
      "采样机制",
      "Redis 3.0",
      "内存淘汰策略"
    ],
    "followup_points": [
      "1. Redis 3.0中近似LRU算法的采样值设置为10，这个值是如何影响算法的准确性和性能的？如果采样值过大或过小，分别会对Redis的内存管理和键值淘汰策略产生哪些具体影响？",
      "2. 在Redis 3.0的近似LRU算法中，采样值为10时，Redis是如何从样本中选择淘汰键的？是否采用了随机采样或其他策略，这种选择机制是否会导致某些热点键被误淘汰？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-policy.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-policy_002",
    "text": "图3Approx LRU Redis 2.8 5 samples：Redis 2.8中近似LRU算法(采样值为5)",
    "answer": "图3Approx LRU Redis 2.8 5 samples：Redis 2.8中近似LRU算法(采样值为5)",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "Redis LRU",
      "近似LRU",
      "采样算法",
      "Redis 2.8",
      "内存淘汰策略"
    ],
    "followup_points": [
      "1. Redis 2.8中近似LRU算法采样值为5的具体实现逻辑是什么？",
      "2. 采样值5对近似LRU算法的精度和性能有何影响？是否需要根据实际场景调整采样值？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-policy.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-policy_003",
    "text": "图4Approx LRU Redis 3.0 5 samples：Redis 3.0中近似LRU算法(采样值为5)",
    "answer": "图4Approx LRU Redis 3.0 5 samples：Redis 3.0中近似LRU算法(采样值为5) 结论：",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "Redis LRU",
      "近似LRU",
      "采样淘汰",
      "Redis 3.0",
      "内存淘汰策略"
    ],
    "followup_points": [
      "1. Redis 3.0中采样值为5的近似LRU算法具体是如何选择样本的？是随机选择还是按照某种特定规则？",
      "2. 采样值的大小（如5）对近似LRU算法的准确性和性能有何影响？在什么场景下需要调整采样值？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-policy.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-policy_004",
    "text": "对比图2和图1：在3.0中采样值为10时，效果非常接近理论LRU",
    "answer": "while (mem_freed dict, db->eviction_pool); while(bestkey == NULL) { evictionPoolPopulate(dict, db->dict, db->eviction_pool); // 从后向前逐一淘汰 for (k = REDIS_EVICTION_POOL_SIZE-1; k >= 0; k--) { if (pool[k].key == NULL) continue; de = dictFind(dict,pool[k].key); // 定位目标 /* Remove the entry from the pool. */ sdsfree(pool[k].key); /* Shift all elements on its right to left. */ memmove(pool+k,pool+k+1, sizeof(pool[0])*(REDIS_EVICTION_POOL_SIZE-k-1)); /* Clear the element on the right which is empty * since we shifted one position to the left. */ pool[REDIS_EVICTION_POOL_SIZE-1].key = NULL; pool[REDIS_EVICTION_POOL_SIZE-1].idle = 0; /* If the key exists, is our pick. Otherwise it is * a ghost and we need to try the next element. */ if (de) { bestkey = dictGetKey(de); // 确定删除键 break; } else { /* Ghost... */ continue; } } } } /* volatile-ttl */ else if (server.maxmemory_policy == EDIS_MAXMEMORY_VOLATILE_TTL) {......} // 最终选定待删除键bestkey if (bestkey) { long long delta; robj *keyobj = createStringObject(bestkey,sdslenbestkey)); // 目标对象 propagateExpire(db,keyobj); latencyStartMonitor(eviction_latency); // 延迟监控开始 dbDelete(db,keyobj); // 从db删除对象 latencyEndMonitor(eviction_latency);// 延迟监控结束 latencyAddSampleIfNeeded(\"eviction-del\",iction_latency); // 延迟采样 latencyRemoveNestedEvent(latency,eviction_latency); delta -= (long long) zmalloc_used_memory(); mem_freed += delta; // 释放内存计数 server.stat_evictedkeys++; // 淘汰key计数，info中可见 notifyKeyspaceEvent(REDIS_NOTIFY_EVICTED, \"evicted\", keyobj, db->id); // 事件通知 decrRefCount(keyobj); // 引用计数更新 keys_freed++; // 避免删除较多键导致的主从延迟，在循环内同步 if (slaves) flushSlavesOutputBuffers(); } }",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "LRU",
      "Redis",
      "淘汰策略",
      "内存管理",
      "数据结构"
    ],
    "followup_points": [
      "1. 在3.0版本中，采样值为10时效果接近理论LRU，这是否意味着采样值过大会影响淘汰策略的准确性？具体影响机制是什么？",
      "2. evictionPoolPopulate函数在采样过程中如何确保样本的代表性和随机性？是否有优化空间以进一步提升采样效率？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-policy.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-policy_005",
    "text": "在LRU中，某个键很少被访问，但在刚刚被访问后其被淘汰概率很低，从而出现这类异常持续存在的缓存；相对的，其他可能被访问的键会被淘汰",
    "answer": "在LRU中，某个键很少被访问，但在刚刚被访问后其被淘汰概率很低，从而出现这类异常持续存在的缓存；相对的，其他可能被访问的键会被淘汰",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "LRU",
      "缓存淘汰策略",
      "缓存异常",
      "缓存命中率",
      "数据访问模式"
    ],
    "followup_points": [
      "1. 这种异常情况对缓存系统的整体命中率会产生怎样的具体影响？是否有量化指标可以衡量这种影响？",
      "2. 除了LRU，还有哪些缓存淘汰策略（如LFU、ARC等）能够有效缓解这类异常问题？它们的原理和适用场景有何不同？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-policy.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-policy_006",
    "text": "allkeys-lfu：所有键按LFU淘汰",
    "answer": "allkeys-lfu：所有键按LFU淘汰 LFU使用Morris counters计数器占用少量位数来评估每个对象的访问频率，并随时间更新计数器。此机制实现与近似LRU中采样类似。但与LRU不同，LFU提供明确参数来指定计数更新频率。",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "LFU",
      "Morris counters",
      "近似LRU",
      "计数器更新频率",
      "淘汰策略"
    ],
    "followup_points": [
      "1. 在allkeys-lfu策略中，Morris counters计数器的位数具体如何影响淘汰精度和内存占用？",
      "2. LFU的计数更新频率参数是否可以动态调整？如果可以，如何平衡实时性和性能开销？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-policy.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-policy_007",
    "text": "lfu-decay-time：衰减周期，单位分钟，计数器衰减的分钟数",
    "answer": "lfu-decay-time：衰减周期，单位分钟，计数器衰减的分钟数 这两个因子形成一种平衡，通过少量访问 VS 多次访问 的评价标准最终形成对键重要性的评判。 > 原文：",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "LFU",
      "缓存淘汰策略",
      "计数器衰减",
      "访问频率",
      "时间衰减"
    ],
    "followup_points": [
      "1. 在lfu-decay-time的衰减周期内，计数器的衰减是线性递减还是指数递减？具体的衰减算法是怎样的？",
      "2. 如果lfu-decay-time设置过短或过长，会对缓存命中率产生哪些具体影响？是否有实际案例或数据支持这种影响？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-policy.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_001",
    "text": "ziplist - 一种实现上类似于TLV, 但比TLV复杂的, 用于存储任意数据的有序序列的数据结构",
    "answer": "ziplist - 一种实现上类似于TLV, 但比TLV复杂的, 用于存储任意数据的有序序列的数据结构",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "ziplist",
      "数据结构",
      "TLV",
      "有序序列",
      "存储任意数据"
    ],
    "followup_points": [
      "1. ziplist在存储任意数据时，是如何解决不同类型数据（如整数、字符串）的统一存储和高效访问问题的？",
      "2. ziplist作为有序序列，其插入和删除操作的时间复杂度是多少？在什么场景下ziplist比其他数据结构（如linkedlist）更具优势？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_002",
    "text": "zipmap - 一种用于在小规模场合使用的轻量级字典结构",
    "answer": "zipmap - 一种用于在小规模场合使用的轻量级字典结构 而衔接\"底层数据结构\"与\"Value Type\"的桥梁的, 则是Redis实现的另外一种数据结构: `redisObject`. Redis中的Key与Value在表层都是一个`redisObject`实例, 故该结构有所谓的\"类型\", 即是`ValueType`. 对于每一种`Value Type`类型的`redisObject`, 其底层至少支持两种不同的底层数据结构来实现. 以应对在不同的应用场景中, Redis的运行效率, 或内存占用.",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "zipmap",
      "redisObject",
      "ValueType",
      "底层数据结构",
      "内存占用"
    ],
    "followup_points": [
      "1. 在zipmap的设计中，是如何平衡小规模场景下的内存占用与访问效率的？",
      "2. 当zipmap中的键值对数量增长到什么程度时，Redis会将其转换为其他底层数据结构（如hashtable）？转换的触发条件和具体实现是什么？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_003",
    "text": "len分别以uint8, uint16, uint32, uint64表示用户数据的长度(不包括末尾的\\0)",
    "answer": "len分别以uint8, uint16, uint32, uint64表示用户数据的长度(不包括末尾的\\0)",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "数据类型",
      "长度表示",
      "内存布局",
      "字符串处理",
      "无符号整数"
    ],
    "followup_points": [
      "1. 如果用户数据的长度超过uint8的最大值(255)，系统会如何处理这种情况？",
      "2. 选择不同长度的uint类型(len的取值范围)对内存使用和性能有什么具体影响？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_004",
    "text": "alloc分别以uint8, uint16, uint32, uint64表示整个SDS, 除过头部与末尾的\\0, 剩余的字节数.",
    "answer": "alloc分别以uint8, uint16, uint32, uint64表示整个SDS, 除过头部与末尾的\\0, 剩余的字节数.",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "SDS",
      "内存分配",
      "数据类型",
      "字节长度",
      "字符串处理"
    ],
    "followup_points": [
      "1. 在不同位宽的alloc字段下，SDS的最大可分配空间分别是多少？是否存在实际应用场景中可能触及这些上限的情况？",
      "2. 当alloc字段从较小位宽（如uint8）升级到较大位宽（如uint64）时，SDS的内存布局和内存对齐方式是否会发生变化？这种变化对性能有何影响？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_005",
    "text": "flag始终为一字节, 以低三位标示着头部的类型, 高5位未使用.",
    "answer": "flag始终为一字节, 以低三位标示着头部的类型, 高5位未使用. 当在程序中持有一个SDS实例时, 直接持有的是数据区的头指针, 这样做的用意是: 通过这个指针, 向前偏一个字节, 就能取到flag, 通过判断flag低三位的值, 能迅速判断: 头部的类型, 已用字节数, 总字节数, 剩余字节数. 这也是为什么sds类型即是char *指针类型别名的原因. 创建一个SDS实例有三个接口, 分别是:",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "数据结构设计",
      "内存布局",
      "指针偏移",
      "位操作",
      "接口封装"
    ],
    "followup_points": [
      "1. 在判断头部类型时，低三位的不同值具体对应哪些头部类型，以及这些类型的设计考虑是什么？",
      "2. 通过向前偏移一个字节获取flag的方式，在内存对齐或跨平台兼容性方面是否需要特殊处理，是否存在潜在的边界问题？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": [
      {
        "code": "// 创建一个不含数据的sds: \n//  头部    3字节 sdshdr8\n//  数据区  0字节\n//  末尾    \\0 占一字节\nsds sdsempty(void);\n// 带数据创建一个sds:\n//  头部    按initlen的值, 选择最小的头部类型\n//  数据区  从入参指针init处开始, 拷贝initlen个字节\n//  末尾    \\0 占一字节\nsds sdsnewlen(const void *init, size_t initlen);\n// 带数据创建一个sds:\n//  头部    按strlen(init)的值, 选择最小的头部类型\n//  数据区  入参指向的字符串中的所有字符, 不包括末尾 \\0\n//  末尾    \\0 占一字节\nsds sdsnew(const char *init);",
        "language": "cgo"
      }
    ]
  },
  {
    "id": "backend-interview_redis-data-structure_006",
    "text": "`sdsnewlen`用于带二进制数据创建sds实例, sdsnew用于带字符串创建sds实例. 接口返回的sds可以直接传入libc中的字符串输出函数中进行操作, 由于无论其中存储的是用户的二进制数据, 还是字符串, 其末尾都带一个\\0, 所以至少调用libc中的字符串输出函数是安全的.",
    "answer": "... /* Return ASAP if there is enough space left. */ if (avail >= addlen) return s; len = sdslen(s); sh = (char*)s-sdsHdrSize(oldtype); newlen = (len+addlen); if (newlen < SDS_MAX_PREALLOC) newlen *= 2; else newlen += SDS_MAX_PREALLOC; ...",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "sds内存管理",
      "字符串长度处理",
      "二进制数据安全",
      "内存预分配策略",
      "字符串终止符处理"
    ],
    "followup_points": [
      "1. 在`sdsnewlen`中，如果传入的二进制数据本身包含`\\0`字符，会对`sds`的长度计算和后续操作产生什么影响？",
      "2. `sdsnew`和`sdsnewlen`在处理字符串和二进制数据时，对`\\0`的插入逻辑是否有差异？如果用户数据末尾已有`\\0`，是否会重复添加？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_007",
    "text": "然后再进一步扩充, 在总体占用空间不超过阈值`SDS_MAC_PREALLOC`时, 申请空间再翻一倍. 若总体空间已经超过了阈值, 则步进增长`SDS_MAC_PREALLOC`. 这个阈值的默认值为 `1024 * 1024`",
    "answer": "然后再进一步扩充, 在总体占用空间不超过阈值`SDS_MAC_PREALLOC`时, 申请空间再翻一倍. 若总体空间已经超过了阈值, 则步进增长`SDS_MAC_PREALLOC`. 这个阈值的默认值为 `1024 * 1024` SDS也提供了接口用于移除所有未使用的内存空间. `sdsRemoveFreeSpace`, 该接口没有间接的被任何SDS其它接口调用, 即默认情况下, SDS不会自动回收预留空间. 在SDS的使用者需要节省内存时, 由使用者自行调用: 总结:",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "内存预分配",
      "空间增长策略",
      "内存阈值",
      "内存回收",
      "动态字符串"
    ],
    "followup_points": [
      "1. 为什么选择1024*1024作为`SDS_MAC_PREALLOC`的默认阈值？这个阈值是基于什么考虑设定的？",
      "2. 在什么场景下，SDS的使用者会需要主动调用`sdsRemoveFreeSpace`来回收未使用内存？这种手动管理内存的方式有什么潜在的影响？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": [
      {
        "code": "sds sdsRemoveFreeSpace(sds s);",
        "language": "cgo"
      }
    ]
  },
  {
    "id": "backend-interview_redis-data-structure_008",
    "text": "SDS除了是某些Value Type的底层实现, 也被大量使用在Redis内部, 用于替代C-Style字符串. 所以默认的创建SDS实例接口, 不分配额外的预留空间. 因为多数字符串在程序运行期间是不变的. 而对于变更数据区的API, 其内部则是调用了 sdsMakeRoomFor, 每一次扩充空间, 都会预留大量的空间. 这样做的考量是: 如果一个SDS实例中的数据被变更了, 那么很有可能会在后续发生多次变更.",
    "answer": "SDS除了是某些Value Type的底层实现, 也被大量使用在Redis内部, 用于替代C-Style字符串. 所以默认的创建SDS实例接口, 不分配额外的预留空间. 因为多数字符串在程序运行期间是不变的. 而对于变更数据区的API, 其内部则是调用了 sdsMakeRoomFor, 每一次扩充空间, 都会预留大量的空间. 这样做的考量是: 如果一个SDS实例中的数据被变更了, 那么很有可能会在后续发生多次变更.",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "SDS",
      "Redis",
      "内存管理",
      "空间预分配",
      "字符串优化"
    ],
    "followup_points": [
      "1. 在sdsMakeRoomFor中，预留空间的策略具体是如何设计的？比如预留空间的大小是按照当前容量的固定比例（如2倍）还是采用其他更复杂的算法，这种策略如何平衡内存占用和性能？",
      "2. 对于频繁变更的SDS实例，如果预留空间仍然不足导致多次扩容，Redis是否有机制来优化这种情况？比如是否记录扩容历史或采用渐进式扩容策略来减少频繁分配内存的开销？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_009",
    "text": "SDS的API内部不负责清除未使用的闲置内存空间, 因为内部API无法判断这样做的合适时机. 即便是在操作数据区的时候导致数据区占用内存减少时, 内部API也不会清除闲置内在空间. 清除闲置内存空间责任应当由SDS的使用者自行担当.",
    "answer": "SDS的API内部不负责清除未使用的闲置内存空间, 因为内部API无法判断这样做的合适时机. 即便是在操作数据区的时候导致数据区占用内存减少时, 内部API也不会清除闲置内在空间. 清除闲置内存空间责任应当由SDS的使用者自行担当.",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "内存管理",
      "API设计",
      "惰性释放",
      "Redis SDS",
      "内存优化"
    ],
    "followup_points": [
      "1. SDS的使用者通常通过哪些具体的API或机制来主动触发和执行闲置内存空间的清除操作？",
      "2. 如果使用者未能及时清除闲置内存，可能会导致哪些潜在的性能或内存管理问题？SDS是否有提供相关的监控或提示机制来帮助使用者优化内存使用？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_010",
    "text": "用SDS替代C-Style字符串时, 由于其头部额外存储了数据区的长度信息, 所以字符串的求长操作时间复杂度为O(1)",
    "answer": "用SDS替代C-Style字符串时, 由于其头部额外存储了数据区的长度信息, 所以字符串的求长操作时间复杂度为O(1)",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "SDS",
      "C-Style字符串",
      "时间复杂度",
      "O(1)",
      "求长操作"
    ],
    "followup_points": [
      "1. SDS的头部除了存储长度信息外，还可能包含哪些额外字段？这些字段分别对字符串操作有什么优化作用？",
      "2. 在SDS中，如果字符串长度频繁变化（如大量拼接或截断操作），其头部存储的长度信息如何保证高效更新，是否存在潜在的内存开销或性能瓶颈？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_011",
    "text": "由于list中的链表结点本身并不直接持有数据, 而是通过value字段, 以void *指针的形式间接持有, 所以数据的生命周期并不完全与链表及其结点一致. 这给了list的使用者相当大的灵活性. 比如可以多个结点持有同一份数据的地址. 但与此同时, 在对链表进行销毁, 结点复制以及查找匹配时, 就需要list的使用者将相关的函数指针赋值于list.dup, list.free, list.match字段.",
    "answer": "由于list中的链表结点本身并不直接持有数据, 而是通过value字段, 以void *指针的形式间接持有, 所以数据的生命周期并不完全与链表及其结点一致. 这给了list的使用者相当大的灵活性. 比如可以多个结点持有同一份数据的地址. 但与此同时, 在对链表进行销毁, 结点复制以及查找匹配时, 就需要list的使用者将相关的函数指针赋值于list.dup, list.free, list.match字段.",
    "category": "algorithm",
    "difficulty": 3,
    "tags": [
      "数据结构",
      "链表",
      "内存管理",
      "函数指针",
      "回调函数"
    ],
    "followup_points": [
      "1. 如果list的使用者没有正确设置dup、free和match函数指针，可能会导致哪些具体的内存管理问题或程序错误？",
      "2. 在多线程环境下，如果多个线程同时操作同一个链表（比如插入、删除或销毁），如何确保dup、free和match函数指针的安全性以及数据的一致性？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_012",
    "text": "dict中存储的键值对, 是通过dictEntry这个结构间接持有的, k通过指针间接持有键, v通过指针间接持有值. 注意, 若值是整数值的话, 是直接存储在v字段中的, 而不是间接持有. 同时next指针用于指向, 在bucket索引值冲突时, 以链式方式解决冲突, 指向同索引的下一个dictEntry结构.",
    "answer": "dict中存储的键值对, 是通过dictEntry这个结构间接持有的, k通过指针间接持有键, v通过指针间接持有值. 注意, 若值是整数值的话, 是直接存储在v字段中的, 而不是间接持有. 同时next指针用于指向, 在bucket索引值冲突时, 以链式方式解决冲突, 指向同索引的下一个dictEntry结构.",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "数据结构",
      "哈希表",
      "键值存储",
      "冲突解决",
      "指针应用"
    ],
    "followup_points": [
      "1. 当值是整数值时，直接存储在v字段中的具体实现方式是怎样的？v字段是如何区分整数值和其他类型的值的？",
      "2. 在解决哈希冲突的链式方式中，当链表过长时，dict是否会采取其他优化策略（如转换为红黑树）来提升查询效率？如果有，具体的转换条件和实现细节是什么？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_013",
    "text": "传统的哈希表实现, 是一块连续空间的顺序表, 表中元素即是结点. 在dictht.table中, 结点本身是散布在内存中的, 顺序表中存储的是dictEntry的指针",
    "answer": "传统的哈希表实现, 是一块连续空间的顺序表, 表中元素即是结点. 在dictht.table中, 结点本身是散布在内存中的, 顺序表中存储的是dictEntry的指针",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "哈希表",
      "顺序表",
      "指针",
      "散列",
      "内存布局"
    ],
    "followup_points": [
      "1. 在Redis的哈希表实现中，采用存储dictEntry指针而非直接存储结点的方式，对内存利用效率和缓存友好性有哪些具体影响？",
      "2. 当哈希表发生扩容或缩容时，dictht.table中存储的指针如何高效地进行重新分配和迁移，以避免频繁的内存拷贝和性能损耗？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_014",
    "text": "哈希表即是dictht结构, 其通过table字段间接的持有顺序表形式的bucket, bucket的容量存储在size字段中, 为了加速将散列值转化为bucket中的数组索引, 引入了sizemask字段, 计算指定键在哈希表中的索引时, 执行的操作类似于dict->type->hashFunction(键) & dict->ht[x].sizemask. 从这里也可以看出来, bucket的容量适宜于为2的幂次, 这样计算出的索引值能覆盖到所有bucket索引位.",
    "answer": "哈希表即是dictht结构, 其通过table字段间接的持有顺序表形式的bucket, bucket的容量存储在size字段中, 为了加速将散列值转化为bucket中的数组索引, 引入了sizemask字段, 计算指定键在哈希表中的索引时, 执行的操作类似于dict->type->hashFunction(键) & dict->ht[x].sizemask. 从这里也可以看出来, bucket的容量适宜于为2的幂次, 这样计算出的索引值能覆盖到所有bucket索引位.",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "哈希表",
      "dictht结构",
      "bucket",
      "sizemask",
      "2的幂次容量"
    ],
    "followup_points": [
      "1. 为什么哈希表的容量选择2的幂次方可以确保索引值覆盖所有bucket索引位，如果选择非2的幂次方会有什么问题？",
      "2. 在哈希表扩容或缩容时，如果新的size不再是2的幂次方，Redis如何调整sizemask和bucket结构来保证索引计算的效率？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_015",
    "text": "dict即为字典. 其中type字段中存储的是本字典使用到的各种函数指针, 包括散列函数, 键与值的复制函数, 释放函数, 以及键的比较函数. privdata是用于存储用户自定义数据. 这样, 字典的使用者可以最大化的自定义字典的实现, 通过自定义各种函数实现, 以及可以附带私有数据, 保证了字典有很大的调优空间.",
    "answer": "dict即为字典. 其中type字段中存储的是本字典使用到的各种函数指针, 包括散列函数, 键与值的复制函数, 释放函数, 以及键的比较函数. privdata是用于存储用户自定义数据. 这样, 字典的使用者可以最大化的自定义字典的实现, 通过自定义各种函数实现, 以及可以附带私有数据, 保证了字典有很大的调优空间.",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "数据结构",
      "字典",
      "函数指针",
      "自定义",
      "调优"
    ],
    "followup_points": [
      "1. 在自定义字典实现时，如何确保自定义的散列函数和键比较函数之间的逻辑一致性，以避免潜在的哈希冲突或查找错误？",
      "2. 当字典需要处理不同类型的键或值时，privdata如何与自定义的复制和释放函数协同工作，以确保内存管理的安全性和高效性？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_016",
    "text": "字典为了支持平滑扩容, 定义了ht[2]这个数组字段. 其用意是这样的:",
    "answer": "1. 一般情况下, 字典dict仅持有一个哈希表dictht的实例, 即整个字典由一个bucket实现. 2. 随着插入操作, bucket中出现冲突的概率会越来越大, 当字典中存储的结点数目, 与bucket数组长度的比值达到一个阈值(1:1)时, 字典为了缓解性能下降, 就需要扩容 3. 扩容的操作是平滑的, 即在扩容时, 字典会持有两个dictht的实例, ht[0]指向旧哈希表, ht[1]指向扩容后的新哈希表. 平滑扩容的重点在于两个策略: 4. 后续每一次的插入, 替换, 查找操作, 都插入到ht[1]指向的哈希表中 5. 每一次插入, 替换, 查找操作执行时, 会将旧表ht[0]中的一个bucket索引位持有的结点链表, 迁移到ht[1]中去. 迁移的进度保存在rehashidx这个字段中.在旧表中由于冲突而被链接在同一索引位上的结点, 迁移到新表后, 可能会散布在多个新表索引中去. 6. 当迁移完成后, ht[0]指向的旧表会被释放, 之后会将新表的持有权转交给ht[0], 再重置ht[1]指向NULL",
    "category": "algorithm",
    "difficulty": 3,
    "tags": [
      "哈希表",
      "字典",
      "平滑扩容",
      "rehash",
      "渐进式rehash"
    ],
    "followup_points": [
      "1. 在平滑扩容过程中，如果字典的插入操作非常频繁，而旧表ht[0]的迁移速度较慢，会导致ht[0]和ht[1]长期共存，这种情况下如何确保字典的性能不会因为双哈希表的存在而显著下降？",
      "2. 当字典完成扩容后，旧表ht[0]的内存是如何被释放的？是否会有内存碎片或延迟释放的问题，以及Redis如何优化这个过程？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_017",
    "text": "这种平滑扩容的优点有两个:",
    "answer": "1. 平滑扩容过程中, 所有结点的实际数据, 即dict->ht[0]->table[rehashindex]->k与dict->ht[0]->table[rehashindex]->v分别指向的实际数据, 内存地址都不会变化. 没有发生键数据与值数据的拷贝或移动, 扩容整个过程仅是各种指针的操作. 速度非常快 2. 扩容操作是步进式的, 这保证任何一次插入操作都是顺畅的, dict的使用者是无感知的. 若扩容是一次性的, 当新旧bucket容量特别大时, 迁移所有结点必然会导致耗时陡增.",
    "category": "algorithm",
    "difficulty": 1,
    "tags": [
      "Redis",
      "哈希表",
      "渐进式rehash",
      "指针操作",
      "无感知扩容"
    ],
    "followup_points": [
      "1. 在平滑扩容过程中，如果发生哈希冲突导致结点需要从ht[0]迁移到ht[1]的不同bucket时，如何保证指针操作的正确性和高效性？",
      "2. 步进式扩容虽然对用户无感知，但在高并发场景下，如何确保扩容过程中的数据一致性和线程安全性？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_018",
    "text": "intset中各字段, 包括contents中存储的数值, 都是以主机序(小端字节序)存储的. 这意味着Redis若运行在PPC这样的大端字节序的机器上时, 存取数据都会有额外的字节序转换开销",
    "answer": "intset中各字段, 包括contents中存储的数值, 都是以主机序(小端字节序)存储的. 这意味着Redis若运行在PPC这样的大端字节序的机器上时, 存取数据都会有额外的字节序转换开销",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "intset",
      "字节序",
      "小端字节序",
      "大端字节序",
      "主机序"
    ],
    "followup_points": [
      "1. 在大端字节序机器上，intset的字节序转换具体发生在哪些操作环节？转换的开销如何量化（例如，对每个元素访问的额外CPU周期）？",
      "2. Redis是否有针对大端字节序机器的优化机制（如编译时检测、运行时分支优化）来减少字节序转换开销？如果没有，为什么不采用更通用的设计（如统一存储为大端序）？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_019",
    "text": "当encoding == INTSET_ENC_INT16时, contents中以int16_t的形式存储着数值. 类似的, 当encoding == INTSET_ENC_INT32时, contents中以int32_t的形式存储着数值.",
    "answer": "当encoding == INTSET_ENC_INT16时, contents中以int16_t的形式存储着数值. 类似的, 当encoding == INTSET_ENC_INT32时, contents中以int32_t的形式存储着数值.",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "intset",
      "encoding",
      "contents",
      "int16_t",
      "int32_t"
    ],
    "followup_points": [
      "1. 当encoding从INTSET_ENC_INT16升级为INTSET_ENC_INT32时，contents中的数据是如何迁移和存储的？",
      "2. 在intset中，不同encoding的数值（如int16_t、int32_t、int64_t）是如何保证有序性和高效查找的？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_020",
    "text": "但凡有一个数值元素的值超过了int32_t的取值范围, 整个intset都要进行升级, 即所有的数值都需要以int64_t的形式存储. 显然升级的开销是很大的.",
    "answer": "但凡有一个数值元素的值超过了int32_t的取值范围, 整个intset都要进行升级, 即所有的数值都需要以int64_t的形式存储. 显然升级的开销是很大的.",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "intset",
      "数据结构升级",
      "内存开销",
      "类型转换",
      "int32_t"
    ],
    "followup_points": [
      "1. 在intset升级过程中，Redis是如何确保数据一致性和避免服务中断的？",
      "2. 如果频繁触发intset升级（例如大量大数插入和删除），是否有优化策略或替代数据结构来降低开销？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_021",
    "text": "intset中的数值是以升序排列存储的, 插入与删除的复杂度均为O(n). 查找使用二分法, 复杂度为O(log_2(n))",
    "answer": "intset中的数值是以升序排列存储的, 插入与删除的复杂度均为O(n). 查找使用二分法, 复杂度为O(log_2(n))",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "intset",
      "有序集合",
      "插入复杂度O(n)",
      "删除复杂度O(n)",
      "查找复杂度O(log n)"
    ],
    "followup_points": [
      "1. 在插入或删除操作时，intset是如何维护升序排列的？具体采用了什么算法或策略来确保有序性？",
      "2. 当intset中的数据量较大时，O(n)的插入和删除复杂度是否会影响性能？是否有优化方案（如分块、跳表等）可以降低复杂度？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_022",
    "text": "intset的代码实现中, 不预留空间, 即每一次插入操作都会调用zrealloc接口重新分配内存. 每一次删除也会调用zrealloc接口缩减占用的内存. 省是省了, 但内存操作的时间开销上升了.",
    "answer": "intset的代码实现中, 不预留空间, 即每一次插入操作都会调用zrealloc接口重新分配内存. 每一次删除也会调用zrealloc接口缩减占用的内存. 省是省了, 但内存操作的时间开销上升了.",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "intset",
      "内存管理",
      "zrealloc",
      "时间复杂度",
      "空间换时间"
    ],
    "followup_points": [
      "1. 在intset的实现中，zrealloc接口的具体实现机制是怎样的？它是如何确保内存分配和释放的高效性的？",
      "2. 考虑到频繁的内存操作可能带来的性能开销，intset是否有其他优化策略（如内存池、预分配阈值等）来平衡内存使用和性能？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_023",
    "text": "zlbytes字段的类型是uint32_t, 这个字段中存储的是整个ziplist所占用的内存的字节数",
    "answer": "zlbytes字段的类型是uint32_t, 这个字段中存储的是整个ziplist所占用的内存的字节数",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "ziplist",
      "zlbytes",
      "内存布局",
      "数据结构",
      "Redis"
    ],
    "followup_points": [
      "1. 为什么zlbytes字段选择uint32_t类型而不是更小的uint16_t或更大的uint64_t？是出于内存效率还是ziplist的预期最大容量考虑？",
      "2. zlbytes字段存储的是整个ziplist的内存占用，那么在ziplist进行扩容或缩容时（如添加/删除元素），zlbytes字段的更新机制是怎样的？是否存在性能优化措施？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_024",
    "text": "zltail字段的类型是uint32_t, 它指的是ziplist中最后一个entry的偏移量. 用于快速定位最后一个entry, 以快速完成pop等操作",
    "answer": "zltail字段的类型是uint32_t, 它指的是ziplist中最后一个entry的偏移量. 用于快速定位最后一个entry, 以快速完成pop等操作",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "ziplist",
      "zltail",
      "偏移量",
      "快速定位",
      "pop操作"
    ],
    "followup_points": [
      "1. 在ziplist发生增删操作导致最后一个entry位置变化时，zltail字段是如何被更新和维护的？",
      "2. zltail字段作为偏移量，在ziplist的内存布局中是如何与实际entry数据关联的？是否存在边界条件或特殊场景需要额外处理？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_025",
    "text": "zllen字段的类型是uint16_t, 它指的是整个ziplit中entry的数量. 这个值只占16位, 所以蛋疼的地方就来了: 如果ziplist中entry的数目小于65535, 那么该字段中存储的就是实际entry的值. 若等于或超过65535, 那么该字段的值固定为65535, 但实际数量需要一个个entry的去遍历所有entry才能得到.",
    "answer": "zllen字段的类型是uint16_t, 它指的是整个ziplit中entry的数量. 这个值只占16位, 所以蛋疼的地方就来了: 如果ziplist中entry的数目小于65535, 那么该字段中存储的就是实际entry的值. 若等于或超过65535, 那么该字段的值固定为65535, 但实际数量需要一个个entry的去遍历所有entry才能得到.",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "ziplist",
      "zllen字段",
      "uint16_t",
      "entry数量",
      "遍历计算"
    ],
    "followup_points": [
      "1. 在ziplist的设计中，为什么选择将zllen字段的最大值限制为65535，而不是采用其他更灵活的编码方式（如动态扩展或使用额外字段）来存储更大的entry数量？",
      "2. 当zllen字段达到65535时，遍历所有entry来获取实际数量的操作对ziplist的性能会有怎样的影响？在哪些典型场景下这种设计可能会成为瓶颈？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_026",
    "text": "zlend是一个终止字节, 其值为全F, 即0xff. ziplist保证任何情况下, 一个entry的首字节都不会是255",
    "answer": "zlend是一个终止字节, 其值为全F, 即0xff. ziplist保证任何情况下, 一个entry的首字节都不会是255 在画图展示entry的内存布局之前, 先讲一下entry中都存储了哪些信息:",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "ziplist",
      "entry结构",
      "终止字节",
      "内存布局",
      "首字节限制"
    ],
    "followup_points": [
      "1. ziplist中如果entry的首字节不可能是0xff，那么zlend作为终止字节是如何与其他entry区分开的？",
      "2. 在ziplist的内存布局中，zlend是否只出现在ziplist的末尾，还是会在其他位置（如entry内部）出现？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_027",
    "text": "每个entry用单独的一块区域, 存储着当前结点的类型: 所谓的类型, 包括当前结点存储的数据是什么(二进制, 还是数值), 如何编码(如果是数值, 数值如何存储, 如果是二进制数据, 二进制数据的长度)",
    "answer": "每个entry用单独的一块区域, 存储着当前结点的类型: 所谓的类型, 包括当前结点存储的数据是什么(二进制, 还是数值), 如何编码(如果是数值, 数值如何存储, 如果是二进制数据, 二进制数据的长度)",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "数据类型",
      "数据编码",
      "二进制存储",
      "数值存储",
      "元数据"
    ],
    "followup_points": [
      "1. 这种类型存储方式的具体实现细节是什么？比如，类型信息是如何编码的，是使用固定长度的标识符还是可变长度的编码？",
      "2. 当数据类型切换或动态调整时，这种存储方式如何保证高效性和一致性？是否存在额外的开销或优化机制？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_028",
    "text": "最后就是真实的数据了",
    "answer": "最后就是真实的数据了 entry的内存布局如下所示: ![](../images/668722-20180910184134043-2011419560.png) `prevlen`即是\"前一个entry所占用的字节数\", 它本身是一个变长字段, 规约如下:",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "Redis",
      "数据结构",
      "内存布局",
      "变长字段",
      "链表"
    ],
    "followup_points": [
      "1. 在entry的内存布局中，`prevlen`字段作为变长字段，其具体的编码规则是什么？不同长度的prevlen是如何通过字节来表示的？",
      "2. 当prevlen字段表示的长度超过某个阈值（如253字节）时，是否会采用额外的字节来扩展存储，这种情况下内存布局会如何变化？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_029",
    "text": "若前一个entry占用的字节数等于或大于 254, 则prevlen字段占五字节: 第一个字节值为 254, 即0xfe, 另外四个字节, 以uint32_t存储着值.",
    "answer": "若前一个entry占用的字节数等于或大于 254, 则prevlen字段占五字节: 第一个字节值为 254, 即0xfe, 另外四个字节, 以uint32_t存储着值. `encoding`字段的规约就复杂了许多",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "数据结构",
      "内存优化",
      "变长编码",
      "整数编码",
      "Redis"
    ],
    "followup_points": [
      "1. 当prevlen字段从单字节扩展到五字节时，Redis如何确保内存分配的连续性和高效性，避免频繁的内存重分配？",
      "2. 在处理prevlen字段扩展的场景下，Redis的ziplist数据结构如何平衡内存占用与访问性能，是否存在潜在的优化空间？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_030",
    "text": "若数据是二进制数据, 且二进制数据长度小于64字节(不包括64), 那么encoding占一字节. 在这一字节中, 高两位值固定为0, 低六位值以无符号整数的形式存储着二进制数据的长度. 即 00xxxxxx, 其中低六位bitxxxxxx是用二进制保存的数据长度.",
    "answer": "若数据是二进制数据, 且二进制数据长度小于64字节(不包括64), 那么encoding占一字节. 在这一字节中, 高两位值固定为0, 低六位值以无符号整数的形式存储着二进制数据的长度. 即 00xxxxxx, 其中低六位bitxxxxxx是用二进制保存的数据长度.",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "二进制编码",
      "数据长度存储",
      "位操作",
      "无符号整数",
      "固定长度字段"
    ],
    "followup_points": [
      "1. 如果二进制数据长度大于或等于64字节，encoding部分会如何设计？",
      "2. 在解码时，如何确保正确区分encoding字节和后续的二进制数据内容？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_031",
    "text": "若数据是二进制数据, 且二进制数据长度大于或等于64字节, 但小于16384(不包括16384)字节, 那么encoding占用两个字节. 在这两个字节16位中, 第一个字节的高两位固定为01, 剩余的14个位, 以小端序无符号整数的形式存储着二进制数据的长度, 即 01xxxxxx, yyyyyyyy, 其中yyyyyyyy是高八位, xxxxxx是低六位.",
    "answer": "若数据是二进制数据, 且二进制数据长度大于或等于64字节, 但小于16384(不包括16384)字节, 那么encoding占用两个字节. 在这两个字节16位中, 第一个字节的高两位固定为01, 剩余的14个位, 以小端序无符号整数的形式存储着二进制数据的长度, 即 01xxxxxx, yyyyyyyy, 其中yyyyyyyy是高八位, xxxxxx是低六位.",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "二进制编码",
      "小端序",
      "无符号整数",
      "位操作",
      "数据长度表示"
    ],
    "followup_points": [
      "1. 如果二进制数据的长度恰好是64字节或16383字节，encoding的具体存储方式是否与题目描述完全一致，是否存在边界值的特殊处理？",
      "2. 在小端序存储中，高八位和低六位的组合是否需要额外的转换步骤，或者直接按字节顺序拼接即可得到正确的长度值？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_032",
    "text": "若数据是二进制数据, 且二进制数据的长度大于或等于16384字节, 但小于2^32-1字节, 则encoding占用五个字节. 第一个字节是固定值10000000, 剩余四个字节, 按小端序uint32_t的形式存储着二进制数据的长度. 这也是ziplist能存储的二进制数据的最大长度, 超过2^32-1字节的二进制数据, ziplist无法存储.",
    "answer": "若数据是二进制数据, 且二进制数据的长度大于或等于16384字节, 但小于2^32-1字节, 则encoding占用五个字节. 第一个字节是固定值10000000, 剩余四个字节, 按小端序uint32_t的形式存储着二进制数据的长度. 这也是ziplist能存储的二进制数据的最大长度, 超过2^32-1字节的二进制数据, ziplist无法存储.",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "ziplist",
      "encoding",
      "小端序",
      "uint32_t",
      "二进制数据长度"
    ],
    "followup_points": [
      "1. 当二进制数据长度小于16384字节时，encoding字段的具体存储格式是怎样的？是否存在其他长度的划分区间及对应的编码方式？",
      "2. 在ziplist中，若存储的二进制数据长度恰好为2^32-1字节，encoding字段的五个字节会如何表示？是否存在边界值的特殊处理逻辑？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_033",
    "text": "若数据是整数值, 则encoding和data的规约如下:",
    "answer": "1. 首先, 所有存储数值的entry, 其encoding都仅占用一个字节. 并且最高两位均是11 2. 若数值取值范围位于[0, 12]中, 则encoding和data挤在同一个字节中. 即为1111 0001~1111 1101, 高四位是固定值, 低四位的值从0001至1101, 分别代表 0 ~ 12这十五个数值 3. 若数值取值范围位于[-128, -1] [13, 127]中, 则encoding == 0b 1111 1110. 数值存储在紧邻的下一个字节, 以int8_t形式编码 4. 若数值取值范围位于[-32768, -129] [128, 32767]中, 则encoding == 0b 1100 0000. 数值存储在紧邻的后两个字节中, 以小端序int16_t形式编码 5. 若数值取值范围位于[-8388608, -32769] [32768, 8388607]中, 则encoding == 0b 1111 0000. 数值存储在紧邻的后三个字节中, 以小端序存储, 占用三个字节. 6. 若数值取值范围位于[-2^31, -8388609] [8388608, 2^31 - 1]中, 则encoding == 0b 1101 0000. 数值存储在紧邻的后四个字节中, 以小端序int32_t形式编码 7. 若数值取值均不在上述范围, 但位于int64_t所能表达的范围内, 则encoding == 0b 1110 0000, 数值存储在紧邻的后八个字节中, 以小端序int64_t形式编码",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "数据编码",
      "位运算",
      "数值范围判断",
      "内存布局",
      "数据压缩"
    ],
    "followup_points": [
      "1. 对于encoding最高两位均为11的设计，是否考虑过其他编码方式（如最高两位为10或01）来区分不同数值范围？这种设计在扩展性或兼容性上是否有潜在优势？",
      "2. 在数值范围位于[-128, -1] [13, 127]时，为何选择encoding为0b11111110而非其他值（如0b11111100）？这种选择是否与后续字节解析的效率或边界条件处理有关？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_034",
    "text": "和intset一样, ziplist也不预留内存空间, 并且在移除结点后, 也是立即缩容, 这代表每次写操作都会进行内存分配操作.",
    "answer": "和intset一样, ziplist也不预留内存空间, 并且在移除结点后, 也是立即缩容, 这代表每次写操作都会进行内存分配操作.",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "ziplist",
      "内存管理",
      "写操作",
      "内存分配",
      "立即缩容"
    ],
    "followup_points": [
      "1. 这种频繁的内存分配操作对Redis的写性能和内存碎片化有什么具体影响？",
      "2. 在高并发写场景下，ziplist的这种设计是否会导致性能瓶颈？Redis是否有其他优化机制来缓解这个问题？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_035",
    "text": "ziplist最蛋疼的一个问题是: 结点如果扩容, 导致结点占用的内存增长, 并且超过254字节的话, 可能会导致链式反应: 其后一个结点的entry.prevlen需要从一字节扩容至五字节. 最坏情况下, 第一个结点的扩容, 会导致整个ziplist表中的后续所有结点的entry.prevlen字段扩容. 虽然这个内存重分配的操作依然只会发生一次, 但代码中的时间复杂度是o(N)级别, 因为链式扩容只能一步一步的计算. 但这种情况的概率十分的小, 一般情况下链式扩容能连锁反映五六次就很不幸了. 之所以说这是一个蛋疼问题, 是因为, 这样的坏场景下, 其实时间复杂度并不高: 依次计算每个entry新的空间占用, 也就是o(N), 总体占用计算出来后, 只执行一次内存重分配, 与对应的memmove操作, 就可以了. 蛋疼说的是: 代码特别难写, 难读. 下面放一段处理插入结点时处理链式反应的代码片断, 大家自行感受一下:",
    "answer": "size_t curlen = intrev32ifbe(ZIPLIST_BYTES(zl)), reqlen; unsigned int prevlensize, prevlen = 0; size_t offset; int nextdiff = 0; unsigned char encoding = 0; long long value = 123456789; /* initialized to avoid warning. Using a value that is easy to see if for some reason we use it uninitialized. */ zlentry tail; /* Find out prevlen for the entry that is inserted. */ if (p[0] != ZIP_END) { ZIP_DECODE_PREVLEN(p, prevlensize, prevlen); } else { unsigned char *ptail = ZIPLIST_ENTRY_TAIL(zl); if (ptail[0] != ZIP_END) { prevlen = zipRawEntryLength(ptail); } } /* See if the entry can be encoded */ if (zipTryEncoding(s,slen,&value,&encoding)) { /* 'encoding' is set to the appropriate integer encoding */ reqlen = zipIntSize(encoding); } else { /* 'encoding' is untouched, however zipStoreEntryEncoding will use the * string length to figure out how to encode it. */ reqlen = slen; } /* We need space for both the length of the previous entry and * the length of the payload. */ reqlen += zipStorePrevEntryLength(NULL,prevlen); reqlen += zipStoreEntryEncoding(NULL,encoding,slen); /* When the insert position is not equal to the tail, we need to * make sure that the next entry can hold this entry's length in * its prevlen field. */ int forcelarge = 0; nextdiff = (p[0] != ZIP_END) ? zipPrevLenByteDiff(p,reqlen) : 0; if (nextdiff == -4 && reqlen rawlensize) { /* This would result in shrinking, which we want to avoid. * So, set \"rawlen\" in the available bytes. */ zipStorePrevEntryLengthLarge(p+rawlen,rawlen); } else { zipStorePrevEntryLength(p+rawlen,rawlen); } /* Stop here, as the raw length of \"next\" has not changed. */ break; } } return zl;",
    "category": "system",
    "difficulty": 5,
    "tags": [
      "ziplist",
      "内存重分配",
      "链式扩容",
      "entry.prevlen",
      "时间复杂度"
    ],
    "followup_points": [
      "1. 在ziplist的链式扩容场景中，代码如何确保在遍历计算新空间占用时，能准确处理每个结点的entry.prevlen字段从1字节扩容至5字节的情况，避免中间状态的数据不一致？",
      "2. 除了插入操作，删除结点时是否也会触发类似的链式扩容问题？如果存在，Redis是如何优化或避免这种连锁反应的？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_036",
    "text": "quicklistNode, 宏观上, quicklist是一个链表, 这个结构描述的就是链表中的结点. 它通过zl字段持有底层的ziplist. 简单来讲, 它描述了一个ziplist实例",
    "answer": "quicklistNode, 宏观上, quicklist是一个链表, 这个结构描述的就是链表中的结点. 它通过zl字段持有底层的ziplist. 简单来讲, 它描述了一个ziplist实例",
    "category": "algorithm",
    "difficulty": 1,
    "tags": [
      "quicklistNode",
      "ziplist",
      "链表",
      "数据结构",
      "Redis"
    ],
    "followup_points": [
      "1. quicklistNode中的zl字段指向的ziplist实例，在内存布局上是如何与quicklistNode本身关联的？是否存在额外的内存管理开销？",
      "2. 当quicklistNode持有的ziplist实例过大或过小时，Redis是否会自动进行ziplist的分裂或合并？这种操作对quicklistNode的结构有何影响？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_037",
    "text": "quicklistLZF, ziplist是一段连续的内存, 用LZ4算法压缩后, 就可以包装成一个quicklistLZF结构. 是否压缩quicklist中的每个ziplist实例是一个可配置项. 若这个配置项是开启的, 那么quicklistNode.zl字段指向的就不是一个ziplist实例, 而是一个压缩后的quicklistLZF实例",
    "answer": "quicklistLZF, ziplist是一段连续的内存, 用LZ4算法压缩后, 就可以包装成一个quicklistLZF结构. 是否压缩quicklist中的每个ziplist实例是一个可配置项. 若这个配置项是开启的, 那么quicklistNode.zl字段指向的就不是一个ziplist实例, 而是一个压缩后的quicklistLZF实例",
    "category": "algorithm",
    "difficulty": 3,
    "tags": [
      "quicklist",
      "ziplist",
      "LZ4",
      "quicklistLZF",
      "内存压缩"
    ],
    "followup_points": [
      "1. 在Redis中，quicklist的压缩配置项是如何具体控制的，是通过配置参数还是其他方式？",
      "2. 当quicklistNode.zl字段指向压缩后的quicklistLZF实例时，Redis在访问数据时是如何解压的，对性能有何影响？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_038",
    "text": "quicklist. 这就是一个双链表的定义. head, tail分别指向头尾指针. len代表链表中的结点. count指的是整个quicklist中的所有ziplist中的entry的数目. fill字段影响着每个链表结点中ziplist的最大占用空间, compress影响着是否要对每个ziplist以LZ4算法进行进一步压缩以更节省内存空间.",
    "answer": "quicklist. 这就是一个双链表的定义. head, tail分别指向头尾指针. len代表链表中的结点. count指的是整个quicklist中的所有ziplist中的entry的数目. fill字段影响着每个链表结点中ziplist的最大占用空间, compress影响着是否要对每个ziplist以LZ4算法进行进一步压缩以更节省内存空间.",
    "category": "algorithm",
    "difficulty": 1,
    "tags": [
      "数据结构",
      "双链表",
      "ziplist",
      "内存优化",
      "LZ4压缩"
    ],
    "followup_points": [
      "1. 在quicklist的设计中，fill字段和compress字段的具体取值范围是什么？它们对内存占用和性能的影响是如何权衡的？",
      "2. 当quicklist中的ziplist因数据插入或删除而达到或超过fill限制时，Redis会如何进行ziplist的分裂或合并操作？这个过程的时间复杂度是多少？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_039",
    "text": "quicklistEntry是对ziplist中的entry概念的封装. quicklist作为一个封装良好的数据结构, 不希望使用者感知到其内部的实现, 所以需要把ziplist.entry的概念重新包装一下.",
    "answer": "1. -1 不超过4kb 2. -2 不超过 8kb 3. -3 不超过 16kb 4. -4 不超过 32kb 5. -5 不超过 64kb 6. 当数值为正数时, 代表以entry数目限制单个ziplist的长度. 值即为数目. 由于该字段仅占16位, 所以以entry数目限制ziplist的容量时, 最大值为2^15个 1. 0 表示不压缩, zl字段直接指向ziplist 2. 1 表示quicklist的链表头尾结点不压缩, 其余结点的zl字段指向的是经过压缩后的quicklistLZF 3. 2 表示quicklist的链表头两个, 与末两个结点不压缩, 其余结点的zl字段指向的是经过压缩后的quicklistLZF 4. 以此类推, 最大值为2^16",
    "category": "redis",
    "difficulty": 2,
    "tags": [
      "quicklist",
      "ziplist",
      "数据结构封装",
      "压缩策略",
      "内存限制"
    ],
    "followup_points": [
      "1. 在选择压缩级别（-1到-5）时，除了考虑单个ziplist的大小限制，是否还需要权衡压缩/解压缩的开销对整体性能的影响？",
      "2. 当使用entry数目限制ziplist容量时（正数值），为什么选择2^15作为最大值而非2^16？是否存在内存对齐或数据结构设计的特殊考量？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_040",
    "text": "键值均是二进制数据, 而不是复合结构或复杂结构. dict支持各种嵌套, 字典本身并不持有数据, 而仅持有数据的指针. 但zipmap是直接持有数据的.",
    "answer": "键值均是二进制数据, 而不是复合结构或复杂结构. dict支持各种嵌套, 字典本身并不持有数据, 而仅持有数据的指针. 但zipmap是直接持有数据的. zipmap的定义与实现在src/zipmap.h与src/zipmap.c两个文件中, 其定义与实现均未定义任何struct结构体, 因为zipmap的内存布局就是一块连续的内存空间. 其内存布局如下所示: ![](../images/668722-20180910184223910-1797391394.png)",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "数据结构",
      "内存布局",
      "指针",
      "二进制数据",
      "zipmap"
    ],
    "followup_points": [
      "1. 在zipmap的连续内存布局中，键和值的长度是如何存储和解析的？是否存在长度限制或优化策略？",
      "2. 当zipmap中的键值对频繁增删时，其连续内存布局如何处理碎片化问题？是否需要重新整理内存？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_041",
    "text": "zipmap起始的第一个字节存储的是zipmap中键值对的个数. 如果键值对的个数大于254的话, 那么这个字节的值就是固定值254, 真实的键值对个数需要遍历才能获得.",
    "answer": "zipmap起始的第一个字节存储的是zipmap中键值对的个数. 如果键值对的个数大于254的话, 那么这个字节的值就是固定值254, 真实的键值对个数需要遍历才能获得.",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Redis数据结构",
      "zipmap实现",
      "内存优化",
      "键值对存储",
      "数据遍历"
    ],
    "followup_points": [
      "1. 当zipmap中键值对个数超过254时，为什么设计为固定值254而不是直接使用更大的数据类型（如uint16_t）来存储？",
      "2. 遍历zipmap获取真实键值对个数时，具体的遍历逻辑是怎样的？是否存在性能优化的空间？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-data-structure_042",
    "text": "zipmap中的每一个键值对, 称为一个entry, 其内存占用如上图, 分别六部分:",
    "answer": "1. len_of_key, 一字节或五字节. 存储的是键的二进制长度. 如果长度小于254, 则用1字节存储, 否则用五个字节存储, 第一个字节的值固定为0xFE, 后四个字节以小端序uint32_t类型存储着键的二进制长度. 2. key_data为键的数据 3. len_of_val, 一字节或五字节, 存储的是值的二进制长度. 编码方式同len_of_key 4. len_of_free, 固定值1字节, 存储的是entry中未使用的空间的字节数. 未使用的空间即为图中的free, 它一般是由于键值对中的值被替换发生的. 比如, 键值对hello word被修改为hello w后, 就空了四个字节的闲置空间 5. val_data, 为值的数据 6. free, 为闲置空间. 由于len_of_free的值最大只能是254, 所以如果值的变更导致闲置空间大于254的话, zipmap就会回收内存空间.",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "数据结构",
      "内存管理",
      "编码方式",
      "小端序",
      "键值对存储"
    ],
    "followup_points": [
      "1. 当entry中的值被替换导致产生未使用的空间（free）时，zipmap是如何管理和回收这些空间的？是直接复用还是会在后续操作中通过压缩等方式清理？",
      "2. 如果zipmap中存在大量entry因值替换而产生碎片化的未使用空间，这种内存碎片化是否会影响zipmap的整体性能？是否有优化机制来减少这种碎片化？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-data-structure.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-rdb_000",
    "text": "AOF：记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据。",
    "answer": "AOF：记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据。 本文将通过下面内容的介绍，希望能够让大家更全面、清晰的认识这两种持久化方式，同时理解这种保存数据的思路，应用于自己的系统设计中。",
    "category": "redis",
    "difficulty": 1,
    "tags": [
      "AOF持久化",
      "数据恢复",
      "写操作记录",
      "服务器重启",
      "命令重执行"
    ],
    "followup_points": [
      "1. AOF记录写操作时，具体是记录哪些命令类型（如SET、DEL、LPUSH等）？是否所有写操作都会被记录？",
      "2. AOF在服务器重启重新执行命令恢复数据时，如果命令文件非常大，恢复过程是否会存在性能瓶颈？是否有优化机制（如AOF重写）来解决这个问题？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-rdb.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-rdb_001",
    "text": "save 900 1 表示900s内如果有1条是写入命令，就触发产生一次快照，可以理解为就进行一次备份",
    "answer": "save 900 1 表示900s内如果有1条是写入命令，就触发产生一次快照，可以理解为就进行一次备份",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "Redis持久化",
      "RDB快照",
      "save配置",
      "自动备份",
      "内存数据库"
    ],
    "followup_points": [
      "1. 除了 save 900 1 这种配置，Redis 还支持哪些类似的 save 配置项，它们各自的使用场景是什么？",
      "2. 如果同时配置了多个 save 规则（如 save 900 1 和 save 300 10），Redis 的快照触发机制是怎样的？会优先满足哪个规则？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-rdb.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-rdb_002",
    "text": "save 300 10 表示300s内有10条写入，就产生快照",
    "answer": "save 300 10 表示300s内有10条写入，就产生快照 下面的类似，那么为什么需要配置这么多条规则呢？因为Redis每个时段的读写请求肯定不是均衡的，为了平衡性能与数据安全，我们可以自由定制什么情况下触发备份。所以这里就是根据自身Redis写入情况来进行合理配置。 `stop-writes-on-bgsave-error yes` 这个配置也是非常重要的一项配置，这是当备份进程出错时，主进程就停止接受新的写入操作，是为了保护持久化的数据一致性问题。如果自己的业务有完善的监控系统，可以禁止此项配置， 否则请开启。 关于压缩的配置 `rdbcompression yes` ，建议没有必要开启，毕竟Redis本身就属于CPU密集型服务器，再开启压缩会带来更多的CPU消耗，相比硬盘成本，CPU更值钱。 当然如果你想要禁用RDB配置，也是非常容易的，只需要在save的最后一行写上：`save \"\"`",
    "category": "redis",
    "difficulty": 2,
    "tags": [
      "Redis持久化配置",
      "RDB快照触发条件",
      "数据一致性保护",
      "bgsave错误处理",
      "RDB压缩优化"
    ],
    "followup_points": [
      "1. 如果业务写入请求在某个时段突然激增，远超配置的save规则阈值，会对Redis性能产生哪些具体影响，又该如何优化配置来应对这种情况？",
      "2. 在开启`stop-writes-on-bgsave-error yes`的情况下，如果备份进程频繁出错导致写入被阻塞，有哪些排查和解决思路来平衡数据安全与业务可用性？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-rdb.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-rdb_003",
    "text": "no：redis不处理交给OS来处理，非常快，但是也最不安全",
    "answer": "no：redis不处理交给OS来处理，非常快，但是也最不安全 一般情况下都采用 `everysec` 配置，这样可以兼顾速度与安全，最多损失1s的数据。 `aof-load-truncated yes` 如果该配置启用，在加载时发现aof尾部不正确是，会向客户端写入一个log，但是会继续执行，如果设置为 `no` ，发现错误就会停止，必须修复后才能重新加载。",
    "category": "redis",
    "difficulty": 1,
    "tags": [
      "Redis持久化",
      "AOF配置",
      "everysec",
      "aof-load-truncated",
      "数据安全"
    ],
    "followup_points": [
      "1. 在什么场景下会优先选择 `no` 配置（即完全交给OS处理），即使知道它最不安全？",
      "2. 如果 `everysec` 配置下最多损失1秒数据，那对于对数据一致性要求极高的业务（如金融交易），是否有更安全的替代方案或优化措施？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-rdb.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-rdb_004",
    "text": "bgsave：该触发方式会fork一个子进程，由子进程负责持久化过程，因此阻塞只会发生在fork子进程的时候。",
    "answer": "bgsave：该触发方式会fork一个子进程，由子进程负责持久化过程，因此阻塞只会发生在fork子进程的时候。",
    "category": "system",
    "difficulty": 2,
    "tags": [
      "Redis持久化",
      "bgsave",
      "fork",
      "子进程",
      "阻塞"
    ],
    "followup_points": [
      "1. 在fork子进程时，主线程具体会阻塞哪些操作，阻塞时间长短通常受哪些因素影响？",
      "2. 子进程完成持久化后，主线程如何感知并处理子进程的结束状态（如成功或失败）？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-rdb.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-rdb_005",
    "text": "执行  shutdown时，如果没有开启aof，也会触发。",
    "answer": "执行 shutdown时，如果没有开启aof，也会触发。 由于 save 基本不会被使用到，我们重点看看 bgsave 这个命令是如何完成RDB的持久化的。 ![](../images/16530eac18882d66.jpg) 这里注意的是 fork 操作会阻塞，导致Redis读写性能下降。我们可以控制单个Redis实例的最大内存，来尽可能降低Redis在fork时的事件消耗。以及上面提到的自动触发的频率减少fork次数，或者使用手动触发，根据自己的机制来完成持久化。",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "RDB持久化",
      "bgsave命令",
      "fork操作",
      "内存控制",
      "手动触发"
    ],
    "followup_points": [
      "1. 在执行 shutdown 触发 bgsave 时，如果 Redis 实例内存占用过大，除了控制最大内存外，还有哪些优化策略可以减少 fork 操作的性能影响？",
      "2. 如果 Redis 同时配置了 RDB 和 AOF，在 shutdown 时会优先触发哪种持久化方式？两者是否会同时执行，如何保证数据一致性？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-rdb.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-rdb_006",
    "text": "合理配置Linux的内存分配策略，避免因为物理内存不足导致fork失败。",
    "answer": "合理配置Linux的内存分配策略，避免因为物理内存不足导致fork失败。 在线上我们到底该怎么做？我提供一些自己的实践经验。",
    "category": "system",
    "difficulty": 3,
    "tags": [
      "Linux内存管理",
      "fork系统调用",
      "OOM Killer",
      "overcommit_memory",
      "swap空间配置"
    ],
    "followup_points": [
      "1. 在配置内存分配策略时，如何根据业务场景（如高并发、大数据处理）调整overcommit_memory和overcommit_ratio参数的具体值？",
      "2. 除了调整内核参数外，线上环境中如何结合cgroups或systemd等工具对进程的内存使用进行精细化限制，避免单个进程过度消耗内存导致fork失败？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-rdb.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-rdb_007",
    "text": "如果Redis中的数据并不是特别敏感或者可以通过其它方式重写生成数据，可以关闭持久化，如果丢失数据可以通过其它途径补回；",
    "answer": "如果Redis中的数据并不是特别敏感或者可以通过其它方式重写生成数据，可以关闭持久化，如果丢失数据可以通过其它途径补回；",
    "category": "redis",
    "difficulty": 1,
    "tags": [
      "Redis持久化",
      "数据持久化策略",
      "数据恢复机制",
      "数据敏感性评估",
      "高可用性"
    ],
    "followup_points": [
      "1. 在实际生产环境中，如何判断Redis中的数据是否属于\"可以通过其它方式重写生成\"的类型？需要满足哪些具体条件？",
      "2. 如果关闭持久化，如何设计数据补回机制？是否需要引入外部工具（如消息队列、定时任务）来确保数据一致性？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-rdb.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-rdb_008",
    "text": "单机如果部署多个实例，要防止多个机器同时运行持久化、重写操作，防止出现内存、CPU、IO资源竞争，让持久化变为串行；",
    "answer": "单机如果部署多个实例，要防止多个机器同时运行持久化、重写操作，防止出现内存、CPU、IO资源竞争，让持久化变为串行；",
    "category": "system",
    "difficulty": 3,
    "tags": [
      "单机多实例部署",
      "持久化操作",
      "重写操作",
      "资源竞争",
      "串行化处理"
    ],
    "followup_points": [
      "1. 在单机多实例场景下，具体是通过什么机制（如文件锁、进程间通信或分布式锁）来确保持久化和重写操作的串行执行？",
      "2. 如果某个实例的持久化或重写操作因异常（如磁盘故障）长时间阻塞，是否有超时或中断机制来避免影响其他实例的正常运行？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-rdb.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-rdb_009",
    "text": "RDB持久化与AOF持久化可以同时存在，配合使用。",
    "answer": "RDB持久化与AOF持久化可以同时存在，配合使用。 > 作者：大愚Talk > 链接：https://juejin.im/post/5b70dfcf518825610f1f5c16 > 来源：掘金 > 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。",
    "category": "redis",
    "difficulty": 2,
    "tags": [
      "Redis持久化",
      "RDB持久化",
      "AOF持久化",
      "持久化策略",
      "数据备份与恢复"
    ],
    "followup_points": [
      "1. 当同时启用RDB和AOF持久化时，Redis在数据恢复时会优先使用哪种持久化文件，为什么这样设计？",
      "2. 同时使用RDB和AOF是否会增加磁盘I/O压力，有哪些优化策略可以减少对性能的影响？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-rdb.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-master-slave_000",
    "text": "一、什么是Redis主从复制？",
    "answer": "主从复制就是现在有俩台redis服务器，把一台redis的数据同步到另一台redis数据库上。前者称之为主节点（master），后者为从节点（slave）。数据是只能master往slave同步单向。 但是在实际过程中是不可能只有俩台redis服务器来做主从复制的，这也就意味这每台redis服务器都有可能会称为主节点（master） 下图案例中，我们的slave3既是master的从节点，也是slave的主节点。 先知道这么个概念，更多详解继续查看下文。 ![](../images/af2760bc01cc4da6808cd34087b7176a.jpeg)",
    "category": "redis",
    "difficulty": 1,
    "tags": [
      "Redis主从复制",
      "主从架构",
      "数据同步",
      "单向复制",
      "级联复制"
    ],
    "followup_points": [
      "1. 在Redis主从复制中，主从节点之间的数据同步具体是如何实现的？同步过程中如果主节点宕机，从节点如何处理？",
      "2. 当从节点同时作为其他从节点的主节点（如案例中的slave3）时，这种级联复制对整体性能和数据一致性有哪些影响？如何优化这种架构？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-master-slave.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-master-slave_001",
    "text": "二、为什么需要Redis主从复制？",
    "answer": "假设我们现在就一台redis服务器，也就是单机状态。 在这种情况下会出现的第一个问题就是服务器宕机，直接导致数据丢失。如果项目是跟￥占关系的，那造成的后果就可想而知。 第二个情况就是内存问题了，当只有一台服务器时内存肯定会到达峰值的，不可能对一台服务器进行无限升级的。 ![](../images/b781d9b31ebd4b718de3083cf036fa4b.jpeg) 所以针对以上俩个问题，我们就多准备几台服务器，配置主从复制。将数据保存在多个服务器上。并且保证每个服务器的数据是同步的。即使有一个服务器宕机了，也不会影响用户的使用。redis可以继续实现高可用、同时实现数据的冗余备份。 这会应该会有很多疑问，master跟slave怎么连接呢？ 如何同步数据呢？ 假如master服务器宕机了呢？别着急，一点一点解决你的问题。 ![](../images/6289b6c04279481789a6459dc8da2cb1.jpeg)",
    "category": "redis",
    "difficulty": 2,
    "tags": [
      "高可用",
      "数据备份",
      "负载均衡",
      "数据同步",
      "容灾"
    ],
    "followup_points": [
      "1. 在Redis主从复制架构中，主从节点之间的数据同步是如何实现的？如果主节点在数据同步过程中宕机，从节点的数据是否会丢失，如何保证数据的一致性？",
      "2. Redis主从复制架构中，如果主节点写入大量数据，从节点如何处理复制延迟的问题？是否有机制可以优化或监控这种延迟？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-master-slave.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-master-slave_002",
    "text": "三、Redis主从复制的作用",
    "answer": "在上边我们说了为什么使用redis的主从复制，那么主从复制的作用就是针对为什么使用它来讲了。 我们继续使用这个图来谈论 - 第一点是数据冗余了，实现了数据的热备份，是持久化之外的另一种方式。 - 第二点是针对单机故障问题。当主节点也就是master出现问题时，可以由从节点来提供服务也就是slave，实现了快速恢复故障，也就是服务冗余。 - 第三点是读写分离，master服务器主要是写，slave主要用来读数据，可以提高服务器的负载能力。同时可以根据需求的变化，添加从节点的数量。 - 第四点是负载均衡，配合读写分离，有主节点提供写服务，从节点提供读服务，分担服务器负载，尤其在写少读多的情况下，通过多个从节点分担读负载，可以大大提高redis服务器的并发量和负载。 - 第五点是高可用的基石，主从复制是哨兵和集群能够实施的基础，因此我们可以说主从复制是高可用的基石。 ![](../images/11b30c167de447ffad6d1ab741f921f6.jpeg)",
    "category": "redis",
    "difficulty": 2,
    "tags": [
      "数据冗余",
      "故障转移",
      "读写分离",
      "负载均衡",
      "高可用"
    ],
    "followup_points": [
      "1. 在实现读写分离时，如果从节点的数量增加，如何保证从节点数据的一致性和同步延迟问题？",
      "2. 当主节点故障时，从节点如何自动选举成为新的主节点？这个过程需要人工干预吗？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-master-slave.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-master-slave_003",
    "text": "四、配置Redis主从复制",
    "answer": "说了这么多，我们先简单的配置一个主从复制案例，然后在谈实现的原理。 redis存储路径为：usr/local/redis 日志跟配置文件存储在：usr/local/redis/data 首先我们先配置俩个配置文件，分别为redis6379.conf 和 redis6380.conf ![](../images/9823874fa8364612b5a4bdf90b705c4c.jpeg) 修改配置文件，主要就是修改端口。为了查看方便在把日志文件和持久化文件的名字都用各自的端口来做标识。 ![](../images/94dee06ef9b64c118916593c0a47f40e.jpeg) 然后分别开启俩个redis服务，一个端口为6379，一个端口为6380。执行命令redis-server redis6380.conf,然后使用redis-cli -p 6380连接，因为redis的默认端口就是6379所以我们启动另外一台redis服务器直接使用redis-server redis6379.conf 然后直接使用redis-cli直接连接就可以。 ![](../images/cc285906b45845efa6a5193ec1747ce0.jpeg) 这个时候我们就成功的配置了俩个redis服务，一台为6380，一台为6379，这里只是为了演示。实际工作中是需要配置在俩台不同的服务器的。 ![](../images/745a5d13ff6a4dbc89e287f3188ca111.jpeg) # 我们先得有一个概念，就是在配置主从复制时，所有的操作都是在从节点来操作，也就是slave。 那么我们在从节点执行一个命令为 slaveof 127.0.0.1 6379，执行完就代表我们连接上了。 ![](../images/789513781c64485b9130dc239706fbbf.jpeg) 我们先测试一下看是否实现主从复制。在master这台服务器上执行俩个set kaka 123 和 set master 127.0.0.1，然后在slave6380端口是可以成功获取到的，也就说明我们的主从复制就已经配置完成了。但是在实现生产环境可不是就这样完事了，后边会在进一步对主从复制进行优化，直到实现高可用。 ![](../images/a4d3cb957f3f4b35b280118bb129fe58.jpeg) # 在使用配置文件启动主从复制之前呢！先需要把之前使用客户端命令行连接的断开，在从主机执行slaveof no one即可断开主从复制。 ![](../images/fd9f917bf17e43d5b7d01ed513e05635.jpeg) 在哪可以查看从节点已经断开了主节点呢！在主节点的客户端输入命令行info查看 这张图是使用从节点使用客户端命令行连接主节点后，在主节点的客户端输入info打印的信息，可以看到有一个slave0的一个信息。 ![](../images/a2e38eaa9f0541769c7569abffe6da48.jpeg) 这个图是在从节点执行完slaveof no one 后，在主节点打印的info，说明从节点已经跟主节点断开连接了。 ![](../images/dab19075906049dfa6156de45a8bdc1e.jpeg) 在根据配置文件启动redis服务，redis-server redis6380.conf 当在从节点重新启动后就可以在主节点直接查看到从节点的连接信息。 ![](../images/d33af09c79c04875b884f51b0c752eeb.jpeg) 测试数据，主节点写的东西，从节点还是会自动同步的。 ![](../images/5a043effdcc54f7bb67e3fa13fcbb2cc.jpeg) # 这种方式配置也是很简单，在启动redis服务器时直接就启动主从复制，执行命令：redis-server --slaveof host port 即可。 # 这个是主节点的日志信息 ![](../images/b68dbf0d64844cf8ab83fca534b04e4a.jpeg) 这个是从节点的信息，其中有连接主节点信息，还有RDB快照保存。 ![](../images/1d905286e19f4a3b960d596b184fa8d5.jpeg)",
    "category": "redis",
    "difficulty": 2,
    "tags": [
      "Redis主从复制",
      "配置文件修改",
      "端口配置",
      "持久化文件",
      "日志文件"
    ],
    "followup_points": [
      "1. 在配置主从复制时，如果主从节点的网络不稳定导致复制中断，Redis是如何处理断线重连的？",
      "2. 主从复制中，如果主节点发生故障，是否有自动切换机制（如哨兵或集群模式）来保证服务的可用性？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-master-slave.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-master-slave_004",
    "text": "五、主从复制工作原理",
    "answer": "# 主从复制完整的工作流程分为以下三个阶段。每一段都有自己的内部工作流程，那么我们会对这三个过程进行谈论。 - 建立连接过程：这个过程就是slave跟master连接的过程 - 数据同步过程：是master给slave同步数据的过程 - 命令传播过程：是反复同步数据 ![](../images/1727327958931dbc.jpg) # ![](../images/17188139b47a27ca.jpg) 上图是一个完整主从复制建立连接工作流程。然后使用简短的话语来描述上边的工作流程。 1. 设置master的地址和端口，保存master的信息 2. 建立socket连接（这个连接做的事情下文会说） 3. 持续发送ping命令 4. 身份验证 5. 发送slave端口信息 在建立连接的过程中，从节点会保存master的地址和端口、主节点master保存从节点slave的端口。 # ![](../images/17273279684debb7.jpg) 这张图是详细描述第一次从节点连接主节点时的数据同步过程。 当从节点第一次连接主节点时，先会执行一次全量复制这次的全量复制是无法避免的。 全量复制执行完成后，主节点就会发送复制积压缓冲区的数据，然后从节点就会执行bgrewriteaof恢复数据，这也就是部分复制。 在这个阶段提到了三个新点，全量复制、部分复制、复制缓冲积压区。会在下文的常见问题里详细说明这几个点。 # 当master数据库被修改后，主从服务器的数据不一致后，此时就会让主从数据同步到一致，这个过程称之为命令传播。 master会将接收到的数据变更命令发送给slave，slave接收命令后执行命令，让主从数据达到一致。 命令传播阶段的部分复制 - 在命令传播阶段出现断网的情况，或者网络抖动时会导致连接断开（connection lost） - 这个时候主节点master还是会继续往replbackbuffer（复制缓冲积压区）写数据 - 从节点会继续尝试连接主机（connect to master） - 当从节点把自己的runid和复制偏移量发送给主节点，并且执行pysnc命令同步 - 如果master判断偏移量是在复制缓冲区范围内，就会返回continue命令。并且发送复制缓冲区的数据给从节点。 - 从节点接收数据执行bgrewriteaof，恢复数据",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "主从复制",
      "数据同步",
      "命令传播",
      "连接建立",
      "工作流程"
    ],
    "followup_points": [
      "1. 在建立连接过程中，如果master设置了密码认证，slave是如何安全地完成认证的？",
      "2. 数据同步过程中，全量同步和增量同步的触发条件分别是什么，如何避免不必要的全量同步？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-master-slave.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-master-slave_005",
    "text": "六. 详细介绍主从复制原理（全量复制+部分复制）",
    "answer": "![](../images/1727327968bf0895.jpg) 这个过程就是主从复制最齐全的流程讲解。那么下来我们对每一步进程简单的介绍 1. 从节点发送指令psync ? 1 psync runid offset 找对应的runid索取数据。但是这里可以考虑一下，当从节点第一次连接的时候根本就不知道主节点的runid 和 offset 。所以第一次发送的指令是psync ？ 1意思就是主节点的数据我全要。 2. 主节点开始执行bgsave生成RDB文件，记录当前的复制偏移量offset 3. 主节点这个时候会把自己的runid 和 offset 通过 +FULLRESYNC runid offset 指令 通过socket发送RDB文件给从节点。 4. 从节点接收到+FULLRESYNC 保存主节点的runid和offset 然后清空当前所有数据，通过socket接收RDB文件，开始恢复RDB数据。 5. 在全量复制后，从节点已经获取到了主节点的runid和offset，开始发送指令 psync runid offset 6. 主节点接收指令，判断runid是否匹配，判断offset是否在复制缓冲区中。 7. 主节点判断runid和offset有一个不满足，就会在返回到步骤2继续执行全量复制。这里的runid不匹配只有的可能是从节点重启了这个问题后边会解决，offset（偏移量）不匹配就是复制积压缓冲区溢出了。 如果runid或offset校验通过，从节点的offset和主节点的offset相同时则忽略。 如果runid或offset检验通过，从节点的offset与offset不相同，则会发送 +CONTINUE offset(这个offset为主节点的)，通过socket发送复制缓冲区中从节点offset到主节点offset的数据。 8. 从节点收到+CONTINUE 保存master的offset 通过socket接收到信息后，执行bgrewriteaof，恢复数据。 **1-4是全量复制 5-8是部分复制** 在主节点的第3步下面 主节点在主从复制的期间是一直在接收客户端的数据，主节点的offset是一直变化的。只有有变化就会给每个slave进行发送，这个发送的过程称之为心跳机制",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "主从复制",
      "psync命令",
      "RDB文件",
      "复制偏移量",
      "runid"
    ],
    "followup_points": [
      "1. 在全量复制阶段，如果主节点在生成RDB文件期间数据量非常大，可能会导致复制时间过长，此时主从复制过程中如何保证主节点的服务可用性和数据一致性？",
      "2. 在部分复制（增量复制）阶段，如果从节点因为网络中断等原因落后主节点较多，导致复制积压缓冲区（replication backlog）中的数据已被覆盖，此时从节点如何处理这种情况？是否会触发全量复制，还是有其他机制来恢复数据？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-master-slave.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-master-slave_007",
    "text": "八、部分复制的三个核心要素",
    "answer": "# 我们先看一下这个run id是什么，执行info命令即可看到。在上文中我们查看启动日志信息也可以看到。 ![](../images/172732797248305f.jpg) redis在启动时会自动生成一个随机的id（这里需要注意的是每次启动的id都会不一样），是由40个随机的十六进制字符串组成，用来唯一识别一个redis节点。 在主从复制初次启动时，master会把自己的runid发送给slave，slave会保存master的这个id，我们可以使用info命令查看 ![](../images/17273279bd947317.jpg) 当断线重连时，slave把这个id发送给master，如果slave保存的runid与master现在的runid相同，master会尝试使用部分复制（这块能否复制成功还有一个因素就是偏移量）。如果slave保存的runid与master现在的runid不同，则会直接进行全量复制。 # 复制缓冲积压区是一个先进先出的队列，用户存储master收集数据的命令记录。复制缓冲区的默认存储空间是1M。 可以在配置文件修改repl-backlog-size 1mb来控制缓冲区大小，这个比例可以根据自己的服务器内存来修改，咔咔这边是预留出了30%左右。 **复制缓冲区到底存储的是什么？** 当执行一个命令为set name kaka时，我们可以查看持久化文件查看 ![](../images/172732798545411e.jpg) 那么复制积压缓冲区就是存储的aof持久化的数据，并且以字节分开，并且每个字节都有自己的偏移量。这个偏移量也就是复制偏移量（offset） ![](../images/172732798af59f73.jpg) 那为什么会说复制缓冲积压区有可能会导致全量复制呢 在命令传播阶段，主节点会把收集的数据存储到复制缓冲区中，然后在发送给从节点。就是这里出现了问题，当主节点数据量在一瞬间特别大的时候，超出了复制缓冲区的内存，就会有一部分数据会被挤出去，从而导致主节点和从节点的数据不一致。从而进行全量复制。如果这个缓冲区大小设置不合理那么很大可能会造成死循环，从节点就会一直全量复制，清空数据，全量复制。 # ![](../images/17273279906f511c.jpg) 主节点复制偏移量是给从节点发送一次记录一次，从节点是接收一次记录一次。 用于同步信息，对比主节点和从节点的差异，当slave断联时恢复数据使用。 这个值也就是来自己于复制缓冲积压区里边的那个偏移量。",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "Redis主从复制",
      "Run ID",
      "断线重连",
      "部分复制",
      "复制偏移量"
    ],
    "followup_points": [
      "1. 如果master在断线重连期间重启了，导致runid发生变化，slave会如何处理这种情况？复制流程会重新开始吗？",
      "2. 除了runid，部分复制是否还有其他关键信息（如复制偏移量）需要配合使用来确保复制的连续性？这些信息是如何交互的？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-master-slave.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis-master-slave_008",
    "text": "九. 主从复制常见的问题",
    "answer": "# 当主节点重启后，runid的值将发生变化，会导致所有的从节点进行全量复制。 这个问题我们无需考虑，知道系统是怎么优化的即可。 在建立完主从复制后主节点会创建master-replid变量，这个生成的策略跟runid一样，长度是41位，runid长度是40位，然后发送给从节点。 在主节点执行shutdown save命令时，进行了一次RDB持久化会把runid 和 offset保存到RDB文件中。可以使用命令redis-check-rdb查看该信息。 ![](../images/17273279a6e90503.jpg) 主节点重启后加载RDB文件，将文件中的repl-id 和repl-offset加载到内存中。纵使让所有从节点认为还是之前的主节点。 # 由于网络环境不佳，从节点网络中断。复制积压缓冲区内存过小导致数据溢出，伴随着从节点偏移量越界，导致全量复制。有可能会导致反复的全量复制。 解决方案：修改复制积压缓冲区的大小：repl-backlog-size 设置建议：测试主节点连接从节点的时间，获取主节点每秒平均产生的命令总量write_size_per_second 复制缓冲区空间设置 = 2 * 主从连接时间 * 主节点每秒产生的数据总量 # 由于主节点的cpu占用过高，或者从节点频繁连接。出现这种情况造成的结果就是主节点各种资源被严重占用，其中包括但不限于缓冲区，宽带，连接等。 为什么会出现主节点资源被严重占用？ 在心跳机制中，从节点每秒会发送一个指令replconf ack指令到主节点。 从节点执行了慢查询，占用大量的cpu 主节点每秒调用复制定时函数replicationCron，然后从节点长时间没有相应。 **解决方案：** - 设置从节点超时释放 - 设置参数：repl-timeout - 这个参数默认为60秒。超过60秒，释放slave。 # 由于网络因素，多个从节点的数据会不一致。这个因素是没有办法避免的。 **关于这个问题给出俩个解决方案：** - 第一个数据需要高度一致配置一台redis服务器，读写都用一台服务器，这种方式仅限于少量数据，并且数据需高度一直。 - 第二个监控主从节点的偏移量，如果从节点的延迟过大，暂时屏蔽客户端对该从节点的访问。设置参数为slave-serve-stale-data yes|no。 这个参数一但设置就只能响应info slaveof等少数命令。 **5. 从节点故障** 这个问题直接在客户端维护一个可用节点列表，当从节点故障时，切换到其他节点进行工作，这个问题在后边集群会说到。",
    "category": "redis",
    "difficulty": 3,
    "tags": [
      "Redis主从复制",
      "runid",
      "全量复制",
      "RDB持久化",
      "repl-id"
    ],
    "followup_points": [
      "1. 在主节点重启后，从节点如何判断是否需要全量复制，具体是通过哪些字段或机制来实现的？",
      "2. 如果主节点在重启前没有执行`shutdown save`命令，RDB文件中不包含repl-id和repl-offset信息，此时从节点会如何处理复制流程？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis-master-slave.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_redis_000",
    "text": "Redis常见的数据结构？",
    "answer": "String、Hash、List、Set、SortedSet。 # 是redis中最基本的数据类型，一个key对应一个value。 String类型是二进制安全的，意思是 redis 的 string 可以包含任何数据。如数字，字符串，jpg图片或者序列化的对象。 **实战场景：** 1. 缓存： 经典使用场景，把常用信息，字符串，图片或者视频等信息放到redis中，redis作为缓存层，mysql做持久化层，降低mysql的读写压力。 2. 计数器：redis是单线程模型，一个命令执行完才会执行下一个，同时数据可以一步落地到其他的数据源。 3. session：常见方案spring session + redis实现session共享 # 是一个Mapmap，指值本身又是一种键值对结构，如 value={{field1,value1},......fieldN,valueN}} ![](../images/1289934-20190621232209365-1000366002.png) **实战场景：** 1.缓存： 能直观，相比string更节省空间，的维护缓存信息，如用户信息，视频信息等。 # List 说白了就是链表（redis 使用双端链表实现的 List），是有序的，value可以重复，可以通过下标取出对应的value值，左右两边都能进行插入和删除数据。 ![](../images/1289934-20190621233618769-504231907.png) 使用列表的技巧 - lpush+lpop=Stack(栈) - lpush+rpop=Queue（队列） - lpush+ltrim=Capped Collection（有限集合） - lpush+brpop=Message Queue（消息队列） **实战场景：** 1.timeline：例如微博的时间轴，有人发布微博，用lpush加入时间轴，展示新的列表信息。 # 集合类型也是用来保存多个字符串的元素，但和列表不同的是集合中 1. 不允许有重复的元素，2.集合中的元素是无序的，不能通过索引下标获取元素，3.支持集合间的操作，可以取多个集合取交集、并集、差集。 ![](../images/1289934-20190622001013515-677922001.png) **实战场景;** 1. 标签（tag）,给用户添加标签，或者用户给消息添加标签，这样有同一标签或者类似标签的可以给推荐关注的事或者关注的人。 2. 点赞，或点踩，收藏等，可以放到set中实现 # 有序集合和集合有着必然的联系，保留了集合不能有重复成员的特性，区别是，有序集合中的元素是可以排序的，它给每个元素设置一个分数，作为排序的依据。 （有序集合中的元素不可以重复，但是score 分数 可以重复，就和一个班里的同学学号不能重复，但考试成绩可以相同）。 ![](../images/1289934-20190622000959260-539243592.png) **实战场景：** 1. 排行榜：有序集合经典使用场景。例如小说视频等网站需要对用户上传的小说视频做排行榜，榜单可以按照用户关注数，更新时间，字数等打分，做排行。",
    "category": "redis",
    "difficulty": 1,
    "tags": [
      "Redis数据结构",
      "String类型",
      "缓存应用",
      "计数器",
      "Session管理"
    ],
    "followup_points": [
      "1. Redis除了String、Hash、List、Set、SortedSet这五种基本数据结构外，在最新版本中还引入了哪些新的数据类型？它们分别解决了什么问题？",
      "2. 在Redis的String类型实战场景中，如果缓存的数据量非常大（比如千万级key），如何优化内存使用和性能？有哪些策略可以避免内存溢出？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Redis/redis.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_000",
    "text": "跨节点的count,order by,group by以及聚合函数问题：分别在各个节点上得到结果后在应用程序端进行合并。",
    "answer": "跨节点的count,order by,group by以及聚合函数问题：分别在各个节点上得到结果后在应用程序端进行合并。",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "分布式聚合",
      "数据分片",
      "结果合并",
      "SQL优化",
      "节点通信"
    ],
    "followup_points": [
      "1. 在应用程序端合并各节点结果时，如何确保合并过程的效率和性能，特别是在数据量较大的情况下？",
      "2. 对于跨节点的order by操作，如果各节点返回的结果集本身已经有序，应用程序端合并时是否需要重新排序？如何优化这一过程？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_001",
    "text": "`select count(*) from table`时，MyISAM更快，因为它有一个变量保存了整个表的总行数，可以直接读取，InnoDB就需要全表扫描。",
    "answer": "`select count(*) from table`时，MyISAM更快，因为它有一个变量保存了整个表的总行数，可以直接读取，InnoDB就需要全表扫描。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "MyISAM",
      "InnoDB",
      "count(*)",
      "全表扫描",
      "行数统计"
    ],
    "followup_points": [
      "1. 在InnoDB中，如果表没有WHERE条件，是否可以通过其他优化方式（如二级索引）避免全表扫描来提升count(*)性能？",
      "2. MyISAM保存总行数的变量在什么情况下会失效（如删除/更新操作），如何保证数据一致性？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_002",
    "text": "InnoDB 存储引擎提供了具有提交、回滚、崩溃恢复能力的事务安全，与 MyISAM 比 InnoDB 写的效率差一些，并且会占用更多的磁盘空间以保留数据和索引",
    "answer": "InnoDB 存储引擎提供了具有提交、回滚、崩溃恢复能力的事务安全，与 MyISAM 比 InnoDB 写的效率差一些，并且会占用更多的磁盘空间以保留数据和索引",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "InnoDB",
      "MyISAM",
      "事务安全",
      "写效率",
      "磁盘空间"
    ],
    "followup_points": [
      "1. InnoDB 写效率差的具体原因是什么？是哪些机制（如redo log、undo log、MVCC等）导致了其写入性能相较于 MyISAM 较低？",
      "2. InnoDB 占用更多磁盘空间除了数据和索引外，还有哪些额外开销（如undo log、doublewrite buffer、事务日志等）？这些空间开销与事务安全性的关系是怎样的？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_003",
    "text": "InnoDB 属于索引组织表，使用共享表空间和多表空间储存数据。MyISAM用`.frm`、`.MYD`、`.MTI`来储存表定义，数据和索引。",
    "answer": "InnoDB 属于索引组织表，使用共享表空间和多表空间储存数据。MyISAM用`.frm`、`.MYD`、`.MTI`来储存表定义，数据和索引。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "InnoDB存储结构",
      "MyISAM存储结构",
      "索引组织表",
      "共享表空间",
      "多表空间"
    ],
    "followup_points": [
      "1. InnoDB 的共享表空间和多表空间存储方式各有什么优缺点，分别在什么场景下更适合使用？",
      "2. MyISAM 的 `.frm`、`.MYD`、`.MYI` 文件分别存储的具体内容是什么，与 InnoDB 的存储结构相比有哪些潜在的性能差异？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_004",
    "text": "1）B+树非叶子节点上是不存储数据的，仅存储键值，而B树节点中不仅存储键值，也会存储数据。innodb中页的默认大小是16KB，如果不存储数据，那么就会存储更多的键值，相应的树的阶数（节点的子节点树）就会更大，树就会更矮更胖，如此一来我们查找数据进行磁盘的IO次数有会再次减少，数据查询的效率也会更快。",
    "answer": "1）B+树非叶子节点上是不存储数据的，仅存储键值，而B树节点中不仅存储键值，也会存储数据。innodb中页的默认大小是16KB，如果不存储数据，那么就会存储更多的键值，相应的树的阶数（节点的子节点树）就会更大，树就会更矮更胖，如此一来我们查找数据进行磁盘的IO次数有会再次减少，数据查询的效率也会更快。",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "B+树",
      "B树",
      "InnoDB",
      "磁盘IO",
      "数据查询效率"
    ],
    "followup_points": [
      "1. 在B+树的非叶子节点中，键值的存储结构是如何设计的（例如是否包含指针信息），以及这种设计如何具体影响树的阶数计算？",
      "2. 当数据量极大或查询模式复杂时（如范围查询），B+树的非叶子节点不存储数据的特性相比B树在性能上是否存在潜在劣势，如何权衡？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_005",
    "text": "2）B+树索引的所有数据均存储在叶子节点，而且数据是按照顺序排列的，链表连着的。那么B+树使得范围查找，排序查找，分组查找以及去重查找变得异常简单。",
    "answer": "2）B+树索引的所有数据均存储在叶子节点，而且数据是按照顺序排列的，链表连着的。那么B+树使得范围查找，排序查找，分组查找以及去重查找变得异常简单。",
    "category": "algorithm",
    "difficulty": 2,
    "tags": [
      "B+树索引",
      "叶子节点",
      "数据排序",
      "链表连接",
      "范围查找"
    ],
    "followup_points": [
      "1. 在B+树索引中，叶子节点通过链表连接，这种设计在范围查找时如何具体优化查询性能，特别是在处理大范围数据时？",
      "2. 对于分组查找和去重查找，B+树的有序性和叶子节点存储特性如何减少磁盘I/O操作，与哈希索引相比有哪些优势？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_006",
    "text": "聚集索引，索引中键值的逻辑顺序决定了表中相应行的物理顺序；非聚集索引，索引中索引的逻辑顺序与磁盘上行的物理存储顺序不同。",
    "answer": "聚集索引，索引中键值的逻辑顺序决定了表中相应行的物理顺序；非聚集索引，索引中索引的逻辑顺序与磁盘上行的物理存储顺序不同。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "聚集索引",
      "非聚集索引",
      "索引键值",
      "逻辑顺序",
      "物理顺序"
    ],
    "followup_points": [
      "1. 在实际应用中，如何根据业务场景选择使用聚集索引还是非聚集索引？请举例说明不同选择对查询性能的影响。",
      "2. 当表中同时存在聚集索引和非聚集索引时，数据更新操作（如INSERT、UPDATE、DELETE）对这两种索引的维护机制有何不同？会对性能产生哪些潜在影响？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_007",
    "text": "索引是通过二叉树的数据结构来描述的，我们可以这么理解聚簇索引：索引的叶节点就是数据节点。而非聚簇索引的叶节点仍然是索引节点，只不过有一个指针指向对应的数据块。",
    "answer": "索引是通过二叉树的数据结构来描述的，我们可以这么理解聚簇索引：索引的叶节点就是数据节点。而非聚簇索引的叶节点仍然是索引节点，只不过有一个指针指向对应的数据块。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "聚簇索引",
      "非聚簇索引",
      "B+树",
      "索引结构",
      "数据指针"
    ],
    "followup_points": [
      "1. 聚簇索引的叶节点直接存储数据，这种设计对数据插入和更新操作的性能有什么具体影响？",
      "2. 非聚簇索引的叶节点通过指针指向数据块，这种指针在InnoDB和MyISAM存储引擎中实现方式有什么区别？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_008",
    "text": "聚集索引：物理存储按照索引排序；非聚集索引：物理存储不按照索引排序；",
    "answer": "聚集索引：物理存储按照索引排序；非聚集索引：物理存储不按照索引排序； 何时使用聚集索引或非聚集索引？ ![](../images/172346f5e5f0ffab.jpg)",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "聚集索引",
      "非聚集索引",
      "索引选择策略",
      "B+树结构",
      "数据存储结构"
    ],
    "followup_points": [
      "1. 在聚集索引的物理存储结构中，数据页是如何通过双向链表进行逻辑连接的？",
      "2. 非聚集索引的叶子节点存储的是行指针还是聚集索引键，这两种方式对查询性能有何影响？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_009",
    "text": "串行化（Serializable）",
    "answer": "串行化（Serializable） Mysql默认的事务隔离级别是可重复读(Repeatable Read)",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "Serializable",
      "MySQL事务隔离级别",
      "可重复读(Repeatable Read)"
    ],
    "followup_points": [
      "1. 在可重复读隔离级别下，MySQL如何解决幻读问题，具体使用了什么机制（如间隙锁）？",
      "2. 除了默认的可重复读，MySQL其他隔离级别（读未提交、读已提交、可串行化）分别解决了哪些并发问题，适用场景是什么？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_010",
    "text": "事务A查询一个范围的结果集，另一个并发事务B往这个范围中插入/删除了数据，并静悄悄地提交，然后事务A再次查询相同的范围，两次读取得到的结果集不一样了，这就是幻读。",
    "answer": "事务A查询一个范围的结果集，另一个并发事务B往这个范围中插入/删除了数据，并静悄悄地提交，然后事务A再次查询相同的范围，两次读取得到的结果集不一样了，这就是幻读。",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "事务隔离级别",
      "幻读",
      "并发控制",
      "范围查询",
      "ACID特性"
    ],
    "followup_points": [
      "1. 在幻读场景下，数据库是如何通过锁机制（如间隙锁）来避免幻读问题的？不同隔离级别（如READ COMMITTED和REPEATABLE READ）下对幻读的处理方式有何差异？",
      "2. 除了幻读，事务的隔离性还可能引发不可重复读和脏读问题，这三种现象的根本区别是什么？在实际业务中，如何根据需求选择合适的隔离级别来平衡数据一致性和并发性能？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_011",
    "text": "`explain` 分析低效 sql 的执行计划（这点非常重要，日常开发中用它分析Sql，会大大降低Sql导致的线上事故）",
    "answer": "`explain` 分析低效 sql 的执行计划（这点非常重要，日常开发中用它分析Sql，会大大降低Sql导致的线上事故）",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "SQL执行计划",
      "EXPLAIN命令",
      "性能分析",
      "索引优化",
      "查询效率"
    ],
    "followup_points": [
      "1. 当你使用 `explain` 分析 SQL 执行计划时，通常会重点关注哪些关键字段或指标来判断 SQL 是否存在性能问题？",
      "2. 能否举例说明一个你通过 `explain` 定位到的 SQL 性能瓶颈，以及你采取了哪些优化措施？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_012",
    "text": "一致性： 指在事务开始之前和事务结束以后，数据不会被破坏，假如A账户给B账户转10块钱，不管成功与否，A和B的总金额是不变的。",
    "answer": "一致性： 指在事务开始之前和事务结束以后，数据不会被破坏，假如A账户给B账户转10块钱，不管成功与否，A和B的总金额是不变的。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "事务",
      "一致性",
      "ACID",
      "数据库",
      "转账"
    ],
    "followup_points": [
      "1. 在转账事务中，如果A账户余额不足10块钱，系统如何保证一致性？是通过事务回滚还是其他机制？",
      "2. 除了转账场景，能否举例说明一致性在其他业务场景（如订单创建、库存扣减）中的具体实现和挑战？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_013",
    "text": "隔离性： 多个事务并发访问时，事务之间是相互隔离的，即一个事务不影响其它事务运行效果。简言之，就是事务之间是进水不犯河水的。",
    "answer": "隔离性： 多个事务并发访问时，事务之间是相互隔离的，即一个事务不影响其它事务运行效果。简言之，就是事务之间是进水不犯河水的。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "数据库事务",
      "并发控制",
      "隔离级别",
      "数据一致性",
      "锁机制"
    ],
    "followup_points": [
      "1. 在实际应用中，如果隔离性级别设置不当，可能会导致哪些具体的问题（例如脏读、不可重复读、幻读）？",
      "2. 数据库是如何通过锁机制（如共享锁、排他锁）或MVCC（多版本并发控制）来保证隔离性的？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_014",
    "text": "原子性：是使用 undo log来实现的，如果事务执行过程中出错或者用户执行了rollback，系统通过undo log日志返回事务开始的状态。",
    "answer": "原子性：是使用 undo log来实现的，如果事务执行过程中出错或者用户执行了rollback，系统通过undo log日志返回事务开始的状态。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "原子性",
      "undo log",
      "事务回滚",
      "事务状态恢复",
      "错误处理"
    ],
    "followup_points": [
      "1. 在InnoDB中，undo log除了实现事务回滚，还如何用于实现多版本并发控制（MVCC）中的读已提交和可重复读隔离级别？",
      "2. 当系统通过undo log回滚时，如果undo log本身记录的数据页版本与当前内存中的版本不一致，InnoDB是如何处理这种版本冲突的？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_015",
    "text": "持久性：使用 redo log来实现，只要redo log日志持久化了，当系统崩溃，即可通过redo log把数据恢复。",
    "answer": "持久性：使用 redo log来实现，只要redo log日志持久化了，当系统崩溃，即可通过redo log把数据恢复。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "持久性",
      "redo log",
      "崩溃恢复",
      "事务",
      "日志持久化"
    ],
    "followup_points": [
      "1. 在redo log日志持久化到磁盘的过程中，MySQL是如何确保redo log本身不会丢失的？比如是否采用了双写机制（doublewrite buffer）来保证redo log的可靠性？",
      "2. 当系统崩溃后，redo log的恢复过程具体是如何执行的？比如是否需要扫描所有redo log记录，是否有检查点（checkpoint）机制来优化恢复效率？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_016",
    "text": "步骤五：还会创建一个SQL线程，从relay log里面读取内容，从Exec_Master_Log_Pos位置开始执行读取到的更新事件，将更新内容写入到slave的db",
    "answer": "步骤五：还会创建一个SQL线程，从relay log里面读取内容，从Exec_Master_Log_Pos位置开始执行读取到的更新事件，将更新内容写入到slave的db",
    "category": "system",
    "difficulty": 3,
    "tags": [
      "MySQL复制",
      "SQL线程",
      "Relay Log",
      "Exec_Master_Log_Pos",
      "主从同步"
    ],
    "followup_points": [
      "1. 如果SQL线程在执行relay log中的更新事件时遇到错误（如主从数据不一致导致的主键冲突），它会采取什么处理机制？是停止复制、跳过错误还是尝试自动修复？",
      "2. 在高并发场景下，SQL线程执行relay log中的更新事件时，如何保证与主库的数据一致性和事务的原子性？是否会涉及分布式事务或锁机制？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_017",
    "text": "主服务器要负责更新操作，对安全性的要求比从服务器要高，所以有些设置参数可以修改，比如sync_binlog=1，innodb_flush_log_at_trx_commit = 1 之类的设置等。",
    "answer": "主服务器要负责更新操作，对安全性的要求比从服务器要高，所以有些设置参数可以修改，比如sync_binlog=1，innodb_flush_log_at_trx_commit = 1 之类的设置等。",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "MySQL主从复制",
      "主从服务器配置差异",
      "数据安全性",
      "sync_binlog",
      "innodb_flush_log_at_trx_commit"
    ],
    "followup_points": [
      "1. 在设置sync_binlog=1和innodb_flush_log_at_trx_commit=1的情况下，主服务器可能会面临哪些性能瓶颈？是否有其他优化参数可以平衡安全性和性能？",
      "2. 如果主服务器突然宕机，这些高安全性设置如何保证数据不丢失？恢复过程中是否需要额外操作？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_018",
    "text": "把一台从服务器当度作为备份使用， 而不提供查询， 那边他的负载下来了， 执行relay log 里面的SQL效率自然就高了。",
    "answer": "把一台从服务器当度作为备份使用， 而不提供查询， 那边他的负载下来了， 执行relay log 里面的SQL效率自然就高了。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "MySQL主从复制",
      "Relay Log",
      "从服务器负载",
      "备份策略",
      "SQL执行效率"
    ],
    "followup_points": [
      "1. 当从服务器仅作为备份使用且不提供查询时，除了负载降低外，还有哪些因素可能影响relay log中SQL的执行效率？",
      "2. 如果从服务器的relay log执行效率显著提升，是否意味着可以进一步优化备份策略（如调整复制线程数量或relay log存储方式）？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_019",
    "text": "如果没有缓存，分析器进行词法分析，提取 sql 语句select等的关键元素。然后判断sql 语句是否有语法错误，比如关键词是否正确等等。",
    "answer": "如果没有缓存，分析器进行词法分析，提取 sql 语句select等的关键元素。然后判断sql 语句是否有语法错误，比如关键词是否正确等等。",
    "category": "redis",
    "difficulty": 2,
    "tags": [
      "词法分析",
      "语法分析",
      "SQL解析",
      "错误检测",
      "关键词提取"
    ],
    "followup_points": [
      "1. 在词法分析阶段，分析器如何处理SQL语句中的注释或特殊字符（如引号、转义字符）？这些特殊字符是否会影响关键元素的提取准确性？",
      "2. 当SQL语句存在语法错误时，分析器会返回具体的错误类型（如关键词错误、语法结构错误等），能否举例说明分析器如何定位并区分不同类型的语法错误？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_020",
    "text": "索引下推优化是 MySQL 5.6 引入的， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。",
    "answer": "索引下推优化是 MySQL 5.6 引入的， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "MySQL索引",
      "索引下推",
      "回表优化",
      "索引遍历",
      "查询优化"
    ],
    "followup_points": [
      "1. 索引下推优化在哪些具体场景下效果最显著，能否举例说明？",
      "2. 如果查询条件中包含索引未覆盖的字段，索引下推优化是否还能生效？为什么？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_021",
    "text": "datetime类型适合用来记录数据的原始的创建时间，修改记录中其他字段的值，datetime字段的值不会改变，除非手动修改它。",
    "answer": "datetime类型适合用来记录数据的原始的创建时间，修改记录中其他字段的值，datetime字段的值不会改变，除非手动修改它。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "datetime",
      "数据类型",
      "不可变性",
      "创建时间",
      "手动修改"
    ],
    "followup_points": [
      "1. 如果业务场景中需要自动追踪数据的最后修改时间，除了手动修改datetime字段外，还有哪些更优的实现方式？",
      "2. 在高并发或分布式系统中，手动修改datetime字段可能存在哪些潜在问题，如何确保时间记录的准确性和一致性？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_022",
    "text": "timestamp类型适合用来记录数据的最后修改时间，只要修改了记录中其他字段的值，timestamp字段的值都会被自动更新。",
    "answer": "timestamp类型适合用来记录数据的最后修改时间，只要修改了记录中其他字段的值，timestamp字段的值都会被自动更新。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "timestamp",
      "自动更新",
      "最后修改时间",
      "数据记录",
      "字段特性"
    ],
    "followup_points": [
      "1. 当表中同时存在多个timestamp字段时，它们的自动更新行为是否会相互影响？",
      "2. 如果记录中包含其他timestamp字段（如创建时间），如何确保只有表示最后修改时间的timestamp字段在更新时自动变更？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_023",
    "text": "Show status, 一些值得监控的变量值：",
    "answer": "Show status, 一些值得监控的变量值： > Bytes_received和Bytes_sent 和服务器之间来往的流量。 > Com_*服务器正在执行的命令。 > Created_*在查询执行期限间创建的临时表和文件。 > Handler_*存储引擎操作。 > Select_*不同类型的联接执行计划。 > Sort_*几种排序信息。",
    "category": "algorithm",
    "difficulty": 1,
    "tags": [
      "MySQL性能监控",
      "服务器状态变量",
      "流量监控",
      "命令执行统计",
      "临时表创建"
    ],
    "followup_points": [
      "1. 对于Com_*变量，能否举例说明哪些具体的命令计数（如Com_select、Com_insert）对评估数据库负载最有意义，以及如何通过这些计数识别潜在的性能瓶颈？",
      "2. 在监控Handler_*变量时，Handler_read_rnd和Handler_read_rnd_next这类值偏高通常意味着什么？如何结合索引使用情况优化相关查询？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_024",
    "text": "text值被视为非二进制字符串（字符字符串）。它们有一个字符集，并根据字符集的排序规则对值进行排序和比较。",
    "answer": "text值被视为非二进制字符串（字符字符串）。它们有一个字符集，并根据字符集的排序规则对值进行排序和比较。",
    "category": "algorithm",
    "difficulty": 1,
    "tags": [
      "字符集",
      "排序规则",
      "字符串比较",
      "非二进制字符串",
      "text类型"
    ],
    "followup_points": [
      "1. 在MySQL中，text类型和varchar类型在存储和字符集处理上有何主要区别？",
      "2. 当text值包含多字节字符（如中文或emoji）时，字符集和排序规则如何影响其排序和比较的结果？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_025",
    "text": "货币在数据库中MySQL常用Decimal和Numric类型表示，这两种类型被MySQL实现为同样的类型。他们被用于保存与金钱有关的数据。",
    "answer": "货币在数据库中MySQL常用Decimal和Numric类型表示，这两种类型被MySQL实现为同样的类型。他们被用于保存与金钱有关的数据。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "MySQL数据类型",
      "Decimal类型",
      "Numeric类型",
      "货币存储",
      "精确数值计算"
    ],
    "followup_points": [
      "1. 在使用Decimal/Numeric类型存储货币数据时，如何确定合适的精度（Precision）和小数位数（Scale）以避免数据溢出或精度损失？",
      "2. 除了Decimal/Numeric类型，是否还有其他适合存储货币数据的类型（如Bigint以分为单位存储）？各自的优缺点是什么？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_026",
    "text": "salary DECIMAL(9,2)，9(precision)代表将被用于存储值的总的小数位数，而2(scale)代表将被用于存储小数点后的位数。存储在salary列中的值的范围是从-9999999.99到9999999.99。",
    "answer": "salary DECIMAL(9,2)，9(precision)代表将被用于存储值的总的小数位数，而2(scale)代表将被用于存储小数点后的位数。存储在salary列中的值的范围是从-9999999.99到9999999.99。",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "DECIMAL数据类型",
      "数值精度(Precision)",
      "数值标度(Scale)",
      "数值范围",
      "数据库列定义"
    ],
    "followup_points": [
      "1. 如果业务需求中salary列需要存储超过9999999.99的值，应该如何调整DECIMAL的precision和 scale参数？",
      "2. 在实际应用中，如果salary列需要支持负数（如退款场景），除了DECIMAL(9,2)，还有哪些数据类型或约束可以确保数据的准确性和一致性？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_027",
    "text": "B+树使用like 进行模糊查询的时候，like后面（比如%开头）的话可以起到优化的作用，Hash索引根本无法进行模糊查询。",
    "answer": "B+树使用like 进行模糊查询的时候，like后面（比如%开头）的话可以起到优化的作用，Hash索引根本无法进行模糊查询。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "B+树索引",
      "Hash索引",
      "模糊查询",
      "索引优化",
      "like查询"
    ],
    "followup_points": [
      "1. 在B+树中，当like查询以%开头时，具体是通过什么机制（如索引范围扫描、前缀匹配等）实现优化的？这种优化是否适用于所有前导%的场景（如\"%%abc\"或\"%abc%\"）？",
      "2. Hash索引无法进行模糊查询的根本原因是什么？如果将模糊查询拆分为多个精确查询（如对关键词分词后使用OR连接），是否可以绕过Hash索引的局限性？这种方案的优缺点是什么？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_028",
    "text": "外连接（outer join）：取得两张表中满足存在连接匹配关系的记录，以及某张表（或两张表）中不满足匹配关系的记录。",
    "answer": "外连接（outer join）：取得两张表中满足存在连接匹配关系的记录，以及某张表（或两张表）中不满足匹配关系的记录。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "SQL",
      "数据库",
      "连接查询",
      "外连接",
      "数据查询"
    ],
    "followup_points": [
      "1. 在实际应用中，外连接（如LEFT JOIN、RIGHT JOIN、FULL JOIN）的选择通常基于哪些业务场景或数据需求？能否举例说明不同外连接类型对结果集的影响？",
      "2. 当外连接中出现不匹配的记录时，数据库（如MySQL、PostgreSQL）如何处理这些记录中的空值（NULL）？这种处理方式可能对后续的数据分析或业务逻辑产生哪些影响？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_029",
    "text": "交叉连接（cross join）：显示两张表所有记录一一对应，没有匹配关系进行筛选，也被称为：笛卡尔积。",
    "answer": "交叉连接（cross join）：显示两张表所有记录一一对应，没有匹配关系进行筛选，也被称为：笛卡尔积。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "SQL",
      "数据库",
      "交叉连接",
      "笛卡尔积",
      "表连接"
    ],
    "followup_points": [
      "1. 在实际业务场景中，交叉连接（笛卡尔积）可能带来哪些性能问题，通常如何避免或优化？",
      "2. 除了直接使用CROSS JOIN语法，还有哪些操作或场景可能导致意外的笛卡尔积结果？如何排查？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_030",
    "text": "host权限表：配合db权限表对给定主机上数据库级操作权限作更细致的控制。这个权限表不受GRANT和REVOKE语句的影响。",
    "answer": "host权限表：配合db权限表对给定主机上数据库级操作权限作更细致的控制。这个权限表不受GRANT和REVOKE语句的影响。",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "MySQL权限控制",
      "host权限表",
      "数据库级权限",
      "GRANT/REVOKE语句",
      "权限管理机制"
    ],
    "followup_points": [
      "1. host权限表与db权限表在权限验证过程中具体的优先级和协同逻辑是怎样的？",
      "2. 既然host权限表不受GRANT和REVOKE影响，那它的权限通常是如何初始化或修改的？是否存在特定的系统命令或手动维护方式？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_031",
    "text": "statement，每一条会修改数据的sql都会记录在binlog中。不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能。由于sql的执行是有上下文的，因此在保存的时候需要保存相关的信息，同时还有一些使用了函数之类的语句无法被记录复制。",
    "answer": "statement，每一条会修改数据的sql都会记录在binlog中。不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能。由于sql的执行是有上下文的，因此在保存的时候需要保存相关的信息，同时还有一些使用了函数之类的语句无法被记录复制。",
    "category": "system",
    "difficulty": 3,
    "tags": [
      "binlog",
      "statement模式",
      "SQL上下文",
      "函数依赖",
      "IO优化"
    ],
    "followup_points": [
      "1. 在statement模式下，对于使用了非确定性函数（如NOW()、RAND()）的SQL语句，MySQL是如何确保从库数据一致性的？",
      "2. 当statement模式的binlog中包含存储过程或触发器时，复制过程中是否会存在额外的上下文信息传递问题？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_032",
    "text": "row，不记录sql语句上下文相关信息，仅保存哪条记录被修改。记录单元为每一行的改动，基本是可以全部记下来但是由于很多操作，会导致大量行的改动(比如alter table)，因此这种模式的文件保存的信息太多，日志量太大。",
    "answer": "row，不记录sql语句上下文相关信息，仅保存哪条记录被修改。记录单元为每一行的改动，基本是可以全部记下来但是由于很多操作，会导致大量行的改动(比如alter table)，因此这种模式的文件保存的信息太多，日志量太大。",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "binlog",
      "row模式",
      "日志量",
      "数据修改",
      "记录单元"
    ],
    "followup_points": [
      "1. 在row模式下，针对alter table这类导致大量行改动的操作，是否有优化机制或策略来减少日志量，比如只记录元数据变更而非具体行数据？",
      "2. row模式下的日志量过大可能会影响I/O性能，在实际生产环境中，是如何平衡row模式的精确性和日志存储/性能开销的？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_033",
    "text": "mixed，一种折中的方案，普通操作使用statement记录，当无法使用statement的时候使用row。",
    "answer": "mixed，一种折中的方案，普通操作使用statement记录，当无法使用statement的时候使用row。",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "MySQL",
      "binlog",
      "复制",
      "mixed模式",
      "statement模式"
    ],
    "followup_points": [
      "1. 在mixed模式下，具体哪些类型的操作会被判定为\"无法使用statement\"，从而触发row格式记录？",
      "2. 当mixed模式从statement切换到row格式记录时，是否会对binlog的大小或复制延迟产生显著影响？如何优化这种场景下的性能？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_034",
    "text": "最左前缀原则，就是最左优先，在创建多列索引时，要根据业务需求，where子句中使用最频繁的一列放在最左边。",
    "answer": "最左前缀原则，就是最左优先，在创建多列索引时，要根据业务需求，where子句中使用最频繁的一列放在最左边。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "最左前缀原则",
      "多列索引",
      "索引创建",
      "where子句",
      "查询优化"
    ],
    "followup_points": [
      "1. 如果业务需求中，多列索引的多个列在 where 子句中的使用频率相近，应该如何判断最左前缀的优先级？",
      "2. 在实际应用中，如果最左前缀原则与查询性能（如索引选择性、数据分布）存在冲突，应如何权衡取舍？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_035",
    "text": "当我们创建一个组合索引的时候，如(k1,k2,k3)，相当于创建了（k1）、(k1,k2)和(k1,k2,k3)三个索引，这就是最左匹配原则。。",
    "answer": "当我们创建一个组合索引的时候，如(k1,k2,k3)，相当于创建了（k1）、(k1,k2)和(k1,k2,k3)三个索引，这就是最左匹配原则。。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "组合索引",
      "最左匹配原则",
      "索引覆盖",
      "索引下推",
      "索引优化"
    ],
    "followup_points": [
      "1. 如果查询条件中包含非最左列（如仅k2或k3），组合索引(k1,k2,k3)是否会被完全失效，还是部分列仍然可以使用？",
      "2. 在最左匹配原则下，如果查询条件中的列顺序与索引定义顺序不同（如WHERE k2=? AND k1=?），数据库会如何处理这种情况？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_036",
    "text": "在B树中，键和值即存放在内部节点又存放在叶子节点；在B+树中，内部节点只存键，叶子节点则同时存放键和值。",
    "answer": "在B树中，键和值即存放在内部节点又存放在叶子节点；在B+树中，内部节点只存键，叶子节点则同时存放键和值。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "B树",
      "B+树",
      "数据结构",
      "索引",
      "存储结构"
    ],
    "followup_points": [
      "1. 为什么B+树内部节点只存键而不存值，这样的设计对数据库索引的性能有哪些具体优势？",
      "2. 在B+树中，叶子节点通过指针连接形成链表，这种结构对范围查询效率的提升体现在哪些方面？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_037",
    "text": "B+树索引的所有数据均存储在叶子节点，而且数据是按照顺序排列的，链表连着的。那么B+树使得范围查找，排序查找，分组查找以及去重查找变得异常简单。.",
    "answer": "B+树索引的所有数据均存储在叶子节点，而且数据是按照顺序排列的，链表连着的。那么B+树使得范围查找，排序查找，分组查找以及去重查找变得异常简单。.",
    "category": "algorithm",
    "difficulty": 1,
    "tags": [
      "B+树",
      "索引",
      "叶子节点",
      "数据排序",
      "范围查询"
    ],
    "followup_points": [
      "1. 在B+树中，如果数据量非常大，叶子节点的链表结构如何影响范围查找的性能？是否存在优化空间？",
      "2. B+树的叶子节点链表在并发环境下如何保证数据的一致性？是否有锁机制或其他并发控制策略？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_038",
    "text": "B+树非叶子节点上是不存储数据的，仅存储键值，而B树节点中不仅存储键值，也会存储数据。innodb中页的默认大小是16KB，如果不存储数据，那么就会存储更多的键值，相应的树的阶数（节点的子节点树）就会更大，树就会更矮更胖，如此一来我们查找数据进行磁盘的IO次数有会再次减少，数据查询的效率也会更快.",
    "answer": "B+树非叶子节点上是不存储数据的，仅存储键值，而B树节点中不仅存储键值，也会存储数据。innodb中页的默认大小是16KB，如果不存储数据，那么就会存储更多的键值，相应的树的阶数（节点的子节点树）就会更大，树就会更矮更胖，如此一来我们查找数据进行磁盘的IO次数有会再次减少，数据查询的效率也会更快.",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "B+树",
      "B树",
      "InnoDB",
      "磁盘IO",
      "数据查询效率"
    ],
    "followup_points": [
      "1. 在B+树的非叶子节点中，键值的存储结构是如何设计的（例如是否包含指向子节点的指针）？这种设计如何确保在16KB页大小下最大化键值数量？",
      "2. 当B+树的阶数增大后，节点的分裂和合并操作会变得更加频繁，这种情况下InnoDB是如何优化这些操作以维持查询效率的？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_039",
    "text": "回表：二级索引无法直接查询所有列的数据，所以通过二级索引查询到聚簇索引后，再查询到想要的数据，这种通过二级索引查询出来的过程，就叫做回表。",
    "answer": "回表：二级索引无法直接查询所有列的数据，所以通过二级索引查询到聚簇索引后，再查询到想要的数据，这种通过二级索引查询出来的过程，就叫做回表。",
    "category": "mysql",
    "difficulty": 1,
    "tags": [
      "回表",
      "二级索引",
      "聚簇索引",
      "索引查询",
      "数据查询"
    ],
    "followup_points": [
      "1. 在什么情况下查询可以避免回表，从而提升查询效率？",
      "2. 回表操作对数据库性能的具体影响有哪些，以及如何优化以减少回表次数？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_040",
    "text": "在B+树的索引中，叶子节点可能存储了当前的key值，也可能存储了当前的key值以及整行的数据，这就是聚簇索引和非聚簇索引。 在InnoDB中，只有主键索引是聚簇索引，如果没有主键，则挑选一个唯一键建立聚簇索引。如果没有唯一键，则隐式的生成一个键来建立聚簇索引。",
    "answer": "在B+树的索引中，叶子节点可能存储了当前的key值，也可能存储了当前的key值以及整行的数据，这就是聚簇索引和非聚簇索引。 在InnoDB中，只有主键索引是聚簇索引，如果没有主键，则挑选一个唯一键建立聚簇索引。如果没有唯一键，则隐式的生成一个键来建立聚簇索引。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "B+树索引",
      "聚簇索引",
      "非聚簇索引",
      "InnoDB",
      "主键索引"
    ],
    "followup_points": [
      "1. 在InnoDB中，聚簇索引的叶子节点存储整行数据，而非聚簇索引的叶子节点存储主键值，这种设计对查询性能和索引维护成本分别有哪些具体影响？",
      "2. 当表没有显式定义主键和唯一键时，InnoDB隐式生成的聚簇索引键（如DB_TRX_ID、DB_ROLL_PTR等）是如何影响表的存储结构和并发操作的？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_041",
    "text": "排他锁: 又叫做写锁。当用户要进行数据的写入时，对数据加上排他锁。排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。",
    "answer": "排他锁: 又叫做写锁。当用户要进行数据的写入时，对数据加上排他锁。排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。 锁兼容性如下： ![](../images/172412db1d202759.jpg)",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "排他锁",
      "写锁",
      "锁兼容性",
      "共享锁",
      "数据写入"
    ],
    "followup_points": [
      "1. 在高并发场景下，如果多个事务同时申请排他锁，数据库是如何处理锁的等待和死锁检测机制的？",
      "2. 排他锁在释放后，其他等待的事务是如何被唤醒的？是否存在优先级机制或公平性问题？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_042",
    "text": "count(列名)只包括列名那一列，在统计结果的时候，会忽略列值为空（这里的空不是只空字符串或者0，而是表示null）的计数，即某个字段值为NULL时，不统计。",
    "answer": "count(列名)只包括列名那一列，在统计结果的时候，会忽略列值为空（这里的空不是只空字符串或者0，而是表示null）的计数，即某个字段值为NULL时，不统计。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "SQL",
      "COUNT函数",
      "NULL值处理",
      "聚合函数",
      "数据统计"
    ],
    "followup_points": [
      "1. 如果表中有多个列存在NULL值，使用count(列名)统计不同列时，结果会有什么差异？这种差异在实际业务中通常用于解决什么问题？",
      "2. 当使用count(*)和count(列名)统计同一张表时，如果表中存在大量NULL值，这两种方式的性能差异主要体现在哪些方面？在什么场景下会更倾向于使用count(列名)？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_043",
    "text": "主键：数据库表中对储存数据对象予以唯一和完整标识的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值（Null）。",
    "answer": "主键：数据库表中对储存数据对象予以唯一和完整标识的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值（Null）。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "数据库主键",
      "唯一性约束",
      "非空约束",
      "数据完整性",
      "标识符"
    ],
    "followup_points": [
      "1. 除了唯一性和非空性，主键在选择时还需要考虑哪些关键因素，例如性能、可读性或业务含义？",
      "2. 在实际数据库设计中，主键与唯一索引（Unique Index）的主要区别是什么？什么场景下更适合使用自增主键而非业务主键？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_044",
    "text": "自增ID：数据存储空间小，查询效率高。但是如果数据量过大,会超出自增长的值范围，多库合并，也有可能有问题。",
    "answer": "自增ID：数据存储空间小，查询效率高。但是如果数据量过大,会超出自增长的值范围，多库合并，也有可能有问题。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "自增ID",
      "数据存储空间",
      "查询效率",
      "数据量过大",
      "多库合并"
    ],
    "followup_points": [
      "1. 当自增ID超出值范围时，具体会有哪些潜在问题，比如数据插入失败、主键冲突还是其他异常？",
      "2. 对于多库合并时可能出现的ID冲突问题，有哪些常见的解决方案（如分片策略、分布式ID生成等），各自的优缺点是什么？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_045",
    "text": "如果是mysqld导致的，show processlist，查看session情况，确定是不是有消耗资源的sql在运行。",
    "answer": "如果是mysqld导致的，show processlist，查看session情况，确定是不是有消耗资源的sql在运行。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "MySQL性能监控",
      "SQL性能分析",
      "会话管理",
      "资源消耗排查",
      "show processlist"
    ],
    "followup_points": [
      "1. 当通过show processlist发现有消耗资源的SQL时，你会优先关注哪些关键指标（如CPU、I/O、锁等待等）来判断其影响程度？",
      "2. 如果确定是特定SQL导致资源消耗，你会采取哪些具体的优化措施（如SQL改写、索引调整、资源限制等）来解决问题？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_046",
    "text": "利用中间件来做代理，负责对数据库的请求识别出读还是写，并分发到不同的数据库中。（如：amoeba，mysql-proxy）",
    "answer": "利用中间件来做代理，负责对数据库的请求识别出读还是写，并分发到不同的数据库中。（如：amoeba，mysql-proxy）",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "数据库代理",
      "读写分离",
      "中间件",
      "请求识别",
      "负载均衡"
    ],
    "followup_points": [
      "1. 中间件如何准确识别数据库请求是读操作还是写操作？具体会解析哪些SQL语句特征或协议信息？",
      "2. 当代理识别到写请求后，除了分发到主库，是否会同步到从库？如果存在延迟或失败，中间件如何处理数据一致性问题？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_047",
    "text": "从数据库的relay-log重做日志文件中再执行一次这些sql语句。（Sql执行线程）",
    "answer": "从数据库的relay-log重做日志文件中再执行一次这些sql语句。（Sql执行线程） 如下图所示： ![](../images/16c4d9dd1b8235c3.jpg) 上图主从复制分了五个步骤进行：",
    "category": "system",
    "difficulty": 3,
    "tags": [
      "数据库复制",
      "Relay Log",
      "SQL线程",
      "主从同步",
      "数据一致性"
    ],
    "followup_points": [
      "1. 在从库执行relay-log中的SQL语句时，如果遇到主从数据不一致或SQL执行失败，通常有哪些常见的处理机制和解决方案？",
      "2. relay-log的清理和轮转策略是怎样的？如何确保relay-log不会无限增长，同时不影响主从复制的可靠性？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_048",
    "text": "步骤五：还会创建一个SQL线程，从relay log里面读取内容，从Exec_Master_Log_Pos位置开始执行读取到的更新事件，将更新内容写入到slave的db",
    "answer": "步骤五：还会创建一个SQL线程，从relay log里面读取内容，从Exec_Master_Log_Pos位置开始执行读取到的更新事件，将更新内容写入到slave的db",
    "category": "system",
    "difficulty": 3,
    "tags": [
      "MySQL主从复制",
      "SQL线程",
      "Relay Log",
      "Exec_Master_Log_Pos",
      "数据一致性"
    ],
    "followup_points": [
      "1. 当SQL线程执行relay log中的更新事件时，如果遇到主从数据冲突（如主键冲突或唯一键冲突），MySQL会如何处理这种情况？",
      "2. 如果SQL线程在执行relay log时遇到错误（如语法错误或表结构不一致），主从复制会如何恢复？是否需要人工干预？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_049",
    "text": "DATETIME 的日期范围是 1001——9999 年；TIMESTAMP 的时间范围是 1970——2038 年",
    "answer": "DATETIME 的日期范围是 1001——9999 年；TIMESTAMP 的时间范围是 1970——2038 年",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "DATETIME",
      "TIMESTAMP",
      "MySQL",
      "数据类型",
      "日期范围"
    ],
    "followup_points": [
      "1. 在实际业务场景中，如果需要存储超出 TIMESTAMP 范围（如 1970 年之前或 2038 年之后）的时间数据，除了使用 DATETIME，还有哪些替代方案或注意事项？",
      "2. TIMESTAMP 在存储时会自动转换为 UTC 时间，这种特性在分布式系统中可能会带来哪些时区相关问题，如何确保数据一致性？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_050",
    "text": "DATETIME 的默认值为 null；TIMESTAMP 的字段默认不为空(not null)，默认值为当前时间(CURRENT_TIMESTAMP)",
    "answer": "DATETIME 的默认值为 null；TIMESTAMP 的字段默认不为空(not null)，默认值为当前时间(CURRENT_TIMESTAMP)",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "DATETIME",
      "TIMESTAMP",
      "CURRENT_TIMESTAMP",
      "MySQL",
      "数据类型"
    ],
    "followup_points": [
      "1. 如果在 TIMESTAMP 字段上显式设置为 DEFAULT NULL，实际存储行为会是怎样的？是否会自动转为 NOT NULL 并使用 CURRENT_TIMESTAMP？",
      "2. 当更新记录时，TIMESTAMP 字段的值是否会自动更新为当前时间？如何控制这种行为？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_051",
    "text": "原子性：是使用 undo log来实现的，如果事务执行过程中出错或者用户执行了rollback，系统通过undo log日志返回事务开始的状态。",
    "answer": "原子性：是使用 undo log来实现的，如果事务执行过程中出错或者用户执行了rollback，系统通过undo log日志返回事务开始的状态。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "原子性",
      "undo log",
      "事务回滚",
      "事务状态恢复",
      "错误处理"
    ],
    "followup_points": [
      "1. 在使用undo log实现原子性时，如果事务执行过程中系统崩溃，undo log如何确保数据能够正确回滚？",
      "2. undo log在记录回滚信息时，是如何与redo log配合来保证事务的持久性和一致性？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_052",
    "text": "持久性：使用 redo log来实现，只要redo log日志持久化了，当系统崩溃，即可通过redo log把数据恢复。",
    "answer": "持久性：使用 redo log来实现，只要redo log日志持久化了，当系统崩溃，即可通过redo log把数据恢复。",
    "category": "general",
    "difficulty": 2,
    "tags": [
      "持久性",
      "redo log",
      "崩溃恢复",
      "数据恢复",
      "日志持久化"
    ],
    "followup_points": [
      "1. 在MySQL中，redo log的刷盘策略（如innodb_flush_log_at_trx_commit参数的不同配置）是如何影响持久性保证的？",
      "2. 除了redo log，InnoDB还使用undo log来实现事务的回滚，这两者协同工作时，如何确保崩溃恢复过程中数据的一致性和完整性？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_053",
    "text": "redo：在页修改的时候，先写到 redo log buffer 里面， 然后写到 redo log 的文件系统缓存里面(fwrite)，然后再同步到磁盘文件（ fsync）。",
    "answer": "redo：在页修改的时候，先写到 redo log buffer 里面， 然后写到 redo log 的文件系统缓存里面(fwrite)，然后再同步到磁盘文件（ fsync）。",
    "category": "redis",
    "difficulty": 2,
    "tags": [
      "redo log",
      "buffer",
      "fwrite",
      "fsync",
      "刷盘机制"
    ],
    "followup_points": [
      "1. 在 redo log buffer 写入 redo log 文件系统缓存后，是什么触发条件或机制决定何时执行 fsync 将日志同步到磁盘？",
      "2. 如果系统在 redo log 写入文件系统缓存后、fsync 前发生崩溃， redo log 的恢复机制如何确保已修改页的持久性和一致性？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_054",
    "text": "Undo：在 MySQL5.5 之前， undo 只能存放在 ibdata文件里面， 5.6 之后，可以通过设置 innodb_undo_tablespaces 参数把 undo log 存放在 ibdata之外。",
    "answer": "Undo：在 MySQL5.5 之前， undo 只能存放在 ibdata文件里面， 5.6 之后，可以通过设置 innodb_undo_tablespaces 参数把 undo log 存放在 ibdata之外。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "MySQL版本",
      "InnoDB存储引擎",
      "Undo Log",
      "文件存储",
      "参数配置"
    ],
    "followup_points": [
      "1. 在 MySQL5.6 中将 undo log 存放在 ibdata 之外，对系统性能和运维管理有哪些具体优势？",
      "2. 设置 innodb_undo_tablespaces 参数时，需要注意哪些配置细节或潜在问题（如 undo 空间扩展、崩溃恢复等）？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_055",
    "text": "因为事务在修改页时，要先记 undo，在记 undo 之前要记 undo 的 redo， 然后修改数据页，再记数据页修改的 redo。 Redo（里面包括 undo 的修改） 一定要比数据页先持久化到磁盘。",
    "answer": "因为事务在修改页时，要先记 undo，在记 undo 之前要记 undo 的 redo， 然后修改数据页，再记数据页修改的 redo。 Redo（里面包括 undo 的修改） 一定要比数据页先持久化到磁盘。",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "事务",
      "Undo Log",
      "Redo Log",
      "WAL",
      "持久化"
    ],
    "followup_points": [
      "1. 为什么在记 undo 之前需要先记 undo 的 redo？这种设计对崩溃恢复时的数据一致性有什么具体作用？",
      "2. 如果 Redo 日志（包括 undo 的修改）和数据页的持久化顺序发生异常（如 Redo 未完全写入但数据页已持久化），系统如何检测并处理这种不一致的情况？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_056",
    "text": "当事务需要回滚时，因为有 undo，可以把数据页回滚到前镜像的 状态，崩溃恢复时，如果 redo log 中事务没有对应的 commit 记录，那么需要用 undo把该事务的修改回滚到事务开始之前。",
    "answer": "当事务需要回滚时，因为有 undo，可以把数据页回滚到前镜像的 状态，崩溃恢复时，如果 redo log 中事务没有对应的 commit 记录，那么需要用 undo把该事务的修改回滚到事务开始之前。",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "事务回滚",
      "Undo Log",
      "崩溃恢复",
      "Redo Log",
      "ACID"
    ],
    "followup_points": [
      "1. 在崩溃恢复过程中，如何确定 undo log 中哪些记录需要被应用，以及如何保证回滚操作的正确性和一致性？",
      "2. 如果事务在回滚过程中再次发生崩溃，系统如何确保 undo log 的幂等性，避免重复回滚导致数据不一致？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_057",
    "text": "也可以使用 salt（前提是客户端有安装 salt）或者 ansible（ ansible 只需要 ssh 免登通了就行）等多线程工具同时操作多台服务",
    "answer": "也可以使用 salt（前提是客户端有安装 salt）或者 ansible（ ansible 只需要 ssh 免登通了就行）等多线程工具同时操作多台服务",
    "category": "system",
    "difficulty": 2,
    "tags": [
      "自动化运维",
      "SaltStack",
      "Ansible",
      "SSH免密登录",
      "批量管理"
    ],
    "followup_points": [
      "1. 在选择 salt 和 ansible 时，主要会基于哪些具体场景或需求来优先选择其中一个工具？",
      "2. 使用这些多线程工具时，如何确保操作的一致性和错误处理的效率？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-interview_058",
    "text": "组合九：Serializable隔离级别",
    "answer": "组合九：Serializable隔离级别 >作者：Jay_huaxiao >链接：https://juejin.im/post/5ec15ab9f265da7bc60e1910 >来源：掘金 >著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "数据库隔离级别",
      "Serializable",
      "事务并发控制",
      "锁机制",
      "ACID特性"
    ],
    "followup_points": [
      "1. 在Serializable隔离级别下，数据库是如何实现并发控制的，具体采用了哪些锁机制或事务隔离技术？",
      "2. Serializable隔离级别虽然能保证强一致性，但可能会对性能产生较大影响，在实际应用中有哪些优化策略或替代方案来平衡一致性和性能？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-interview.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-index-b-plus_004",
    "text": "聚集索引 VS 非聚集索引",
    "answer": "在上节介绍B+树索引的时候，我们提到了图中的索引其实是聚集索引的实现方式。那什么是聚集索引呢？ 在MySQL中，B+树索引按照存储方式的不同分为聚集索引和非聚集索引。 这里我们着重介绍innodb中的聚集索引和非聚集索引。 1. 聚集索引（聚簇索引）：以innodb作为存储引擎的表，表中的数据都会有一个主键，即使你不创建主键，系统也会帮你创建一个隐式的主键。这是因为innodb是把数据存放在B+树中的，而B+树的键值就是主键，在B+树的叶子节点中，存储了表中所有的数据。这种以主键作为B+树索引的键值而构建的B+树索引，我们称之为聚集索引。 2. 非聚集索引（非聚簇索引）：以主键以外的列值作为键值构建的B+树索引，我们称之为非聚集索引。非聚集索引与聚集索引的区别在于非聚集索引的叶子节点不存储表中的数据，而是存储该列对应的主键，想要查找数据我们还需要根据主键再去聚集索引中进行查找，这个再根据聚集索引查找数据的过程，我们称为回表。 明白了聚集索引和非聚集索引的定义，我们应该明白这样一句话：数据即索引，索引即数据。 # 前面我们讲解B+树索引的时候并没有去说怎么在B+树中进行数据的查找，主要就是因为还没有引出聚集索引和非聚集索引的概念。下面我们通过讲解如何通过聚集索引以及非聚集索引查找数据表中数据的方式介绍一下B+树索引查找数据方法。 利用聚集索引查找数据 ![](../images/zaTh5uayeeT1.webp) 还是这张B+树索引图，现在我们应该知道这就是聚集索引，表中的数据存储在其中。现在假设我们要查找id>=18并且id=18 and id =18 and id <40或者范围值，我们首先需要找到id=18的键值。 从页1中我们可以找到键值18，此时我们需要根据指针p2，定位到页3。 2. 要从页3中查找数据，我们就需要拿着p2指针去磁盘中进行读取页3。 从磁盘中读取页3后将页3放入内存中，然后进行查找，我们可以找到键值18，然后再拿到页3中的指针p1，定位到页8。 3. 同样的页8页不在内存中，我们需要再去磁盘中将页8读取到内存中。 将页8读取到内存中后。因为页中的数据是链表进行连接的，而且键值是按照顺序存放的，此时可以根据二分查找法定位到键值18。 此时因为已经到数据页了，此时我们已经找到一条满足条件的数据了，就是键值18对应的数据。 因为是范围查找，而且此时所有的数据又都存在叶子节点，并且是有序排列的，那么我们就可以对页8中的键值依次进行遍历查找并匹配满足条件的数据。 我们可以一直找到键值为22的数据，然后页8中就没有数据了，此时我们需要拿着页8中的p指针去读取页9中的数据。 4. 因为页9不在内存中，就又会加载页9到内存中，并通过和页8中一样的方式进行数据的查找，直到将页12加载到内存中，发现41大于40，此时不满足条件。那么查找到此终止。 最终我们找到满足条件的所有数据为：`(18,kl),(19,kl),(22,hj),(24,io),(25,vg),(29,jk),(31,jk),(33,rt),(34,ty),(35,yu),(37,rt),(39,rt)` 总共12条记录。 下面看下具体的查找流程图： ![](../images/ieHie2ur2ooh.webp) 利用非聚集索引查找数据 ![](../images/FiaChoSij8ej.webp) 读者看到这张图的时候可能会蒙，这是啥东西啊？怎么都是数字。 如果有这种感觉，请仔细看下图中红字的解释。什么？还看不懂？那我再来解释下吧。首先，这个非聚集索引表示的是用户幸运数字的索引（为什么是幸运数字？一时兴起想起来的:-)），此时表结构是这样的。 |id |name| luckyNum| |----|----|----| 1| zs| 23 2| ls| 7 在叶子节点中，不在存储所有的数据了，存储的是键值和主键。 对于叶子节点中的x-y，比如1-1。左边的1表示的是索引的键值，右边的1表示的是主键值。如果我们要找到幸运数字为33的用户信息，对应的sql语句为select * from user where luckNum=33。 查找的流程跟聚集索引一样，这里就不详细介绍了。我们最终会找到主键值47，找到主键后我们需要再到聚集索引中查找具体对应的数据信息，此时又回到了聚集索引的查找流程。 下面看下具体的查找流程图： ![](../images/giethaD1Eice.webp) 在MyISAM中，聚集索引和非聚集索引的叶子节点都会存储数据的文件地址。",
    "category": "mysql",
    "difficulty": 2,
    "tags": [
      "聚集索引",
      "非聚集索引",
      "B+树",
      "主键",
      "Innodb"
    ],
    "followup_points": [
      "1. 在InnoDB中，如果一个表没有显式定义主键，系统会创建一个隐式主键，这个隐式主键是如何生成的，它对表性能和存储空间有什么影响？",
      "2. 非聚集索引的叶子节点存储的是主键值，这种设计在查询时需要回表操作，能否举例说明什么情况下非聚集索引会导致性能问题，以及如何优化？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-index-b-plus.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_mysql-mvcc_001",
    "text": "MVCC 的实现原理",
    "answer": "MVCC 使用了“三个隐藏字段”来实现版本并发控制，我查了很多资料，看到有很多博客上写的是通过 一个创建事务id字段和一个删除事务id字段 来控制实现的。但后来发现并不是很正确，我们先来看一看 MySQL 在建表的时候 innoDB 创建的真正的三个隐藏列吧。 |RowID |DB_TRX_ID |DB_ROLL_PTR| id| name |password| | ---- | ---- | ---- | ---- | ---- | ----| |自动创建的id |事务id |回滚指针| id| name| password| - RowID：隐藏的自增ID，当建表没有指定主键，InnoDB会使用该RowID创建一个聚簇索引。 - DB_TRX_ID：最近修改（更新/删除/插入）该记录的事务ID。 - DB_ROLL_PTR：回滚指针，指向这条记录的上一个版本。 > 其实还有一个删除的flag字段，用来判断该行记录是否已经被删除。 而 MVCC 使用的是其中的 事务字段，回滚指针字段，是否删除字段。我们来看一下现在的表格(isDelete是我自己取的，按照官方说法是在一行开头的content里面，这里其实位置无所谓，你只要知道有就行了)。 |isDelete |DB_TRX_ID |DB_ROLL_PTR| id |name |password| | ---- | ---- | ---- | ---- | ---- |---- | |true/false| 事务id |回滚指针 |id| name |password| 那么如何通过这三个字段来实现 MVCC 的 可见性算法 呢？ 还差点东西！ undoLog(回滚日志) 和 read-view(读视图)。 - undoLog: 事务的回滚日志，是 可见性算法 的非常重要的部分，分为两类。 - insert undo log：事务在插入新记录产生的undo log，当事务提交之后可以直接丢弃 - update undo log：事务在进行 update 或者 delete 的时候产生的 undo log，在快照读的时候还是需要的，所以不能直接删除，只有当系统没有比这个log更早的read-view了的时候才能删除。ps：所以长事务会产生很多老的视图导致undo log无法删除 大量占用存储空间。 - read-view: 读视图，是MySQL秒级创建视图的必要条件，比如一个事务在进行 select 操作(快照读)的时候会创建一个 read-view ，这个read-view 其实只是三个字段。 - alive_trx_list(我自己取的)：read-view生成时刻系统中正在活跃的事务id。 - up_limit_id：记录上面的 alive_trx_list 中的最小事务id。 - low_limit_id：read-view生成时刻，目前已出现的事务ID的最大值 + 1。 这时候，万事俱备，只欠东风了。下面我来介绍一下，最重要的 可见性算法。 其实主要思路就是：当生成read-view的时候如何去拿获取的 DB_TRX_ID 去和 read-view 中的三个属性(上面讲了)去作比较。我来说一下三个步骤，如果不是很理解可以参考着我后面的实践结合着去理解。 - 首先比较这条记录的 DB_TRX_ID 是否是 小于 up_limit_id 或者 等于当前事务id。如果满足，那么说明当前事务能看到这条记录。如果大于则进入下一轮判断 - 然后判断这条记录的 DB_TRX_ID 是否 大于等于 low-limit-id。如果大于等于则说明此事务无法看见该条记录，不然就进入下一轮判断。 - 判断该条记录的 DB_TRX_ID 是否在活跃事务的数组中，如果在则说明这条记录还未提交对于当前操作的事务是不可见的，如果不在则说明已经提交，那么就是可见的。 > 如果此条记录对于该事务不可见且 ROLL_PTR 不为空那么就会指向回滚指针的地址，通过undolog来查找可见的记录版本。 下面我画了一个可见性的算法的流程图 ![](../images/16dddb3da13ee747.jpg)",
    "category": "mysql",
    "difficulty": 3,
    "tags": [
      "MVCC",
      "隐藏字段",
      "版本控制",
      "InnoDB",
      "事务ID"
    ],
    "followup_points": [
      "1. 您提到“三个隐藏字段”中 RowID 在没有主键时会自动创建，那在有主键的情况下，这三个隐藏字段（特别是 RowID）的行为和存储方式会有什么变化？",
      "2. 在 MVCC 的实现中，DB_TRX_ID 和 DB_ROLL_PTR 是如何协同工作来支持事务的版本控制和回滚的？能否结合一个具体的事务场景（如更新、删除或快照读）详细说明？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/MySQL/mysql-mvcc.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_q019_000",
    "text": "**在方法内把局部变量指针返回** 局部变量原本应该在栈中分配，在栈中回收。但是由于返回时被外部引用，因此其生命周期大于栈，则溢出。",
    "answer": "**在方法内把局部变量指针返回** 局部变量原本应该在栈中分配，在栈中回收。但是由于返回时被外部引用，因此其生命周期大于栈，则溢出。",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "局部变量",
      "指针",
      "栈内存",
      "生命周期",
      "内存溢出"
    ],
    "followup_points": [
      "1. 如果确实需要返回局部变量的指针，有哪些常见的解决方案可以避免栈溢出问题？",
      "2. 在不同的编程语言（如C/C++、Java、Python）中，处理局部变量指针返回的生命周期问题有哪些差异或特定机制？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/q019.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_q019_001",
    "text": "**发送指针或带有指针的值到 channel 中。**  在编译时，是没有办法知道哪个 `goroutine` 会在 `channel` 上接收数据。所以编译器没法知道变量什么时候才会被释放。",
    "answer": "**发送指针或带有指针的值到 channel 中。** 在编译时，是没有办法知道哪个 `goroutine` 会在 `channel` 上接收数据。所以编译器没法知道变量什么时候才会被释放。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Go语言",
      "并发编程",
      "Channel",
      "指针",
      "内存管理"
    ],
    "followup_points": [
      "1. 如果发送到 channel 的是指针，接收方在处理完指针指向的数据后，是否有必要显式地将指针置为 nil？为什么？",
      "2. 在并发场景下，如何确保发送到 channel 的指针指向的数据不会被多个 goroutine 同时修改，从而引发数据竞争问题？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/q019.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_q019_002",
    "text": "**在一个切片上存储指针或带指针的值。** 一个典型的例子就是 `[]*string` 。这会导致切片的内容逃逸。尽管其后面的数组可能是在栈上分配的，但其引用的值一定是在堆上。",
    "answer": "**在一个切片上存储指针或带指针的值。** 一个典型的例子就是 `[]*string` 。这会导致切片的内容逃逸。尽管其后面的数组可能是在栈上分配的，但其引用的值一定是在堆上。",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "Go逃逸分析",
      "切片",
      "指针",
      "内存分配",
      "堆栈"
    ],
    "followup_points": [
      "1. 除了 `[]*string` 之外，还有哪些常见的切片存储指针或带指针值的场景会导致逃逸？",
      "2. 如果切片存储的是指针，如何通过逃逸分析工具（如 `go build -gcflags=-m`）来验证其堆分配情况？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/q019.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_q019_003",
    "text": "**slice 的背后数组被重新分配了，因为 append 时可能会超出其容量( cap )。** slice 初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。",
    "answer": "**slice 的背后数组被重新分配了，因为 append 时可能会超出其容量( cap )。** slice 初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "slice",
      "append",
      "cap",
      "内存分配",
      "栈与堆"
    ],
    "followup_points": [
      "1. 在什么具体场景下，编译器可以确定 slice 的初始化位置在栈上，而什么情况下会直接在堆上分配？",
      "2. 如果 slice 在运行时被频繁 append 且超出容量，频繁的堆分配会对性能产生哪些影响，有哪些优化手段可以减少这种开销？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/q019.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_q019_004",
    "text": "**在 interface 类型上调用方法。**  在 interface 类型上调用方法都是动态调度的 —— 方法的真正实现只能在运行时知道。想像一个 io.Reader 类型的变量 r , 调用 r.Read(b) 会使得 r 的值和切片b 的背后存储都逃逸掉，所以会在堆上分配。",
    "answer": "**在 interface 类型上调用方法。** 在 interface 类型上调用方法都是动态调度的 —— 方法的真正实现只能在运行时知道。想像一个 io.Reader 类型的变量 r , 调用 r.Read(b) 会使得 r 的值和切片b 的背后存储都逃逸掉，所以会在堆上分配。",
    "category": "system",
    "difficulty": 3,
    "tags": [
      "interface",
      "动态调度",
      "方法调用",
      "内存逃逸",
      "堆分配"
    ],
    "followup_points": [
      "1. 除了 io.Reader.Read() 方法外，还有哪些常见的 interface 方法调用会导致变量逃逸到堆上？",
      "2. 在性能敏感的场景下，如何优化 interface 类型上的方法调用以减少堆内存分配？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/q019.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_q019_005",
    "text": "`./main.go:8:10: new(A) escapes to heap` 说明 `new(A)` 逃逸了,符合上述提到的常见情况中的第一种。",
    "answer": "`./main.go:8:10: new(A) escapes to heap` 说明 `new(A)` 逃逸了,符合上述提到的常见情况中的第一种。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "Go逃逸分析",
      "new关键字",
      "内存分配",
      "堆内存",
      "栈内存"
    ],
    "followup_points": [
      "1. 除了第一种情况外，还有哪些常见的 Go 逃逸场景？",
      "2. 逃逸到堆会对程序性能产生哪些影响，如何优化？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/q019.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_q019_006",
    "text": "`./main.go:14:11: main a.s + \" world\" does not escape` 说明 b 变量没有逃逸，因为它只在方法内存在，会在方法结束时被回收。",
    "answer": "`./main.go:14:11: main a.s + \" world\" does not escape` 说明 b 变量没有逃逸，因为它只在方法内存在，会在方法结束时被回收。",
    "category": "general",
    "difficulty": 1,
    "tags": [
      "Go逃逸分析",
      "变量作用域",
      "内存管理",
      "栈分配",
      "垃圾回收"
    ],
    "followup_points": [
      "1. 如果将 `b` 变量作为返回值返回，逃逸分析结果会如何变化？为什么？",
      "2. 逃逸分析对程序性能有什么具体影响？什么情况下需要关注变量的逃逸情况？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/q019.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_q019_007",
    "text": "`./main.go:15:9: b + \"!\" escapes to heap` 说明 c 变量逃逸，通过`fmt.Println(a ...interface{})`打印的变量，都会发生逃逸，感兴趣的朋友可以去查查为什么。",
    "answer": "`./main.go:15:9: b + \"!\" escapes to heap` 说明 c 变量逃逸，通过`fmt.Println(a ...interface{})`打印的变量，都会发生逃逸，感兴趣的朋友可以去查查为什么。 以上操作其实就叫逃逸分析。下篇文章，跟大家聊聊怎么用一个比较trick的方法使变量不逃逸。方便大家在面试官面前秀一波。 >原文",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "Go逃逸分析",
      "fmt.Println",
      "变量逃逸",
      "堆内存分配",
      "性能优化"
    ],
    "followup_points": [
      "1. 除了`fmt.Println`，还有哪些常见的Go语言函数或操作会导致变量逃逸到堆上？",
      "2. 变量逃逸对程序性能有哪些具体影响，以及在实际开发中如何尽量避免不必要的逃逸？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/q019.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_go-scheduler_000",
    "text": "切换机制：如何把挑选出来的goroutine放到CPU上运行？",
    "answer": "切换机制：如何把挑选出来的goroutine放到CPU上运行？ 对这三大问题的解决构成了调度器的所有工作，因而我们对调度器的分析也必将围绕着它们所展开。 第二章我们已经详细的分析了调度器的初始化以及goroutine的切换机制，本章将重点讨论调度器如何挑选下一个goroutine出来运行的策略问题，而剩下的与调度时机相关的内容我们将在第4～6章进行全面的分析。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Goroutine调度",
      "CPU调度",
      "调度策略",
      "调度时机",
      "上下文切换"
    ],
    "followup_points": [
      "1. 调度器在挑选goroutine时，具体采用了哪些策略来优先选择高优先级或I/O密集型的任务？",
      "2. 在多核环境下，调度器如何确保goroutine在CPU核心间的负载均衡，避免某些核心过载而其他核心空闲？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/go-scheduler.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_go-scheduler_001",
    "text": "第一步，从全局运行队列中寻找goroutine。为了保证调度的公平性，每个工作线程每经过61次调度就需要优先尝试从全局运行队列中找出一个goroutine来运行，这样才能保证位于全局运行队列中的goroutine得到调度的机会。全局运行队列是所有工作线程都可以访问的，所以在访问它之前需要加锁。",
    "answer": "第一步，从全局运行队列中寻找goroutine。为了保证调度的公平性，每个工作线程每经过61次调度就需要优先尝试从全局运行队列中找出一个goroutine来运行，这样才能保证位于全局运行队列中的goroutine得到调度的机会。全局运行队列是所有工作线程都可以访问的，所以在访问它之前需要加锁。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Goroutine调度",
      "全局运行队列",
      "工作线程",
      "调度公平性",
      "锁机制"
    ],
    "followup_points": [
      "1. 为什么选择61次调度作为从全局运行队列中获取goroutine的阈值？这个数字是如何确定的，是否存在理论依据或性能考量？",
      "2. 在全局运行队列加锁的情况下，如何避免锁竞争对调度性能的影响？是否有其他优化策略（如分段锁、无锁队列等）来减少锁争用？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/go-scheduler.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_go-scheduler_002",
    "text": "第二步，从工作线程本地运行队列中寻找goroutine。如果不需要或不能从全局运行队列中获取到goroutine则从本地运行队列中获取。",
    "answer": "第二步，从工作线程本地运行队列中寻找goroutine。如果不需要或不能从全局运行队列中获取到goroutine则从本地运行队列中获取。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Goroutine调度",
      "工作窃取",
      "本地运行队列",
      "全局运行队列",
      "调度器"
    ],
    "followup_points": [
      "1. 为什么在本地运行队列中寻找goroutine时，需要判断\"不需要或不能从全局运行队列中获取\"？这个判断的具体逻辑是什么？",
      "2. 如果本地运行队列和全局运行队列都没有可用的goroutine，工作线程会如何处理？会进入什么状态或采取什么后续策略？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/go-scheduler.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_go-scheduler_003",
    "text": "第三步，从其它工作线程的运行队列中偷取goroutine。如果上一步也没有找到需要运行的goroutine，则调用findrunnable从其他工作线程的运行队列中偷取goroutine，findrunnable函数在偷取之前会再次尝试从全局运行队列和当前线程的本地运行队列中查找需要运行的goroutine。",
    "answer": "第三步，从其它工作线程的运行队列中偷取goroutine。如果上一步也没有找到需要运行的goroutine，则调用findrunnable从其他工作线程的运行队列中偷取goroutine，findrunnable函数在偷取之前会再次尝试从全局运行队列和当前线程的本地运行队列中查找需要运行的goroutine。 下面我们先来看如何从全局运行队列中获取goroutine。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Goroutine调度",
      "工作窃取",
      "运行队列",
      "全局运行队列",
      "本地运行队列"
    ],
    "followup_points": [
      "1. findrunnable函数在从其他工作线程的运行队列中偷取goroutine时，是如何选择目标工作线程的？是否有特定的策略或优先级规则？",
      "2. 在偷取过程中，如果多个工作线程同时尝试从同一个目标线程的运行队列中偷取goroutine，Go runtime是如何避免竞争或数据不一致的问题的？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/go-scheduler.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_go-scheduler_004",
    "text": "位于`atomic.LoadAcq`之后的代码，对内存的读取和写入必须在`atomic.LoadAcq`读取完成后才能执行，编译器和CPU都不能打乱这个顺序；",
    "answer": "位于`atomic.LoadAcq`之后的代码，对内存的读取和写入必须在`atomic.LoadAcq`读取完成后才能执行，编译器和CPU都不能打乱这个顺序；",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "内存屏障",
      "原子操作",
      "内存顺序",
      "编译器优化",
      "CPU乱序执行"
    ],
    "followup_points": [
      "1. 如果在`atomic.LoadAcq`之后插入一个普通的内存读写操作，编译器或CPU是否会尝试将其优化到`atomic.LoadAcq`之前，从而破坏内存顺序？",
      "2. 在多线程环境下，如果另一个线程通过`atomic.StoreRel`写入数据，`atomic.LoadAcq`是否能保证一定能看到这个最新的写入，还是需要额外的同步机制？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/go-scheduler.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_go-scheduler_005",
    "text": "当前线程执行`atomic.LoadAcq`时可以读取到其它线程最近一次通过`atomic.CasRel`对同一个变量写入的值，与此同时，位于`atomic.LoadAcq`之后的代码，不管读取哪个内存地址中的值，都可以读取到其它线程中位于atomic.CasRel（对同一个变量操作）之前的代码最近一次对内存的写入。",
    "answer": "当前线程执行`atomic.LoadAcq`时可以读取到其它线程最近一次通过`atomic.CasRel`对同一个变量写入的值，与此同时，位于`atomic.LoadAcq`之后的代码，不管读取哪个内存地址中的值，都可以读取到其它线程中位于atomic.CasRel（对同一个变量操作）之前的代码最近一次对内存的写入。",
    "category": "system",
    "difficulty": 5,
    "tags": [
      "原子操作",
      "内存屏障",
      "内存序",
      "Acquire语义",
      "Release语义"
    ],
    "followup_points": [
      "1. 如果在`atomic.LoadAcq`和后续代码之间插入一个普通的非原子操作（如变量赋值），是否会影响内存可见性的保证？为什么？",
      "2. 如果多个线程同时执行`atomic.CasRel`和`atomic.LoadAcq`，是否存在竞争条件导致内存可见性失效？如何确保正确性？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/go-scheduler.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_go-scheduler_006",
    "text": "位于`atomic.CasRel`之前的代码，对内存的读取和写入必须在`atomic.CasRel`对内存的写入之前完成，编译器和CPU都不能打乱这个顺序；",
    "answer": "位于`atomic.CasRel`之前的代码，对内存的读取和写入必须在`atomic.CasRel`对内存的写入之前完成，编译器和CPU都不能打乱这个顺序；",
    "category": "general",
    "difficulty": 3,
    "tags": [
      "内存屏障",
      "原子操作",
      "内存顺序",
      "编译器优化",
      "CPU乱序执行"
    ],
    "followup_points": [
      "1. 如果在`atomic.CasRel`之前有多个内存读写操作，编译器和CPU是否会以何种顺序保证这些操作之间的相对顺序？",
      "2. 如果`atomic.CasRel`之前的代码中包含非原子操作（如普通变量的读写），这些操作与`atomic.CasRel`之间的内存顺序是否仍然会被严格保证？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/go-scheduler.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_go-scheduler_007",
    "text": "线程执行`atomic.CasRel`完成后其它线程通过`atomic.LoadAcq`读取同一个变量可以读到最新的值，与此同时，位于`atomic.CasRel`之前的代码对内存写入的值，可以被其它线程中位于`atomic.LoadAcq`（对同一个变量操作）之后的代码读取到。",
    "answer": "线程执行`atomic.CasRel`完成后其它线程通过`atomic.LoadAcq`读取同一个变量可以读到最新的值，与此同时，位于`atomic.CasRel`之前的代码对内存写入的值，可以被其它线程中位于`atomic.LoadAcq`（对同一个变量操作）之后的代码读取到。 因为可能有多个线程会并发的修改和读取`runqhead`，以及需要依靠runqhead的值来读取runq数组的元素，所以需要使用atomic.LoadAcq和atomic.CasRel来保证上述语义。 我们可能会问，为什么读取p的runqtail成员不需要使用atomic.LoadAcq或atomic.load？因为runqtail不会被其它线程修改，只会被当前工作线程修改，此时没有人修改它，所以也就不需要使用原子相关的操作。 最后，由`p`的`runq`、`runqhead`和`runqtail`这三个成员组成的这个无锁循环队列非常精妙，我们会在后面的章节对这个循环队列进行分析。",
    "category": "system",
    "difficulty": 3,
    "tags": [
      "原子操作",
      "内存屏障",
      "内存顺序",
      "并发编程",
      "Go语言"
    ],
    "followup_points": [
      "1. 为什么读取p的runqtail成员不需要使用atomic.LoadAcq或atomic.load？",
      "2. 在并发场景下，如果多个线程同时修改runqhead和runqtail，如何确保runqtail的读取不会导致数据竞争或不一致？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/go-scheduler.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_go-scheduler-base_000",
    "text": "goroutine简介",
    "answer": "goroutine是Go语言实现的用户态线程，主要用来解决操作系统线程太“重”的问题，所谓的太重，主要表现在以下两个方面： - 创建和切换太重：操作系统线程的创建和切换都需要进入内核，而进入内核所消耗的性能代价比较高，开销较大； - 内存使用太重：一方面，为了尽量避免极端情况下操作系统线程栈的溢出，内核在创建操作系统线程时默认会为其分配一个较大的栈内存（虚拟地址空间，内核并不会一开始就分配这么多的物理内存），然而在绝大多数情况下，系统线程远远用不了这么多内存，这导致了浪费；另一方面，栈内存空间一旦创建和初始化完成之后其大小就不能再有变化，这决定了在某些特殊场景下系统线程栈还是有溢出的风险。 而相对的，用户态的goroutine则轻量得多： - goroutine是用户态线程，其创建和切换都在用户代码中完成而无需进入操作系统内核，所以其开销要远远小于系统线程的创建和切换； - goroutine启动时默认栈大小只有2k，这在多数情况下已经够用了，即使不够用，goroutine的栈也会自动扩大，同时，如果栈太大了过于浪费它还能自动收缩，这样既没有栈溢出的风险，也不会造成栈内存空间的大量浪费。 正是因为Go语言中实现了如此轻量级的线程，才使得我们在Go程序中，可以轻易的创建成千上万甚至上百万的goroutine出来并发的执行任务而不用太担心性能和内存等问题。 **注意：** 为了避免混淆，从现在开始，后面出现的所有的线程一词均是指操作系统线程，而goroutine我们不再称之为什么什么线程而是直接使用goroutine这个词。",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "并发编程",
      "用户态线程",
      "Go语言",
      "线程开销",
      "内存管理"
    ],
    "followup_points": [
      "1. goroutine的调度机制是如何实现轻量级切换的，与操作系统线程调度有何不同？",
      "2. goroutine的栈内存是如何实现动态扩缩容的，具体是如何解决初始栈浪费和溢出风险的？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/go-scheduler-base.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_q015_000",
    "text": "golang 并发题目测试",
    "answer": "题目来源： [Go并发编程小测验： 你能答对几道题？](https://colobu.com/2019/04/28/go-concurrency-quizzes/) # - A: 不能编译 - B: 输出 main --> A --> B --> C - C: 输出 main - D: panic # - A: 不能编译 - B: 输出 1 - C: 程序hang住 - D: panic # - A: 不能编译 - B: 无输出，正常退出 - C: 程序hang住 - D: panic # - A: 不能编译 - B: 可以编译，正确实现了单例 - C: 可以编译，有并发问题，f函数可能会被执行多次 - D: 可以编译，但是程序运行会panic # - A: 不能编译 - B: 输出 1, 1 - C: 输出 1, 2 - D: panic # - A: 不能编译 - B: 可以编译，运行时正常，内存稳定 - C: 可以编译，运行时内存可能暴涨 - D: 可以编译，运行时内存先暴涨，但是过一会会回收掉 # - A: 不能编译 - B: 一段时间后总是输出 `#goroutines: 1` - C: 一段时间后总是输出 `#goroutines: 2` - D: panic # - A: 不能编译 - B: 输出 1 - C: 输出 0 - D: panic # - A: 不能编译 - B: 输出 1 - C: 输出 0 - D: panic # - A: 不能编译 - B: 输出 1 - C: 输出 0 - D: panic",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "golang并发",
      "goroutine",
      "channel",
      "sync",
      "竞态条件"
    ],
    "followup_points": [
      "1. 在第一个题目中，如果将 `defer` 语句放在 `go` 关键字之前，程序的输出会有什么变化？",
      "2. 第二个题目中，如果将 `ch := make(chan int)` 改为 `ch := make(chan int, 1)`，程序的执行结果会怎样？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/q015.md",
    "code_examples": [
      {
        "code": "package main\nimport (\n\t\"fmt\"\n\t\"sync\"\n)\nvar mu sync.Mutex\nvar chain string\nfunc main() {\n\tchain = \"main\"\n\tA()\n\tfmt.Println(chain)\n}\nfunc A() {\n\tmu.Lock()\n\tdefer mu.Unlock()\n\tchain = chain + \" --> A\"\n\tB()\n}\nfunc B() {\n\tchain = chain + \" --> B\"\n\tC()\n}\nfunc C() {\n\tmu.Lock()\n\tdefer mu.Unlock()\n\tchain = chain + \" --> C\"\n}",
        "language": "go"
      },
      {
        "code": "package main\nimport (\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n)\nvar mu sync.RWMutex\nvar count int\nfunc main() {\n\tgo A()\n\ttime.Sleep(2 * time.Second)\n\tmu.Lock()\n\tdefer mu.Unlock()\n\tcount++\n\tfmt.Println(count)\n}\nfunc A() {\n\tmu.RLock()\n\tdefer mu.RUnlock()\n\tB()\n}\nfunc B() {\n\ttime.Sleep(5 * time.Second)\n\tC()\n}\nfunc C() {\n\tmu.RLock()\n\tdefer mu.RUnlock()\n}",
        "language": "go"
      },
      {
        "code": "package main\nimport (\n\t\"sync\"\n\t\"time\"\n)\nfunc main() {\n\tvar wg sync.WaitGroup\n\twg.Add(1)\n\tgo func() {\n\t\ttime.Sleep(time.Millisecond)\n\t\twg.Done()\n\t\twg.Add(1)\n\t}()\n\twg.Wait()\n}",
        "language": "go"
      },
      {
        "code": "package doublecheck\nimport (\n\t\"sync\"\n)\ntype Once struct {\n\tm    sync.Mutex\n\tdone uint32\n}\nfunc (o *Once) Do(f func()) {\n\tif o.done == 1 {\n\t\treturn\n\t}\n\to.m.Lock()\n\tdefer o.m.Unlock()\n\tif o.done == 0 {\n\t\to.done = 1\n\t\tf()\n\t}\n}",
        "language": "go"
      },
      {
        "code": "package main\nimport (\n\t\"fmt\"\n\t\"sync\"\n)\ntype MyMutex struct {\n\tcount int\n\tsync.Mutex\n}\nfunc main() {\n\tvar mu MyMutex\n\tmu.Lock()\n\tvar mu2 = mu\n\tmu.count++\n\tmu.Unlock()\n\tmu2.Lock()\n\tmu2.count++\n\tmu2.Unlock()\n\tfmt.Println(mu.count, mu2.count)\n}",
        "language": "go"
      },
      {
        "code": "package main\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"runtime\"\n\t\"sync\"\n\t\"time\"\n)\nvar pool = sync.Pool{New: func() interface{} { return new(bytes.Buffer) }}\nfunc main() {\n\tgo func() {\n\t\tfor {\n\t\t\tprocessRequest(1 << 28) // 256MiB\n\t\t}\n\t}()\n\tfor i := 0; i < 1000; i++ {\n\t\tgo func() {\n\t\t\tfor {\n\t\t\t\tprocessRequest(1 << 10) // 1KiB\n\t\t\t}\n\t\t}()\n\t}\n\tvar stats runtime.MemStats\n\tfor i := 0; ; i++ {\n\t\truntime.ReadMemStats(&stats)\n\t\tfmt.Printf(\"Cycle %d: %dB\\n\", i, stats.Alloc)\n\t\ttime.Sleep(time.Second)\n\t\truntime.GC()\n\t}\n}\nfunc processRequest(size int) {\n\tb := pool.Get().(*bytes.Buffer)\n\ttime.Sleep(500 * time.Millisecond)\n\tb.Grow(size)\n\tpool.Put(b)\n\ttime.Sleep(1 * time.Millisecond)\n}",
        "language": "go"
      },
      {
        "code": "package main\nimport (\n\t\"fmt\"\n\t\"runtime\"\n\t\"time\"\n)\nfunc main() {\n\tvar ch chan int\n\tgo func() {\n\t\tch = make(chan int, 1)\n\t\tch <- 1\n\t}()\n\tgo func(ch chan int) {\n\t\ttime.Sleep(time.Second)\n\t\t<-ch\n\t}(ch)\n\tc := time.Tick(1 * time.Second)\n\tfor range c {\n\t\tfmt.Printf(\"#goroutines: %d\\n\", runtime.NumGoroutine())\n\t}\n}",
        "language": "go"
      },
      {
        "code": "package main\nimport \"fmt\"\nfunc main() {\n\tvar ch chan int\n\tvar count int\n\tgo func() {\n\t\tch <- 1\n\t}()\n\tgo func() {\n\t\tcount++\n\t\tclose(ch)\n\t}()\n\t<-ch\n\tfmt.Println(count)\n}",
        "language": "go"
      },
      {
        "code": "package main\nimport (\n\t\"fmt\"\n\t\"sync\"\n)\nfunc main() {\n\tvar m sync.Map\n\tm.LoadOrStore(\"a\", 1)\n\tm.Delete(\"a\")\n\tfmt.Println(m.Len())\n}",
        "language": "go"
      },
      {
        "code": "package main\nvar c = make(chan int)\nvar a int\nfunc f() {\n\ta = 1\n\t<-c\n}\nfunc main() {\n\tgo f()\n\tc <- 0\n\tprint(a)\n}",
        "language": "go"
      }
    ]
  },
  {
    "id": "backend-interview_Go 语言 map 如何顺序读取？_000",
    "text": "[Go 语言 map 是并发安全的吗？](https://mp.weixin.qq.com/s/4mDzMdMbunR_p94Du65QOA)",
    "answer": "[Go 语言 map 是并发安全的吗？](https://mp.weixin.qq.com/s/4mDzMdMbunR_p94Du65QOA)",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "Go语言",
      "并发安全",
      "map",
      "数据竞争",
      "sync.Map"
    ],
    "followup_points": [
      "1. 如果需要在并发场景下安全地使用 Go 的 map，有哪些常见的解决方案？各自的优缺点是什么？",
      "2. Go 1.9 引入的 `sync.Map` 与原生 map + `sync.RWMutex` 相比，在哪些场景下性能更优？哪些场景下可能反而不如后者？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/Go 语言 map 如何顺序读取？.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_Go 语言 map 如何顺序读取？_001",
    "text": "[Go 语言切片是如何扩容的？](https://mp.weixin.qq.com/s/VVM8nqs4mMGdFyCNJx16_g)",
    "answer": "[Go 语言切片是如何扩容的？](https://mp.weixin.qq.com/s/VVM8nqs4mMGdFyCNJx16_g)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Go语言",
      "切片",
      "扩容机制",
      "内存分配",
      "算法策略"
    ],
    "followup_points": [
      "1. 如果扩容后的容量超过原容量的两倍，Go 的扩容策略为什么会选择 `max(newCap, cap*2)` 这样的规则，而不是直接采用固定的增长比例？这种设计在内存分配和性能上有什么权衡？",
      "2. 在扩容过程中，如果切片的元素类型包含指针或引用类型（如 `[]*struct`），扩容后的内存布局是否会影响原有元素的引用关系？是否存在潜在的内存泄漏或数据一致性问题？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/Go 语言 map 如何顺序读取？.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_Go 语言 map 如何顺序读取？_002",
    "text": "[Go 语言数组和切片的区别](https://mp.weixin.qq.com/s/esaAmAdmV4w3_qjtAzTr4A)",
    "answer": "[Go 语言数组和切片的区别](https://mp.weixin.qq.com/s/esaAmAdmV4w3_qjtAzTr4A)",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "Go语言基础",
      "数组",
      "切片",
      "内存布局",
      "长度与容量"
    ],
    "followup_points": [
      "1. 在函数参数传递时，数组作为参数和切片作为参数有什么区别？",
      "2. 切片的扩容机制是怎样的？底层是如何实现的？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/Go 语言 map 如何顺序读取？.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_Go 语言 map 如何顺序读取？_003",
    "text": "[Go 语言 new 和 make 关键字的区别](https://mp.weixin.qq.com/s/NBDkI3roHgNgW1iW4e_6cA)",
    "answer": "[Go 语言 new 和 make 关键字的区别](https://mp.weixin.qq.com/s/NBDkI3roHgNgW1iW4e_6cA)",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "Go语言关键字",
      "内存分配",
      "内置函数",
      "new关键字",
      "make关键字"
    ],
    "followup_points": [
      "1. 在什么场景下，使用 `new` 来初始化切片、map 或 channel 会比直接使用字面量（如 `slice := []int{}`）更合适？",
      "2. 如果尝试对 `new` 返回的指针类型调用 `make`（如 `newSlice := new([]int); make(*newSlice, 10)`），编译器会如何报错？正确的操作应该是什么？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/Go 语言 map 如何顺序读取？.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_Go 语言 map 如何顺序读取？_004",
    "text": "[为什么 Go 不支持 \\[\\]T 转换为 \\[\\]interface](https://mp.weixin.qq.com/s/cwDEgnicK4jkuNpzulU2bw)",
    "answer": "[为什么 Go 不支持 \\[\\]T 转换为 \\[\\]interface](https://mp.weixin.qq.com/s/cwDEgnicK4jkuNpzulU2bw)",
    "category": "network",
    "difficulty": 3,
    "tags": [
      "Go语言类型系统",
      "接口类型转换",
      "切片类型转换",
      "类型安全",
      "内存布局"
    ],
    "followup_points": [
      "1. 如果 Go 支持 `[]T` 转换为 `[]interface{}`，可能会带来哪些具体的运行时安全问题或性能损耗？",
      "2. 在实际开发中，如果确实需要将 `[]T` 转换为 `[]interface{}`，有哪些推荐的替代方案或最佳实践？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/Go 语言 map 如何顺序读取？.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_Go 语言 map 如何顺序读取？_005",
    "text": "[为什么 Go 语言 struct 要使用 tags](https://mp.weixin.qq.com/s/L7-TJ-CzYfuVrIBWP7Ebaw)",
    "answer": "[为什么 Go 语言 struct 要使用 tags](https://mp.weixin.qq.com/s/L7-TJ-CzYfuVrIBWP7Ebaw)",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "Go struct tags",
      "序列化与反序列化",
      "JSON 编码",
      "ORM 映射",
      "反射机制"
    ],
    "followup_points": [
      "1. 在 Go 的标准库中，`encoding/json` 和 `database/sql` 包都广泛使用了 struct tags，能否举例说明这两个包中 tags 的具体应用场景及其设计差异？",
      "2. 如果需要在自定义类型（如自定义 struct 或第三方库类型）中实现类似 tags 的功能，有哪些可行的扩展方案或最佳实践？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/Go 语言 map 如何顺序读取？.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_q021_000",
    "text": "说明 `http.Get` 默认使用 `DefaultTransport` 管理连接。",
    "answer": "说明 `http.Get` 默认使用 `DefaultTransport` 管理连接。 DefaultTransport 是干嘛的呢？",
    "category": "network",
    "difficulty": 2,
    "tags": [
      "http.Get",
      "DefaultTransport",
      "连接管理",
      "HTTP客户端",
      "Transport"
    ],
    "followup_points": [
      "1. DefaultTransport 的核心配置参数有哪些，这些参数如何影响连接管理行为？",
      "2. DefaultTransport 如何处理连接池（如最大空闲连接数、连接复用逻辑）？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/q021.md",
    "code_examples": [
      {
        "code": "// It establishes network connections as needed\n// and caches them for reuse by subsequent calls.",
        "language": "go"
      }
    ]
  },
  {
    "id": "backend-interview_q021_001",
    "text": "`DefaultTransport` 的作用是根据需要建立网络连接并缓存它们以供后续调用重用。",
    "answer": "`DefaultTransport` 的作用是根据需要建立网络连接并缓存它们以供后续调用重用。 那么 `DefaultTransport` 什么时候会建立连接呢？ 接着上面的代码堆栈往下翻 ```go func send(ireq *Request, rt RoundTripper, deadline time.Time)",
    "category": "redis",
    "difficulty": 2,
    "tags": [
      "网络连接池",
      "HTTP客户端",
      "连接复用",
      "RoundTripper",
      "连接建立时机"
    ],
    "followup_points": [
      "1. 在 `send` 函数中，`DefaultTransport` 是如何判断当前是否需要建立新连接的？",
      "2. 如果 `DefaultTransport` 发现连接池中没有可用的连接，它会通过什么机制来创建新的连接？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/q021.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_q021_002",
    "text": "一次建立连接，就会启动一个读goroutine和写goroutine。这就是为什么一次`http.Get()`会泄漏两个goroutine的来源。",
    "answer": "一次建立连接，就会启动一个读goroutine和写goroutine。这就是为什么一次`http.Get()`会泄漏两个goroutine的来源。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Go并发",
      "goroutine",
      "HTTP连接",
      "资源泄漏",
      "Go语言特性"
    ],
    "followup_points": [
      "1. 在什么情况下，这两个goroutine会正常结束而不是泄漏？",
      "2. 除了读goroutine和写goroutine，是否还有其他潜在的goroutine泄漏场景？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/q021.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_q021_003",
    "text": "如果执行 earlyCloseFn ，waitForBodyRead 通道输入的是 false，alive 也会是 false，那 readLoop() 这个 goroutine 就会退出。",
    "answer": "如果执行 earlyCloseFn ，waitForBodyRead 通道输入的是 false，alive 也会是 false，那 readLoop() 这个 goroutine 就会退出。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Goroutine生命周期控制",
      "通道通信",
      "布尔值状态管理",
      "函数指针调用",
      "并发控制"
    ],
    "followup_points": [
      "1. 在 readLoop() 退出后，是否有其他 goroutine 或机制负责清理与该连接相关的资源（如缓冲区、上下文等）？",
      "2. 如果 earlyCloseFn 被多次触发，或者 waitForBodyRead 通道的 false 被重复发送，是否存在竞态条件或重复退化的风险？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/q021.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_q021_004",
    "text": "如果执行 fn ，其中包括正常情况下 body 读完数据抛出 io.EOF 时的 case，waitForBodyRead 通道输入的是 true，那 alive 会是 true，那么 readLoop() 这个 goroutine 就不会退出，同时还顺便执行了 tryPutIdleConn(trace) 。",
    "answer": "如果执行 fn ，其中包括正常情况下 body 读完数据抛出 io.EOF 时的 case，waitForBodyRead 通道输入的是 true，那 alive 会是 true，那么 readLoop() 这个 goroutine 就不会退出，同时还顺便执行了 tryPutIdleConn(trace) 。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Goroutine生命周期管理",
      "通道通信",
      "io.EOF错误处理",
      "连接池管理",
      "HTTP请求处理流程"
    ],
    "followup_points": [
      "1. 在 readLoop() 不会退出的情况下，后续的请求复用该连接时，如何确保 waitForBodyRead 通道的信号被正确消费，避免 goroutine 阻塞？",
      "2. tryPutIdleConn(trace) 执行时，如果连接池已满或连接不可用，具体会采取什么策略处理该连接？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/q021.md",
    "code_examples": [
      {
        "code": "// tryPutIdleConn adds pconn to the list of idle persistent connections awaiting\n// a new request.\n// If pconn is no longer needed or not in a good state, tryPutIdleConn returns\n// an error explaining why it wasn't registered.\n// tryPutIdleConn does not close pconn. Use putOrCloseIdleConn instead for that.\nfunc (t *Transport) tryPutIdleConn(pconn *persistConn) error",
        "language": "go"
      }
    ]
  },
  {
    "id": "backend-interview_q021_005",
    "text": "tryPutIdleConn 将 pconn 添加到等待新请求的空闲持久连接列表中，也就是之前说的连接会复用。",
    "answer": "es.mu.Lock() defer es.mu.Unlock() if es.closed { return nil } es.closed = true if es.earlyCloseFn != nil && es.rerr != io.EOF { return es.earlyCloseFn() // 关闭时执行 earlyCloseFn } err := es.body.Close() return es.condfn(err)",
    "category": "system",
    "difficulty": 2,
    "tags": [
      "互斥锁 (Mutex)",
      "连接复用 (Connection Reuse)",
      "资源关闭 (Resource Closing)",
      "错误处理 (Error Handling)",
      "条件函数 (Conditional Function)"
    ],
    "followup_points": [
      "1. 在 `tryPutIdleConn` 中，如何确保并发安全地管理空闲连接列表，避免竞态条件？",
      "2. 如果 `es.closed` 为 true 时，为什么直接返回 nil 而不是执行其他清理逻辑？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/q021.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_q021_006",
    "text": "这个`read`，其实就是 `bodyEOFSignal` 里的",
    "answer": "... n, err = es.body.Read(p) if err != nil { ... // 这里会有一个io.EOF的报错，意思是读完了 err = es.condfn(err) } return if es.fn == nil { return err } err = es.fn(err) // 这了执行了 fn es.fn = nil return err",
    "category": "system",
    "difficulty": 1,
    "tags": [
      "Go语言",
      "错误处理",
      "io.EOF",
      "条件函数",
      "函数指针"
    ],
    "followup_points": [
      "1. 在 `err = es.condfn(err)` 这一步，`condfn` 函数具体是如何处理 `io.EOF` 错误的？是否会改变错误类型或添加额外上下文信息？",
      "2. 当 `es.fn` 不为空时，执行 `es.fn(err)` 后立即将 `es.fn` 置为 `nil`，这种设计是为了确保 `fn` 只执行一次吗？是否有其他潜在的场景需要考虑 `fn` 的重复执行或状态管理？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/q021.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_q021_007",
    "text": "上面这个其实就是我们比较收悉的读取 body 里的内容。 ioutil.ReadAll() ,在读完 body 的内容时会执行 fn，也就是此时 readLoop() 里的 waitForBodyRead 通道输入的是 true，alive 也会是 true，那 readLoop() 这个 goroutine 就不会退出，goroutine 会泄露，然后执行 tryPutIdleConn(trace) 把连接放回池子里复用。",
    "answer": "上面这个其实就是我们比较收悉的读取 body 里的内容。 ioutil.ReadAll() ,在读完 body 的内容时会执行 fn，也就是此时 readLoop() 里的 waitForBodyRead 通道输入的是 true，alive 也会是 true，那 readLoop() 这个 goroutine 就不会退出，goroutine 会泄露，然后执行 tryPutIdleConn(trace) 把连接放回池子里复用。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Goroutine泄漏",
      "HTTP连接池",
      "ioutil.ReadAll",
      "readLoop",
      "waitForBodyRead"
    ],
    "followup_points": [
      "1. 在 readLoop() 中，除了 waitForBodyRead 通道输入 true 会导致 goroutine 不退出外，还有其他哪些场景或条件可能导致 goroutine 泄露？",
      "2. tryPutIdleConn(trace) 将连接放回池子复用时，是否有机制检测或防止已泄露的 goroutine 所持有的连接被错误复用？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/q021.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_q021_008",
    "text": "所以结论呼之欲出了，虽然执行了 6 次循环，而且每次都没有执行 Body.Close() ,就是因为执行了ioutil.ReadAll()把内容都读出来了，连接得以复用，因此只泄漏了一个读goroutine和一个写goroutine，最后加上main goroutine，所以答案就是3个goroutine。",
    "answer": "所以结论呼之欲出了，虽然执行了 6 次循环，而且每次都没有执行 Body.Close() ,就是因为执行了ioutil.ReadAll()把内容都读出来了，连接得以复用，因此只泄漏了一个读goroutine和一个写goroutine，最后加上main goroutine，所以答案就是3个goroutine。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Goroutine泄漏",
      "HTTP连接复用",
      "ioutil.ReadAll",
      "Body.Close",
      "并发模型"
    ],
    "followup_points": [
      "1. 在连接复用的情况下，ioutil.ReadAll()是如何确保连接被正确关闭的？如果读取过程中发生错误，连接是否会被正确释放？",
      "2. 如果循环中改用io.ReadAll()而不调用Body.Close()，是否还会出现goroutine泄漏？为什么？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/q021.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_q021_009",
    "text": "从另外一个角度说，正常情况下我们的代码都会执行 ioutil.ReadAll()，但如果此时忘了 resp.Body.Close()，确实会导致泄漏。但如果你调用的域名一直是同一个的话，那么只会泄漏一个 读goroutine 和一个写goroutine，这就是为什么代码明明不规范但却看不到明显内存泄漏的原因。",
    "answer": "从另外一个角度说，正常情况下我们的代码都会执行 ioutil.ReadAll()，但如果此时忘了 resp.Body.Close()，确实会导致泄漏。但如果你调用的域名一直是同一个的话，那么只会泄漏一个 读goroutine 和一个写goroutine，这就是为什么代码明明不规范但却看不到明显内存泄漏的原因。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "Go",
      "HTTP",
      "ioutil.ReadAll",
      "goroutine",
      "内存泄漏"
    ],
    "followup_points": [
      "1. 如果调用的域名不同，泄漏的goroutine数量会如何变化？是否会导致更严重的内存泄漏问题？",
      "2. 除了goroutine泄漏，未关闭resp.Body还会带来其他潜在风险（如文件描述符耗尽）吗？如何验证这些风险？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/q021.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_q021_010",
    "text": "那么问题又来了，为什么上面要特意强调是同一个域名呢？改天，回头，以后有空再说吧。",
    "answer": "那么问题又来了，为什么上面要特意强调是同一个域名呢？改天，回头，以后有空再说吧。 >作者：9號同学 链接：https://juejin.cn/post/6896993332019822605 来源：掘金 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 作者：9號同学 链接：https://juejin.cn/post/6896993332019822605 来源：掘金 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。",
    "category": "network",
    "difficulty": 1,
    "tags": [
      "浏览器安全",
      "同源策略",
      "Cookie",
      "跨域",
      "HTTP协议"
    ],
    "followup_points": [
      "1. 如果不是同一个域名，可能会遇到哪些具体的安全或跨域问题？",
      "2. 同一个域名下的不同子域名（如 a.example.com 和 b.example.com）是否会被视为同一个域名？为什么？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/q021.md",
    "code_examples": []
  },
  {
    "id": "backend-interview_q014_001",
    "text": "写出以下打印结果，并解释下为什么这么打印的。",
    "answer": "golang 中的切片底层其实使用的是数组。当使用`str1[1:]` 使，`str2` 和 `str1` 底层共享一个数组，这回导致 `str2[1] = \"new\"` 语句影响 `str1`。 而 `append` 会导致底层数组扩容，生成新的数组，因此追加数据后的 `str2` 不会影响 `str1`。 但是为什么对 `str2` 复制后影响的确实 `str1` 的第三个元素呢？这是因为切片 `str2` 是从数组的第二个元素开始，`str2` 索引为 1 的元素对应的是 `str1` 索引为 2 的元素。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "golang切片",
      "切片底层数组",
      "切片共享内存",
      "append扩容",
      "切片索引偏移"
    ],
    "followup_points": [
      "1. 在切片扩容时，Go 底层是如何决定新数组的容量的？是基于当前容量的某个增长因子吗？",
      "2. 如果在创建切片时显式指定容量（如 `str2 := make([]string, 2, 5)`），会对底层数组共享和扩容行为产生什么影响？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/q014.md",
    "code_examples": [
      {
        "code": "package main\nimport (\n    \"fmt\"\n)\nfunc main() {\n    str1 := []string{\"a\", \"b\", \"c\"}\n    str2 := str1[1:]\n    str2[1] = \"new\"\n    fmt.Println(str1)\n    str2 = append(str2, \"z\", \"x\", \"y\")\n    fmt.Println(str1)\n}",
        "language": "go"
      }
    ]
  },
  {
    "id": "backend-interview_q014_002",
    "text": "下面代码写法有什么问题？",
    "answer": "golang中的`map` 通过`key`获取到的实际上是两个值，第一个是获取到的值，第二个是是否存在该`key`。因此不能直接通过`key`来赋值对象。",
    "category": "go",
    "difficulty": 3,
    "tags": [
      "golang",
      "map",
      "key",
      "value",
      "赋值"
    ],
    "followup_points": [
      "1. 如果直接通过`key`赋值对象，会导致什么具体的运行时错误或行为？",
      "2. 在实际开发中，如何正确处理`map`中`key`不存在的情况，有哪些常见的最佳实践？"
    ],
    "source_repo": "backend-interview",
    "source_file": "/home/fengxu/mylib/interview-agent/backend/data/repos/backend-interview/Go/q014.md",
    "code_examples": [
      {
        "code": "package main\nimport (\n    \"fmt\"\n)\ntype Student struct {\n    Age int\n}\nfunc main() {\n    kv := map[string]Student{\"menglu\": {Age: 21}}\n    kv[\"menglu\"].Age = 22\n    s := []Student{{Age: 21}}\n    s[0].Age = 22\n    fmt.Println(kv, s)\n}",
        "language": "go"
      }
    ]
  }
]