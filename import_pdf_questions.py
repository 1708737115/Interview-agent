#!/usr/bin/env python3
"""
PDFé¢˜åº“å¯¼å…¥è„šæœ¬
ç”¨äºè§£æç”¨æˆ·ä¸Šä¼ çš„PDFæ–‡ä»¶å¹¶æå–é¢è¯•é¢˜ç›®ï¼Œåˆå¹¶åˆ°ç°æœ‰é¢˜åº“ä¸­

ä½¿ç”¨æ–¹æ³•:
    python import_pdf_questions.py [--pdf-dir PDF_DIR] [--output OUTPUT]

å‚æ•°:
    --pdf-dir: PDFæ–‡ä»¶å­˜æ”¾ç›®å½• (é»˜è®¤: question_pdfs/)
    --output: è¾“å‡ºåˆå¹¶åçš„é¢˜åº“æ–‡ä»¶ (é»˜è®¤: backend/app/data/merged_question_bank.json)
    --base-bank: åŸºç¡€é¢˜åº“æ–‡ä»¶ (é»˜è®¤: question_bank_config.json)
"""

import os
import sys
import json
import argparse
import re
from pathlib import Path
from typing import List, Dict, Any

# æ·»åŠ backendåˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

try:
    import PyPDF2
except ImportError:
    print("âŒ é”™è¯¯: éœ€è¦å®‰è£…PyPDF2")
    print("   pip install PyPDF2")
    sys.exit(1)


def clean_text(text: str) -> str:
    """æ¸…æ´—æ–‡æœ¬ï¼Œå»é™¤ä¹±ç å’Œå¤šä½™å†…å®¹"""
    if not text or len(text) < 10:
        return ""
    
    # å»é™¤ä¹±ç å­—ç¬¦ï¼ˆä¿ç•™å¸¸è§ä¸­æ–‡å­—ç¬¦ã€è‹±æ–‡å­—æ¯ã€æ•°å­—å’Œæ ‡ç‚¹ï¼‰
    text = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9\s\n\r.,;:!?ï¼Œã€‚ï¼›ï¼šï¼ï¼Ÿã€""''ï¼ˆï¼‰()-]', '', text)
    
    # å»é™¤URL
    text = re.sub(r'https?://\S+', '', text)
    
    # å»é™¤é‚®ç®±
    text = re.sub(r'[\w\-]+@[\w\-]+\.\w+', '', text)
    
    # å»é™¤å¤šä½™ç©ºæ ¼
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text


def extract_questions_from_pdf(pdf_path: str) -> List[Dict[str, Any]]:
    """ä»PDFä¸­æå–é¢è¯•é¢˜ç›®"""
    questions = []
    
    try:
        with open(pdf_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            
            print(f"ğŸ“– æ­£åœ¨è§£æ: {os.path.basename(pdf_path)} ({len(pdf_reader.pages)} é¡µ)")
            
            # æå–æ‰€æœ‰æ–‡æœ¬
            full_text = ""
            for page_num, page in enumerate(pdf_reader.pages):
                try:
                    text = page.extract_text()
                    if text:
                        full_text += text + "\n"
                except Exception as e:
                    print(f"   âš ï¸  ç¬¬ {page_num + 1} é¡µè§£æå¤±è´¥: {e}")
                    continue
            
            # æ¸…æ´—æ–‡æœ¬
            full_text = clean_text(full_text)
            
            # è¯†åˆ«é¢˜ç›®æ¨¡å¼
            # æ¨¡å¼1: åŒ…å«é—®å·/é—®å·çš„è¡Œ
            # æ¨¡å¼2: ä»¥æ•°å­—/å­—æ¯ç¼–å·å¼€å¤´çš„é—®é¢˜
            # æ¨¡å¼3: åŒ…å«ç‰¹å®šå…³é”®è¯çš„é—®é¢˜
            
            lines = full_text.split('\n')
            
            for i, line in enumerate(lines):
                line = line.strip()
                if not line:
                    continue
                
                # è¯†åˆ«é¢˜ç›®
                is_question = False
                
                # æ¨¡å¼1: åŒ…å«é—®å·
                if '?' in line or 'ï¼Ÿ' in line:
                    if 15 <= len(line) <= 200:
                        is_question = True
                
                # æ¨¡å¼2: ä»¥æ•°å­—/å­—æ¯ç¼–å·å¼€å¤´
                elif re.match(r'^(\d+[.ï¼ã€]|[(ï¼ˆ]?\d+[)ï¼‰]?|[A-Za-z][.ï¼ã€])', line):
                    if 15 <= len(line) <= 200 and ('æ˜¯' in line or 'ä»€ä¹ˆ' in line or 'æ€ä¹ˆ' in line or 'å¦‚ä½•' in line):
                        is_question = True
                
                # æ¨¡å¼3: åŒ…å«é¢è¯•é¢˜å…³é”®è¯
                elif re.search(r'(ä»€ä¹ˆæ˜¯|ä¸ºä»€ä¹ˆ|è¯·è§£é‡Š|è¯·æè¿°|å¦‚ä½•|æ€ä¹ˆ|ä»‹ç»)', line):
                    if 15 <= len(line) <= 200:
                        is_question = True
                
                if is_question:
                    # å°è¯•åˆ†ç±»
                    category = classify_question(line)
                    
                    # ç”Ÿæˆé¢˜ç›®å¯¹è±¡
                    question = {
                        'id': f"pdf_{len(questions)}",
                        'text': line[:150],
                        'category': category,
                        'difficulty': 3,  # é»˜è®¤ä¸­ç­‰éš¾åº¦
                        'type': 'technical',
                        'source': os.path.basename(pdf_path)
                    }
                    
                    questions.append(question)
    
    except Exception as e:
        print(f"âŒ è§£æå¤±è´¥ {pdf_path}: {e}")
        return []
    
    return questions


def classify_question(text: str) -> str:
    """æ ¹æ®å†…å®¹è‡ªåŠ¨åˆ†ç±»é¢˜ç›®"""
    text_lower = text.lower()
    
    # Goè¯­è¨€
    if any(kw in text_lower for kw in ['go', 'golang', 'goroutine', 'channel', 'slice', 'map', 'defer', 'gc']):
        return 'language_go'
    
    # Java
    elif any(kw in text_lower for kw in ['java', 'jvm', 'spring', 'hashmap', 'concurrenthashmap']):
        return 'language_java'
    
    # MySQL
    elif any(kw in text_lower for kw in ['mysql', 'sql', 'ç´¢å¼•', 'äº‹åŠ¡', 'innodb', 'b+æ ‘', 'é”']):
        return 'database_mysql'
    
    # Redis
    elif any(kw in text_lower for kw in ['redis', 'ç¼“å­˜', 'æŒä¹…åŒ–', 'rdb', 'aof', 'ç©¿é€', 'å‡»ç©¿']):
        return 'database_redis'
    
    # Kafka
    elif any(kw in text_lower for kw in ['kafka', 'æ¶ˆæ¯é˜Ÿåˆ—', 'partition', 'topic', 'consumer']):
        return 'mq_kafka'
    
    # Docker
    elif any(kw in text_lower for kw in ['docker', 'å®¹å™¨', 'é•œåƒ', 'container']):
        return 'backend_docker'
    
    # Linux
    elif any(kw in text_lower for kw in ['linux', 'å‘½ä»¤', 'è¿›ç¨‹', 'çº¿ç¨‹', 'shell']):
        return 'basics_linux'
    
    # ç½‘ç»œ
    elif any(kw in text_lower for kw in ['tcp', 'http', 'udp', 'ç½‘ç»œ', 'ä¸‰æ¬¡æ¡æ‰‹', 'å››æ¬¡æŒ¥æ‰‹']):
        return 'basics_network'
    
    # æ“ä½œç³»ç»Ÿ
    elif any(kw in text_lower for kw in ['è¿›ç¨‹', 'çº¿ç¨‹', 'å†…å­˜', 'è°ƒåº¦', 'æ­»é”', 'è™šæ‹Ÿå†…å­˜']):
        return 'basics_os'
    
    # å¾®æœåŠ¡
    elif any(kw in text_lower for kw in ['å¾®æœåŠ¡', 'ddd', 'æœåŠ¡æ‹†åˆ†', 'æ²»ç†']):
        return 'architecture_microservices'
    
    # åˆ†å¸ƒå¼
    elif any(kw in text_lower for kw in ['åˆ†å¸ƒå¼', 'cap', 'base', 'åˆ†å¸ƒå¼é”', 'åˆ†å¸ƒå¼äº‹åŠ¡']):
        return 'architecture_distributed'
    
    # ç³»ç»Ÿè®¾è®¡
    elif any(kw in text_lower for kw in ['è®¾è®¡', 'ç§’æ€', 'çŸ­é“¾æ¥', 'æ¨é€', 'æ’è¡Œæ¦œ', 'è®¡æ•°å™¨']):
        return 'system_design'
    
    # é»˜è®¤
    return 'general'


def load_base_question_bank(base_path: str) -> Dict[str, Any]:
    """åŠ è½½åŸºç¡€é¢˜åº“"""
    try:
        with open(base_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"âš ï¸  åŸºç¡€é¢˜åº“ä¸å­˜åœ¨: {base_path}")
        print("   å°†åˆ›å»ºæ–°çš„é¢˜åº“ç»“æ„")
        return create_empty_bank()
    except Exception as e:
        print(f"âŒ åŠ è½½åŸºç¡€é¢˜åº“å¤±è´¥: {e}")
        sys.exit(1)


def create_empty_bank() -> Dict[str, Any]:
    """åˆ›å»ºç©ºçš„é¢˜åº“ç»“æ„"""
    return {
        'version': '1.0',
        'description': 'AIé¢è¯•ç³»ç»Ÿé¢˜åº“',
        'groups': {
            'languages': {
                'name': 'ç¼–ç¨‹è¯­è¨€',
                'description': 'Goã€Javaã€Pythonç­‰ç¼–ç¨‹è¯­è¨€',
                'enabled': True,
                'categories': {
                    'language_go': {'name': 'Goè¯­è¨€', 'enabled': True, 'questions': []},
                    'language_java': {'name': 'Java', 'enabled': True, 'questions': []},
                }
            },
            'databases': {
                'name': 'æ•°æ®åº“',
                'description': 'MySQLã€Redisç­‰æ•°æ®åº“',
                'enabled': True,
                'categories': {
                    'database_mysql': {'name': 'MySQL', 'enabled': True, 'questions': []},
                    'database_redis': {'name': 'Redis', 'enabled': True, 'questions': []},
                }
            },
            'general': {
                'name': 'å…¶ä»–',
                'description': 'å…¶ä»–é¢˜ç›®',
                'enabled': True,
                'categories': {
                    'general': {'name': 'é€šç”¨', 'enabled': True, 'questions': []}
                }
            }
        }
    }


def merge_questions(base_bank: Dict[str, Any], new_questions: List[Dict[str, Any]]) -> Dict[str, Any]:
    """åˆå¹¶æ–°é¢˜ç›®åˆ°åŸºç¡€é¢˜åº“"""
    added_count = 0
    
    for question in new_questions:
        category = question['category']
        
        # æŸ¥æ‰¾å¯¹åº”çš„åˆ†ç±»
        found = False
        for group in base_bank['groups'].values():
            if category in group['categories']:
                group['categories'][category]['questions'].append(question)
                group['categories'][category]['count'] = group['categories'][category].get('count', 0) + 1
                added_count += 1
                found = True
                break
        
        # å¦‚æœæ²¡æ‰¾åˆ°å¯¹åº”åˆ†ç±»ï¼Œæ”¾å…¥general
        if not found:
            if 'general' not in base_bank['groups']:
                base_bank['groups']['general'] = {
                    'name': 'å…¶ä»–',
                    'description': 'å…¶ä»–é¢˜ç›®',
                    'enabled': True,
                    'categories': {}
                }
            if 'general' not in base_bank['groups']['general']['categories']:
                base_bank['groups']['general']['categories']['general'] = {
                    'name': 'é€šç”¨',
                    'enabled': True,
                    'questions': []
                }
            
            base_bank['groups']['general']['categories']['general']['questions'].append(question)
            base_bank['groups']['general']['categories']['general']['count'] = \
                base_bank['groups']['general']['categories']['general'].get('count', 0) + 1
            added_count += 1
    
    return base_bank, added_count


def save_merged_bank(bank: Dict[str, Any], output_path: str):
    """ä¿å­˜åˆå¹¶åçš„é¢˜åº“"""
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(bank, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… å·²ä¿å­˜åˆå¹¶é¢˜åº“: {output_path}")


def print_statistics(bank: Dict[str, Any]):
    """æ‰“å°é¢˜åº“ç»Ÿè®¡ä¿¡æ¯"""
    print("\n" + "=" * 60)
    print("ğŸ“Š é¢˜åº“ç»Ÿè®¡")
    print("=" * 60)
    
    total = 0
    for group_name, group in bank['groups'].items():
        group_total = sum(cat.get('count', len(cat.get('questions', []))) 
                         for cat in group['categories'].values())
        if group_total > 0:
            print(f"\nã€{group['name']}ã€‘- {group_total}é¢˜")
            for cat_name, cat in group['categories'].items():
                count = cat.get('count', len(cat.get('questions', [])))
                if count > 0:
                    print(f"  â”œâ”€ {cat['name']}: {count}é¢˜")
            total += group_total
    
    print("\n" + "-" * 60)
    print(f"æ€»è®¡: {total} é“é¢˜ç›®")
    print("=" * 60)


def main():
    parser = argparse.ArgumentParser(description='å¯¼å…¥PDFé¢˜åº“')
    parser.add_argument('--pdf-dir', default='question_pdfs', 
                       help='PDFæ–‡ä»¶å­˜æ”¾ç›®å½• (é»˜è®¤: question_pdfs/)')
    parser.add_argument('--output', default='backend/app/data/merged_question_bank.json',
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--base-bank', default='question_bank_config.json',
                       help='åŸºç¡€é¢˜åº“æ–‡ä»¶')
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸ“š PDFé¢˜åº“å¯¼å…¥å·¥å…·")
    print("=" * 60)
    print()
    
    # 1. åŠ è½½åŸºç¡€é¢˜åº“
    print(f"1ï¸âƒ£  åŠ è½½åŸºç¡€é¢˜åº“: {args.base_bank}")
    base_bank = load_base_question_bank(args.base_bank)
    
    # ç»Ÿè®¡åŸºç¡€é¢˜åº“æ•°é‡
    base_count = sum(
        cat.get('count', len(cat.get('questions', [])))
        for group in base_bank['groups'].values()
        for cat in group['categories'].values()
    )
    print(f"   åŸºç¡€é¢˜åº“: {base_count} é“é¢˜ç›®")
    print()
    
    # 2. æ‰«æPDFæ–‡ä»¶
    print(f"2ï¸âƒ£  æ‰«æPDFç›®å½•: {args.pdf_dir}")
    
    if not os.path.exists(args.pdf_dir):
        print(f"   âš ï¸  ç›®å½•ä¸å­˜åœ¨ï¼Œåˆ›å»º: {args.pdf_dir}")
        os.makedirs(args.pdf_dir, exist_ok=True)
    
    pdf_files = list(Path(args.pdf_dir).glob('*.pdf'))
    
    if not pdf_files:
        print("   âš ï¸  æœªæ‰¾åˆ°PDFæ–‡ä»¶")
        print("   ğŸ’¡ æç¤º: å°†PDFæ–‡ä»¶æ”¾å…¥æ­¤ç›®å½•å³å¯è‡ªåŠ¨å¯¼å…¥")
        print()
        # æ²¡æœ‰PDFæ—¶ä¹Ÿä¿å­˜åŸºç¡€é¢˜åº“
        save_merged_bank(base_bank, args.output)
        print_statistics(base_bank)
        return
    
    print(f"   å‘ç° {len(pdf_files)} ä¸ªPDFæ–‡ä»¶")
    for pdf_file in pdf_files:
        print(f"   - {pdf_file.name}")
    print()
    
    # 3. è§£æPDFæ–‡ä»¶
    print("3ï¸âƒ£  è§£æPDFæ–‡ä»¶...")
    all_new_questions = []
    
    for pdf_file in pdf_files:
        questions = extract_questions_from_pdf(str(pdf_file))
        all_new_questions.extend(questions)
        print(f"   âœ… {pdf_file.name}: æå– {len(questions)} é¢˜")
    
    print(f"\n   å…±æå– {len(all_new_questions)} é“æ–°é¢˜ç›®")
    print()
    
    # 4. åˆå¹¶é¢˜åº“
    print("4ï¸âƒ£  åˆå¹¶é¢˜åº“...")
    merged_bank, added_count = merge_questions(base_bank, all_new_questions)
    print(f"   æ–°å¢é¢˜ç›®: {added_count} é“")
    print()
    
    # 5. ä¿å­˜åˆå¹¶åçš„é¢˜åº“
    print("5ï¸âƒ£  ä¿å­˜åˆå¹¶é¢˜åº“...")
    save_merged_bank(merged_bank, args.output)
    print()
    
    # 6. æ‰“å°ç»Ÿè®¡
    print_statistics(merged_bank)
    
    print("\nâœ… å¯¼å…¥å®Œæˆï¼")
    print(f"   åˆå¹¶é¢˜åº“å·²ä¿å­˜åˆ°: {args.output}")
    print()
    print("ğŸ’¡ ä½¿ç”¨æç¤º:")
    print("   1. å°†æ›´å¤šPDFæ”¾å…¥ question_pdfs/ ç›®å½•")
    print("   2. é‡æ–°è¿è¡Œæ­¤è„šæœ¬å¯ç»§ç»­å¯¼å…¥")
    print("   3. éƒ¨ç½²æ—¶ç³»ç»Ÿä¼šè‡ªåŠ¨åŠ è½½åˆå¹¶åçš„é¢˜åº“")


if __name__ == '__main__':
    main()
