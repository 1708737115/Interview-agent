后端⾯试题集！学会⾯试包过！  ⼤家好，我是⼩⽩。⼤家知道，我已经从事后端程序员好多年了，在学习和参与⾯试的过程中遇到过很多⾯试题。最近花了些时间整理了⼀下后端程序员成⻓路线和⾼频⾯试题，这是⼀份涵盖⼤部分后端程序员所需要掌握的核⼼知识。这些⾯试题从能⼒模型上对标字节资深后端开发，因为字节主要使⽤GO语⾔，因此语⾔⽅⾯的⾯试题，主要是⾯向go相关的题⽬。但除了语⾔这块，其他中间件和⼯程能⼒相关的⾯试题，对于所有后端开发都适⽤！！
如果不想要go相关的⾯试题，只要其他后端⾯试题，可以在后台回复【后端⾯试】。⾯试题集PDF还会不断迭代更新，⼀般两个⽉更新⼀次，后续最新版本都会在我的个⼈公众号「⼩⽩debug」⾥第⼀时间发布！建议拿到这份PDF之后，去关注「⼩⽩debug」，并重新获取⼀份最新的，因为你⼿上这份PDF可能已经过时了！！ 在公众号⾥回复【⾯试】即可获得！！
如果⼤家看完电⼦书，觉得内容还不错，强烈希望⼤家能在微信公众号⾥搜索关注，并星标我的公众号，第⼀时间获取最新更新内容！
 
 还有技术划⽔【交流群】，点击公众号右下⻆【联系我】或扫描以下⼆维码，备注“进群”，欢迎⼤家进群交流~。如果⼤家对⽹络基础感兴趣的话，公众号⾥也有⾮常多相关的⽂章，也欢迎关注收看哈。图解⽹络相关的⽂章，已经重新整理成⼀份的电⼦书。在公众号内回复【⽹络】，就可以获得整理的PDF电⼦书。
 同时我也为公众号粉丝准备了⼀些学习资料，关注公众号并回复【视频】、【操作系统】、【⽹络】即可获得相应学习资料！
 并且，学习资料也会不断更新，后续会根据读者需求整理更多相关资源，有需要的读者也可以在公众号内留⾔。 更多资源获取 欢迎⼤家访问我的博客 https://xiaobaidebug.top/ 。在公众号内回复【⾯试】，可以获得整理的⾯试PDF电⼦书（含golang），适合快速备战⾯试查漏补缺。在公众号内回复【后端⾯试】，可以获得整理的⾯试PDF电⼦书（不含golang），适合快速备战⾯试查漏补缺。在公众号内回复【⽹络】，可以获得整理的图解PDF电⼦书，图⽂并茂，通俗易懂，⾮常适合巩固基础和进阶。在公众号内回复【视频】，可以获得整理的视频教程，内含实战教程，适合⼩⽩上路。
 


脑图持续不断更新中，在线查看地址后续⽂章和内容会不断更新到 github项⽬ https://github.com/xiaobaiTech/golangFamily  中，欢迎关注。 ⽬录 后端⾯试题集！学会⾯试包过！建议拿到这份PDF之后，去关注「⼩⽩debug」，并重新获取⼀份最新的，因为你⼿上这份PDF可能已经过时了！！更多资源获取⽬录Go ⼊⻔与其他语⾔相⽐，使⽤ Go 有什么好处？Golang 使⽤什么数据类型？Golang开发新⼿常犯的50个错误Go 程序中的包是什么？连nil切⽚和空切⽚⼀不⼀样都不清楚？那BAT⾯试官只好让你回去等通知了。golang⾯试题：字符串转成byte数组，会发⽣内存拷⻉吗？golang⾯试题：翻转含有中⽂、数字、英⽂字⺟的字符串golang⾯试题：拷⻉⼤切⽚⼀定⽐⼩切⽚代价⼤吗？golang⾯试题：json包变量不加tag会怎么样？golang⾯试题：reflect（反射包）如何获取字段tag？为什么json包不能导出私有变量的tag？昨天那个在for循环⾥append元素的同事，今天还在么？go struct能不能⽐较Go ⽀持什么形式的类型转换？将整数转换为浮点数。Log包线程安全吗？Goroutine和线程的区别?什么是 Goroutine？你如何停⽌它？Golang中除了加Mutex锁以外还有哪些⽅式安全读写共享变量？⽆缓冲 Chan 的发送和接收是否同步?go语⾔的并发机制以及它所使⽤的CSP并发模型．Golang 中常⽤的并发模型？
JSON 标准库对 nil slice 和 空 slice 的处理是⼀致的吗？　协程，线程，进程的区别。互斥锁，读写锁，死锁问题是怎么解决。Golang的内存模型，为什么⼩对象多了会造成gc压⼒。说下Go中的锁有哪些?三种锁，读写锁，互斥锁，还有map的安全的锁?什么是channel，为什么它可以做到线程安全？读写锁或者互斥锁读的时候能写吗?怎么限制Goroutine的数量.Channel是同步的还是异步的.Data Race问题怎么解决？能不能不加锁解决这个问题？如何在运⾏时检查变量类型？Go 两个接⼝之间可以存在什么关系？Go 当中同步锁有什么特点？作⽤是什么Go 语⾔当中 Channel（通道）有什么特点，需要注意什么？Go 语⾔当中 Channel 缓冲有什么特点？Go 语⾔中 cap 函数可以作⽤于那些内容？go convey 是什么？⼀般⽤来做什么？Go 语⾔当中 new 和 make 有什么区别吗？Go 语⾔中 make 的作⽤是什么？Printf(),Sprintf(),FprintF()都是格式化输出，有什么不同？Go 语⾔当中数组和切⽚的区别是什么？Go 语⾔当中值传递和地址传递（引⽤传递）如何运⽤？有什么区别？举例说明Go 语⾔当中数组和切⽚在传递的时候的区别是什么？Go 语⾔是如何实现切⽚扩容的？看下⾯代码的 defer 的执⾏顺序是什么？ defer 的作⽤和特点是什么？Golang Slice 的底层实现Golang Slice 的扩容机制，有什么注意点？扩容前后的 Slice 是否相同？Golang 的参数传递、引⽤类型Golang Map 底层实现Golang Map 如何扩容Golang Map 查找介绍⼀下 ChannelGo 语⾔的 Channel 特性？Channel 的 ring buffer 实现Go 进阶golang⾯试官：for select时，如果通道已经关闭会怎么样？如果只有⼀个case呢？golang⾯试题：对已经关闭的的chan进⾏读写，会怎么样？为什么？golang⾯试题：对未初始化的的chan进⾏读写，会怎么样？为什么？golang⾯试题：能说说uintptr和unsafe.Pointer的区别吗？golang ⾯试题：reflect（反射包）如何获取字段 tag？为什么 json 包不能导出私有变量的 tag？golang⾯试题：怎么避免内存逃逸？golang⾯试题：简单聊聊内存逃逸？Golang GC 时会发⽣什么?Golang 中 Goroutine 如何调度?并发编程概念是什么？Mutex ⼏种状态Mutex 正常模式和饥饿模式
Mutex 允许⾃旋的条件RWMutex 实现RWMutex 注意事项Cond 是什么Broadcast 和 Signal 区别Cond 中 Wait 使⽤WaitGroup ⽤法WaitGroup 实现原理什么是 sync.Once什么操作叫做原⼦操作原⼦操作和锁的区别什么是 CASsync.Pool 有什么⽤Go ⾼级Goroutine 定义GMP 指的是什么给⼤家丢脸了，⽤了三年golang，我还是没答对这道内存泄漏题你⼀定会遇到的内存回收策略导致的疑似内存泄漏的问题GMP⾥为什么要有P?go栈扩容和栈缩容，连续栈的缺点golang隐藏技能:怎么访问私有成员1.0 之前 GM 调度模型GMP 调度流程GMP 中 work stealing 机制GMP 中 hand off 机制协作式的抢占式调度基于信号的抢占式调度GMP 调度过程中存在哪些阻塞sysmon 有什么作⽤三⾊标记原理插⼊写屏障删除写屏障写屏障混合写屏障GC 触发时机Go 语⾔中 GC 的流程是什么？GC 如何调优Go语⾔的栈空间管理是怎么样的?Goroutine和Channel的作⽤分别是什么?怎么查看Goroutine的数量?微服务您对微服务有何了解？说说微服务架构的优势微服务有哪些特点？微服务架构是什么样⼦的?微服务架构如何运作？微服务架构的优缺点是什么？单⽚，SOA 和微服务架构有什么区别？怎么做弹性扩缩容，原理是什么?
说⼀下中间件原理.在使⽤微服务架构时，您⾯临哪些挑战？SOA 和微服务架构之间的主要区别是什么？微服务有什么特点？什么是领域驱动设计？为什么需要域驱动设计（DDD）？什么是⽆所不在的语⾔？什么是凝聚⼒？什么是耦合？什么是 REST / RESTful 以及它的⽤途是什么？什么是不同类型的微服务测试？容器技术为什么需要 DevOpsDocker 是什么？Docker 与虚拟机有何不同？什么是 Docker 镜像？什么是 Docker 容器？Docker 容器有⼏种状态？Dockerfile 中最常⻅的指令是什么？ Dockerfile 中的命令 COPY 和 ADD 命令有什么区别？解释⼀下 Dockerfile 的 ONBUILD 指令？ 什么是 Docker Swarm？如何在⽣产中监控 Docker？DevOps 有哪些优势？CI 服务有什么⽤途？如何使⽤ Docker 技术创建与环境⽆关的容器系统？Dockerfile 配置⽂件中的 COPY 和 ADD 指令有什么不同？Docker 映像（image）是什么？Docker 容器（container）是什么？Docker 中⼼（hub）什么概念？在任意给定时间点指出⼀个 Docker 容器可能存在的运⾏阶段？有什么⽅法确定⼀个 Docker 容器运⾏状态？在 Dockerfile 配置⽂件中最常⽤的指令有哪些？什么类型的应⽤（⽆状态性或有状态性）更适合 Docker 容器技术？解释基本 Docker 应⽤流程Docker Image 和 Docker Layer (层)有什么不同？虚拟化技术是什么？虚拟管理层（程序）是什么？Docker 群（Swarm）是什么？在使⽤ Docker 技术的产品中如何监控其运⾏？什么是孤⼉卷及如何删除它？什么是半虚拟化（Paravirtualization）？Docker 技术与虚拟机技术有何不同？请解释⼀下 docerfile 配置⽂件中的 ONBUILD 指令的⽤途含义？有否在创建有状态性的 Docker 应⽤的较好实践？最适合的场景有什么？在 Windows 系统上可以运⾏原⽣的 Docker 容器吗？在⾮ Linux 操作系统平台上如何运⾏ Docker ?容器化技术在底层的运⾏原理？说说容器化技术与虚拟化技术的优缺点
如何使 Docker 适应多种运⾏环境？为什么 Docker compose 采取的是并不等待前⾯依赖服务项的容器启动就绪后再启动的组合容器启动策略？Redis什么是 Redis?Redis 的数据类型？使⽤ Redis 有哪些好处？Redis 相⽐ Memcached 有哪些优势？Memcache 与 Redis 的区别都有哪些？Redis 是单进程单线程的？⼀个字符串类型的值能存储最⼤容量是多少？Redis 集群最⼤节点个数是多少？Reids 的特点 使⽤ Redis 有哪些好处？为什么 edis 需要把所有数据放到内存中？Redis 的内存⽤完了会发⽣什么？Redis  的回收策略（淘汰策略）Redis 的持久化机制是什么？各⾃的优缺点？Redis 常⻅性能问题和解决⽅案：Redis 过期键的删除策略？Redis 的回收策略（淘汰策略）?为什么 Redis 需要把所有数据放到内存中？Redis 的同步机制了解么？Pipeline 有什么好处，为什么要⽤ Pipeline？是否使⽤过 Redis 集群，集群的原理是什么？Redis 集群⽅案什么情况下会导致整个集群不可⽤？Redis ⽀持的 Java 客户端都有哪些？官⽅推荐⽤哪个？Jedis 与 Redisson 对⽐有什么优缺点？Redis 如何设置密码及验证密码？说说 Redis 哈希槽的概念？Redis 集群的主从复制模型是怎样的？Redis 集群会有写操作丢失吗？为什么？Redis 集群之间是如何复制的？Redis 集群最⼤节点个数是多少？Redis 集群如何选择数据库？怎么测试 Redis 的连通性怎么理解 Redis 事务？Redis 事务相关的命令有哪⼏个？Redis key 的过期时间和永久有效分别怎么设置？Redis 如何做内存优化？Redis 回收进程如何⼯作的？都有哪些办法可以降低 Redis 的内存使⽤情况呢？Redis 的内存⽤完了会发⽣什么？⼀个 Redis 实例最多能存放多少的 keys？ List、Set、 Sorted Set 他们最多能存放多少元素？MySQL ⾥有2000w 数据，Redis 中只存20w 的数据，如何保证 redis 中的数据都是热点数据？Redis 内存数据集⼤⼩上升到⼀定⼤⼩的时候，就会施⾏数据淘汰策略。Redis 最适合的场景？假如 Redis ⾥⾯有1 亿个 key，其中有10w 个 key 是以某个固定的已知的前缀开头的，如果将它们全部找出来？如果有⼤量的 key 需要设置同⼀时间过期，⼀般需要注意什么？使⽤过 Redis 做异步队列么，你是怎么⽤的？
使⽤过 Redis 分布式锁么，它是什么回事假如 Redis ⾥⾯有 1 亿个 key，其中有 10w 个 key 是以某个固定的已知的前缀开头的，如果将它们全部找出来？Memcached  与 Redis  的区别？ Redis  常⻅性能问题和解决⽅案：缓存如何实现⾼并发？Redis 和 Memcached 的区别⽤缓存可能出现的问题当查询缓存报错，怎么提⾼可⽤性？如果避免缓存”穿透”的问题？如何避免缓存“雪崩”的问题？如果避免缓存“击穿”的问题？什么是缓存预热？如何实现缓存预热？缓存数据的淘汰策略有哪些？MySQL隔离级别与锁的关系实践中如何优化 MySQL？ 优化⼦查询的⽅法前缀索引MySQL 5.6 和 MySQL 5.7 对索引做了哪些优化？MySQL 有关权限的表有哪⼏个呢？MySQL 中都有哪些触发器？⼤表怎么优化？分库分表了是怎么做的？分表分库了有什么问题？ 有⽤到中间件么？他们的原理知道么？B+ Tree 索引和 Hash 索引区别？数据库索引的原理，为什么要⽤  B+树，为什么不⽤⼆叉树？据库三⼤范式是什么MySQL 有关权限的表都有哪⼏个？MySQL 的 Binlog 有有⼏种录⼊格式？分别有什么区别？MySQL 存储引擎 MyISAM 与 InnoDB 区别MyISAM 索引与 InnoDB 索引的区别？什么是索引？索引有哪些优缺点？索引有哪⼏种类型？MySQL 中有哪⼏种锁？MySQL 中 InnoDB ⽀持的四种事务隔离级别名称，以及逐级之间的区别？char 和 varchar 的区别？主键和候选键有什么区别？如何在 Unix 和 MySQL 时间戳之间进⾏转换？MyISAM 表类型将在哪⾥存储，并且还提供其存储格式？MySQL ⾥记录货币⽤什么字段类型好创建索引时需要注意什么？使⽤索引查询⼀定能提⾼查询的性能吗？为什么百万级别或以上的数据如何删除什么是最左前缀原则？什么是最左匹配原则什么是聚簇索引？何时使⽤聚簇索引与⾮聚簇索引MySQL 连接器MySQL 查询缓存MySQL 分析器MySQL 优化器MySQL 执⾏器
什么是临时表，何时删除临时表？谈谈 SQL 优化的经验什么叫外链接？什么叫内链接？使⽤ union 和 union all 时需要注意些什么？MyISAM 存储引擎的特点InnoDB 存储引擎的特点Mysql⾼可⽤⽅案有哪些?Linux 什么是 LinuxUnix 和 Linux 有什么区别？什么是 Linux 内核？Linux 的基本组件是什么？Linux 的体系结构BASH 和 DOS 之间的基本区别是什么？Linux 开机启动过程？Linux 系统缺省的运⾏级别？Linux 使⽤的进程间通信⽅式？Linux 有哪些系统⽇志⽂件？Linux 系统安装多个桌⾯环境有帮助吗？什么是交换空间？什么是 Root 帐户什么是 LILO？什么是 BASH？什么是 CLI？什么是 GUI？开源的优势是什么？GNU 项⽬的重要性是什么？绝对路径⽤什么符号表示？当前⽬录、上层⽬录⽤什么表示？主⽬录⽤什么表示? 切换⽬录⽤什么命令？怎么查看当前进程？怎么执⾏退出？怎么查看当前路径？怎么清屏？怎么退出当前命令？怎么执⾏睡眠？怎么查看当前⽤户 id？查看指定帮助⽤什么命令？Ls 命令执⾏什么功能？可以带哪些参数，有什么区别？建⽴软链接(快捷⽅式)，以及硬链接的命令。⽬录创建⽤什么命令？创建⽂件⽤什么命令？复制⽂件⽤什么命令？查看⽂件内容有哪些命令可以使⽤？随意写⽂件命令？怎么向屏幕输出带空格的字符串，⽐如”hello world”?终端是哪个⽂件夹下的哪个⽂件？⿊洞⽂件是哪个⽂件夹下的哪个命令？移动⽂件⽤哪个命令？改名⽤哪个命令？复制⽂件⽤哪个命令？如果需要连同⽂件夹⼀块复制呢？如果需要有提示功能呢？删除⽂件⽤哪个命令？如果需要连⽬录及⽬录下⽂件⼀块删除呢？删除空⽂件夹⽤什么命令？Linux 下命令有哪⼏种可使⽤的通配符？分别代表什么含义?⽤什么命令对⼀个⽂件的内容进⾏统计？(⾏号、单词数、字节数)Grep 命令有什么⽤？如何忽略⼤⼩写？如何查找不含该串的⾏?Linux 中进程有哪⼏种状态？在 ps 显示出来的信息中，分别⽤什么符号表示的？怎么使⼀个命令在后台运⾏?利⽤ ps 怎么显示所有的进程? 怎么利⽤ ps 查看指定进程的信息？哪个命令专⻔⽤来查看后台任务?把后台任务调到前台执⾏使⽤什么命令?把停下的后台任务在后台执⾏起来⽤什么命令?终⽌进程⽤什么命令? 带什么参数?
怎么查看系统⽀持的所有信号？搜索⽂件⽤什么命令? 格式是怎么样的?查看当前谁在使⽤该主机⽤什么命令? 查找⾃⼰所在的终端信息⽤什么命令?使⽤什么命令查看⽤过的命令列表?使⽤什么命令查看磁盘使⽤空间？空闲空间呢?使⽤什么命令查看⽹络是否连通?使⽤什么命令查看 ip 地址及接⼝信息？查看各类环境变量⽤什么命令?通过什么命令指定命令提示符?查找命令的可执⾏⽂件是去哪查找的? 怎么对其进⾏设置及添加?通过什么命令查找执⾏命令?怎么对命令进⾏取别名？du 和 df 的定义，以及区别？awk 详解。当你需要给命令绑定⼀个宏或者按键的时候，应该怎么做呢？如果⼀个linux新⼿想要知道当前系统⽀持的所有命令的列表，他需要怎么做？如果你的助⼿想要打印出当前的⽬录栈，你会建议他怎么做？你的系统⽬前有许多正在运⾏的任务，在不重启机器的条件下，有什么⽅法可以把所有正在运⾏的进程移除呢？bash shell 中的hash 命令有什么作⽤？哪⼀个bash内置命令能够进⾏数学运算。怎样⼀⻚⼀⻚地查看⼀个⼤⽂件的内容呢？数据字典属于哪⼀个⽤户的？怎样查看⼀个linux命令的概要与⽤法？假设你在/bin⽬录中偶然看到⼀个你从没⻅过的的命令，怎样才能知道它的作⽤和⽤法呢？使⽤哪⼀个命令可以查看⾃⼰⽂件系统的磁盘空间配额呢？说⼀下异步和⾮阻塞的区别?滑动窗⼝的概念以及应⽤?Epoll原理.负载均衡原理是什么?LVS相关了解.⽹络和操作系统进程和线程的区别？协程与线程的区别？并发和并⾏有什么区别？进程与线程的切换流程？为什么虚拟地址空间切换会⽐较耗时？进程间通信⽅式有哪些？进程间同步的⽅式有哪些？线程同步的⽅式有哪些？线程的分类？什么是临界区，如何解决冲突？什么是死锁？死锁产⽣的条件？进程调度策略有哪⼏种？进程有哪些状态？什么是分⻚？什么是分段？分⻚和分段有什区别？什么是交换空间？⻚⾯替换算法有哪些？
什么是缓冲区溢出？有什么危害？什么是虚拟内存？讲⼀讲 IO 多路复⽤？硬链接和软链接有什么区别？中断的处理过程?中断和轮询有什么区别？请详细介绍⼀下 TCP 的三次握⼿机制，为什么要三次握⼿？讲⼀讲 SYN 超时，洪泛攻击，以及解决策略详细介绍⼀下 TCP 的四次挥⼿机制，为什么要有 TIME_WAIT 状态，为什么需要四次握⼿？服务器出现了⼤量 CLOSE_WAIT 状态如何解决？RocketMQ  ⾯试题 多个 MQ 如何选型？为什么要使⽤ MQ？RocketMQ 由哪些⻆⾊组成，每个⻆⾊作⽤和特点是什么？ RocketMQ 中的 Topic 和 JMS 的 queue 有什么区别？RocketMQ 消费模式有⼏种？Broker 如何处理拉取请求的？RocketMQ 如何做负载均衡？消息重复消费RocketMQ 如何保证消息不丢失Producer 端如何保证消息不丢失Broker 端如何保证消息不丢失Consumer 端如何保证消息不丢失⾼吞吐量下如何优化⽣产者和消费者的性能? KafkaKafka 是什么？主要应⽤场景有哪些？和其他消息队列相⽐，Kafka 的优势在哪⾥？什么是 Producer、Consumer、Broker、Topic、 Partition？Kafka 的多副本机制了解吗？Kafka 的多分区（Partition）以及多副本（Replica）机制有什么好处呢？Zookeeper 在 Kafka 中的作⽤知道吗？Kafka 如何保证消息的消费顺序？Kafka 如何保证消息不丢失？Kafka 判断⼀个节点是否还活着有那两个条件？producer 是否直接将数据发送到 broker 的 leader（主节点）？Kafka consumer 是否可以消费指定分区消息吗？Kafka ⾼效⽂件存储设计特点是什么？partition 的数据如何保存到硬盘？kafka ⽣产数据时数据的分组策略是怎样的？consumer 是推还是拉？kafka 维护消费状态跟踪的⽅法有什么？是什么确保了 Kafka 中服务器的负载平衡？消费者 API 的作⽤是什么？解释流 API 的作⽤？ Kafka 为什么那么快? Kafka 系统⼯具有哪些类型？partition  的数据如何保存到硬盘Zookeeper 对于 Kafka 的作⽤是什么？流 API 的作⽤是什么？
Kafka 的流处理是什么意思？Kafka 集群中保留期的⽬的是什么？Memcached  ⾯试题 Memcached 的多线程是什么？如何使⽤它们？Memcached 是什么，有什么作⽤？Memcached 与 Redis 的区别？ 什么是⼆进制协议，我该关注吗？如果缓存数据在导出导⼊之间过期了，你⼜怎么处理这些数据 呢？ 如何实现集群中的 session 共享存储？Memcached 和 MySQL 的 query cache 相⽐，有什么优缺点？Memcached 是原⼦的吗？Memcached 能够更有效地使⽤内存吗？Memcached 的内存分配器是如何⼯作的？为什么不适⽤ malloc/free？为何要使⽤ slabs？MongoDB  ⾯试题 ObjectID 有哪些部分组成当我试图更新⼀个正在被迁移的块(chunk)上的⽂档时会发⽣什 么? 为什么要在 MongoDB 中使⽤分析器解释⼀下 MongoDB 中的索引是什么？什么是集合（表） 提到如何检查函数的源代码？什么是 NoSQL 数据库？NoSQL 和 RDBMS 有什么区别？在哪 些情况下使⽤和不使⽤ NoSQL 数据库？ 提及插⼊⽂档的命令语法是什么？如果在⼀个分⽚（shard）停⽌或者很慢的时候,我发起⼀个查询 会怎样? 如何执⾏事务/加锁？ Nginx  ⾯试题 Nginx  是如何实现⾼并发的？请解释  Nginx  如何处理  HTTP  请求。 为什么要做动、静分离？nginx 是如何实现⾼并发的？Nginx 静态资源? Nginx 配置⾼可⽤性怎么配置？502 错误可能原因在  Nginx  中，解释如何在  URL 中保留双斜线? Nginx 服务器上的 Master 和 Worker 进程分别是什么? Nginx 的优缺点？RabbitMQ  RabbitMQ routing 路由模式 消息怎么路由？RabbitMQ publish/subscribe 发布订阅(共享资源) 能够在地理上分开的不同数据中⼼使⽤  RabbitMQ cluster  么？ RabbitMQ 有那些基本概念？什么情况下会出现  blackholed  问题？ 什么是消费者 Consumer? 消息如何分发？Basic.Reject  的⽤法是什么？什么是 Binding 绑定？ 分布式分布式服务接⼝的幂等性如何设计？分布式系统中的接⼝调⽤如何保证顺序性？
分布式锁实现原理，⽤过吗？Etcd怎么实现分布式锁?说说 ZooKeeper ⼀般都有哪些使⽤场景？说说你们的分布式 session ⽅案是啥？怎么做的？分布式事务了解吗？那常⻅的分布式锁有哪些解决⽅案？ZK 和 Redis 的区别，各⾃有什么优缺点？MySQL 如何做分布式锁？你了解业界哪些⼤公司的分布式锁框架请讲⼀下你对 CAP 理论的理解请讲⼀下你对 BASE 理论的理解分布式与集群的区别是什么？请讲⼀下 BASE 理论的三要素请说⼀下对两阶段提交协议的理解请讲⼀下对 TCC 协议的理解ClickHouse  ⾯试题 什么是 ClickHouse？ ClickHouse 有哪些应⽤场景？ClickHouse 列式存储的优点有哪些？ClickHouse 的缺点是是什么？ClickHouse 的架构是怎样的？ClickHouse 的逻辑数据模型？ClickHouse 的核⼼特性？使⽤ ClickHouse 时有哪些注意点？ClickHouse  的引擎有哪些？建表引擎参数有哪些？Elasticsearch  ⾯试题 Elasticsearch  读取数据 您能解释⼀下 X-Pack for Elasticsearch 的功能和重要性吗？Elasticsearch  中的节点（⽐如共  20  个），其中的  10  个选了 ⼀个 master，另外  10  个选了另⼀个  master，怎么办？解释⼀下  Elasticsearch 集群中的  索引的概念  ？ 你可以列出  Elasticsearch  各种类型的分析器吗？解释⼀下  Elasticsearch Node？ 在安装 Elasticsearch 时，请说明不同的软件包及其重要性？Elasticsearch 在部署时，对 Linux 的设置有哪些优化⽅法？ 请解释有关  Elasticsearch 的  NRT？ elasticsearch  的  document 设计  Go ⼊⻔ 
与其他语⾔相⽐，使⽤ Go 有什么好处？ 与其他作为学术实验开始的语⾔不同，Go 代码的设计是务实的。每个功能和语法决策都旨在让程序员的⽣活更轻松。Golang 针对并发进⾏了优化，并且在规模上运⾏良好。由于单⼀的标准代码格式，Golang 通常被认为⽐其他语⾔更具可读性。⾃动垃圾收集明显⽐ Java 或 Python 更有效，因为它与程序同时执⾏。Golang 使⽤什么数据类型？ Golang 使⽤以下类型：Method Boolean Numeric String Array Slice Struct Pointer Function Interface Map Channel  Golang开发新⼿常犯的50个错误 https://blog.csdn.net/gezhonglei2007/article/details/52237582 Go 程序中的包是什么？ 包(pkg)是 Go ⼯作区中包含 Go 源⽂件或其他包的⽬录。源⽂件中的每个函数、变量和类型都存储在链接包中。每个 Go 源⽂件都属于⼀个包，该包在⽂件顶部使⽤以下命令声明： 您可以使⽤以下⽅法导⼊和导出包以重⽤导出的函数或类型： Golang 的标准包是 fmt，其中包含格式化和打印功能，如 Println().package <packagename>
import <packagename>
 连nil切⽚和空切⽚⼀不⼀样都不清楚？那BAT⾯试官只好让你回去等通知了。  https://mp.weixin.qq.com/s/sW4PD1MiaunURNDIU4BbQQ  golang⾯试题：字符串转成byte数组，会发⽣内存拷⻉吗？  https://mp.weixin.qq.com/s/qmlPuGVISx8NYp2b9LrqnA  golang⾯试题：翻转含有中⽂、数字、英⽂字⺟的字符串  https://mp.weixin.qq.com/s/ssinnUM22PHPWRug8EzAkg  golang⾯试题：拷⻉⼤切⽚⼀定⽐⼩切⽚代价⼤吗？  https://mp.weixin.qq.com/s/8Dp2eCYzDdBbxAG5-jNevQ  golang⾯试题：json包变量不加tag会怎么样？  https://mp.weixin.qq.com/s/bZlKV_BWSqc-qCa4DrsCbg  golang⾯试题：reflect（反射包）如何获取字段tag？为什么json包不能导出私有变量的tag？  https://mp.weixin.qq.com/s/P7TEx2mInwEktXTEE6JDWQ  昨天那个在for循环⾥append元素的同事，今天还在么？  https://mp.weixin.qq.com/s/SHxcspmiKyPwPBbhfVxsGA   
go struct能不能⽐较 相同struct类型的可以⽐较不同struct类型的不可以⽐较,编译都不过，类型不匹配
 Go ⽀持什么形式的类型转换？将整数转换为浮点数。 Go ⽀持显式类型转换以满⾜其严格的类型要求。
 Log包线程安全吗？ Golang的标准库提供了log的机制，但是该模块的功能较为简单（看似简单，其实他有他的设计思路）。在输出的位置做了线程安全的保护。package mainimport "fmt"func main() {    type A struct {        a int    }    type B struct {        a int    }    a := A{1}    //b := A{1}    b := B{1}    if a == b {        fmt.Println("a == b")    }else{        fmt.Println("a != b")    }} // output// command-line-arguments [command-line-arguments.test]// ./.go:14:7: invalid operation: a == b (mismatched types A and B) 
i := 55 //intj := 67.8 //float64sum := i + int(j)//j is converted to int
Goroutine和线程的区别? 从调度上看，goroutine的调度开销远远⼩于线程调度开销。OS的线程由OS内核调度，每隔⼏毫秒，⼀个硬件时钟中断发到CPU，CPU调⽤⼀个调度器内核函数。这个函数暂停当前正在运⾏的线程，把他的寄存器信息保存到内存中，查看线程列表并决定接下来运⾏哪⼀个线程，再从内存中恢复线程的注册表信息，最后继续执⾏选中的线程。这种线程切换需要⼀个完整的上下⽂切换：即保存⼀个线程的状态到内存，再恢复另外⼀个线程的状态，最后更新调度器的数据结构。某种意义上，这种操作还是很慢的。Go运⾏的时候包涵⼀个⾃⼰的调度器，这个调度器使⽤⼀个称为⼀个M:N调度技术，m个goroutine到n个os线程（可以⽤GOMAXPROCS来控制n的数量），Go的调度器不是由硬件时钟来定期触发的，⽽是由特定的go语⾔结构来触发的，他不需要切换到内核语境，所以调度⼀个goroutine⽐调度⼀个线程的成本低很多。从栈空间上，goroutine的栈空间更加动态灵活。每个OS的线程都有⼀个固定⼤⼩的栈内存，通常是2MB，栈内存⽤于保存在其他函数调⽤期间哪些正在执⾏或者临时暂停的函数的局部变量。这个固定的栈⼤⼩，如果对于goroutine来说，可能是⼀种巨⼤的浪费。作为对⽐goroutine在⽣命周期开始只有⼀个很⼩的栈，典型情况是2KB, 在go程序中，⼀次创建⼗万左右的goroutine也不罕⻅（2KB*100,000=200MB）。⽽且goroutine的栈不是固定⼤⼩，它可以按需增⼤和缩⼩，最⼤限制可以到1GB。goroutine没有⼀个特定的标识。在⼤部分⽀持多线程的操作系统和编程语⾔中，线程有⼀个独特的标识，通常是⼀个整数或者指针，这个特性可以让我们构建⼀个线程的局部存储，本质是⼀个全局的map，以线程的标识作为键，这样每个线程可以独⽴使⽤这个map存储和获取值，不受其他线程⼲扰。goroutine中没有可供程序员访问的标识，原因是⼀种纯函数的理念，不希望滥⽤线程局部存储导致⼀个不健康的超距作⽤，即函数的⾏为不仅取决于它的参数，还取决于运⾏它的线程标识。  什么是 Goroutine？你如何停⽌它？ ⼀个 Goroutine 是⼀个函数或⽅法执⾏同时旁边其他任何够程采⽤了特殊的 Goroutine 线程。Goroutine 线程⽐标准线程更轻量级，⼤多数 Golang 程序同时使⽤数千个 g、Goroutine。要创建 Goroutine，请 go 在函数声明之前添加关键字。 您可以通过向 Goroutine 发送⼀个信号通道来停⽌它。Goroutines 只能在被告知检查时响应信号，因此您需要在逻辑位置（例如 for 循环顶部）包含检查。go f(x, y, z)
package mainfunc main(){  quit := make(chan bool) go func(){
 Golang中除了加Mutex锁以外还有哪些⽅式安全读写共享变量？ Golang中Goroutine 可以通过 Channel 进⾏安全读写共享变量。⽆缓冲 Chan 的发送和接收是否同步? channel⽆缓冲时，发送阻塞直到数据被接收，接收阻塞直到读到数据。channel有缓冲时，当缓冲满时发送阻塞，当缓冲空时接收阻塞。go语⾔的并发机制以及它所使⽤的CSP并发模型． CSP模型是上个世纪七⼗年代提出的,不同于传统的多线程通过共享内存来通信，CSP讲究的是“以通信的⽅式来共享内存”。⽤于描述两个独⽴的并发实体通过共享的通讯 channel(管道)进⾏通信的并发模型。 CSP中channel是第⼀类对象，它不关注发送消息的实体，⽽关注与发送消息时使⽤的channel。Golang中channel 是被单独创建并且可以在进程之间传递，它的通信模式类似于 boss-worker 模式的，⼀个实体通过将消息发送到channel 中，然后⼜监听这个 channel 的实体处理，两个实体之间是匿名的，这个就实现实体中间的解耦，其中 channel 是同步的⼀个消息被发送到 channel 中，最终是⼀定要被另外的实体消费掉的，在实现原理上其实类似⼀个阻塞的消息队列。    for {      select {      case <-quit:        return default:        //…      }      }  }()  //…  quit <- true}
ch := make(chan int)    ⽆缓冲的channel由于没有缓冲发送和接收需要同步.ch := make(chan int, 2) 有缓冲channel不要求发送和接收操作同步. 
Goroutine 是Golang实际并发执⾏的实体，它底层是使⽤协程(coroutine)实现并发，coroutine是⼀种运⾏在⽤户态的⽤户线程，类似于 greenthread，go底层选择使⽤coroutine的出发点是因为，它具有以下特点：⽤户空间 避免了内核态和⽤户态的切换导致的成本。可以由语⾔和框架层进⾏调度。更⼩的栈空间允许创建⼤量的实例。Golang中的Goroutine的特性:Golang内部有三个对象： P对象(processor) 代表上下⽂（或者可以认为是cpu），M(work thread)代表⼯作线程，G对象（goroutine）.正常情况下⼀个cpu对象启⼀个⼯作线程对象，线程去检查并执⾏goroutine对象。碰到goroutine对象阻塞的时候，会启动⼀个新的⼯作线程，以充分利⽤cpu资源。 所有有时候线程对象会⽐处理器对象多很多.我们⽤如下图分别表示P、M、G:
G（Goroutine） ：我们所说的协程，为⽤户级的轻量级线程，每个Goroutine对象中的sched保存着其上下⽂信息.M（Machine） ：对内核级线程的封装，数量对应真实的CPU数（真正⼲活的对象）.P（Processor） ：即为G和M的调度对象，⽤来调度G和M之间的关联关系，其数量可通过GOMAXPROCS()来设置，默认为核⼼数.在单核情况下，所有Goroutine运⾏在同⼀个线程（M0）中，每⼀个线程维护⼀个上下⽂（P），任何时刻，⼀个上下⽂中只有⼀个Goroutine，其他Goroutine在runqueue中等待。⼀个Goroutine运⾏完⾃⼰的时间⽚后，让出上下⽂，⾃⼰回到runqueue中（如下图所示）。当正在运⾏的G0阻塞的时候（可以需要IO），会再创建⼀个线程（M1），P转到新的线程中去运⾏。
当M0返回时，它会尝试从其他线程中“偷”⼀个上下⽂过来，如果没有偷到，会把Goroutine放到Global runqueue中去，然后把⾃⼰放⼊线程缓存中。 上下⽂会定时检查Global runqueue。Golang是为并发⽽⽣的语⾔，Go语⾔是为数不多的在语⾔层⾯实现并发的语⾔；也正是Go语⾔的并发特性，吸引了全球⽆数的开发者。Golang的CSP并发模型，是通过Goroutine和Channel来实现的。Goroutine 是Go语⾔中并发的执⾏单位。有点抽象，其实就是和传统概念上的”线程“类似，可以理解为”线程“。 Channel是Go语⾔中各个并发结构体(Goroutine)之前的通信机制。通常Channel，是各个Goroutine之间通信的”管道“，有点类似于Linux中的管道。通信机制channel也很⽅便，传数据⽤channel <- data，取数据⽤<-channel。在通信过程中，传数据channel <- data和取数据<-channel必然会成对出现，因为这边传，那边取，两个goroutine之间才会实现通信。⽽且不管传还是取，必阻塞，直到另外的goroutine传或者取为⽌。Golang 中常⽤的并发模型？ Golang 中常⽤的并发模型有三种:通过channel通知实现并发控制⽆缓冲的通道指的是通道的⼤⼩为0，也就是说，这种类型的通道在接收前没有能⼒保存任何值，它要求发送 goroutine 和接收 goroutine 同时准备好，才可以完成发送和接收操作。
从上⾯⽆缓冲的通道定义来看，发送 goroutine 和接收 gouroutine 必须是同步的，同时准备后，如果没有同时准备好的话，先执⾏的操作就会阻塞等待，直到另⼀个相对应的操作准备好为⽌。这种⽆缓冲的通道我们也称之为同步通道。
当主 goroutine 运⾏到 <-ch 接受 channel 的值的时候，如果该 channel 中没有数据，就会⼀直阻塞等待，直到有值。 这样就可以简单实现并发控制通过sync包中的WaitGroup实现并发控制Goroutine是异步执⾏的，有的时候为了防⽌在结束mian函数的时候结束掉Goroutine，所以需要同步等待，这个时候就需要⽤ WaitGroup了，在 sync 包中，提供了 WaitGroup ，它会等待它收集的所有 goroutine 任务全部完成。在WaitGroup⾥主要有三个⽅法:Add, 可以添加或减少 goroutine的数量.Done, 相当于Add(-1).Wait, 执⾏后会堵塞主线程，直到WaitGroup ⾥的值减⾄0.在主 goroutine 中 Add(delta int) 索要等待goroutine 的数量。 在每⼀个 goroutine 完成后 Done() 表示这⼀个goroutine 已经完成，当所有的 goroutine 都完成后，在主 goroutine 中 WaitGroup 返回返回。func main() {    ch := make(chan struct{})    go func() {        fmt.Println("start working")        time.Sleep(time.Second * 1)        ch <- struct{}{}    }()    <-ch    fmt.Println("finished")}
func main(){    var wg sync.WaitGroup    var urls = []string{        "http://www.golang.org/",        "http://www.google.com/",    }    for _, url := range urls {        wg.Add(1)        go func(url string) {            defer wg.Done()            http.Get(url)        }(url)    }    wg.Wait()}
在Golang官⽹中对于WaitGroup介绍是A WaitGroup must not be copied after first use,在 WaitGroup 第⼀次使⽤后，不能被拷⻉应⽤示例:
运⾏:
它提示所有的 goroutine 都已经睡眠了，出现了死锁。这是因为 wg 给拷⻉传递到了 goroutine 中，导致只有 Add 操作，其实 Done操作是在 wg 的副本执⾏的。因此 Wait 就死锁了。这个第⼀个修改⽅式:将匿名函数中 wg 的传⼊类型改为 *sync.WaitGrou,这样就能引⽤到正确的WaitGroup了。 这个第⼆个修改⽅式:将匿名函数中的 wg 的传⼊参数去掉，因为Go⽀持闭包类型，在匿名函数中可以直接使⽤外⾯的 wg 变量在Go 1.7 以后引进的强⼤的Context上下⽂，实现并发控制通常,在⼀些简单场景下使⽤ channel 和 WaitGroup 已经⾜够了，但是当⾯临⼀些复杂多变的⽹络并发场景下 channel 和 WaitGroup 显得有些⼒不从⼼了。 ⽐如⼀个⽹络请求 Request，每个 Request 都需要开启⼀个 goroutine 做⼀些事情，这些 goroutine ⼜可能会开启其他的 goroutine，⽐如数据库和RPC服务。 所以我们需要⼀种可以跟踪 goroutine 的⽅案，才可以达到控制他们的⽬的，这就是Go语⾔为我们提供的 Context，称之为上下⽂⾮常贴切，它就是goroutine 的上下⽂。 它是包括⼀个程序的运⾏环境、现场和快照等。每个程序要运⾏时，都需要知道当前程序的运⾏状态，通常Go 将这些封装在⼀个 Context ⾥，再将它传给要执⾏的 goroutine 。context 包主要是⽤来处理多个 goroutine 之间共享数据，及多个 goroutine 的管理。func main(){ wg := sync.WaitGroup{}    for i := 0; i < 5; i++ {        wg.Add(1)        go func(wg sync.WaitGroup, i int) {            fmt.Printf("i:%d", i)            wg.Done()        }(wg, i)    }    wg.Wait()    fmt.Println("exit")}i:1i:3i:2i:0i:4fatal error: all goroutines are asleep - deadlock!goroutine 1 [semacquire]:sync.runtime_Semacquire(0xc000094018)        /home/keke/soft/go/src/runtime/sema.go:56 +0x39sync.(*WaitGroup).Wait(0xc000094010)        /home/keke/soft/go/src/sync/waitgroup.go:130 +0x64main.main()        /home/keke/go/Test/wait.go:17 +0xabexit status 2
context 包的核⼼是 struct Context，接⼝声明如下：
Done() 返回⼀个只能接受数据的channel类型，当该context关闭或者超时时间到了的时候，该channel就会有⼀个取消信号Err() 在Done() 之后，返回context 取消的原因。Deadline() 设置该context cancel的时间点Value() ⽅法允许 Context 对象携带request作⽤域的数据，该数据必须是线程安全的。Context 对象是线程安全的，你可以把⼀个 Context 对象传递给任意个数的 gorotuine，对它执⾏ 取消 操作时，所有 goroutine 都会接收到取消信号。⼀个 Context 不能拥有 Cancel ⽅法，同时我们也只能 Done channel 接收数据。 其中的原因是⼀致的：接收取消信号的函数和发送信号的函数通常不是⼀个。 典型的场景是：⽗操作为⼦操作操作启动 goroutine，⼦操作也就不能取消⽗操作。JSON 标准库对 nil slice 和 空 slice 的处理是⼀致的吗？　 ⾸先JSON 标准库对 nil slice 和 空 slice 的处理是不⼀致.通常错误的⽤法，会报数组越界的错误，因为只是声明了slice，却没有给实例化的对象。此时slice的值是nil，这种情况可以⽤于需要返回slice的函数，当函数出现异常的时候，保证函数依然会有nil的返回值。empty slice 是指slice不为nil，但是slice没有值，slice的底层的空间是空的，此时的定义如下：// A Context carries a deadline, cancelation signal, and request-scoped values// across API boundaries. Its methods are safe for simultaneous use by multiple// goroutines.type Context interface {    // Done returns a channel that is closed when this `Context` is canceled    // or times out.    Done() <-chan struct{}    // Err indicates why this Context was canceled, after the Done channel    // is closed.    Err() error    // Deadline returns the time when this Context will be canceled, if any.    Deadline() (deadline time.Time, ok bool)    // Value returns the value associated with key or nil if none.    Value(key interface{}) interface{}}
var slice []intslice[1] = 0
当我们查询或者处理⼀个空的列表的时候，这⾮常有⽤，它会告诉我们返回的是⼀个列表，但是列表内没有任何值。总之，nil slice 和 empty slice是不同的东⻄,需要我们加以区分的.协程，线程，进程的区别。 进程进程是具有⼀定独⽴功能的程序关于某个数据集合上的⼀次运⾏活动,进程是系统进⾏资源分配和调度的⼀个独⽴单位。每个进程都有⾃⼰的独⽴内存空间，不同进程通过进程间通信来通信。由于进程⽐较重量，占据独⽴的内存，所以上下⽂进程间的切换开销（栈、寄存器、虚拟内存、⽂件句柄等）⽐较⼤，但相对⽐较稳定安全。线程线程是进程的⼀个实体,是CPU调度和分派的基本单位,它是⽐进程更⼩的能独⽴运⾏的基本单位.线程⾃⼰基本上不拥有系统资源,只拥有⼀点在运⾏中必不可少的资源(如程序计数器,⼀组寄存器和栈),但是它可与同属⼀个进程的其他的线程共享进程所拥有的全部资源。线程间通信主要通过共享内存，上下⽂切换很快，资源开销较少，但相⽐进程不够稳定容易丢失数据。协程协程是⼀种⽤户态的轻量级线程，协程的调度完全由⽤户控制。协程拥有⾃⼰的寄存器上下⽂和栈。协程调度切换时，将寄存器上下⽂和栈保存到其他地⽅，在切回来的时候，恢复先前保存的寄存器上下⽂和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下⽂的切换⾮常快。互斥锁，读写锁，死锁问题是怎么解决。 互斥锁互斥锁就是互斥变量mutex，⽤来锁住临界区的.条件锁就是条件变量，当进程的某些资源要求不满⾜时就进⼊休眠，也就是锁住了。当资源被分配到了，条件锁打开，进程继续运⾏；读写锁，也类似，⽤于缓冲区等临界资源能互斥访问的。读写锁通常有些公共数据修改的机会很少，但其读的机会很多。并且在读的过程中会伴随着查找，给这种代码加锁会降低我们的程序效率。读写锁可以解决这个问题。
注意：写独占，读共享，写锁优先级⾼死锁slice := make([]int,0）slice := []int{}
⼀般情况下，如果同⼀个线程先后两次调⽤lock，在第⼆次调⽤时，由于锁已经被占⽤，该线程会挂起等待别的线程释放锁，然⽽锁正是被⾃⼰占⽤着的，该线程⼜被挂起⽽没有机会释放锁，因此就永远处于挂起等待状态了，这叫做死锁（Deadlock）。 另外⼀种情况是：若线程A获得了锁1，线程B获得了锁2，这时线程A调⽤lock试图获得锁2，结果是需要挂起等待线程B释放锁2，⽽这时线程B也调⽤lock试图获得锁1，结果是需要挂起等待线程A释放锁1，于是线程A和B都永远处于挂起状态了。死锁产⽣的四个必要条件:1. 互斥条件：⼀个资源每次只能被⼀个进程使⽤2. 请求与保持条件：⼀个进程因请求资源⽽阻塞时，对已获得的资源保持不放。3. 不剥夺条件:进程已获得的资源，在末使⽤完之前，不能强⾏剥夺。4. 循环等待条件:若⼲进程之间形成⼀种头尾相接的循环等待资源关系。 这四个条件是死锁的必要条件，只要系统发⽣死锁，这些条件必然成⽴，⽽只要上述条件之⼀不满⾜，就不会发⽣死锁。a. 预防死锁可以把资源⼀次性分配：（破坏请求和保持条件）然后剥夺资源：即当某进程新的资源未满⾜时，释放已占有的资源（破坏不可剥夺条件）资源有序分配法：系统给每类资源赋予⼀个编号，每⼀个进程按编号递增的顺序请求资源，释放则相反（破坏环路等待条件）b. 避免死锁预防死锁的⼏种策略，会严重地损害系统性能。因此在避免死锁时，要施加较弱的限制，从⽽获得 较满意的系统性能。由于在避免死锁的策略中，允许进程动态地申请资源。因⽽，系统在进⾏资源分配之前预先计算资源分配的安全性。若此次分配不会导致系统进⼊不安全状态，则将资源分配给进程；否则，进程等待。其中最具有代表性的避免死锁算法是银⾏家算法。c. 检测死锁⾸先为每个进程和每个资源指定⼀个唯⼀的号码,然后建⽴资源分配表和进程等待表.d. 解除死锁当发现有进程死锁后，便应⽴即把它从死锁状态中解脱出来，常采⽤的⽅法有.e. 剥夺资源从其它进程剥夺⾜够数量的资源给死锁进程，以解除死锁状态.f. 撤消进程可以直接撤消死锁进程或撤消代价最⼩的进程，直⾄有⾜够的资源可⽤，死锁状态.消除为⽌.所谓代价是指优先级、运⾏代价、进程的重要性和价值等。Golang的内存模型，为什么⼩对象多了会造成gc压⼒。 通常⼩对象过多会导致GC三⾊法消耗过多的GPU。优化思路是，减少对象分配. 
说下Go中的锁有哪些?三种锁，读写锁，互斥锁，还有map的安全的锁? Go中的三种锁包括:互斥锁,读写锁,sync.Map的安全的锁.互斥锁Go并发程序对共享资源进⾏访问控制的主要⼿段，由标准库代码包中sync中的Mutex结构体表示。
sync.Mutex包中的类型只有两个公开的指针⽅法Lock和Unlock。
声明⼀个互斥锁：不像C或Java的锁类⼯具，我们可能会犯⼀个错误：忘记及时解开已被锁住的锁，从⽽导致流程异常。但Go由于存在defer，所以此类问题出现的概率极低。关于defer解锁的⽅式如下：
如果对⼀个已经上锁的对象再次上锁，那么就会导致该锁定操作被阻塞，直到该互斥锁回到被解锁状态.//Mutex 是互斥锁， 零值是解锁的互斥锁， ⾸次使⽤后不得复制互斥锁。type Mutex struct {   state int32   sema  uint32}//Locker表示可以锁定和解锁的对象。type Locker interface {   Lock()   Unlock()}//锁定当前的互斥量//如果锁已被使⽤，则调⽤goroutine//阻塞直到互斥锁可⽤。func (m *Mutex) Lock() //对当前互斥量进⾏解锁//如果在进⼊解锁时未锁定m，则为运⾏时错误。//锁定的互斥锁与特定的goroutine⽆关。//允许⼀个goroutine锁定Mutex然后安排另⼀个goroutine来解锁它。func (m *Mutex) Unlock()var mutex sync.Mutexvar mutex sync.Mutexfunc Write()  {   mutex.Lock()   defer mutex.Unlock()}
我们在for循环之前开始加锁，然后在每⼀次循环中创建⼀个协程，并对其加锁，但是由于之前已经加锁了，所以这个for循环中的加锁会陷⼊阻塞直到main中的锁被解锁， time.Sleep(time.Second) 是为了能让系统有⾜够的时间运⾏for循环，输出结果如下：
这⾥可以看到解锁后，三个协程会重新抢夺互斥锁权，最终协程3获胜。互斥锁锁定操作的逆操作并不会导致协程阻塞，但是有可能导致引发⼀个⽆法恢复的运⾏时的panic，⽐如对⼀个未锁定的互斥锁进⾏解锁时就会发⽣panic。避免这种情况的最有效⽅式就是使⽤defer。fpackage mainimport (    "fmt"    "sync"    "time")func main() {    var mutex sync.Mutex    fmt.Println("begin lock")    mutex.Lock()    fmt.Println("get locked")    for i := 1; i <= 3; i++ {        go func(i int) {            fmt.Println("begin lock ", i)            mutex.Lock()            fmt.Println("get locked ", i)        }(i)    }    time.Sleep(time.Second)    fmt.Println("Unlock the lock")    mutex.Unlock()    fmt.Println("get unlocked")    time.Sleep(time.Second)}
> go run mutex.go begin lockget lockedbegin lock  3begin lock  1begin lock  2Unlock the lockget unlockedget locked  3
我们知道如果遇到panic，可以使⽤recover⽅法进⾏恢复，但是如果对重复解锁互斥锁引发的panic却是⽆⽤的（Go 1.8及以后）。
运⾏:package mainimport (    "fmt"    "sync")func main() {    defer func() {        fmt.Println("Try to recover the panic")        if p := recover(); p != nil {            fmt.Println("recover the panic : ", p)        }    }()    var mutex sync.Mutex    fmt.Println("begin lock")    mutex.Lock()    fmt.Println("get locked")    fmt.Println("unlock lock")    mutex.Unlock()    fmt.Println("lock is unlocked")    fmt.Println("unlock lock again")    mutex.Unlock()}> go run mutex.go begin lockget lockedunlock locklock is unlockedunlock lock againfatal error: sync: unlock of unlocked mutexgoroutine 1 [running]:runtime.throw(0x4bc1a8, 0x1e)        /home/keke/soft/go/src/runtime/panic.go:617 +0x72 fp=0xc000084ea8 sp=0xc000084e78 pc=0x427ba2sync.throw(0x4bc1a8, 0x1e)        /home/keke/soft/go/src/runtime/panic.go:603 +0x35 fp=0xc000084ec8 sp=0xc000084ea8 pc=0x427b25sync.(*Mutex).Unlock(0xc00001a0c8)        /home/keke/soft/go/src/sync/mutex.go:184 +0xc1 fp=0xc000084ef0 sp=0xc000084ec8 pc=0x45f821
这⾥试图对重复解锁引发的panic进⾏recover，但是我们发现操作失败，虽然互斥锁可以被多个协程共享，但还是建议将对同⼀个互斥锁的加锁解锁操作放在同⼀个层次的代码中。读写锁读写锁是针对读写操作的互斥锁，可以分别针对读操作与写操作进⾏锁定和解锁操作 。读写锁的访问控制规则如下：① 多个写操作之间是互斥的 ② 写操作与读操作之间也是互斥的 ③ 多个读操作之间不是互斥的在这样的控制规则下，读写锁可以⼤⼤降低性能损耗。在Go的标准库代码包中sync中的RWMutex结构体表示为:
sync中的RWMutex有以下⼏种⽅法：main.main()        /home/keke/go/Test/mutex.go:25 +0x25f fp=0xc000084f98 sp=0xc000084ef0 pc=0x486c1fruntime.main()        /home/keke/soft/go/src/runtime/proc.go:200 +0x20c fp=0xc000084fe0 sp=0xc000084f98 pc=0x4294ecruntime.goexit()        /home/keke/soft/go/src/runtime/asm_amd64.s:1337 +0x1 fp=0xc000084fe8 sp=0xc000084fe0 pc=0x450ad1exit status 2
// RWMutex是⼀个读/写互斥锁，可以由任意数量的读操作或单个写操作持有。// RWMutex的零值是未锁定的互斥锁。//⾸次使⽤后，不得复制RWMutex。//如果goroutine持有RWMutex进⾏读取⽽另⼀个goroutine可能会调⽤Lock，那么在释放初始读锁之前，goroutine不应该期望能够获取读锁定。 //特别是，这种禁⽌递归读锁定。 这是为了确保锁最终变得可⽤; 阻⽌的锁定会阻⽌新读操作获取锁定。type RWMutex struct {   w           Mutex  //如果有待处理的写操作就持有   writerSem   uint32 // 写操作等待读操作完成的信号量   readerSem   uint32 //读操作等待写操作完成的信号量   readerCount int32  // 待处理的读操作数量   readerWait  int32  // number of departing readers}
Unlock⽅法会试图唤醒所有想进⾏读锁定⽽被阻塞的协程，⽽ RUnlock⽅法只会在已⽆任何读锁定的情况下，试图唤醒⼀个因欲进⾏写锁定⽽被阻塞的协程。若对⼀个未被写锁定的读写锁进⾏写解锁，就会引发⼀个不可恢复的panic，同理对⼀个未被读锁定的读写锁进⾏读写锁也会如此。由于读写锁控制下的多个读操作之间不是互斥的，因此对于读解锁更容易被忽视。对于同⼀个读写锁，添加多少个读锁定，就必要有等量的读解锁，这样才能其他协程有机会进⾏操作。
运⾏://对读操作的锁定func (rw *RWMutex) RLock()//对读操作的解锁func (rw *RWMutex) RUnlock()//对写操作的锁定func (rw *RWMutex) Lock()//对写操作的解锁func (rw *RWMutex) Unlock()//返回⼀个实现了sync.Locker接⼝类型的值，实际上是回调rw.RLock and rw.RUnlock.func (rw *RWMutex) RLocker() Locker
package mainimport (    "fmt"    "sync"    "time")func main() {    var rwm sync.RWMutex    for i := 0; i < 5; i++ {        go func(i int) {            fmt.Println("try to lock read ", i)            rwm.RLock()            fmt.Println("get locked ", i)            time.Sleep(time.Second * 2)            fmt.Println("try to unlock for reading ", i)            rwm.RUnlock()            fmt.Println("unlocked for reading ", i)        }(i)    }    time.Sleep(time.Millisecond * 1000)    fmt.Println("try to lock for writing")    rwm.Lock()    fmt.Println("locked for writing")}
这⾥可以看到创建了五个协程⽤于对读写锁的读锁定与读解锁操作。在 rwm.Lock()种会对main中协程进⾏写锁定，但是for循环中的读解锁尚未完成，因此会造成mian中的协程阻塞。当for循环中的读解锁操作都完成后就会试图唤醒main中阻塞的协程，main中的写锁定才会完成。sync.Map安全锁golang中的sync.Map是并发安全的，其实也就是sync包中golang⾃定义的⼀个名叫Map的结构体。应⽤示例:> go run rwmutex.go try to lock read  0get locked  0try to lock read  4get locked  4try to lock read  3get locked  3try to lock read  1get locked  1try to lock read  2get locked  2try to lock for writingtry to unlock for reading  0unlocked for reading  0try to unlock for reading  2unlocked for reading  2try to unlock for reading  1unlocked for reading  1try to unlock for reading  3unlocked for reading  3try to unlock for reading  4unlocked for reading  4locked for writing
package mainimport (    "sync"    "fmt")func main() {    //开箱即⽤    var sm sync.Map    //store ⽅法,添加元素    sm.Store(1,"a")    //Load ⽅法，获得value    if v,ok:=sm.Load(1);ok{        fmt.Println(v)    }
运⾏ :
sync.Map的数据结构:
read的数据结构是：    //LoadOrStore⽅法，获取或者保存    //参数是⼀对key：value，如果该key存在且没有被标记删除则返回原先的value（不更新）和true；不存在则store，返回该value 和false    if vv,ok:=sm.LoadOrStore(1,"c");ok{        fmt.Println(vv)    }    if vv,ok:=sm.LoadOrStore(2,"c");!ok{        fmt.Println(vv)    }    //遍历该map，参数是个函数，该函数参的两个参数是遍历获得的key和value，返回⼀个bool值，当返回false时，遍历⽴刻结束。    sm.Range(func(k,v interface{})bool{        fmt.Print(k)        fmt.Print(":")        fmt.Print(v)        fmt.Println()        return true    })}aac1:a2:c type Map struct {    // 该锁⽤来保护dirty    mu Mutex    // 存读的数据，因为是atomic.value类型，只读类型，所以它的读是并发安全的    read atomic.Value // readOnly    //包含最新的写⼊的数据，并且在写的时候，会把read 中未被删除的数据拷⻉到该dirty中，因为是普通的map存在并发安全问题，需要⽤到上⾯的mu字段。    dirty map[interface{}]*entry    // 从read读数据的时候，会将该字段+1，当等于len（dirty）的时候，会将dirty拷⻉到read中（从⽽提升读的性能）。    misses int}
entry的数据结构：
Delete ⽅法:type readOnly struct {    m  map[interface{}]*entry    // 如果Map.dirty的数据和m 中的数据不⼀样是为true    amended bool }type entry struct {    //可⻅value是个指针类型，虽然read和dirty存在冗余情况（amended=false），但是由于是指针类型，存储的空间应该不是问题    p unsafe.Pointer // *interface{}}func (m *Map) Delete(key interface{}) {    read, _ := m.read.Load().(readOnly)    e, ok := read.m[key]    //如果read中没有，并且dirty中有新元素，那么就去dirty中去找    if !ok && read.amended {        m.mu.Lock()        //这是双检查（上⾯的if判断和锁不是⼀个原⼦性操作）        read, _ = m.read.Load().(readOnly)        e, ok = read.m[key]        if !ok && read.amended {            //直接删除            delete(m.dirty, key)        }        m.mu.Unlock()    }    if ok {    //如果read中存在该key，则将该value 赋值nil（采⽤标记的⽅式删除！）        e.delete()    }}func (e *entry) delete() (hadValue bool) {    for {        p := atomic.LoadPointer(&e.p)        if p == nil || p == expunged {            return false        }        if atomic.CompareAndSwapPointer(&e.p, p, nil) {            return true        }    }}
Store ⽅法:func (m *Map) Store(key, value interface{}) {    // 如果m.read存在这个key，并且没有被标记删除，则尝试更新。    read, _ := m.read.Load().(readOnly)    if e, ok := read.m[key]; ok && e.tryStore(&value) {        return    }    // 如果read不存在或者已经被标记删除    m.mu.Lock()    read, _ = m.read.Load().(readOnly)    if e, ok := read.m[key]; ok {    //如果entry被标记expunge，则表明dirty没有key，可添加⼊dirty，并更新entry        if e.unexpungeLocked() {             //加⼊dirty中            m.dirty[key] = e        }        //更新value值        e.storeLocked(&value)         //dirty 存在该key，更新    } else if e, ok := m.dirty[key]; ok {         e.storeLocked(&value)        //read 和dirty都没有，新添加⼀条    } else {     //dirty中没有新的数据，往dirty中增加第⼀个新键        if !read.amended {             //将read中未删除的数据加⼊到dirty中            m.dirtyLocked()             m.read.Store(readOnly{m: read.m, amended: true})        }        m.dirty[key] = newEntry(value)     }    m.mu.Unlock()}//将read中未删除的数据加⼊到dirty中func (m *Map) dirtyLocked() {    if m.dirty != nil {        return    }    read, _ := m.read.Load().(readOnly)    m.dirty = make(map[interface{}]*entry, len(read.m))    //read如果较⼤的话，可能影响性能    for k, e := range read.m {    //通过此次操作，dirty中的元素都是未被删除的，可⻅expunge的元素不在dirty中        if !e.tryExpungeLocked() {            m.dirty[k] = e        }
因此，每次操作先检查read，因为read 并发安全，性能好些；read不满⾜，则加锁检查dirty，⼀旦是新的键值，dirty会被read更新。Load⽅法:Load⽅法是⼀个加载⽅法，查找key。    }}//判断entry是否被标记删除，并且将标记为nil的entry更新标记为expungefunc (e *entry) tryExpungeLocked() (isExpunged bool) {    p := atomic.LoadPointer(&e.p)    for p == nil {        // 将已经删除标记为nil的数据标记为expunged        if atomic.CompareAndSwapPointer(&e.p, nil, expunged) {            return true        }        p = atomic.LoadPointer(&e.p)    }    return p == expunged}//对entry 尝试更新func (e *entry) tryStore(i *interface{}) bool {    p := atomic.LoadPointer(&e.p)    if p == expunged {        return false    }    for {        if atomic.CompareAndSwapPointer(&e.p, p, unsafe.Pointer(i)) {            return true        }        p = atomic.LoadPointer(&e.p)        if p == expunged {            return false        }    }}//read⾥ 将标记为expunge的更新为nilfunc (e *entry) unexpungeLocked() (wasExpunged bool) {    return atomic.CompareAndSwapPointer(&e.p, expunged, nil)}//更新entryfunc (e *entry) storeLocked(i *interface{}) {    atomic.StorePointer(&e.p, unsafe.Pointer(i))}
sync.Map是通过冗余的两个数据结构(read、dirty),实现性能的提升。为了提升性能，load、delete、store等操作尽量使⽤只读的read；为了提⾼read的key击中概率，采⽤动态调整，将dirty数据提升为read；对于数据的删除，采⽤延迟标记删除法，只有在提升dirty的时候才删除。 func (m *Map) Load(key interface{}) (value interface{}, ok bool) {    //因read只读，线程安全，先查看是否满⾜条件    read, _ := m.read.Load().(readOnly)    e, ok := read.m[key]    //如果read没有，并且dirty有新数据，那从dirty中查找，由于dirty是普通map，线程不安全，这个时候⽤到互斥锁了    if !ok && read.amended {        m.mu.Lock()        // 双重检查        read, _ = m.read.Load().(readOnly)        e, ok = read.m[key]        // 如果read中还是不存在，并且dirty中有新数据        if !ok && read.amended {            e, ok = m.dirty[key]            // mssLocked（）函数是性能是sync.Map 性能得以保证的重要函数，⽬的讲有锁的dirty数据，替换到只读线程安全的read⾥            m.missLocked()        }        m.mu.Unlock()    }    if !ok {        return nil, false    }    return e.load()}//dirty 提升⾄read 关键函数，当misses 经过多次因为load之后，⼤⼩等于len（dirty）时候，讲dirty替换到read⾥，以此达到性能提升。func (m *Map) missLocked() {    m.misses++    if m.misses < len(m.dirty) {        return    }    //原⼦操作，耗时很⼩    m.read.Store(readOnly{m: m.dirty})    m.dirty = nil    m.misses = 0}
什么是channel，为什么它可以做到线程安全？ Channel是Go中的⼀个核⼼类型，可以把它看成⼀个管道，通过它并发核⼼单元就可以发送或者接收数据进⾏通讯(communication),Channel也可以理解是⼀个先进先出的队列，通过管道进⾏通信。Golang的Channel,发送⼀个数据到Channel 和 从Channel接收⼀个数据 都是 原⼦性的。⽽且Go的设计思想就是:不要通过共享内存来通信，⽽是通过通信来共享内存，前者就是传统的加锁，后者就是Channel。也就是说，设计Channel的主要⽬的就是在多任务间传递数据的，这当然是安全的。 读写锁或者互斥锁读的时候能写吗? Go中读写锁包括读锁和写锁，多个读线程可以同时访问共享数据；写线程必须等待所有读线程都释放锁以后，才能取得锁；同样的，读线程必须等待写线程释放锁后，才能取得锁，也就是说读写锁要确保的是如下互斥关系，可以同时读，但是读-写，写-写都是互斥的。怎么限制Goroutine的数量. 在Golang中，Goroutine虽然很好，但是数量太多了，往往会带来很多麻烦，⽐如耗尽系统资源导致程序崩溃，或者CPU使⽤率过⾼导致系统忙不过来。所以我们可以限制下Goroutine的数量,这样就需要在每⼀次执⾏go之前判断goroutine的数量，如果数量超了，就要阻塞go的执⾏。第⼀时间想到的就是使⽤通道。每次执⾏的go之前向通道写⼊值，直到通道满的时候就阻塞了，
运⾏:package mainimport "fmt"var ch chan  intfunc elegance(){    <-ch    fmt.Println("the ch value receive",ch)}func main(){    ch = make(chan int,5)    for i:=0;i<10;i++{        ch <-1        fmt.Println("the ch value send",ch)        go elegance()        fmt.Println("the result i",i)    }}> go run goroutine.go 
the ch value send 0xc00009c000the result i 0the ch value send 0xc00009c000the result i 1the ch value send 0xc00009c000the result i 2the ch value send 0xc00009c000the result i 3the ch value send 0xc00009c000the result i 4the ch value send 0xc00009c000the result i 5the ch value send 0xc00009c000the ch value receive 0xc00009c000the result i 6the ch value receive 0xc00009c000the ch value send 0xc00009c000the result i 7the ch value send 0xc00009c000the result i 8the ch value send 0xc00009c000the result i 9the ch value send 0xc00009c000the ch value receive 0xc00009c000the ch value receive 0xc00009c000the ch value receive 0xc00009c000the result i 10the ch value send 0xc00009c000the result i 11the ch value send 0xc00009c000the result i 12the ch value send 0xc00009c000the result i 13the ch value send 0xc00009c000the ch value receive 0xc00009c000the ch value receive 0xc00009c000the ch value receive 0xc00009c000the ch value receive 0xc00009c000the result i 14the ch value receive 0xc00009c000> go run goroutine.go the ch value send 0xc00007e000the result i 0the ch value send 0xc00007e000the result i 1the ch value send 0xc00007e000the result i 2the ch value send 0xc00007e000the result i 3
这样每次同时运⾏的goroutine就被限制为5个了。但是新的问题于是就出现了，因为并不是所有的goroutine都执⾏完了，在main函数退出之后，还有⼀些goroutine没有执⾏完就被强制结束了。这个时候我们就需要⽤到sync.WaitGroup。使⽤WaitGroup等待所有的goroutine退出。the ch value send 0xc00007e000the ch value receive 0xc00007e000the result i 4the ch value send 0xc00007e000the ch value receive 0xc00007e000the result i 5the ch value send 0xc00007e000the ch value receive 0xc00007e000the result i 6the ch value send 0xc00007e000the result i 7the ch value send 0xc00007e000the ch value receive 0xc00007e000the ch value receive 0xc00007e000the ch value receive 0xc00007e000the result i 8the ch value send 0xc00007e000the result i 9
package mainimport (    "fmt"    "runtime"    "sync"    "time")// Pool Goroutine Pooltype Pool struct {    queue chan int    wg *sync.WaitGroup}// New 新建⼀个协程池func NewPool(size int) *Pool{    if size <=0{        size = 1    }    return &Pool{        queue:make(chan int,size),        wg:&sync.WaitGroup{},    }}// Add 新增⼀个执⾏func (p *Pool)Add(delta int){    // delta为正数就添加
运⾏:    for i :=0;i<delta;i++{        p.queue <-1    }    // delta为负数就减少    for i:=0;i>delta;i--{        <-p.queue    }    p.wg.Add(delta)}// Done 执⾏完成减⼀func (p *Pool) Done(){    <-p.queue    p.wg.Done()}// Wait 等待Goroutine执⾏完毕func (p *Pool) Wait(){    p.wg.Wait()}func main(){    // 这⾥限制5个并发    pool := NewPool(5)    fmt.Println("the NumGoroutine begin is:",runtime.NumGoroutine())    for i:=0;i<20;i++{        pool.Add(1)        go func(i int) {            time.Sleep(time.Second)            fmt.Println("the NumGoroutine continue is:",runtime.NumGoroutine())            pool.Done()        }(i)    }    pool.Wait()    fmt.Println("the NumGoroutine done is:",runtime.NumGoroutine())}the NumGoroutine begin is: 1the NumGoroutine continue is: 6the NumGoroutine continue is: 7the NumGoroutine continue is: 6the NumGoroutine continue is: 6the NumGoroutine continue is: 6the NumGoroutine continue is: 6the NumGoroutine continue is: 6the NumGoroutine continue is: 6the NumGoroutine continue is: 6the NumGoroutine continue is: 6the NumGoroutine continue is: 6
其中，Go的GOMAXPROCS默认值已经设置为CPU的核数， 这⾥允许我们的Go程序充分使⽤机器的每⼀个CPU,最⼤程度的提⾼我们程序的并发性能。runtime.NumGoroutine函数在被调⽤后，会返回系统中的处于特定状态的Goroutine的数量。这⾥的特指是指Grunnable\Gruning\Gsyscall\Gwaition。处于这些状态的Groutine即被看做是活跃的或者说正在被调度。这⾥需要注意下：垃圾回收所在Groutine的状态也处于这个范围内的话，也会被纳⼊该计数器。Channel是同步的还是异步的. Channel是异步进⾏的。channel存在3种状态：nil，未初始化的状态，只进⾏了声明，或者⼿动赋值为nilactive，正常的channel，可读或者可写closed，已关闭，千万不要误认为关闭channel后，channel的值是nil   Data Race问题怎么解决？能不能不加锁解决这个问题？ 同步访问共享数据是处理数据竞争的⼀种有效的⽅法.golang在1.1之后引⼊了竞争检测机制，可以使⽤ go run -race 或者 go build -race来进⾏静态检测。 其在内部的实现是,开启多个协程执⾏同⼀个命令， 并且记录下每个变量的状态.竞争检测器基于C/C++的ThreadSanitizer 运⾏时库，该库在Google内部代码基地和Chromium找到许多错误。这个技术在2012年九⽉集成到Go中，从那时开始，它已经在标准库中检测到42个竞争条件。现在，它已经是我们持续构建过程的⼀部分，当竞争条件出现时，它会继续捕捉到这些错误。竞争检测器已经完全集成到Go⼯具链中，仅仅添加-race标志到命令⾏就使⽤了检测器。the NumGoroutine continue is: 6the NumGoroutine continue is: 6the NumGoroutine continue is: 6the NumGoroutine continue is: 6the NumGoroutine continue is: 6the NumGoroutine continue is: 6the NumGoroutine continue is: 6the NumGoroutine continue is: 3the NumGoroutine continue is: 2the NumGoroutine done is: 1
$ go test -race mypkg    // 测试包$ go run -race mysrc.go  // 编译和运⾏程序$ go build -race mycmd   // 构建程序$ go install -race mypkg // 安装程序
要想解决数据竞争的问题可以使⽤互斥锁sync.Mutex,解决数据竞争(Data race),也可以使⽤管道解决,使⽤管道的效率要⽐互斥锁⾼. 如何在运⾏时检查变量类型？ 类型开关是在运⾏时检查变量类型的最佳⽅式。类型开关按类型⽽不是值来评估变量。每个 Switch ⾄少包含⼀个 case，⽤作条件语句，和⼀个 defaultcase，如果没有⼀个 case 为真，则执⾏。Go 两个接⼝之间可以存在什么关系？ 如果两个接⼝有相同的⽅法列表，那么他们就是等价的，可以相互赋值。如果接⼝ A的⽅法列表是接⼝ B的⽅法列表的⾃⼰，那么接⼝ B可以赋值给接⼝ A。接⼝查询是否成功，要在运⾏期才能够确定。Go 当中同步锁有什么特点？作⽤是什么 当⼀个 Goroutine（协程）获得了 Mutex 后，其他 Gorouline（协程）就只能乖乖的等待，除⾮该 gorouline 释放了该 MutexRWMutex在读锁占⽤的情况下，会阻⽌写，但不阻⽌读 RWMutex 在写锁占⽤情况下，会阻⽌任何其他goroutine（⽆论读和写）进来，整个锁相当于由该 goroutine 独占同步锁的作⽤是保证资源在使⽤时的独有性，不会因为并发⽽导致数据错乱，保证系统的稳定性。Go 语⾔当中 Channel（通道）有什么特点，需要注意什么？ 如果给⼀个 nil 的 channel 发送数据，会造成永远阻塞如果从⼀个 nil 的 channel 中接收数据，也会造成永久爱阻塞给⼀个已经关闭的 channel 发送数据，会引起 pannic 从⼀个已经关闭的 channel 接收数据，如果缓冲区中为空，则返回⼀个零值。Go 语⾔当中 Channel 缓冲有什么特点？ ⽆缓冲的 channel 是同步的，⽽有缓冲的 channel 是⾮同步的。Go 语⾔中 cap 函数可以作⽤于那些内容？ cap 函数在讲引⽤的问题中已经提到，可以作⽤于的类型有：array(数组)slice(切⽚)channel(通道)go convey 是什么？⼀般⽤来做什么？ go convey 是⼀个⽀持 golang 的单元测试框架go convey 能够⾃动监控⽂件修改并启动测试，并可以将测试结果实时输出到 Web界⾯go convey 提供了丰富的断⾔简化测试⽤例的编写
Go 语⾔当中 new 和 make 有什么区别吗？ new的作⽤是初始化⼀个纸箱类型的指针 new函数是内建函数，函数定义：使⽤ new函数来分配空间传递给 new函数的是⼀个类型，⽽不是⼀个值返回值是指向这个新⾮配的地址的指针Go 语⾔中 make 的作⽤是什么？ make的作⽤是为 slice, map or chan 的初始化然后返回引⽤ make函数是内建函数，函数定义：make(T, args)函数的⽬的和 new(T)不同仅仅⽤于创建 slice, map, channel ⽽且返回类型是实例。Printf(),Sprintf(),FprintF()都是格式化输出，有什么不同？ 虽然这三个函数，都是格式化输出，但是输出的⽬标不⼀样 Printf 是标准输出，⼀般是屏幕，也可以重定向。 Sprintf()是把格式化字符串输出到指定的字符串中。 Fprintf()是吧格式化字符串输出到⽂件中。Go 语⾔当中数组和切⽚的区别是什么？ 数组：数组固定⻓度数组⻓度是数组类型的⼀部分，所以[3]int 和[4]int 是两种不同的数组类型数组需要指定⼤⼩，不指定也会根据处初始化对的⾃动推算出⼤⼩，不可改变数组是通过值传递的切⽚：切⽚可以改变⻓度切⽚是轻量级的数据结构，三个属性，指针，⻓度，容量不需要指定⼤⼩切⽚是地址传递（引⽤传递）可以通过数组来初始化，也可以通过内置函数 make()来初始化，初始化的时候 len=cap，然后进⾏扩容。Go 语⾔当中值传递和地址传递（引⽤传递）如何运⽤？有什么区别？举例说明 1. 值传递只会把参数的值复制⼀份放进对应的函数，两个变量的地址不同，不可相互修改。2. 地址传递(引⽤传递)会将变量本身传⼊对应的函数，在函数中可以对该变量进⾏值内容的修改。Go 语⾔当中数组和切⽚在传递的时候的区别是什么？ 1. 数组是值传递2. 切⽚是引⽤传递func new(Type)*Type 
func make(Type, size IntegerType) Type
Go 语⾔是如何实现切⽚扩容的？ 
我们可以看下结果依次是0,1,2,4,8,16,32,64,128,256,512,1024 但到了1024 之后,就变成了1024,1280,1696,2304 每次都是扩容了四分之⼀左右 看下⾯代码的 defer 的执⾏顺序是什么？ defer 的作⽤和特点是什么？ defer 的作⽤是：你只需要在调⽤普通函数或⽅法前加上关键字 defer，就完成了 defer 所需要的语法。当 defer 语句被执⾏时，跟在 defer 后⾯的函数会被延迟执⾏。直到包含该 defer 语句的函数执⾏完毕时，defer 后的函数才会被执⾏，不论包含 defer 语句的函数是通过 return 正常结束，还是由于 panic 导致的异常结束。你可以在⼀个函数中执⾏多条 defer 语句，它们的执⾏顺序与声明顺序相反。 defer 的常⽤场景：defer 语句经常被⽤于处理成对的操作，如打开、关闭、连接、断开连接、加锁、释放锁。通过 defer 机制，不论函数逻辑多复杂，都能保证在任何执⾏路径下，资源被释放。释放资源的 defer 应该直接跟在请求资源的语句后。Golang Slice 的底层实现 切⽚是基于数组实现的，它的底层是数组，它⾃⼰本身⾮常⼩，可以理解为对底层数组的抽象。因为基于数组实现，所以它的底层的内存是连续分配的，效率⾮常⾼，还可以通过索引获得数据，可以迭代以及垃圾回收优化。切⽚本身并不是动态数组或者数组指针。它内部实现的数据结构通过指针引⽤底层数组，设定相关属性将数据读写操作限定在指定的区域内。切⽚本身是⼀个只读对象，其⼯作机制类似数组指针的⼀种封装。切⽚对象⾮常⼩，是因为它是只有3 个字段的数据结构：指向底层数组的指针切⽚的⻓度切⽚的容量func main(){  arr := make([]int,0)  for i := 0; i < 2000; i++{    fmt.Println("len 为", len(arr),"cap 为", cap(arr)) arr = append(arr, i)  }}
Golang Slice 的扩容机制，有什么注意点？ Go 中切⽚扩容的策略是这样的：⾸先判断，如果新申请容量⼤于2 倍的旧容量，最终容量就是新申请的容量否则判断，如果旧切⽚的⻓度⼩于1024，则最终容量就是旧容量的两倍否则判断，如果旧切⽚⻓度⼤于等于1024，则最终容量从旧容量开始循环增加原来的1/4,直到最终容量⼤于等于新申请的容量如果最终容量计算值溢出，则最终容量就是新申请容量扩容前后的 Slice 是否相同？ 情况⼀：原数组还有容量可以扩容（实际容量没有填充完），这种情况下，扩容以后的数组还是指向原来的数组，对⼀个切⽚的操作可能影响多个指针指向相同地址的 Slice。情况⼆：原来数组的容量已经达到了最⼤值，再想扩容， Go 默认会先开⼀⽚内存区域，把原来的值拷⻉过来，然后再执⾏ append()操作。这种情况丝毫不影响原数组。要复制⼀个 Slice，最好使⽤ Copy函数。Golang 的参数传递、引⽤类型 Go 语⾔中所有的传参都是值传递(传值)，都是⼀个副本，⼀个拷⻉。因为拷 ⻉的内容有时候是⾮引⽤类型(int、string、struct 等这些)，这样就在函 数中就⽆法修改原内容数据;有的是引⽤类型(指针、map、slice、chan等 这些)，这样就可以修改原内容数据。Golang 的引⽤类型包括 slice、map 和 channel。它们有复杂的内部结构，除 了申请内存外，还需要初始化相关属性。内置函数 new 计算类型⼤⼩，为其分 配零值内存，返回指针。⽽ make 会被编译器翻译成具体的创建函数，由其分 配内存和初始化成员结构，返回对象⽽⾮指针。 Golang Map 底层实现 Golang 中 map的底层实现是⼀个散列表，因此实现 map的过程实际上就是实现散表的过程。在这个散列表中，主要出现的结构体有两个，⼀个叫 hmap(a header for a go map)，⼀个叫 bmap(a bucket for a Go map，通常叫其bucket)。  Golang Map 如何扩容 装载因⼦：count/2^B 触发条件：1. 装填因⼦是否⼤于6.5 2. overflow bucket 是否太多解决⽅法：
1. 双倍扩容：扩容采取了⼀种称为“渐进式”地⽅式，原有的 key 并不会⼀次性搬迁完毕，每次最多只会搬迁2 个 bucket 2. 等量扩容：重新排列，极端情况下，重新排列也解决不了，map成了链表，性能⼤⼤降低，此时哈希种⼦ hash0 的设置，可以降低此类极端场景的发⽣。Golang Map 查找 Go语⾔中 map采⽤的是哈希查找表，由⼀个 key 通过哈希函数得到哈希值，64 位系统中就⽣成⼀个64bit 的哈希值，由这个哈希值将 key 对应到不同的桶bucket）中，当有多个哈希映射到相同的的桶中时，使⽤链表解决哈希冲突。key 经过 hash 后共64 位，根据 hmap中 B的值，计算它到底要落在哪个桶时，桶的数量为2^B，如 B=5，那么⽤64 位最后5 位表示第⼏号桶，在⽤ hash 值的⾼8 位确定在 bucket 中的存储位置，当前 bmap中的 bucket 未找到，则查询对应的 overflow bucket，对应位置有数据则对⽐完整的哈希值，确定是否是要查找的数据。如果两个不同的 key 落在的同⼀个桶上，hash 冲突使⽤链表法接近，遍历 bucket 中的 key 如果当前处于 map进⾏了扩容，处于数据搬移状态，则优先从 oldbuckets 查找。介绍⼀下 Channel Go语⾔中，不要通过共享内存来通信，⽽要通过通信来实现内存共享。Go的 CSP(Communicating Sequential Process)并发模型，中⽂可以叫做通信顺序进程，是通过 goroutine 和 channel 来实现的。所以 channel 收发遵循先进先出 FIFO，分为有缓存和⽆缓存，channel 中⼤致有 buffer(当缓冲区⼤⼩部位0 时，是个 ring buffer)、sendx 和 recvx 收发的位置(ring buffer 记录实现)、sendq、recvq 当前 channel 因为缓冲区不⾜⽽阻塞的队列、使⽤双向链表存储、还有⼀个 mutex 锁控制并发、其他原属等。Go 语⾔的 Channel 特性？ 1. 给⼀个 nil channel 发送数据，造成永远阻塞2. 从⼀个 nil channel 接收数据，造成永远阻塞3. 给⼀个已经关闭的 channel 发送数据，引起 panic 4. 从⼀个已经关闭的 channel 接收数据，如果缓冲区中为空，则返回⼀个零值5. ⽆缓冲的 channel 是同步的，⽽有缓冲的 channel 是⾮同步的6. 关闭⼀个 nil channel 将会发⽣ panic Channel 的 ring buffer 实现 channel 中使⽤了 ring buffer(环形缓冲区)来缓存写⼊的数据。ring buffer 有很多好处，⽽且⾮常适合⽤来实现 FIFO 式的固定⻓度队列。在 channel 中，ring buffer 的实现如下：

hchan 中有两个与 buffer 相关的变量:recvx 和 sendx。其中 sendx 表示buffer 中可写的 index，recvx 表示 buffer 中可读的 index。从 recvx 到 sendx 之间的元素，表示已正常存放⼊ buffer 中的数据。我们可以直接使⽤ buf[recvx]来读取到队列的第⼀个元素，使⽤ buf[sendx]= x 来将元素放到队尾。Go 进阶   golang⾯试官：for select时，如果通道已经关闭会怎么样？如果只有⼀个case呢？  https://mp.weixin.qq.com/s/Oa3eExufo2Req_9IrDys-g   golang⾯试题：对已经关闭的的chan进⾏读写，会怎么样？为什么？  https://mp.weixin.qq.com/s/izbZ3JRqX6jI6Wn7bV6xNQ  golang⾯试题：对未初始化的的chan进⾏读写，会怎么样？为什么？  https://mp.weixin.qq.com/s/ixJu0wrGXsCcGzveCqnr6A  golang⾯试题：能说说uintptr和unsafe.Pointer的区别吗？  https://mp.weixin.qq.com/s/PSkz0zj-vqKzmIKa_b-xAA  golang ⾯试题：reflect（反射包）如何获取字段 tag？为什么 json 包不能导出私有变量的 tag？  https://mp.weixin.qq.com/s/WK9StkC3Jfy-o1dUqlo7Dg   
golang⾯试题：怎么避免内存逃逸？  https://mp.weixin.qq.com/s/VzRTHz1JaDUvNRVB_yJa1A  golang⾯试题：简单聊聊内存逃逸？  https://mp.weixin.qq.com/s/wJmztRMB1ZAAIItyMcS0tw    Golang GC 时会发⽣什么? ⾸先我们先来了解下垃圾回收.什么是垃圾回收？内存管理是程序员开发应⽤的⼀⼤难题。传统的系统级编程语⾔（主要指C/C++）中，程序开发者必须对内存⼩⼼的进⾏管理操作，控制内存的申请及释放。因为稍有不慎，就可能产⽣内存泄露问题，这种问题不易发现并且难以定位，⼀直成为困扰程序开发者的噩梦。如何解决这个头疼的问题呢？过去⼀般采⽤两种办法：内存泄露检测⼯具。这种⼯具的原理⼀般是静态代码扫描，通过扫描程序检测可能出现内存泄露的代码段。然⽽检测⼯具难免有疏漏和不⾜，只能起到辅助作⽤。智能指针。这是 c++ 中引⼊的⾃动内存管理⽅法，通过拥有⾃动内存管理功能的指针对象来引⽤对象，是程序员不⽤太关注内存的释放，⽽达到内存⾃动释放的⽬的。这种⽅法是采⽤最⼴泛的做法，但是对程序开发者有⼀定的学习成本（并⾮语⾔层⾯的原⽣⽀持），⽽且⼀旦有忘记使⽤的场景依然⽆法避免内存泄露。为了解决这个问题，后来开发出来的⼏乎所有新语⾔（java，python，php等等）都引⼊了语⾔层⾯的⾃动内存管理 – 也就是语⾔的使⽤者只⽤关注内存的申请⽽不必关⼼内存的释放，内存释放由虚拟机（virtual machine）或运⾏时（runtime）来⾃动进⾏管理。⽽这种对不再使⽤的内存资源进⾏⾃动回收的⾏为就被称为垃圾回收。常⽤的垃圾回收的⽅法:引⽤计数（reference counting）这是最简单的⼀种垃圾回收算法，和之前提到的智能指针异曲同⼯。对每个对象维护⼀个引⽤计数，当引⽤该对象的对象被销毁或更新时被引⽤对象的引⽤计数⾃动减⼀，当被引⽤对象被创建或被赋值给其他对象时引⽤计数⾃动加⼀。当引⽤计数为0时则⽴即回收对象。这种⽅法的优点是实现简单，并且内存的回收很及时。这种算法在内存⽐较紧张和实时性⽐较⾼的系统中使⽤的⽐较⼴泛，如ios cocoa框架，php，python等。但是简单引⽤计数算法也有明显的缺点：1. 频繁更新引⽤计数降低了性能。⼀种简单的解决⽅法就是编译器将相邻的引⽤计数更新操作合并到⼀次更新；还有⼀种⽅法是针对频繁发⽣的临时变量引⽤不进⾏计数，⽽是在引⽤达到0时通过扫描堆栈确认是否还有临时对象引⽤⽽决定是否释放。等等还有很多其他⽅法，具体可以参考这⾥。
1. 循环引⽤。当对象间发⽣循环引⽤时引⽤链中的对象都⽆法得到释放。最明显的解决办法是避免产⽣循环引⽤，如cocoa引⼊了strong指针和weak指针两种指针类型。或者系统检测循环引⽤并主动打破循环链。当然这也增加了垃圾回收的复杂度。标记-清除（mark and sweep）标记-清除（mark and sweep）分为两步，标记从根变量开始迭代得遍历所有被引⽤的对象，对能够通过应⽤遍历访问到的对象都进⾏标记为“被引⽤”；标记完成后进⾏清除操作，对没有标记过的内存进⾏回收（回收同时可能伴有碎⽚整理操作）。这种⽅法解决了引⽤计数的不⾜，但是也有⽐较明显的问题：每次启动垃圾回收都会暂停当前所有的正常代码执⾏，回收是系统响应能⼒⼤⼤降低！当然后续也出现了很多mark&sweep算法的变种（如三⾊标记法）优化了这个问题。分代搜集（generation）java的jvm 就使⽤的分代回收的思路。在⾯向对象编程语⾔中，绝⼤多数对象的⽣命周期都⾮常短。分代收集的基本思想是，将堆划分为两个或多个称为代（generation）的空间。新创建的对象存放在称为新⽣代（young generation）中（⼀般来说，新⽣代的⼤⼩会⽐ ⽼年代⼩很多），随着垃圾回收的重复执⾏，⽣命周期较⻓的对象会被提升（promotion）到⽼年代中（这⾥⽤到了⼀个分类的思路，这个是也是科学思考的⼀个基本思路）。因此，新⽣代垃圾回收和⽼年代垃圾回收两种不同的垃圾回收⽅式应运⽽⽣，分别⽤于对各⾃空间中的对象执⾏垃圾回收。新⽣代垃圾回收的速度⾮常快，⽐⽼年代快⼏个数量级，即使新⽣代垃圾回收的频率更⾼，执⾏效率也仍然⽐⽼年代垃圾回收强，这是因为⼤多数对象的⽣命周期都很短，根本⽆需提升到⽼年代。Golang GC 时会发⽣什么?Golang 1.5后，采取的是“⾮分代的、⾮移动的、并发的、三⾊的”标记清除垃圾回收算法。golang 中的 gc 基本上是标记清除的过程：
gc的过程⼀共分为四个阶段：1. 栈扫描（开始时STW）2. 第⼀次标记（并发）3. 第⼆次标记（STW）4. 清除（并发）
整个进程空间⾥申请每个对象占据的内存可以视为⼀个图，初始状态下每个内存对象都是⽩⾊标记。1. 先STW，做⼀些准备⼯作，⽐如 enable write barrier。然后取消STW，将扫描任务作为多个并发的goroutine⽴即⼊队给调度器，进⽽被CPU处理2. 第⼀轮先扫描root对象，包括全局指针和 goroutine 栈上的指针，标记为灰⾊放⼊队列3. 第⼆轮将第⼀步队列中的对象引⽤的对象置为灰⾊加⼊队列，⼀个对象引⽤的所有对象都置灰并加⼊队列后，这个对象才能置为⿊⾊并从队列之中取出。循环往复，最后队列为空时，整个图剩下的⽩⾊内存空间即不可到达的对象，即没有被引⽤的对象；4. 第三轮再次STW，将第⼆轮过程中新增对象申请的内存进⾏标记（灰⾊），这⾥使⽤了write barrier（写屏障）去记录Golang gc 优化的核⼼就是尽量使得 STW(Stop The World) 的时间越来越短。详细的Golang的GC介绍可以参看Golang垃圾回收.Golang 中 Goroutine 如何调度? goroutine是Golang语⾔中最经典的设计，也是其魅⼒所在，goroutine的本质是协程，是实现并⾏计算的核⼼。 goroutine使⽤⽅式⾮常的简单，只需使⽤go关键字即可启动⼀个协程，并且它是处于异步⽅式运⾏，你不需要等它运⾏完成以后在执⾏以后的代码。协程:协程拥有⾃⼰的寄存器上下⽂和栈。协程调度切换时，将寄存器上下⽂和栈保存到其他地⽅，在切回来的时候，恢复先前保存的寄存器上下⽂和栈。 因此，协程能保留上⼀次调⽤时的状态（即所有局部状态的⼀个特定组合），每次过程重⼊时，就相当于进⼊上⼀次调⽤的状态，换种说法：进⼊上⼀次离开时所处逻辑流的位置。 线程和进程的操作是由程序触发系统接⼝，最后的执⾏者是系统；协程的操作执⾏者则是⽤户⾃身程序，goroutine也是协程。groutine能拥有强⼤的并发实现是通过GPM调度模型实现.
Go的调度器内部有四个重要的结构：M，P，S，Sched，如上图所示（Sched未给出）.M:M代表内核级线程，⼀个M就是⼀个线程，goroutine就是跑在M之上的；M是⼀个很⼤的结构，⾥⾯维护⼩对象内存cache（mcache）、当前执⾏的goroutine、随机数发⽣器等等⾮常多的信息G:代表⼀个goroutine，它有⾃⼰的栈，instruction pointer和其他信息（正在等待的channel等等），⽤于调度。P:P全称是Processor，处理器，它的主要⽤途就是⽤来执⾏goroutine的，所以它也维护了⼀个goroutine队列，⾥⾯存储了所有需要它来执⾏的goroutineSched：代表调度器，它维护有存储M和G的队列以及调度器的⼀些状态信息等。调度实现:go func()//通过go关键字启动⼀个协程来运⾏函数
从上图中可以看到，有2个物理线程M，每⼀个M都拥有⼀个处理器P，每⼀个也都有⼀个正在运⾏的goroutine。P的数量可以通过GOMAXPROCS()来设置，它其实也就代表了真正的并发度，即有多少个goroutine可以同时运⾏。图中灰⾊的那些goroutine并没有运⾏，⽽是出于ready的就绪态，正在等待被调度。P维护着这个队列（称之为runqueue），Go语⾔⾥，启动⼀个goroutine很容易：go function 就⾏，所以每有⼀个go语句被执⾏，runqueue队列就在其末尾加⼊⼀个goroutine，在下⼀个调度点，就从runqueue中取出（如何决定取哪个goroutine？）⼀个goroutine执⾏。当⼀个OS线程M0陷⼊阻塞时，P转⽽在运⾏M1，图中的M1可能是正被创建，或者从线程缓存中取出。
当MO返回时，它必须尝试取得⼀个P来运⾏goroutine，⼀般情况下，它会从其他的OS线程那⾥拿⼀个P过来， 如果没有拿到的话，它就把goroutine放在⼀个global runqueue⾥，然后⾃⼰睡眠（放⼊线程缓存⾥）。所有的P也会周期性的检查global runqueue并运⾏其中的goroutine，否则global runqueue上的goroutine永远⽆法执⾏。另⼀种情况是P所分配的任务G很快就执⾏完了（分配不均），这就导致了这个处理器P很忙，但是其他的P还有任务，此时如果global runqueue没有任务G了，那么P不得不从其他的P⾥拿⼀些G来执⾏。

通常来说，如果P从其他的P那⾥要拿任务的话，⼀般就拿run queue的⼀半，这就确保了每个OS线程都能充分的使⽤。并发编程概念是什么？ 并⾏是指两个或者多个事件在同⼀时刻发⽣；并发是指两个或多个事件在同⼀时间间隔发⽣。并⾏是在不同实体上的多个事件，并发是在同⼀实体上的多个事件。在⼀台处理器上“同时”处理多个任务，在多台处理器上同时处理多个任务。如hadoop分布式集群并发偏重于多个任务交替执⾏，⽽多个任务之间有可能还是串⾏的。⽽并⾏是真正意义上的“同时执⾏”。并发编程是指在⼀台处理器上“同时”处理多个任务。并发是在同⼀实体上的多个事件。多个事件在同⼀时间间隔发⽣。并发编程的⽬标是充分的利⽤处理器的每⼀个核，以达到最⾼的处理性能。  Mutex ⼏种状态 mutexLocked —表示互斥锁的锁定状态；mutexWoken —表示从正常模式被从唤醒；mutexStarving —当前的互斥锁进⼊饥饿状态；waitersCount —当前互斥锁上等待的 Goroutine 个数；Mutex 正常模式和饥饿模式 正常模式(⾮公平锁)正常模式下，所有等待锁的 goroutine 按照 FIFO(先进先出)顺序等待。唤醒的 goroutine 不会直接拥有锁，⽽是会和新请求锁的 goroutine 竞争锁的拥有。新请求锁的 goroutine 具有优势：它正在 CPU上执⾏，⽽且可能有好⼏个，所以刚刚唤醒的 goroutine 有很⼤可能在锁竞争中失败。在这种情况下，这个被唤醒的 goroutine 会加⼊到等待队列的前⾯。如果⼀个等待的 goroutine 超过1ms没有获取锁，那么它将会把锁转变为饥饿模式。饥饿模式(公平锁)为了解决了等待 G队列的⻓尾问题饥饿模式下，直接由 unlock 把锁交给等待队列中排在第⼀位的 G(队头)，同时，饥饿模式下，新进来的 G不会参与抢锁也不会进⼊⾃旋状态，会直接进⼊等待队列的尾部,这样很好的解决了⽼的 g ⼀直抢不到锁的场景。饥饿模式的触发条件，当⼀个 G等待锁时间超过1 毫秒时，或者当前队列只剩下⼀个 g 的时候，Mutex切换到饥饿模式。总结对于两种模式，正常模式下的性能是最好的，goroutine 可以连续多次获取锁，饥饿模式解决了取锁公平的问题，但是性能会下降，其实是性能和公平的⼀个平衡模式。
Mutex 允许⾃旋的条件 1 锁已被占⽤，并且锁不处于饥饿模式。2 积累的⾃旋次数⼩于最⼤⾃旋次数（active_spin=4）。3 cpu 核数⼤于1。4 有空闲的 P。5 当前 goroutine 所挂载的 P下，本地待运⾏队列为空。RWMutex 实现 通过记录 readerCount 读锁的数量来进⾏控制，当有⼀个写锁的时候，会将读锁数量设置为负数1<<30。⽬的是让新进⼊的读锁等待写锁之后释放通知读锁。同样的写锁也会等等待之前的读锁都释放完毕，才会开始进⾏后续的操作。⽽等写锁释放完之后，会将值重新加上1<<30,并通知刚才新进⼊的读锁(rw.readerSem)，两者互相限制。RWMutex 注意事项 RWMutex 是单写多读锁，该锁可以加多个读锁或者⼀个写锁读锁占⽤的情况下会阻⽌写，不会阻⽌读，多个 goroutine 可以同时获取读锁写锁会阻⽌其他 goroutine（⽆论读和写）进来，整个锁由该 goroutine 独占适⽤于读多写少的场景RWMutex 类型变量的零值是⼀个未锁定状态的互斥锁。RWMutex 在⾸次被使⽤之后就不能再被拷⻉。RWMutex 的读锁或写锁在未锁定状态，解锁操作都会引发 panic。RWMutex 的⼀个写锁 Lock 去锁定临界区的共享资源，如果临界区的共享资源已被（读锁或写锁）锁定，这个写锁操作的 goroutine 将被阻塞直到解锁。RWMutex 的读锁不要⽤于递归调⽤，⽐较容易产⽣死锁。RWMutex 的锁定状态与特定的 goroutine 没有关联。⼀个 goroutine 可以 RLock（Lock），另⼀个 goroutine 可以 RUnlock（Unlock）。写锁被解锁后，所有因操作锁定读锁⽽被阻塞的 goroutine 会被唤醒，并都可以成功锁定读锁。读锁被解锁后，在没有被其他读锁锁定的前提下，所有因操作锁定写锁⽽被阻塞的 goroutine，其中等待时间最⻓的⼀个 goroutine 会被唤醒。 Cond 是什么 Cond实现了⼀种条件变量，可以使⽤在多个 Reader 等待共享资源 ready 的场景（如果只有⼀读⼀写，⼀个锁或者 channel 就搞定了）每个 Cond都会关联⼀个 Lock（sync.Mutex or sync.RWMutex），当修改条件或者调⽤ Wait ⽅法时，必须加锁，保护 condition。
Broadcast 和 Signal 区别 Broadcast 会唤醒所有等待 c 的 goroutine。调⽤ Broadcast 的时候，可以加锁，也可以不加锁。Signal 只唤醒1 个等待 c 的 goroutine。调⽤ Signal 的时候，可以加锁，也可以不加锁。 Cond 中 Wait 使⽤  Wait()会⾃动释放 c.L，并挂起调⽤者的 goroutine。之后恢复执⾏，Wait()会在返回时对 c.L 加锁。除⾮被 Signal 或者 Broadcast 唤醒，否则 Wait()不会返回。由于 Wait()第⼀次恢复时，C.L 并没有加锁，所以当 Wait 返回时，调⽤者通常并不能假设条件为真。取⽽代之的是,调⽤者应该在循环中调⽤ Wait。（简单来说，只要想使⽤ condition，就必须加锁。）
 WaitGroup ⽤法 ⼀个 WaitGroup 对象可以等待⼀组协程结束。使⽤⽅法是：1.main 协程通过调⽤ wg.Add(delta int)设置 worker 协程的个数，然后创建 worker 协程；2.worker 协程执⾏结束以后，都要调⽤ wg.Done()；3.main 协程调⽤ wg.Wait()且被 block，直到所有 worker 协程全部执⾏结束后返回。func (c *Cond) Broadcast()func (c *Cond) Signal()
func (c *Cond) Wait()
c.L.Lock()for !condition(){  c.Wait()}... make use of condition ... c.L.Unlock()
 WaitGroup 实现原理 WaitGroup 主要维护了2 个计数器，⼀个是请求计数器 v，⼀个是等待计数器 w，⼆者组成⼀个64bit 的值，请求计数器占⾼32bit，等待计数器占低32bit。每次 Add执⾏，请求计数器 v 加1，Done⽅法执⾏，请求计数器减1，v 为0 时通过信号量唤醒 Wait()。什么是 sync.Once Once 可以⽤来执⾏且仅仅执⾏⼀次动作，常常⽤于单例对象的初始化场景。Once 常常⽤来初始化单例资源，或者并发访问只需初始化⼀次的共享资源，或者在测试的时候初始化⼀次测试资源。sync.Once 只暴露了⼀个⽅法 Do，你可以多次调⽤ Do ⽅法，但是只有第⼀次调⽤ Do ⽅法时 f 参数才会执⾏，这⾥的 f 是⼀个⽆参数⽆返回值的函数。什么操作叫做原⼦操作 ⼀个或者多个操作在 CPU执⾏过程中不被中断的特性，称为原⼦性(atomicity)。这些操作对外表现成⼀个不可分割的整体，他们要么都执⾏，要么都不执⾏，外界不会看到他们只执⾏到⼀半的状态。⽽在现实世界中，CPU 不可能不中断的执⾏⼀系列操作，但如果我们在执⾏多个操作时，能让他们的中间状态对外不可⻅，那我们就可以宣城他们拥有了“不可分割”的原⼦性。在 Go中，⼀条普通的赋值语句其实不是⼀个原⼦操作。列如，在32 位机器上写 int64 类型的变量就会有中间状态，因为他会被拆成两次写操作(MOV)——写低32 位和写⾼32 位。原⼦操作和锁的区别 原⼦操作由底层硬件⽀持，⽽锁则由操作系统的调度器实现。锁应当⽤来保护⼀段逻辑，对于⼀个变量更新的保护，原⼦操作通常会更有效率，并且更能利⽤计算机多核的优势，如果要更新的是⼀个复合对象，则应当使⽤ atomic.Value 封装好的实现。什么是 CAS CAS的全称为 Compare And Swap，直译就是⽐较交换。是⼀条 CPU的原⼦指令，其作⽤是让 CPU先进⾏⽐较两个值是否相等，然后原⼦地更新某个位置的值，其实现⽅式是给予硬件平台的汇编指令，在 intel 的 CPU中，使⽤的 cmpxchg指令，就是说 CAS是靠硬件实现的，从⽽在硬件层⾯提升效率。简述过程是这样：假设包含3 个参数内存位置(V)、预期原值(A)和新值(B)。V表示要更新变量的值，E表示预期值，N表示新值。仅当 V值等于 E值时，才会将 V的值设为 N，如果 V值和 E值不同，则说明已经有其他线程在做更新，则当前线程什么都不做，最后 CAS返回当前 V的真实值。CAS操作时抱着乐观的态度进⾏的，它总是认为⾃⼰可以成功完成操作。基于这样的原理，CAS操作即使没有锁，也可以发现其他线程对于当前线程的⼲扰。
sync.Pool 有什么⽤ 对于很多需要重复分配、回收内存的地⽅，sync.Pool 是⼀个很好的选择。频繁地分配、回收内存会给 GC 带来⼀定的负担，严重的时候会引起 CPU 的⽑刺，⽽ sync.Pool 可以将暂时不⽤的对象缓存起来，待下次需要的时候直接使⽤，不⽤再次经过内存分配，复⽤对象的内存，减轻 GC 的压⼒，提升系统的性能。Go ⾼级 Goroutine 定义 Goroutine 是⼀个与其他 goroutines 并⾏运⾏在同⼀地址空间的 Go 函数或⽅法。⼀个运⾏的程序由⼀个或更多个 goroutine 组成。它与线程、协程、进程等不同。它是⼀个 goroutine”—— Rob Pike Goroutines 在同⼀个⽤户地址空间⾥并⾏独⽴执⾏ functions，channels 则⽤于 goroutines 间的通信和同步访问控制。GMP 指的是什么 G（Goroutine）：我们所说的协程，为⽤户级的轻量级线程，每个 Goroutine 对象中的 sched 保存着其上下⽂信息.M（Machine）：对内核级线程的封装，数量对应真实的 CPU数（真正⼲活的对象）.P（Processor）：即为 G和 M的调度对象，⽤来调度 G和 M之间的关联关系，其数量可通过 GOMAXPROCS()来设置，默认为核⼼数。 给⼤家丢脸了，⽤了三年golang，我还是没答对这道内存泄漏题  https://mp.weixin.qq.com/s/-agtdhlW7Yj7S88a0z7KHg  你⼀定会遇到的内存回收策略导致的疑似内存泄漏的问题  https://colobu.com/2019/08/28/go-memory-leak-i-dont-think-so/  GMP⾥为什么要有P?  https://mp.weixin.qq.com/s/SEE2TUeZQZ7W1BKkmnelAA  
go栈扩容和栈缩容，连续栈的缺点  https://segmentfault.com/a/1190000019570427  golang隐藏技能:怎么访问私有成员  https://www.jianshu.com/p/7b3638b47845  1.0 之前 GM 调度模型 调度器把 G都分配到 M上，不同的 G在不同的 M并发运⾏时，都需要向系统申请资源，⽐如堆栈内存等，因为资源是全局的，就会因为资源竞争照成很多性能损耗。为了解决这⼀的问题 go 从1.1 版本引⼊，在运⾏时系统的时候加⼊ p 对象，让 P去管理这个 G对象，M想要运⾏ G，必须绑定 P，才能运⾏ P所管理的 G。1．单⼀全局互斥锁(Sched.Lock)和集中状态存储2．Goroutine 传递问题（M 经常在 M 之间传递”可运⾏”的 goroutine）3．每个 M做内存缓存，导致内存占⽤过⾼，数据局部性较差4．频繁 syscall 调⽤，导致严重的线程阻塞/解锁，加剧额外的性能损耗。GMP 调度流程 
每个 P有个局部队列，局部队列保存待执⾏的 goroutine(流程2)，当 M绑定的 P的的局部队列已经满了之后就会把 goroutine 放到全局队列(流程2-1)每个 P和⼀个 M绑定，M是真正的执⾏ P中 goroutine 的实体(流程3)，M 从绑定的 P中的局部队列获取 G来执⾏当 M绑定的 P的局部队列为空时，M会从全局队列获取到本地队列来执⾏
G(流程3.1)，当从全局队列中没有获取到可执⾏的 G时候，M会从其他 P 的局部队列中偷取 G来执⾏(流程3.2)，这种从其他 P偷的⽅式称为 work stealing 当 G因系统调⽤(syscall)阻塞时会阻塞 M，此时 P会和 M解绑即 hand off，并寻找新的 idle 的 M，若没有 idle 的 M就会新建⼀个 M(流程5.1)。当 G因 channel 或者 network I/O 阻塞时，不会阻塞 M，M会寻找其他 runnable 的 G；当阻塞的 G恢复后会重新进⼊ runnable 进⼊ P队列等待执⾏(流程5.3)GMP 中 work stealing 机制 存到 P本地队列或者是全局队列。P此时去唤醒⼀个 M。P继续执⾏它的执⾏序。M寻找是否有空闲的 P，如果有则将该 G对象移动到它本身。接下来 M执⾏⼀个调度循环(调⽤ G对象->执⾏->清理线程→继续找新的 Goroutine 执⾏)。GMP 中 hand off 机制 当本线程 M因为 G进⾏的系统调⽤阻塞时，线程释放绑定的 P，把 P转移给其他空闲的 M'执⾏。当发⽣上线⽂切换时，需要对执⾏现场进⾏保护，以便下次被调度执⾏时进⾏现场恢复。Go调度器 M的栈保存在 G对象上，只需要将 M所需要的寄存器(SP、PC等)保存到 G对象上就可以实现现场保护。当这些寄存器数据被保护起来，就随时可以做上下⽂切换了，在中断之前把现场保存起来。如果此时 G任务还没有执⾏完，M可以将任务重新丢到 P的任务队列，等待下⼀次被调度执⾏。当再次被调度执⾏时，M通过访问 G的 vdsoSP、vdsoPC寄存器进⾏现场恢复(从上次中断位置继续执⾏)。协作式的抢占式调度 在1.14 版本之前，程序只能依靠 Goroutine 主动让出 CPU 资源才能触发调度，存在问题某些 Goroutine 可以⻓时间占⽤线程，造成其它 Goroutine 的饥饿垃圾回收需要暂停整个程序（Stop-the-world，STW），最⻓可能需要⼏分钟的时间，导致整个程序⽆法⼯作。基于信号的抢占式调度 在任何情况下，Go运⾏时并⾏执⾏（注意，不是并发）的 goroutines 数量是⼩于等于 P 的数量的。为了提⾼系统的性能，P 的数量肯定不是越⼩越好，所以官⽅默认值就是 CPU 的核⼼数，设置的过⼩的话，如果⼀个持有 P 的 M，由于 P 当前执⾏的 G 调⽤了 syscall ⽽导致 M 被阻塞，那么此时关键点： GO 的调度器是迟钝的，它很可能什么都没做，直到 M 阻塞了相当⻓时间以后，才会发现有⼀个 P/M 被 syscall 阻塞了。然后，才会⽤空闲的 M 来强这个 P。通过 sysmon 监控实现的抢占式调度，最快在20us，最慢在10-20ms才会发现有⼀个 M 持有 P 并阻塞了。操作系统在1ms 内可以完成很多次线程调度（⼀般情况1ms可以完成⼏⼗次线程调度），Go 发起 IO/syscall 的时候执⾏该 G 的 M 会阻塞然后被 OS调度⾛，P什么也不⼲，sysmon 最慢要10-20ms 才能发现这个阻塞，说不定那时候阻塞已经结束了，宝贵的 P资源就这么被阻塞的 M浪费了。GMP 调度过程中存在哪些阻塞 I/O，select block on syscallchannel 等待锁
runtime.Gosched()sysmon 有什么作⽤ sysmon 也叫监控线程，变动的周期性检查，好处释放闲置超过5 分钟的 span 物理内存；如果超过2 分钟没有垃圾回收，强制执⾏；将⻓时间未处理的 netpoll 添加到全局队列；向⻓时间运⾏的 G 任务发出抢占调度(超过10ms的 g，会进⾏ retake)；收回因 syscall ⻓时间阻塞的 P；三⾊标记原理 我们⾸先看⼀张图，⼤概就会对三⾊标记法有⼀个⼤致的了解：
原理：⾸先把所有的对象都放到⽩⾊的集合中从根节点开始遍历对象，遍历到的⽩⾊对象从⽩⾊集合中放到灰⾊集合中遍历灰⾊集合中的对象，把灰⾊对象引⽤的⽩⾊集合的对象放⼊到灰⾊集合中，同时把遍历过的灰⾊集合中的对象放到⿊⾊的集合中循环步骤3，知道灰⾊集合中没有对象步骤4 结束后，⽩⾊集合中的对象就是不可达对象，也就是垃圾，进⾏回收插⼊写屏障 golang 的回收没有混合屏障之前，⼀直是插⼊写屏障，由于栈赋值没有 hook 的原因，所以栈中没有启⽤写屏障，所以有 STW。golang 的解决⽅法是：只是需要在结束时启动 STW来重新扫描栈。这个⾃然就会导致整个进程的赋值器卡顿，所以后⾯ golang 是引⽤混合写屏障解决这个问题。混合写屏障之后，就没有 STW。
删除写屏障 goalng 没有这⼀步，golang 的内存写屏障是由插⼊写屏障到混合写屏障过渡的。简单介绍⼀下，⼀个对象即使被删除了最后⼀个指向它的指针也依旧可以活过这⼀轮，在下⼀轮 GC中被清理掉。写屏障 Go在进⾏三⾊标记的时候并没有 STW，也就是说，此时的对象还是可以进⾏修改。那么我们考虑⼀下，下⾯的情况。
我们在进⾏三⾊标记中扫描灰⾊集合中，扫描到了对象 A，并标记了对象 A的所有引⽤，这时候，开始扫描对象 D的引⽤，⽽此时，另⼀个 goroutine 修改了 D->E的引⽤，变成了如下图所示
这样会不会导致 E对象就扫描不到了，⽽被误认为为⽩⾊对象，也就是垃圾写屏障就是为了解决这样的问题，引⼊写屏障后，在上述步骤后， E会被认为是存活的，即使后⾯ E被 A对象抛弃，E会被在下⼀轮的 GC中进⾏回收，这⼀轮 GC中是不会对对象 E进⾏回收的。混合写屏障 混合写屏障继承了插⼊写屏障的优点，起始⽆需 STW 打快照，直接并发扫描垃圾即可；混合写屏障继承了删除写屏障的优点，赋值器是⿊⾊赋值器，GC期间，任何在栈上创建的新对象，均为⿊⾊。扫描过⼀次就不需要扫描了，这样就消除了插⼊写屏障时期最后 STW 的重新扫描栈；混合写屏障扫描精度继承了删除写屏障，⽐插⼊写屏障更低，随着带来的是 GC 过程全程⽆ STW；混合写屏障扫描栈虽然没有 STW，但是扫描某⼀个具体的栈的时候，还是要停⽌这个 goroutine 赋值器的⼯作的哈（针对⼀个 goroutine 栈来说，是暂停扫的，要么全灰，要么全⿊哈，原⼦状态切换）。GC 触发时机 主动触发：调⽤ runtime.GC 被动触发：使⽤系统监控，该触发条件由 runtime.forcegcperiod 变量控制，默认为2 分钟。当超过两分钟没有产⽣任何 GC 时，强制触发 GC。使⽤步调（Pacing）算法，其核⼼思想是控制内存增⻓的⽐例。如 Go 的 GC 是⼀种⽐例 GC,下⼀次 GC 结束时的堆⼤⼩和上⼀次 GC 存活堆⼤⼩成⽐例.由 GOGC 控制,默认100,即2 倍的关系,200 就是3 倍,当 Go新创建的对象所占⽤的内存⼤⼩，除以上次 GC结束后保留下来的对象占⽤内存⼤⼩。
Go 语⾔中 GC 的流程是什么？ 当前版本的 Go 以 STW 为界限，可以将 GC 划分为五个阶段：阶段说明赋值器状态 GCMark标记准备阶段，为并发标记做准备⼯作，启动写屏障 STWGCMark扫描标记阶段，与赋值器并发执⾏，写屏障开启并发 GCMarkTermination 标记终⽌阶段，保证⼀个周期内标记任务完成，停⽌写屏障 STWGCoff内存清扫阶段，将需要回收的内存归还到堆中，写屏障关闭并发 GCoff内存归还阶段，将过多的内存归还给操作系统，写屏障关闭并发。GC 如何调优 通过 go tool pprof 和 go tool trace 等⼯具控制内存分配的速度，限制 goroutine 的数量，从⽽提⾼赋值器对 CPU 的利⽤率。减少并复⽤内存，例如使⽤ sync.Pool 来复⽤需要频繁创建临时对象，例如提前分配⾜够的内存来降低多余的拷⻉。需要时，增⼤ GOGC 的值，降低 GC 的运⾏频率。 Go语⾔的栈空间管理是怎么样的? Go语⾔的运⾏环境（runtime）会在goroutine需要的时候动态地分配栈空间，⽽不是给每个goroutine分配固定⼤⼩的内存空间。这样就避免了需要程序员来决定栈的⼤⼩。分块式的栈是最初Go语⾔组织栈的⽅式。当创建⼀个goroutine的时候，它会分配⼀个8KB的内存空间来给goroutine的栈使⽤。我们可能会考虑当这8KB的栈空间被⽤完的时候该怎么办?为了处理这种情况，每个Go函数的开头都有⼀⼩段检测代码。这段代码会检查我们是否已经⽤完了分配的栈空间。如果是的话，它会调⽤morestack函数。morestack函数分配⼀块新的内存作为栈空间，并且在这块栈空间的底部填⼊各种信息（包括之前的那块栈地址）。在分配了这块新的栈空间之后，它会重试刚才造成栈空间不⾜的函数。这个过程叫做栈分裂（stack split）。在新分配的栈底部，还插⼊了⼀个叫做lessstack的函数指针。这个函数还没有被调⽤。这样设置是为了从刚才造成栈空间不⾜的那个函数返回时做准备的。当我们从那个函数返回时，它会跳转到lessstack。lessstack函数会查看在栈底部存放的数据结构⾥的信息，然后调整栈指针（stack pointer）。这样就完成了从新的栈块到⽼的栈块的跳转。接下来，新分配的这个块栈空间就可以被释放掉了。分块式的栈让我们能够按照需求来扩展和收缩栈的⼤⼩。 Go开发者不需要花精⼒去估计goroutine会⽤到多⼤的栈。创建⼀个新的goroutine的开销也不⼤。当 Go开发者不知道栈会扩展到多少⼤时，它也能很好的处理这种情况。这⼀直是之前Go语⾔管理栈的的⽅法。但这个⽅法有⼀个问题。缩减栈空间是⼀个开销相对较⼤的操作。如果在⼀个循环⾥有栈分裂，那么它的开销就变得不可忽略了。⼀个函数会扩展，然后分裂栈。当它返回的时候⼜会释放之前分配的内存块。如果这些都发⽣在⼀个循环⾥的话，代价是相当⼤的。 这就是所谓的热分裂问题（hot split problem）。它是Go语⾔开发者选择新的栈管理⽅法的主要原因。新的⽅法叫做栈复制法（stack copying）。栈复制法⼀开始和分块式的栈很像。当goroutine运⾏并⽤完栈空间的时候，与之前的⽅法⼀样，栈溢出检查会被触发。但是，不像之前的⽅法那样分配⼀个新的内存块并链接到⽼的栈内存块，新的⽅法会分配⼀个两倍⼤的内存块并把⽼的内存块内容复制到新的内存块⾥。这样做意味着当栈缩减回之前⼤⼩时，我们不需要做任何事情。栈的缩减没有任何代价。⽽且，当栈再次扩展时，运⾏环境也不需要再做任何事。它可以重⽤之前分配的空间。
栈的复制听起来很容易，但实际操作并⾮那么简单。存储在栈上的变量的地址可能已经被使⽤到。也就是说程序使⽤到了⼀些指向栈的指针。当移动栈的时候，所有指向栈⾥内容的指针都会变得⽆效。然⽽，指向栈内容的指针⾃身也必定是保存在栈上的。这是为了保证内存安全的必要条件。否则⼀个程序就有可能访问⼀段已经⽆效的栈空间了。因为垃圾回收的需要，我们必须知道栈的哪些部分是被⽤作指针了。当我们移动栈的时候，我们可以更新栈⾥的指针让它们指向新的地址。所有相关的指针都会被更新。我们使⽤了垃圾回收的信息来复制栈，但并不是任何使⽤栈的函数都有这些信息。因为很⼤⼀部分运⾏环境是⽤C语⾔写的，很多被调⽤的运⾏环境⾥的函数并没有指针的信息，所以也就不能够被复制了。当遇到这种情况时，我们只能退回到分块式的栈并⽀付相应的开销。这也是为什么现在运⾏环境的开发者正在⽤Go语⾔重写运⾏环境的⼤部分代码。⽆法⽤Go语⾔重写的部分（⽐如调度器的核⼼代码和垃圾回收器）会在特殊的栈上运⾏。这个特殊栈的⼤⼩由运⾏环境的开发者设置。这些改变除了使栈复制成为可能，它也允许我们在将来实现并⾏垃圾回收。另外⼀种不同的栈处理⽅式就是在虚拟内存中分配⼤内存段。由于物理内存只是在真正使⽤时才会被分配，因此看起来好似你可以分配⼀个⼤内存段并让操 作系统处理它。下⾯是这种⽅法的⼀些问题⾸先，32位系统只能⽀持4G字节虚拟内存，并且应⽤只能⽤到其中的3G空间。由于同时运⾏百万goroutines的情况并不少⻅，因此你很可 能⽤光虚拟内存，即便我们假设每个goroutine的stack只有8K。第⼆，然⽽我们可以在64位系统中分配⼤内存，它依赖于过量内存使⽤。所谓过量使⽤是指当你分配的内存⼤⼩超出物理内存⼤⼩时，依赖操作系统保证 在需要时能够分配出物理内存。然⽽，允许过量使⽤可能会导致⼀些⻛险。由于⼀些进程分配了超出机器物理内存⼤⼩的内存，如果这些进程使⽤更多内存 时，操作系统将不得不为它们补充分配内存。这会导致操作系统将⼀些内存段放⼊磁盘缓存，这常常会增加不可预测的处理延迟。正是考虑到这个原因，⼀ 些新系统关闭了对过量使⽤的⽀持。Goroutine和Channel的作⽤分别是什么? 进程是内存资源管理和cpu调度的执⾏单元。为了有效利⽤多核处理器的优势，将进程进⼀步细分，允许⼀个进程⾥存在多个线程，这多个线程还是共享同⼀⽚内存空间，但cpu调度的最⼩单元变成了线程。那协程⼜是什么呢，以及与线程的差异性??协程，可以看作是轻量级的线程。但与线程不同的是，线程的切换是由操作系统控制的，⽽协程的切换则是由⽤户控制的。最早⽀持协程的程序语⾔应该是lisp⽅⾔scheme⾥的continuation（续延），续延允许scheme保存任意函数调⽤的现场，保存起来并重新执⾏。Lua,C#,python等语⾔也有⾃⼰的协程实现。Go中的goroutinue就是协程,可以实现并⾏，多个协程可以在多个处理器同时跑。⽽协程同⼀时刻只能在⼀个处理器上跑（可以把宿主语⾔想象成单线程的就好了）。 然⽽,多个goroutine之间的通信是通过channel，⽽协程的通信是通过yield和resume()操作。goroutine⾮常简单，只需要在函数的调⽤前⾯加关键字go即可，例如:我们也可以启动5个goroutines分别打印索引。go elegance()
在分析goroutine执⾏的随机性和并发性，启动了5个goroutine，再加上main函数的主goroutine，总共有6个goroutines。由于goroutine类似于”守护线程“，异步执⾏的,如果主goroutine不等待⽚刻，可能程序就没有输出打印了。在Golang中channel则是goroutinues之间进⾏通信的渠道。可以把channel形象⽐喻为⼯⼚⾥的传送带,⼀头的⽣产者goroutine往传输带放东⻄,另⼀头的消费者goroutinue则从输送带取东⻄。channel实际上是⼀个有类型的消息队列,遵循先进先出的特点。1. channel的操作符号ch <- data 表示data被发送给channel ch；data <- ch 表示从channel ch取⼀个值，然后赋给data。1. 阻塞式channelchannel默认是没有缓冲区的，也就是说，通信是阻塞的。send操作必须等到有消费者accept才算完成。应⽤示例:
在函数pump()⾥的channel在接受到第⼀个元素后就被阻塞了，直到主goroutinue取⾛了数据。最终channel阻塞在接受第⼆个元素，程序只打印 1。没有缓冲(buffer)的channel只能容纳⼀个元素，⽽带有缓冲(buffer)channel则可以⾮阻塞容纳N个元素。发送数据到缓冲(buffer) channel不会被阻塞，除⾮channel已满；同样的，从缓冲(buffer) channel取数据也不会被阻塞，除⾮channel空了。func main() {    for i:=1;i<5;i++ {        go func(i int) {            fmt.Println(i)        }(i)    }    // 停歇5s，保证打印全部结束    time.Sleep(5*time.Second)}
func main() {    ch1 := make(chan int)    go pump(ch1) // pump hangs    fmt.Println(<-ch1) // prints only 1}func pump(ch chan int) {    for i:= 1; ; i++ {        ch <- i    }}
怎么查看Goroutine的数量? GOMAXPROCS中控制的是未被阻塞的所有Goroutine,可以被Multiplex到多少个线程上运⾏,通过GOMAXPROCS可以查看Goroutine的数量。  微服务 您对微服务有何了解？ 微服务，⼜称微服务架构，是⼀种架构⻛格，它将应⽤程序构建为以业务领域为模型的⼩型⾃治服务集合。通俗地说，你必须看到蜜蜂如何通过对⻬六⻆形蜡细胞来构建它们的蜂窝状物。他们最初从使⽤各种材料的⼩部分开始，并继续从中构建⼀个⼤型蜂箱。这些细胞形成图案，产⽣坚固的结构，将蜂窝的特定部分固定在⼀起。这⾥，每个细胞独⽴于另⼀个细胞，但它也与其他细胞相关。这意味着对⼀个细胞的损害不会损害其他细胞，因此，蜜蜂可以在不影响完整蜂箱的情况下重建这些细胞。
图1：微服务的蜂窝表示–微服务访谈问题
  优势说明  独⽴开发所有微服务都可以根据各⾃的功能轻松开发独⽴部署根据他们所提供的服务，可以在任何应⽤中单独部署故障隔离即使应⽤中的⼀个服务不起作⽤，系统仍然继续运⾏混合技术栈可以⽤不同的语⾔和技术来构建同⼀应⽤程序的不同服务粒度缩放各个组件可根据需要进⾏扩展，⽆需将所有组件融合到⼀起 请参考上图。这⾥，每个六边形形状代表单独的服务组件。与蜜蜂的⼯作类似，每个敏捷团队都使⽤可⽤的框架和所选的技术堆栈构建单独的服务组件。就像在蜂箱中⼀样，每个服务组件形成⼀个强⼤的微服务架构，以提供更好的可扩展性。此外，敏捷团队可以单独处理每个服务组件的问题，⽽对整个应⽤程序没有影响或影响最⼩。说说微服务架构的优势  
微服务有哪些特点？ 解耦—系统内的服务很⼤程度上是分离的。因此，整个应⽤程序可以轻松构建，更改和扩展组件化—微服务被视为可以轻松更换和升级的独⽴组件业务能⼒—微服务⾮常简单，专注于单⼀功能⾃治—开发⼈员和团队可以彼此独⽴⼯作，从⽽提⾼速度持续交付—通过软件创建，测试和批准的系统⾃动化，允许频繁发布软件责任—微服务不关注应⽤程序作为项⽬。相反，他们将应⽤程序视为他们负责的产品分散治理—重点是使⽤正确的⼯具来做正确的⼯作。这意味着没有标准化模式或任何技术模式。开发⼈员可以⾃由选择最有⽤的⼯具来解决他们的问题敏捷—微服务⽀持敏捷开发。任何新功能都可以快速开发并再次丢弃 微服务架构是什么样⼦的? 通常传统的项⽬体积庞⼤，需求、设计、开发、测试、部署流程固定。新功能需要在原项⽬上做修改。但是微服务可以看做是对⼤项⽬的拆分，是在快速迭代更新上线的需求下产⽣的。新的功能模块会发布成新的服务组件，与其他已发布的服务组件⼀同协作。 服务内部有多个⽣产者和消费者，通常以http rest的⽅式调⽤，服务总体以⼀个（或⼏个）服务的形式呈现给客户使⽤。微服务架构是⼀种思想对微服务架构我们没有⼀个明确的定义，但简单来说微服务架构是：采⽤⼀组服务的⽅式来构建⼀个应⽤，服务独⽴部署在不同的进程中，不同服务通过⼀些轻量级交互机制来通信，例如 RPC、HTTP 等，服务可独⽴扩展伸缩，每个服务定义了明确的边界，不同的服务甚⾄可以采⽤不同的编程语⾔来实现，由独⽴的团队来维护。
Golang的微服务框架kit中有详细的微服务的例⼦,可以参考学习.微服务架构设计包括：1. 服务熔断降级限流机制 熔断降级的概念(Rate Limiter 限流器,Circuit breaker 断路器).2. 框架调⽤⽅式解耦⽅式 Kit 或 Istio 或 Micro 服务发现(consul zookeeper kubeneters etcd ) RPC调⽤框架.3. 链路监控,zipkin和prometheus.4. 多级缓存.5. ⽹关 (kong gateway).6. Docker部署管理 Kubenetters.7. ⾃动集成部署 CI/CD 实践.8. ⾃动扩容机制规则.9. 压测 优化.10. Trasport 数据传输(序列化和反序列化).11. Logging ⽇志.12. Metrics 指针对每个请求信息的仪表盘化.微服务架构介绍详细的可以参考:Microservice Architectures 微服务架构如何运作？ 微服务架构具有以下组件：客户端–来⾃不同设备的不同⽤户发送请求。身份提供商–验证⽤户或客户身份并颁发安全令牌。API ⽹关–处理客户端请求。静态内容–容纳系统的所有内容。管理–在节点上平衡服务并识别故障。服务发现–查找微服务之间通信路径的指南。内容交付⽹络–代理服务器及其数据中⼼的分布式⽹络。远程服务–启⽤驻留在 IT 设备⽹络上的远程访问信息。微服务架构的优缺点是什么？ 微服务架构的优点微服务架构的缺点⾃由使⽤不同的技术增加故障排除挑战每个微服务都侧重于单⼀功能由于远程呼叫⽽增加延迟⽀持单个可部署单元增加了配置和其他操作的⼯作量允许经常发布软件难以保持交易安全确保每项服务的安全性艰难地跨越各种便捷跟踪数据多个服务是并⾏开发和部署的难以在服务之间进⾏编码单⽚，SOA 和微服务架构有什么区别？ 
单⽚ SOA 和微服务之间的⽐较–微服务访谈问题单⽚架构类似于⼤容器，其中应⽤程序的所有软件组件组装在⼀起并紧密封装。⼀个⾯向服务的架构是⼀种相互通信服务的集合。通信可以涉及简单的数据传递，也可以涉及两个或多个协调某些活动的服务。微服务架构是⼀种架构⻛格，它将应⽤程序构建为以业务域为模型的⼩型⾃治服务集合。  怎么做弹性扩缩容，原理是什么? 弹性伸缩（Auto Scaling）根据您的业务需求和伸缩策略，为您⾃动调整计算资源。您可设置定时、周期或监控策略，恰到好处地增加或减少CVM实例，并完成实例配置，保证业务平稳健康运⾏。在需求⾼峰期时，弹性伸缩⾃动增加CVM实例的数量，以保证性能不受影响；当需求较低时，则会减少CVM实例数量以降低成本。弹性伸缩既适合需求稳定的应⽤程序，同时也适合每天、每周、每⽉使⽤量不停波动的应⽤程序。 说⼀下中间件原理. 中间件（middleware）是基础软件的⼀⼤类，属于可复⽤软件的范畴。中间件处于操作系统软件与⽤户的应⽤软件的中间。中间件在操作系统、⽹络和数据库之上，应⽤软件的下层，总的作⽤是为处于⾃⼰上层的应⽤软件提供运⾏与开发的环境，帮助⽤户灵活、⾼效地开发和集成复杂的应⽤软件 IDC的定义是：中间件是⼀种独⽴的系统软件或服务程序，分布式应⽤软件借助这种软件在不同的技术之间共享资源，中间件位于客户机服务器的操作系统之上，管理计算资源和⽹络通信。中间件解决的问题是：在中间件产⽣以前，应⽤软件直接使⽤操作系统、⽹络协议和数据库等开发，这些都是计算机最底层的东⻄，越底层越复杂，开发者不得不⾯临许多很棘⼿的问题，如操作系统的多样性，繁杂的⽹络程序设计、管理，复杂多变的⽹络环境，数据分散处理带来的不⼀致性问题、性能和效率、安全，等等。这些与⽤户的业务没有直接关系，但⼜必须解决，耗费了⼤量有限的时间和精⼒。于是，有⼈提出能不能将应⽤软件所要⾯临的共性问题进⾏提炼、抽象，在操作系统之上再形成⼀个可复⽤的部分，供成千上万的应⽤软件重复使⽤。这⼀技术思想最终构成了中间件这类的软件。中间件屏蔽了底层操作系统的复杂性，使程序开发⼈员⾯对⼀个简单⽽统⼀的开发环境，减少程序设
计的复杂性，将注意⼒集中在⾃⼰的业务上，不必再为程序在不同系统软件上的移植⽽重复⼯作，从⽽⼤⼤减少了技术上的负担。    在使⽤微服务架构时，您⾯临哪些挑战？ 开发⼀些较⼩的微服务听起来很容易，但开发它们时经常遇到的挑战如下。⾃动化组件：难以⾃动化，因为有许多较⼩的组件。因此，对于每个组件，我们必须遵循 Build，Deploy 和 Monitor 的各个阶段。易感性：将⼤量组件维护在⼀起变得难以部署，维护，监控和识别问题。它需要在所有组件周围具有很好的感知能⼒。配置管理：有时在各种环境中维护组件的配置变得困难。调试：很难找到错误的每⼀项服务。维护集中式⽇志记录和仪表板以调试问题⾄关重要。SOA 和微服务架构之间的主要区别是什么？ SOA 和微服务之间的主要区别如下：SOA 微服务遵循“尽可能多的共享”架构⽅法遵循“尽可能少分享”架构⽅法重要性在于“业务功能”重⽤重要性在于“有界背景”的概念它们有共同的治理和标准它们专注于⼈们的合作和其他选择的⾃由使⽤企业服务总线（ESB）进⾏通信简单的消息系统它们⽀持多种消息协议它们使⽤轻量级协议，如 HTTP/REST 等单线程，通常使⽤ Event Loop 功能进⾏⾮多线程，有跟多的开销来处理 I/O 锁定 I/O 处理最⼤化应⽤程序服务可重⽤性专注于解耦传统的关系数据库更常⽤现代关系数据库更常⽤系统的变化需要修改整体系统的变化是创造⼀种新的服务DevOps/Continuous Delivery 正在变得流专注于 DevOps/持续交付⾏，但还不是主流微服务有什么特点？ 您可以列出微服务的特征，如下所示：
图7：微服务的特征–微服务访谈问题什么是领域驱动设计？ 
图8： DDD 原理–微服务⾯试问题为什么需要域驱动设计（DDD）？ 
图9：我们需要 DDD 的因素–微服务⾯试问题
什么是⽆所不在的语⾔？ 如果您必须定义泛在语⾔（UL），那么它是特定域的开发⼈员和⽤户使⽤的通⽤语⾔，通过该语⾔可以轻松解释域。⽆处不在的语⾔必须⾮常清晰，以便它将所有团队成员放在同⼀⻚⾯上，并以机器可以理解的⽅式进⾏翻译。什么是凝聚⼒？ 模块内部元素所属的程度被认为是凝聚⼒。什么是耦合？ 组件之间依赖关系强度的度量被认为是耦合。⼀个好的设计总是被认为具有⾼内聚⼒和低耦合性。什么是 REST / RESTful 以及它的⽤途是什么？ Representational State Transfer（REST）/ RESTful Web 服务是⼀种帮助计算机系统通过 Internet 进⾏通信的架构⻛格。这使得微服务更容易理解和实现。微服务可以使⽤或不使⽤ RESTful API 实现，但使⽤ RESTful API 构建松散耦合的微服务总是更容易。什么是不同类型的微服务测试？ 在使⽤微服务时，由于有多个微服务协同⼯作，测试变得⾮常复杂。因此，测试分为不同的级别。在底层，我们有⾯向技术的测试，如单元测试和性能测试。这些是完全⾃动化的。在中间层⾯，我们进⾏了诸如压⼒测试和可⽤性测试之类的探索性测试。在顶层，我们的验收测试数量很少。这些验收测试有助于利益相关者理解和验证软件功能。容器技术 为什么需要 DevOps 在当今，软件开发公司在软件新版本发布⽅⾯，多尝试通过发布⼀系列以⼩的特性改变集为⽬标的新软件版本，代替发布⼀个⼤特性改变集的新软件版本的⽅式。这种⽅式有许多优点，诸如，快速的客户反馈，软件质量的保证等。也会获得较⾼的客户满意度评价。完成这样的软件发布模式，开发公司需要做到：增加软件布署的频率降低新发布版本的失败率缩短修复缺陷的交付时间加快解决版本冲突的问题DevOps 满⾜所有这些需求且帮助公司⾼质完成软件⽆缝交付的⽬标。
Docker 是什么？ Docker 是⼀个容器化平台，它包装你所有开发环境依赖成⼀个整体，像⼀个容器。保证项⽬开发，如开发、测试、发布等各⽣产环节都可以⽆缝⼯作在不同的平台Docker 容器：将⼀个软件包装在⼀个完整的⽂件系统中，该⽂件系统包含运⾏所需的⼀切：代码，运⾏时，系统⼯具，系统库等。可以安装在服务器上的任何东⻄。这保证软件总是运⾏在相同的运⾏环境，⽆需考虑基础环境配置的改变。  Docker 与虚拟机有何不同？ Docker 不是虚拟化⽅法。它依赖于实际实现基于容器的虚拟化或操作系统级虚拟化的其他⼯具。为此，Docker 最初使⽤ LXC 驱动程序，然后移动到libcontainer 现在重命名为 runc。Docker 主要专注于在应⽤程序容器内⾃动部署应⽤程序。应⽤程序容器旨在打包和运⾏单个服务，⽽系统容器则设计为运⾏多个进程，如虚拟机。因此，Docker 被视为容器化系统上的容器管理或应⽤程序部署⼯具。容器不需要引导操作系统内核，因此可以在不到⼀秒的时间内创建容器。此功能使基于容器的虚拟化⽐其他虚拟化⽅法更加独特和可取。 由于基于容器的虚拟化为主机增加了很少或没有开销，因此基于容器的虚拟化具有接近本机的性能。对于基于容器的虚拟化，与其他虚拟化不同，不需要其他软件。主机上的所有容器共享主机的调度程序，从⽽节省了额外资源的需求。与虚拟机映像相⽐，容器状态（Docker 或 LXC 映像）的⼤⼩很⼩，因此容器映像很容易分发。容器中的资源管理是通过 cgroup 实现的。Cgroups 不允许容器消耗⽐分配给它们更多的资源。虽然主机的所有资源都在虚拟机中可⻅，但⽆法使⽤。这可以通过在容器和主机上同时运⾏ top 或 htop 来实现。所有环境的输出看起来都很相似。 什么是 Docker 镜像？ Docker 镜像是 Docker 容器的源代码，Docker 镜像⽤于创建容器。使⽤build 命令创建镜像。什么是 Docker 容器？ Docker 容器包括应⽤程序及其所有依赖项，作为操作系统的独⽴进程运⾏。Docker 容器有⼏种状态？ 四种状态：运⾏、已暂停、重新启动、已退出。Dockerfile 中最常⻅的指令是什么？ FROM：指定基础镜像LABEL：功能是为镜像指定标签RUN：运⾏指定的命令CMD：容器启动时要运⾏的命令
 Dockerfile 中的命令 COPY 和 ADD 命令有什么区别？ COPY 与 ADD 的区别 COPY 的 SRC 只能是本地⽂件，其他⽤法⼀致。  解释⼀下 Dockerfile 的 ONBUILD 指令？ 当镜像⽤作另⼀个镜像构建的基础时，ONBUILD 指令向镜像添加将在稍后执⾏的触发指令。如果要构建将⽤作构建其他镜像的基础的镜像（例如，可以使⽤特定于⽤户的配置⾃定义的应⽤程序构建环境或守护程序），这将⾮常有⽤。 什么是 Docker Swarm？ Docker Swarm 是 Docker 的本机群集。它将 Docker 主机池转变为单个虚拟Docker 主机。Docker Swarm 提供标准的 Docker API，任何已经与 Docker守护进程通信的⼯具都可以使⽤ Swarm 透明地扩展到多个主机。 如何在⽣产中监控 Docker？ Docker 提供 docker stats 和 docker 事件等⼯具来监控⽣产中的 Docker。我们可以使⽤这些命令获取重要统计数据的报告。Docker 统计数据：当我们使⽤容器 ID 调⽤ docker stats 时，我们获得容器的CPU，内存使⽤情况等。它类似于 Linux 中的 top 命令。Docker 事件：Docker 事件是⼀个命令，⽤于查看 Docker 守护程序中正在进⾏的活动流。 ⼀些常⻅的 Docker 事件：attach，commit，die，detach，rename，destroy 等。我们还可以使⽤各种选项来限制或过滤我们感兴趣的事件。 DevOps 有哪些优势？ 技术优势: 持续的软件交付能⼒修复问题变得简单更快得解决问题商业优势: 更快交付的特性更稳定的操作系统环境更多时间可⽤于创造价值(⽽不是修复/维护)
CI 服务有什么⽤途？ CI （Continuous Integration）--持续集成服务--主要⽤于整合团队开发中不同开发者提交到开发仓库中的项⽬代码变化，并即时整合编译，检查整合编译错误的服务。它需要⼀天中多次整合编译代码的能⼒，若出现整合错误，可以优异地准确定位提交错误源。如何使⽤ Docker 技术创建与环境⽆关的容器系统？ Docker 技术有三中主要的技术途径辅助完成此需求：存储卷（Volumes）环境变量（Environment variable）注⼊只读（Read-only）⽂件系统Dockerfile 配置⽂件中的 COPY 和 ADD 指令有什么不同？ 虽然 ADD 和 COPY 功能相似，推荐 COPY 。那是因为 COPY ⽐ ADD 更直观易懂。 COPY 只是将本地⽂件拷⼊容器这么简单，⽽ ADD 有⼀些其它特性功能（诸如，本地归档解压和⽀持远程⽹址访问等），这些特性在指令本身体现并不明显。因此，有必要使⽤ ADD 指令的最好例⼦是需要在本地⾃动解压归档⽂件到容器中的情况，如 ADD rootfs.tar.xz 。Docker 映像（image）是什么？ Docker image 是 Docker 容器的源。换⾔之，Docker images ⽤于创建 Docker 容器（containers）。映像（Images）通过 Docker build 命令创建，当 run 映像时，它启动成⼀个容器（container）进程。做好的映像由于可能⾮常庞⼤，常注册存储在诸如 registry.hub.docker.com 这样的公共平台上。映像常被分层设计，每层可单独成为⼀个⼩映像，由多层⼩映像再构成⼤映像，这样碎⽚化的设计为了使映像在互联⽹上共享时，最⼩化传输数据需求。Docker 容器（container）是什么？ Docker containers -- Docker 容器--是包含其所有运⾏依赖环境，但与其它容器共享操作系统内核的应⽤，它运⾏在独⽴的主机操作系统⽤户空间进程中。Docker 容器并不紧密依赖特定的基础平台：可运⾏在任何配置的计算机，任何平台以及任何云平台上。Docker 中⼼（hub）什么概念？ Docker hub 是云基础的 Docker 注册服务平台，它允许⽤户进⾏访问 Docker 中⼼资源库，创建⾃⼰的 Docker 映像并测试，推送并存储创建好的 Docker 映像，连接 Docker 云平台将已创建好的指定 Docker 映像布署到本地主机等任务。它提供了⼀个查找发现 Docker 映像，发布 Docker 映像及控制变化升级的资源中⼼，成为⽤户组或团队协作开发中保证⾃动化开发流程的有效技术途径。在任意给定时间点指出⼀个 Docker 容器可能存在的运⾏阶段？ 在任意时间点，⼀个 Docker 容器可能存在以下运⾏阶段：运⾏中（Running）已暂停（Paused）重启中（Restarting）已退出（Exited）
有什么⽅法确定⼀个 Docker 容器运⾏状态？ 使⽤如下命令⾏命令确定⼀个 Docker 容器的运⾏状态这将列表形式输出运⾏在主机上的所有 Docker 容器及其运⾏状态。从这个列表中很容易找到想要的容器及其运⾏状态。在 Dockerfile 配置⽂件中最常⽤的指令有哪些？ ⼀些最常⽤的指令如下：FROM：使⽤ FROM 为后续的指令建⽴基础映像。在所有有效的 Dockerfile 中， FROM 是第⼀条指令。LABEL：LABEL 指令⽤于组织项⽬映像，模块，许可等。在⾃动化布署⽅⾯ LABEL 也有很⼤⽤途。在 LABEL 中指定⼀组键值对，可⽤于程序化配置或布署 Docker 。RUN：RUN 指令可在映像当前层执⾏任何命令并创建⼀个新层，⽤于在映像层中添加功能层，也许最来的层会依赖它。CMD：使⽤ CMD 指令为执⾏的容器提供默认值。在 Dockerfile ⽂件中，若添加多个 CMD 指令，只有最后的 CMD 指令运⾏。什么类型的应⽤（⽆状态性或有状态性）更适合 Docker 容器技术？ 对于 Docker 容器创建⽆状态性（Stateless）的应⽤更可取。通过从应⽤项⽬中将与状态相关的信息及配置提取掉，我们可以在项⽬环境外建⽴不依赖项⽬环境的 Docker 容器。这样，我们可以在任意产品中运⾏同⼀容器，只需根据产品需要像问&答（QA）⼀样给其配置环境即可。这帮助我们在不同场景重⽤相同的 Docker 映像。另外，使⽤⽆状态性（Stateless）容器应⽤相⽐有状态性（Stateful）容器应⽤更具伸缩性，也容易创建。解释基本 Docker 应⽤流程 初始，所有都有赖于 Dockerfile 配置⽂件。Dockerfile 配置⽂件就是创建 Docker image (映像)的源代码。⼀旦 Dockerfile 配置好了，就可以创建（build）并⽣成'image（映像）'，'image'就是 Dockerfile 配置⽂件中「源代码」的「编译」版本。⼀旦有了'image'，就可以在 registry（注册中⼼）发布它。'registry'类似 git 的资源库--你可以推送你的映像（image），也可取回库中的映像image）。之后，你就可以使⽤ image 去启动运⾏'containers（容器）'。运⾏中的容器在许多⽅⾯，与虚拟机⾮常相似，但容器的运⾏不需要虚拟管理软件的运⾏。Docker Image 和 Docker Layer (层)有什么不同？ Image：⼀个 Docker Image 是由⼀系列 Docker 只读层（read-only Layer）创建出来的。Layer：在 Dockerfile 配置⽂件中完成的⼀条配置指令，即表示⼀个 Docker 层（Layer）。如下 Dockerfile ⽂件包含4 条指令，每条指令创建⼀个层（Layer）。$ docker ps –a 
重点，每层只对其前⼀层进⾏⼀（某）些进化。虚拟化技术是什么？ 最初的构想，virtualisation（虚拟化）被认为是逻辑划分⼤型主机使得多个应⽤可以并⾏运⾏的⼀种技术⽅案。然⽽，随着技术公司及开源社区的推进，现实发⽣了戏剧性的转变，以致产⽣了以⼀种或某种⽅式操作特权指令可以在单台基于 x86 硬件的系统上同时运⾏多个（种）操作系统的技术。实质的效果是，虚拟化技术允许你在⼀个硬件平台下运⾏2 个完全不同的操作系统。每个客户操作系统可完成像系统⾃检、启动、载⼊系统内核等像在独⽴硬件上的⼀切动作。同时也具备坚实的安全基础，例如，客户操作系统不能获取完全访问主机或其它客户系统的权限，及其它涉及安全，可能把系统搞坏的操作。基于对客户操作系统虚拟硬件、运⾏环境模拟⽅法的不同，对虚拟化技术进⾏分类，主要的有如下3 种虚拟化技术种类：全模拟（Emulation）半虚拟（Paravirtualization）基于容器的虚拟化（Container-based virtualization）虚拟管理层（程序）是什么？ hypervisor --虚拟管理层（程序）--负责创建客户虚拟机系统运⾏所需虚拟硬件环境。它监管客户虚拟操作系统的运⾏，并为客户系统提供必要的运⾏资源，保证客户虚拟系统的运⾏。虚拟管理层（程序）驻留在物理主机系统和虚拟客户系统之间，为虚拟客户系统提供必要的虚拟服务。如何理解它，它侦听运⾏在虚拟机中的客户操作系统的操作并在主机操作系统中模拟客户操作系统所需硬件资源请求。满⾜客户机的运⾏需求。虚拟化技术的快速发展，主要在云平台，由于在虚拟管理程序的帮助下，可允许在单台物理服务器上⽣成多个虚拟服务器，驱动着虚拟化技术快速发展及⼴泛应⽤。诸如， Xen，VMware，KVM 等，以及商业化的处理器硬件⽣产⼚商也加⼊在硬件层⾯⽀持虚拟化技术的⽀持。诸如，Intel 的 VT 和 AMD-V 。Docker 群（Swarm）是什么？ Docker Swarm -- Docker 群--是原⽣的 Docker 集群服务⼯具。它将⼀群 Docker 主机集成为单⼀⼀个虚拟 Docker 主机。利⽤⼀个 Docker 守护进程，通过标准的 Docker API 和任何完善的通讯⼯具，Docker Swarm 提供透明地将 Docker 主机扩散到多台主机上的服务。FROM ubuntu:15.04 COPY ./app RUN make /app CMD python /app/app.py
在使⽤ Docker 技术的产品中如何监控其运⾏？ Docker 在产品中提供如运⾏统计和 Docker 事件的⼯具。可以通过这些⼯具命令获取 Docker 运⾏状况的统计信息或报告。Docker stats ：通过指定的容器 id 获取其运⾏统计信息，可获得容器对 CPU，内存使⽤情况等的统计信息，类似 Linux 系统中的 top 命令。 Docker events ：Docker 事件是⼀个命令，⽤于观察显示运⾏中的 Docker ⼀系列的⾏为活动。⼀般的 Docker 事件有：attach（关联），commit（提交），die（僵死）， detach（取消关联），rename（改名），destory（销毁）等。也可使⽤多个选项对事件记录筛选找到想要的事件信息。什么是孤⼉卷及如何删除它？ 孤⼉卷是未与任何容器关联的卷。在 Docker v。1.9 之前的版本中，删除这些孤⼉卷存在很⼤问题。什么是半虚拟化（Paravirtualization）？ Paravirtualization，也称为第1 类虚拟机管理（层）程序，其直接在硬件或裸机（bare-metal）上运⾏，提供虚拟机直接使⽤物理硬件的服务，它帮助主机操作系统，虚拟化硬件和实际硬件进⾏协作以实现最佳性能。这种虚拟层管理技术的程序⼀般占⽤系统资源较⼩，其本身并不需要占⽤⼤量系统资源。 
这种虚拟层管理程序有 Xen, KVM 等。Docker 技术与虚拟机技术有何不同？ Docker 不是严格意义上的虚拟化硬件的技术。它依赖 container-based virtualization（基于容器的虚拟化）的技术实现⼯具，或可以认为它是操作系统⽤户运⾏级别的虚拟化。因此， Docker 最初使⽤ LXC 驱动它，后来移⾄由 libcontainer 基础库驱动它，现已更名为 runc 。 Docker 主要致⼒于应⽤容器内的应⽤程序的⾃动化部署。应⽤容器设计⽤于包装和运⾏单⼀服务，⽽操作系统设计⽤于运⾏多进程任务，提供多种运算服务的能⼒。如虚拟机中等同完全操作系统的能⼒。因此，Docker 被认为是容器化系统上管理容器及应⽤容器化的布署⼯具。

与虚拟机不同，容器⽆需启动操作系统内核，因此，容器可在不到1 秒钟时间内运⾏起来。这个特性，使得容器化技术⽐其它虚拟化技术更具有独特性及可取性。由于容器化技术很少或⼏乎不给主机系统增加负载，因此，基于容器的虚拟化技术具有近乎原⽣的性能表现。基于容器的虚拟化，与其他硬件虚拟化不同，运⾏时不需要其他额外的虚拟管理层软件。主机上的所有容器共享主机操作系统上的进程调度，从⽽节省了额外的资源的需求。与虚拟机 image 相⽐，容器（Docker 或 LXC images）映像较⼩，因此，容器映像易于分发。容器中的资源分配由 Cgroups 实现。 Cgroup 不会让容器占⽤⽐给它们分配的更多的资源。但是，现在其它的虚拟化技术，对于虚拟机，主机的所有资源都可⻅，但⽆法使⽤。这可以通过在容器和主机上同时运⾏ top 或 htop 来观察到。在两个环境中的输出看起来相同。请解释⼀下 docerfile 配置⽂件中的 ONBUILD 指令的⽤途含义？ 配置⽂件中的 ONBUILD 指令为创建的 Docker image （映像）加⼊在将来执⾏的指令（译注：在当前配置⽂件⽣成的映像中并不执⾏），⽤于在以这个创建的映像为基础的创建的⼦映像（image）中执⾏或定制。举例，以基映像创建⾃⼰的映像时，可定制创建特有的⽤户化的配置环境。译注：由于原⽂较短，关于这个问题容易迷惑。译者认为，总体来说关键理解--以基础映像创建⾃有的映像过程中，基础映像中所有的创建层或指令是以整体或固化的⽅式导⼊⾃有映像中的，⾃有映像是不能对这个过程进⾏⾃有定制。⽽ ONBUILD 指令提供了将某些层从基础映像中剥离出来提供给之后以⾃有映像为基础映像派⽣新的映像的可定制途径。这对发布映像⽽普适在不同的运⾏环境定制⾮常有⽤。不当之处，请指正！）有否在创建有状态性的 Docker 应⽤的较好实践？最适合的场景有什么？ 有状态性 Docker 应⽤的问题关键在于状态数据保存在哪⼉的问题。若所有数据保存在容器内，当更新软件版本或想将 Docker 容器移到其它机器上时，找回这些在运⾏中产⽣的状态数据将⾮常困难。您需要做的是将这些表达运⾏状态的数据保存在永久卷中。参考如下3 种模式。
译注：1 图中⽂字：数据保存在容器中，当容器停⽌运⾏时，运⾏状态数据丢失！2 图中⽂字：数据保存在主机卷（Host Volume）中，当主机停机时，运⾏状态数据将⽆法访问3 图中⽂字：数据保存在⽹络⽂件系统卷中，数据访问不依赖容器的运⾏与主机的运⾏若您使⽤：docker run -v hostFolder:/containerfolder 命令运⾏您的容器，容器运⾏中任何对/containerfolder ⽬录下数据的改变，将永久保存在主机的 hostfolder ⽬录下。使⽤⽹络⽂件系统（nfs）与此类似。那样您就可以运⾏您的容器在任何主机上且其运⾏状态数据被保存在⽹络⽂件系统上。
在 Windows 系统上可以运⾏原⽣的 Docker 容器吗？ 在'Windows Server 2016'系统上，你可以运⾏ Windows 的原⽣容器，微软推出其映像是'Windows Nano Server'，⼀个轻量级的运⾏在容器中的 Windows 原⽣系统。您可以在其中布署基于.NET 的应⽤。译注：结合 Docker 的基本技术原理，参考后⾯的问题26 和问题27，可推测，微软在系统内核上开发了对 Docker 的⽀持，⽀持其闭源系统的容器化虚拟技术。但译者认为， Windows 系统本就是闭源紧耦合的系统，好像你在本机上不装.NET 组件，各应⽤能很好运⾏似的。何必再弄个容器，浪费资源。这只是译者⾃⼰之孔⻅，想喷就喷！另： Windows Server 2016 版本之后的都可⽀持这种原⽣ Docker 技术，如 Windows Server 2018 版。在⾮ Linux 操作系统平台上如何运⾏ Docker ? 容器化虚拟技术概念可能来源于，在 Linux 内核版本2.6.24 上加⼊的对命名空间（ namespace）的技术⽀持特性。容器化进程加⼊其进程 ID 到其创建的每个进程上并且对每个进程中的系统级调⽤进⾏访问控制及审查。其本身是由系统级调⽤ clone ()克隆出来的进程，允许其创建属于⾃⼰命名空间的进程实例，⽽区别于之前的，归属与整个本机系统的进程实例。如果上述在 Linux 系统内核上的技术实现成为可能，那么明显的问题是如何在⾮ Linux 系统上运⾏容器化的 Docker 。过去， Mac 和 Windows 系统上运⾏ Docker 容器都使⽤ Linux 虚拟机（VMs）技术， Docker ⼯具箱使⽤的容器运⾏在 Virtual Box 虚拟机上。现在，最新的情况是， Windows 平台上使⽤的是 Hyper-V 产品技术，Mac 平台上使⽤的是 Hypervisor.framework （框架）产品技术。容器化技术在底层的运⾏原理？ 2006 年前后，⼈们，包括⼀些⾕歌的雇员，在 Linux 内核级别上实现了⼀种新的名为命名空间（namespace）的技术（实际上这种概念在 FreeBSD 系统上由来已久）。我们知道，操作系统的⼀个功能就是进程共享公共资源，诸如，⽹络和硬盘空间等。但是，如果⼀些公共资源被包装在⼀个命名空间中，只允许属于这个命名空间中的进程访问⼜如何呢？也就是说，可以分配⼀⼤块硬盘空间给命名空间 X 供其使⽤，但是，命名空间 Y 中的进程⽆法看到或访问这部分资源。同样地，命名空间 Y 中分配的资源，命名空间 X 中的进程也⽆法访问。当然， X 中的进程⽆法与 Y 中的进程进⾏交互。这提供了某种对公共资源的虚拟化和隔离的技术。这就是 Docker 技术的底层⼯作原理：每个容器运⾏在它⾃⼰的命名空间中，但是，确实与其它运⾏中的容器共⽤相同的系统内核。隔离的产⽣是由于系统内核清楚地知道命名空间及其中的进程，且这些进程调⽤系统 API 时，内核保证进程只能访问属于其命名空间中的资源。

图上⽂字说明：运⾏中的容器是隔离的。准确地说，各容器共享操作系统内核及操作系统 API。说说容器化技术与虚拟化技术的优缺点 仅有下⾯的⼀些对⽐：不能像虚拟机那样在容器上运⾏与主机完全不同的操作系统。然⽽，可以在容器上运⾏不同的 Linux 发布版，由于容器共享系统内核的缘故。容器的隔离性没有虚拟机那么健壮。事实上，在早期容器化技术实现上，存在某种⽅法使客户容器可接管整个主机系统。也可看到，载⼊新容器并运⾏，并不会像虚拟机那样装载⼀个新的操作系统进来。所有的容器共享同⼀系统内核，这也就是容器被认为⾮常轻量化的原因。同样的原因，不像虚拟机，你不须为容器预分配⼤量的内存空间，因为它不是运⾏新的整个的操作系统。这使得在⼀个操作系统主机上，可以同时运⾏成百上千个容器应⽤，在运⾏完整操作系统的虚拟机上，进⾏这么多的并⾏沙箱实验是不可能的。如何使 Docker 适应多种运⾏环境？ 您必然想改变您的 Docker 应⽤配置以更适应现实运⾏环境的变化。下⾯包含⼀些修改建议：移除应⽤代码中对任何固定存储卷的绑定，由于代码驻留在容器内部，⽽不能从外部进⾏修正。绑定应⽤端⼝到主机上的不同端⼝差异化设置环境变量（例如：减少⽇志冗余或者使能发电⼦邮件）设定重启策略（例如： restart: always ），避免⻓时间宕机加⼊额外的服务（例如： log aggregator）由于以上原因，您更需要⼀个 Compose 配置⽂件，⼤概叫production.yml ，它配置了恰当的产品整合服务。这个配置⽂件只需包含您选择的合适的原始 Compose 配置⽂件中，你改动的部分。docker-compose -f docker-com 为什么 Docker compose 采取的是并不等待前⾯依赖服务项的容器启动就绪后再启动的组合容器启动策略？ Docker 的 Compose 配置总是以依赖启动序列来启动或停⽌ Compose 中的服务容器，依赖启动序列是由 Compose 配置⽂件中的 depends_on ， links ， volumes_from 和 network_mode: "service : ..."等这些配置指令所确定的。然⽽， Compose 启动中，各容器的启动并不等待其依赖容器（这必定是你整个应⽤中的某个依赖的服务或应⽤）启动就绪后才启动。使⽤这种策略较好的理由如下：等待⼀个数据库服务（举例）就绪这样的问题，在⼤型分布式系统中仅是相⽐其它⼤问题的某些⼩问题。在实际发布产品运维中，您的数据库服务会由于各种原因，或者迁移宿主机导致其不可访问。您发布的产品需要有应对这样状况的弹性。掌控这些，开发设计您的应⽤，使其在访问数据库失效的情况下，能够试图重连数据库，直⾄其连接到数据库为⽌。最佳的解决⽅案是在您的应⽤代码中检查是否有应对意外的发⽣，⽆论是任何原因导致的启动或连接失效都应考虑在内。Redis 
什么是 Redis? Redis 是完全开源免费的，遵守 BSD 协议，是⼀个⾼性能的 key-value 数据库。Redis 与其他 key - value 缓存产品有以下三个特点：Redis ⽀持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进⾏使⽤。Redis 不仅仅⽀持简单的 key-value 类型的数据，同时还提供 list， set，zset，hash 等数据结构的存储。Redis ⽀持数据的备份，即 master-slave 模式的数据备份。Redis 优势：性能极⾼– Redis 能读的速度是110000 次/s,写的速度是81000 次/s 。丰富的数据类型– Redis ⽀持⼆进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。原⼦– Redis 的所有操作都是原⼦性的，意思就是要么成功执⾏要么失败完全不执⾏。单个操作是原⼦性的。多个操作也⽀持事务，即原⼦性，通过 MULTI 和 EXEC 指令包起来。丰富的特性– Redis 还⽀持 publish/subscribe,通知, key 过期等等特性。Redis 与其他 key-value 存储有什么不同？Redis 有着更为复杂的数据结构并且提供对他们的原⼦性操作，这是⼀个不同于其他数据库的进化路径。Redis 的数据类型都是基于基本数据结构的同时对程序员透明，⽆需进⾏额外的抽象。Redis 运⾏在内存中但是可以持久化到磁盘，所以在对不同数据集进⾏⾼速读写时需要权衡内存，因为数据量不能⼤于硬件内存。在内存数据库⽅⾯的另⼀个优点是，相⽐在磁盘上相同的复杂的数据结构，在内存中操作起来⾮常简单，这样 Redis 可以做很多内部复杂性很强的事情。同时，在磁盘格式⽅⾯他们是紧凑的以追加的⽅式产⽣的，因为他们并不需要进⾏随机访问。Redis 的数据类型？ Redis ⽀持五种数据类型：string（字符串），hash（哈希），list（列表），set（集合）及 zsetsorted set：有序集合)。我们实际项⽬中⽐较常⽤的是 string，hash 如果你是 Redis 中⾼级⽤户，还需要加上下⾯⼏种数据结构 HyperLogLog、Geo、Pub/Sub。如果你说还玩过 Redis Module，像 BloomFilter，RedisSearch，Redis-ML，⾯试官得眼睛就开始发亮了。使⽤ Redis 有哪些好处？ 速度快，因为数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是 O1)⽀持丰富数据类型，⽀持 string，list，set，Zset，hash 等⽀持事务，操作都是原⼦性，所谓的原⼦性就是对数据的更改要么全部执⾏，要么全部不执⾏丰富的特性：可⽤于缓存，消息，按 key 设置过期时间，过期后将会⾃动删除Redis 相⽐ Memcached 有哪些优势？ Memcached 所有的值均是简单的字符串，redis 作为其替代者，⽀持更为丰富的数据类Redis 的速度⽐ Memcached 快很Redis 可以持久化其数据
Memcache 与 Redis 的区别都有哪些？ 存储⽅式 Memecache 把数据全部存在内存之中，断电后会挂掉，数据不能超过内存⼤⼩。 Redis 有部份存在硬盘上，这样能保证数据的持久性。数据⽀持类型 Memcache 对数据类型⽀持相对简单。 Redis 有复杂的数据类型。使⽤底层模型不同它们之间底层实现⽅式以及与客户端之间通信的应⽤协议不⼀样。 Redis 直接⾃⼰构建了 VM 机制，因为⼀般的系统调⽤系统函数的话，会浪费⼀定的时间去移动和请求。Redis 是单进程单线程的？ Redis 是单进程单线程的，redis 利⽤队列技术将并发访问变为串⾏访问，消除了传统数据库串⾏控制的开销。⼀个字符串类型的值能存储最⼤容量是多少？ 答：512M   Redis 集群最⼤节点个数是多少？ 16384 个。 Reids 的特点 Redis 本质上是⼀个 Key-Value 类型的内存数据库，很像 数据库统统加载在内存当中进⾏操作，定期通过异步操作把数据库数据 硬盘上进⾏保存。 Memcached，整个flush 到因为是纯内存操作，Redis 的性能⾮常出⾊，每秒可以处理超过  10 万次读写操 作，是已知性能最快的 Key-Value DB。 Redis 的出⾊之处不仅仅是性能，Redis 最⼤的魅⼒是⽀持保存多种数据结构， 此外单个 value 的最⼤限制是 1GB，不像  Memcached 只能保存 1MB 的数据， 因此 Redis 可以⽤来实现很多有⽤的功能。⽐⽅说⽤他的 List 来做 FIFO 双向链表，实现⼀个轻量级的⾼性  能消息队列服 务，⽤他的 Set 可以做⾼性能的 tag 系统等等。另外 Redis 也可以对存⼊的 Key- Value 设置 expire 时间，因此也可以被当作⼀  个功能加强版的 Memcached 来⽤。 Redis 的主要缺点是数据库容量受到物理内存的限制，不能⽤作海量数据的⾼性 能读写，因此 Redis 适合的场景主要局限在较⼩数据量的⾼性能操作和运算上。 
使⽤ Redis 有哪些好处？ 速度快，因为数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是 O(1)。 ⽀持丰富数据类型，⽀持 string，list，set，sorted set，hash。 ⽀持事务，操作都是原⼦性，所谓的原⼦性就是对数据的更改要么全部执⾏， 要么全部不执⾏。 丰富的特性：可⽤于缓存，消息，按 key 设置过期时间，过期后将会⾃动删 除。 为什么 edis 需要把所有数据放到内存中？ Redis 为了达到最快的读写速度将数据都读到内存中，并通过异步的⽅式将数据 写⼊磁盘。所以 Redis 具有快速和数据持久化的特征。如果不将数据放在内存 中，磁盘 I/O 速度为严重影响 Redis 的性能。在内存越来越便宜的今天，Redis 将会越来越受欢迎。如果设置了最⼤使⽤的内存，则数据已有记录数达到内存限 值后不能继续插⼊新值。Redis 的内存⽤完了会发⽣什么？ 如果达到设置的上限， 返回。）或者你可以将 限时会冲刷掉旧的内容。 Redis 的写命令会返回错误信息（但是读命令还可以正常 Redis 当缓存来使⽤配置淘汰机制，当 Redis 达到内存上Redis 的回收策略（淘汰策略） volatile-lru：从已设置过期时间的数据集（  server.db[i].expires）中挑选最近 最少使⽤的数据淘汰。 volatile-ttl：  从已设置过期时间的数据集（  server.db[i].expires）  中挑选将要 过期的数据淘汰。 volatile-random：  从已设置过期时间的数据集（  server.db[i].expires）  中任 意选择数据淘汰。 allkeys-lru：  从数据集（  server.db[i].dict）  中挑选最近最少使⽤的数据淘汰。 allkeys-random：  从数据集（  server.db[i].dict）  中任意选择数据淘汰。 no-enviction（  驱逐）  ：  禁⽌驱逐数据。 注意这⾥的  6  种机制，volatile  和  allkeys  规定了是对已设置过期时间的数据 集淘汰数据还是从全部数据集淘汰数据，  后⾯的  lru、tt- 以及  random  是三 种不同的淘汰策略，  再加上⼀种  no-enviction  永不回收的策略。 使⽤策略规则：如果数据呈现幂律分布，也就是⼀部分数据访问频率⾼，⼀部分数据访问频 率  低，  则使⽤  allkeys-lru。 如果数据呈现平等分布，  也就是所有的数据访问频率都相同，  则使⽤ allkeys-random。  Redis 的持久化机制是什么？各⾃的优缺点？ Redis 提供两种持久化机制 RDB 和 AOF 机制： RDBRedis DataBase)持久化⽅式：是指⽤数据集快照的⽅式半持久化模式)记录 redis 数据库的所有键值对,在某个时间点将数据写⼊⼀个临时⽂件，持久化结束后，⽤这个临时⽂件替换上次持久化的⽂件，达到数据恢复。优点：只有⼀个⽂件 dump.rdb，⽅便持久化。
容灾性好，⼀个⽂件可以保存到安全的磁盘。性能最⼤化，fork ⼦进程来完成写操作，让主进程继续处理命令，所以是 IO 最⼤化。使⽤单独⼦进程来进⾏持久化，主进程不会进⾏任何 IO 操作，保证了 redis 的⾼性能)相对于数据集⼤时，⽐ AOF 的启动效率更⾼。缺点：数据安全性低。RDB 是间隔⼀段时间进⾏持久化，如果持久化之间 redis 发⽣故障，会发⽣数据丢失。所以这种⽅式更适合数据要求不严谨的时候。AOFAppend-only file)持久化⽅式：是指所有的命令⾏记录以 redis 命令请求协议的格式完全持久化存储)保存为 aof ⽂件。优点：数据安全，aof 持久化可以配置 appendfsync 属性，有 always，每进⾏⼀次命令操作就记录到 aof ⽂件中⼀次。通过 append 模式写⽂件，即使中途服务器宕机，可以通过 redis- check-aof ⼯具解决数据⼀致性问题。AOF 机制的 rewrite 模式。AOF ⽂件没被 rewrite 之前（⽂件过⼤时会对命令进⾏合并重写），可以删除其中的某些命令（⽐如误操作的 flushall）)缺点：AOF ⽂件⽐ RDB ⽂件⼤，且恢复速度慢。数据集⼤的时候，⽐ rdb 启动效率低。Redis 常⻅性能问题和解决⽅案： 1）Master 最好不要写内存快照，如果 Master 写内存快照，save 命令调度 rdbSave 函数，会阻塞主线程的⼯作，当快照⽐较⼤时对性能影响是⾮常⼤的，会间断性暂停服务2）如果数据⽐较重要，某个 Slave 开启 AOF 备份数据，策略设置为每秒同步⼀3）为了主从复制的速度和连接的稳定性，Master 和 Slave 最好在同⼀个局域⽹4）尽量避免在压⼒很⼤的主库上增加从5）主从复制不要⽤图状结构，⽤单向链表结构更为稳定，即：Master <- Slave1<- Slave2 <- Slave3…这样的结构⽅便解决单点故障问题，实现 Slave 对 Master 的替换。如果 Master 挂了，可以⽴刻启⽤ Slave1 做 Master，其他不变。Redis 过期键的删除策略？ 1）定时删除:在设置键的过期时间的同时，创建⼀个定时器 timer).让定时器在键的过期时间来临时，⽴即执⾏对键的删除操作。2）惰性删除:放任键过期不管，但是每次从键空间中获取键时，都检查取得的键是否过期，如果过期的话，就删除该键;如果没有过期，就返回该键。3）定期删除:每隔⼀段时间程序就对数据库进⾏⼀次检查，删除⾥⾯的过期键。⾄于要删除多少过期键，以及要检查多少个数据库，则由算法决定。
Redis 的回收策略（淘汰策略）? volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使⽤的数据淘汰volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使⽤的数据淘汰allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰no-enviction（驱逐）：禁⽌驱逐数据注意这⾥的6 种机制，volatile 和 allkeys 规定了是对已设置过期时间的数据集淘汰数据还是从全部数据集淘汰数据，后⾯的 lru、ttl 以及 random 是三种不同的淘汰策略，再加上⼀种 no-enviction 永不回收的策略。使⽤策略规则：如果数据呈现幂律分布，也就是⼀部分数据访问频率⾼，⼀部分数据访问频率低，则使⽤ allkeys-lr 如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使⽤ allkeys-random 为什么 Redis 需要把所有数据放到内存中？ Redis 为了达到最快的读写速度将数据都读到内存中，并通过异步的⽅式将数据写⼊磁盘。所以 redis 具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘 I/O 速度为严重影响 redis 的性能。在内存越来越便宜的今天， redis 将会越来越受欢迎。如果设置了最⼤使⽤的内存，则数据已有记录数达到内存限值后不能继续插⼊新值。Redis 的同步机制了解么？ Redis 可以使⽤主从同步，从从同步。第⼀次同步时，主节点做⼀次 bgsave，并同时将后续修改操作记录到内存 buffer，待完成后将 rdb ⽂件全量同步到复制节点，复制节点接受完成后将 rdb 镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进⾏重放就完成了同步过程。Pipeline 有什么好处，为什么要⽤ Pipeline？ 可以将多次 IO 往返的时间缩减为⼀次，前提是 pipeline 执⾏的指令之间没有因果相关性。使⽤ redis-benchmark 进⾏压测的时候可以发现影响 redis 的 QPS 峰值的⼀个重要因素是 pipeline 批次指令的数⽬。是否使⽤过 Redis 集群，集群的原理是什么？ Redis Sentinal 着眼于⾼可⽤，在 master 宕机时会⾃动将 slave 提升为 master，继续提供服务。Redis Cluster 着眼于扩展性，在单个 redis 内存不⾜时，使⽤ Cluster 进⾏分⽚存储。
Redis 集群⽅案什么情况下会导致整个集群不可⽤？ 有 A，B，C 三个节点的集群,在没有复制模型的情况下,如果节点 B 失败了，那么整个集群就会以为缺少5501-11000 这个范围的槽⽽不可⽤。Redis ⽀持的 Java 客户端都有哪些？官⽅推荐⽤哪个？ Redisson、Jedis、lettuce 等等，官⽅推荐使⽤ Redisson。Jedis 与 Redisson 对⽐有什么优缺点？ Jedis 是 Redis 的 Java 实现的客户端，其 API 提供了⽐较全⾯的 Redis 命令的⽀持；Redisson 实现了分布式和可扩展的 Java 数据结构，和 Jedis 相⽐，功能较为简单，不⽀持字符串操作，不⽀持排序、事务、管道、分区等 Redis 特性。Redisson 的宗旨是促进使⽤者对 Redis 的关注分离，从⽽让使⽤者能够将精⼒更集中地放在处理业务逻辑上。Redis 如何设置密码及验证密码？ 设置密码：config set requirepass 123456 授权密码：auth 123456 说说 Redis 哈希槽的概念？ Redis 集群没有使⽤⼀致性 hash,⽽是引⼊了哈希槽的概念，Redis 集群有16384 个哈希槽，每个 key 通过 CRC16 校验后对16384 取模来决定放置哪个槽，集群的每个节点负责⼀部分 hash 槽。Redis 集群的主从复制模型是怎样的？ 为了使在部分节点失败或者⼤部分节点⽆法通信的情况下集群仍然可⽤，所以集群使⽤了主从复制模型,每个节点都会有 N-1 个复制品。Redis 集群会有写操作丢失吗？为什么？ Redis 并不能保证数据的强⼀致性，这意味这在实际中集群在特定的条件下可能会丢失写操作。Redis 集群之间是如何复制的？ 异步复制Redis 集群最⼤节点个数是多少？ 16384 个。Redis 集群如何选择数据库？ Redis 集群⽬前⽆法做数据库选择，默认在0 数据库。
怎么测试 Redis 的连通性 使⽤ ping 命令。怎么理解 Redis 事务？ 1）事务是⼀个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执⾏。事务在执⾏的过程中，不会被其他客户端发送来的命令请求所打断。2）事务是⼀个原⼦操作：事务中的命令要么全部被执⾏，要么全部都不执⾏。Redis 事务相关的命令有哪⼏个？ MULTI、 EXEC、 DISCARD、 WATCH Redis key 的过期时间和永久有效分别怎么设置？ EXPIRE 和 PERSIST 命令。Redis 如何做内存优化？ 尽可能使⽤散列表（hashes），散列表（是说散列表⾥⾯存储的数少）使⽤的内存⾮常⼩，所以你应该尽可能的将你的数据模型抽象到⼀个散列表⾥⾯。⽐如你的 web 系统中有⼀个⽤户对象，不要为这个⽤户的名称，姓⽒，邮箱，密码设置单独的 key,⽽是应该把这个⽤户的所有信息存储到⼀张散列表⾥⾯。Redis 回收进程如何⼯作的？ ⼀个客户端运⾏了新的命令，添加了新的数据。Redi 检查内存使⽤情况，如果⼤于 maxmemory 的限制,则根据设定好的策略进⾏回收。⼀个新的命令被执⾏，等等。所以我们不断地穿越内存限制的边界，通过不断达到边界然后不断地回收回到边界以下。如果⼀个命令的结果导致⼤量内存被使⽤（例如很⼤的集合的交集保存到⼀个新的键），不⽤多久内存限制就会被这个内存使⽤量超越。都有哪些办法可以降低 Redis 的内存使⽤情况呢？ 如果你使⽤的是32 位的 Redis 实例，可以好好利⽤ Hash,list,sorted set,set 等集合类型数据，因为通常情况下很多⼩的 Key-Value 可以⽤更紧凑的⽅式存放到⼀起。Redis 的内存⽤完了会发⽣什么？ 如果达到设置的上限，Redis 的写命令会返回错误信息（但是读命令还可以正常返回。）或者你可以将 Redis 当缓存来使⽤配置淘汰机制，当 Redis 达到内存上限时会冲刷掉旧的内容。⼀个 Redis 实例最多能存放多少的 keys？ List、Set、 Sorted Set 他们最多能存放多少元素？ 理论上 Redis 可以处理多达232 的 keys，并且在实际中进⾏了测试，每个实例⾄少存放了2 亿5 千万的 keys。我们正在测试⼀些较⼤的值。任何 list、 set、和 sorted set 都可以放232 个元素。换句话说，Redis 的存储极限是系统中的可⽤内存值。
MySQL ⾥有2000w 数据，Redis 中只存20w 的数据，如何保证 redis 中的数据都是热点数据？Redis 内存数据集⼤⼩上升到⼀定⼤⼩的时候，就会施⾏数据淘汰策略。  相关知识：Redis 提供6 种数据淘汰策略：volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使⽤的数据淘汰volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使⽤的数据淘汰allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-enviction（驱逐）：禁⽌驱逐数据Redis 最适合的场景？ 会话缓存（Session Cache）最常⽤的⼀种使⽤ Redis 的情景是会话缓存（session cache）。⽤ Redis 缓存会话⽐其他存储（如 Memcached）的优势在于：Redis 提供持久化。当维护⼀个不是严格要求⼀致性的缓存时，如果⽤户的购物⻋信息全部丢失，⼤部分⼈都会不⾼兴的，现在，他们还会这样吗？幸运的是，随着 Redis 这些年的改进，很容易找到怎么恰当的使⽤ Redis 来缓存会话的⽂档。甚⾄⼴为⼈知的商业平台 Magento 也提供 Redis 的插件。全⻚缓存（FPC）除基本的会话 token 之外，Redis 还提供很简便的 FPC 平台。回到⼀致性问题，即使重启了 Redis 实例，因为有磁盘的持久化，⽤户也不会看到⻚⾯加载速度的下降，这是⼀个极⼤改进，类似 PHP 本地 FPC。再次以 Magento 为例，Magento 提供⼀个插件来使⽤ Redis 作为全⻚缓存后端。此外，对 WordPress 的⽤户来说，Pantheon 有⼀个⾮常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的⻚⾯。队列Reids 在内存存储引擎领域的⼀⼤优点是提供 list 和 set 操作，这使得 Redis 能作为⼀个很好的消息队列平台来使⽤。Redis 作为队列使⽤的操作，就类似于本地程序语⾔（如 Python）对 list 的 push/pop 操作。如果你快速的在 Google 中搜索“Redis queues”，你⻢上就能找到⼤量的开源项⽬，这些项⽬的⽬的就是利⽤ Redis 创建⾮常好的后端⼯具，以满⾜各种队列需求。例如，Celery 有⼀个后台就是使⽤ Redis 作为 broker，你可以从这⾥去查看。排⾏榜/计数器Redis 在内存中对数字进⾏递增或递减的操作实现的⾮常好。集合（Set）和有序集合（Sorted Set）也使得我们在执⾏这些操作的时候变的⾮常简单，Redis 只是正好提供了这两种数据结构。所以，我们要从排序集合中获取到排名最靠前的10 个⽤户–我们称之为“user_scores”，我们只需要像下⾯⼀样执⾏即可：当然，这是假定你是根据你⽤户的分数做递增的排序。如果你想返回⽤户及⽤户的分数，你需要这样执⾏： ZRANGE user_scores 0 10 WITHSCORES Agora Games 就是⼀个很好的例⼦，⽤ Ruby 实现的，它的排⾏榜就是使⽤ Redis 来存储数据的，你可以在这⾥看到。发布/订阅
最后（但肯定不是最不重要的）是 Redis 的发布/订阅功能。发布/订阅的使⽤场景确实⾮常多。我已看⻅⼈们在社交⽹络连接中使⽤，还可作为基于发布/订阅的脚本触发器，甚⾄⽤ Redis 的发布/订阅功能来建⽴聊天系统！假如 Redis ⾥⾯有1 亿个 key，其中有10w 个 key 是以某个固定的已知的前缀开头的，如果将它们全部找出来？ 使⽤ keys 指令可以扫出指定模式的 key 列表。对⽅接着追问：如果这个 redis 正在给线上的业务提供服务，那使⽤ keys 指令会有什么问题？这个时候你要回答 redis 关键的⼀个特性：redis 的单线程的。keys 指令会导致线程阻塞⼀段时间，线上服务会停顿，直到指令执⾏完毕，服务才能恢复。这个时候可以使⽤ scan 指令，scan 指令可以⽆阻塞的提取出指定模式的key 列表，但是会有⼀定的重复概率，在客户端做⼀次去重就可以了，但是整体所花费的时间会⽐直接⽤ keys 指令⻓。如果有⼤量的 key 需要设置同⼀时间过期，⼀般需要注意什么？ 如果⼤量的 key 过期时间设置的过于集中，到过期的那个时间点，redis 可能会出现短暂的卡顿现象。⼀般需要在时间上加⼀个随机值，使得过期时间分散⼀些。使⽤过 Redis 做异步队列么，你是怎么⽤的？ ⼀般使⽤ list 结构作为队列，rpush ⽣产消息，lpop 消费消息。当 lpop 没有消息的时候，要适当 sleep ⼀会再重试。如果对⽅追问可不可以不⽤ sleep 呢？list 还有个指令叫 blpop，在没有消息的时候，它会阻塞住直到消息到来。如果对⽅追问能不能⽣产⼀次消费多次呢？使⽤ pub/sub 主题订阅者模式，可以实现1:N 的消息队列。如果对⽅追问 pub/sub 有什么缺点？在消费者下线的情况下，⽣产的消息会丢失，得使⽤专业的消息队列如 RabbitMQ 等。如果对⽅追问 redis 如何实现延时队列？我估计现在你很想把⾯试官⼀棒打死如果你⼿上有⼀根棒球棍的话，怎么问的这么详细。但是你很克制，然后神态⾃若的回答道：使⽤ sortedset，拿时间戳作为 score，消息内容作为 key 调⽤ zadd 来⽣产消息，消费者⽤ zrangebyscore 指令获取 N 秒之前的数据轮询进⾏处理。到这⾥，⾯试官暗地⾥已经对你竖起了⼤拇指。但是他不知道的是此刻你却竖起了中指，在椅⼦背后。使⽤过 Redis 分布式锁么，它是什么回事 先拿 setnx 来争抢锁，抢到之后，再⽤ expire 给锁加⼀个过期时间防⽌锁忘记了释放。这时候对⽅会告诉你说你回答得不错，然后接着问如果在 setnx 之后执⾏ expire 之前进程意外 crash 或者要重启维护了，那会怎么样？这时候你要给予惊讶的反馈：唉，是喔，这个锁就永远得不到释放了。紧接着你需要抓⼀抓⾃⼰得脑袋，故作思考⽚刻，好像接下来的结果是你主动思考出来的，然后回答：我记得 set 指令有⾮常复杂的参数，这个应该是可以同时把 setnx 和 expire 合成⼀条指令来⽤的！对⽅这时会显露笑容，⼼⾥开始默念：摁，这⼩⼦还不错。 
 假如 Redis ⾥⾯有 1 亿个 key，其中有 10w 个 key 是以某个固定的已知的前缀开头的，如果将它们全部找出来？ 使⽤ keys 指令可以扫出指定模式的 key 列表。 对⽅接着追问：如果这个 Redis 正在给线上的业务提供服务，那使⽤ keys 指令 会有什么问题？这个时候你要回答 Redis 关键的⼀个特性：Redis 的单线程的。keys 指令会导 致线程阻塞⼀段时间，线上服务会停顿，直到指令执⾏完毕，服务才能恢复。这 个时候可以使⽤ scan 指令，scan 指令可以⽆阻塞的提取出指定模式的 key 列 表，但是会有⼀定的重复概率，在客户端做⼀次去重就可以了，但是整体所花费 的时间会⽐直接⽤ keys 指令⻓。 Memcached 与 Redis 的区别？ Redis  不仅仅⽀持简单的  k/v  类型的数据，同时还提供  list，set，zset， hash  等数据结构的存储。⽽  memcache  只⽀持简单数据类型，需要客户端⾃ ⼰处理复杂对象。 Redis  ⽀持数据的持久化，  可以将内存中的数据保持在磁盘中，  重启的时 候可以再次加载进⾏使⽤（  PS：  持久化在  rdb、aof）。 Redis 常⻅性能问题和解决⽅案： Master  最好不要写内存快照，如果  Master  写内存快照，save  命令调度 rdbSave 函数，  会阻塞主线程的⼯作，  当快照⽐较⼤时对性能影响是⾮常⼤ 的，  会间断性暂停服务。 如果数据⽐较重要，  某个  Slave  开启  AOF  备份数据，  策略设置为每秒 同步⼀。 为了主从复制的速度和连接的稳定性，  Master  和  Slave  最好在同⼀个局 域⽹。 尽量避免在压⼒很⼤的主库上增加从。 主从复制不要⽤图状结构，  ⽤单向链表结构更为稳定，  即：Master <- Slave1<- Slave2 <- Slave3…  这样的结构⽅便解决单点故障问题，实现  Slave 对  Master  的替换。如果  Master  挂了，  可以⽴刻启⽤  Slave1  做  Master， 其他不变。  
缓存如何实现⾼并发？
 
 Redis 和 Memcached 的区别 redis 拥有更多的数据结构和丰富的数据操作redis 内存利⽤率⾼于 memcached redis 是单线程，memcached是多线程，在存储⼤数据的情况下，redis ⽐ memcached稍有逊⾊memcached没有原⽣的集群模式，redis 官⽅⽀持 redis cluster 集群模式⽤缓存可能出现的问题 数据不⼀致缓存雪崩缓存穿透缓存并发竞争
当查询缓存报错，怎么提⾼可⽤性？ 缓存可以极⼤的提⾼查询性能，但是缓存数据丢失和缓存不可⽤不能影响应⽤的正常⼯作。因此，⼀般情况下，如果缓存出现异常，需要⼿动捕获这个异常，并且记录⽇志，并且从数据库查询数据返回给⽤户，⽽不应该导致业务不可⽤。如果避免缓存”穿透”的问题？ 缓存穿透，是指查询⼀个⼀定不存在的数据，由于缓存是不命中时被动写，并且处于容错考虑，如果从 DB 查不到数据则不写⼊缓存，这将导致这个不存在的数据每次请求都要到 DB 去查询，失去了缓存的意义。如何解决 有两种⽅案可以解决：⽅案⼀，缓存空对象。当从 DB 查询数据为空，我们仍然将这个空结果进⾏缓存，具体的值需要使⽤特殊的标识，能和真正缓存的数据区分开。另外，需要设置较短的过期时间，⼀般建议不要超过5 分钟。⽅案⼆，BloomFilter 布隆过滤器。在缓存服务的基础上，构建 BloomFilter 数据结构，在 BloomFilter 中存储对应的 KEY 是否存在，如果存在，说明该 KEY 对应的值不为空。如何避免缓存“雪崩”的问题？ 缓存雪崩缓存雪崩，是指缓存由于某些原因⽆法提供服务(例如，缓存挂掉了)，所有请求全部达到 DB 中，导致 DB 负荷⼤增，最终挂掉的情况。如何解决预防和解决缓存雪崩的问题，可以从以下多个⽅⾯进⾏共同着⼿。1）缓存⾼可⽤：通过搭建缓存的⾼可⽤，避免缓存挂掉导致⽆法提供服务的情况，从⽽降低出现缓存雪崩的情况。假设我们使⽤ Redis 作为缓存，则可以使⽤ Redis Sentinel 或 Redis Cluster 实现⾼可⽤。2）本地缓存：如果使⽤本地缓存时，即使分布式缓存挂了，也可以将 DB 查询到的结果缓存到本地，避免后续请求全部到达 DB 中。如果我们使⽤ JVM ，则可以使⽤ Ehcache、Guava Cache 实现本地缓存的功能。如果避免缓存“击穿”的问题？ 缓存击穿缓存击穿，是指某个极度“热点”数据在某个时间点过期时，恰好在这个时间点对这个 KEY 有⼤量的并发请求过来，这些请求发现缓存过期⼀般都会从 DB 加载数据并回设到缓存，但是这个时候⼤并发的请求可能会瞬间 DB 压垮。对于⼀些设置了过期时间的 KEY ，如果这些 KEY 可能会在某些时间点被超⾼并发地访问，是⼀种⾮常“热点”的数据。这个时候，需要考虑这个问题。区别：和缓存“雪崩“”的区别在于，前者针对某⼀ KEY 缓存，后者则是很多 KEY 。
和缓存“穿透“”的区别在于，这个 KEY 是真实存在对应的值的。如何解决有两种⽅案可以解决：1）⽅案⼀，使⽤互斥锁。请求发现缓存不存在后，去查询 DB 前，使⽤分布式锁，保证有且只有⼀个线程去查询 DB ，并更新到缓存。2）⽅案⼆，⼿动过期。缓存上从不设置过期时间，功能上将过期时间存在 KEY 对应的 VALUE ⾥。流程如下：1、获取缓存。通过 VALUE 的过期时间，判断是否过期。如果未过期，则直接返回；如果已过期，继续往下执⾏。2、通过⼀个后台的异步线程进⾏缓存的构建，也就是“⼿动”过期。通过后台的异步线程，保证有且只有⼀个线程去查询 DB。3、同时，虽然 VALUE 已经过期，还是直接返回。通过这样的⽅式，保证服务的可⽤性，虽然损失了⼀定的时效性。什么是缓存预热？如何实现缓存预热？ 缓存预热在刚启动的缓存系统中，如果缓存中没有任何数据，如果依靠⽤户请求的⽅式重建缓存数据，那么对数据库的压⼒⾮常⼤，⽽且系统的性能开销也是巨⼤的。此时，最好的策略是启动时就把热点数据加载好。这样，⽤户请求时，直接读取的就是缓存的数据，⽽⽆需去读取 DB 重建缓存数据。举个例⼦，热⻔的或者推荐的商品，需要提前预热到缓存中。如何实现⼀般来说，有如下⼏种⽅式来实现：数据量不⼤时，项⽬启动时，⾃动进⾏初始化。写个修复数据脚本，⼿动执⾏该脚本。写个管理界⾯，可以⼿动点击，预热对应的数据到缓存中。缓存数据的淘汰策略有哪些？ 除了缓存服务器⾃带的缓存⾃动失效策略之外，我们还可以根据具体的业务需求进⾏⾃定义的“⼿动”缓存淘汰，常⻅的策略有两种：1、定时去清理过期的缓存。2、当有⽤户请求过来时，再判断这个请求所⽤到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。两者各有优劣，第⼀种的缺点是维护⼤量缓存的 key 是⽐较麻烦的，第⼆种的缺点就是每次⽤户请求过来都要判断缓存失效，逻辑相对⽐较复杂！具体⽤哪种⽅案，⼤家可以根据⾃⼰的应⽤场景来权衡。 MySQL
MySQL 隔离级别与锁的关系 回答这个问题，可以先阐述四种隔离级别，再阐述它们的实现原理。隔离级别就是依赖锁 和 MVCC 实现的。 实践中如何优化 MySQL？ 最好是按照以下顺序优化： SQL 语句及索引的优化 数据库表结构的优化系统配置的优化硬件的优化 优化⼦查询的⽅法 ⽤关联查询替代。 优化 GROUP BY 和 DISTINCT。 这两种查询据可以使⽤索引来优化，是最有效的优化⽅法。 - 关联查询中，使⽤标识列分组的效率更⾼。 如果不需要 ORDER BY，进⾏ GROUP BY 时加 ORDER BY NULL，MySQL 不会再进⾏⽂件排序。WITH ROLLUP 超级聚合，可以挪到应⽤程序处理。 前缀索引 语法：index(field(10))，使⽤字段值的前 10 个字符建⽴索引，默认是使⽤字段的全部内容建⽴索引。前提：前缀的标识度⾼。⽐如密码就适合建⽴前缀索引，因为密码⼏乎各不相同。实操的难度：在于前缀截取的⻓度。我们可以利⽤ select count(*)/count(distinct left(password,prefixLen));，通过从调整 prefixLen 的值（从 1 ⾃增）查看不同前缀⻓度的⼀个平均匹配度，接近 1 时就可 以了（表示⼀个密码的前 prefixLen 个字符⼏乎能确定唯⼀⼀条记录）。 MySQL 5.6 和 MySQL 5.7 对索引做了哪些优化？ MySQL5.6 引⼊了索引下推优化，默认是开启的。例⼦：user 表中（a,b,c）构成⼀个索引。select * from user where a='23' and b like '%eqw%' and c like 'dasd'。 解释：如果没有索引下推原则，则 MySQL 会通过 a='23'  先查询出⼀个对应的数据。然后返回到 MySQL 服务端。MySQL 服务端再基于两个 like 模糊查询来校验 and 查询出的数据是否符合条件。这个过程就设计到回表操作。如果使⽤了索引下推技术，则 MySQL 会⾸先返回返回条件 a='23'的数据的索引，然后根据模糊查询的条件来校验索引⾏数据是否符合条件，如果符合条件，则直接根据 索引来定位对应的数据，如果不符合直接 reject 掉。因此，有了索引下推优化，可以 在有 like 条件的情况下，减少回表的次数。
MySQL 有关权限的表有哪⼏个呢？ MySQL 服务器通过权限表来控制⽤户对数据库的访问，权限表存放在 MySQL 数据库 ⾥，由 MySQL_install_db 脚本初始化。这些权限表分别 user，db，table_priv， columns_priv 和 host。 user 权限表：记录允许连接到服务器的⽤户帐号信息，⾥⾯的权限是全局级的。 2、 db 权限表：记录各个帐号在各个数据库上的操作权限。table_priv 权限表：记录数据表级的操作权限。columns_priv 权限表：记录数据列级的操作权限。host 权限表：配合 db 权限表对给定主机上数据库级操作权限作更细致的控制。这个 权限表不受 GRANT 和 REVOKE语句的影响。MySQL 中都有哪些触发器？ MySQ- 数据库中有六种触发器： - Before Insert After Insert Before Update - After Update - Before Delete - After Delete ⼤表怎么优化？分库分表了是怎么做的？分表分库了有什么问题？ 有⽤到中间件么？他们的原理知道么？ 当 MySQL 单表记录数过⼤时，数据库的 CRUD 性能会明显下降，⼀些常⻅的优化措施如 下： 限定数据的范围：  务必禁⽌不带任何限制数据范围条件的查询语句。⽐如：我们当⽤户在查询订单历史的时候，我们可以控制在⼀个⽉的范围内。；读/写分离：  经典的数据库拆分⽅案，主库负责写，从库负责读；缓存：  使⽤ MySQL 的缓存，另外对重量级、更新少的数据可以考虑使⽤应⽤级别的缓存； 还有就是通过分库分表的⽅式进⾏优化。主要有垂直分区、垂直分表、⽔平分区、⽔平分 表 垂直分区 根据数据库⾥⾯数据表的相关性进⾏拆分。  例如，⽤户表中既有⽤户的登录信息⼜有 ⽤户的基本信息，可以将⽤户表拆分成两个单独的表，甚⾄放到单独的库做分库。简单来说垂直拆分是指数据表列的拆分，把⼀张列⽐较多的表拆分为多张表。  如下图 所示，这样来说⼤家应该就更容易理解了。
垂直拆分的优点：
可以使得⾏数据变⼩，在查询时减少读取的 Block 数，减少 I/O 次数。此外，垂直分区可 以简化表的结构，易于维护。垂直拆分的缺点：主键会出现冗余，需要管理冗余列，并会引起 Join 操作，可以通过在应⽤层进⾏ Join 来 解决。此外，垂直分区会让事务变得更加复杂。 垂直分表 把主键和⼀些列放在⼀个表，然后把主键和另外的列放在另⼀个表中
适⽤场景 如果⼀个表中某些列常⽤，另外⼀些列不常⽤可以使数据⾏变⼩，⼀个数据⻚能存储更多数据，查询时减少 I/O 次数 缺点 有些分表的策略基于应⽤层的逻辑算法，⼀旦逻辑算法改变，整个分表逻辑都会改变，扩展性较差对于应⽤层来说，逻辑算法增加开发成本管理冗余列，查询所有数据需要 join 操作 ⽔平分区 保持数据表结构不变，通过某种策略存储数据分⽚。这样每⼀⽚数据分散到不同的表或者库中，达到了分布式的⽬的。  ⽔平拆分可以⽀撑⾮常⼤的数据量。⽔平拆分是指数据表⾏的拆分，表的⾏数超过 200 万⾏时，就会变慢，这时可以把⼀
张的表的数据拆成多张表来存放。举个例⼦：我们可以将⽤户信息表拆分成多个⽤户 信息表，这样就可以避免单⼀表数据量过⼤对性能造成影响。
⽔品拆分可以⽀持⾮常⼤的数据量。需要注意的⼀点是过⼤的问题，但由于表的数据还是在同⼀台机器上，其实对于提升 没有什么意义，所以 ⽔平拆分最好分库 。  :分表仅仅是解决了单⼀表数据MySQL 并发能⼒⽔平拆分能够⽀持⾮常⼤的数据量存储，应⽤端改造也少，但 分⽚事务难以解决 ，跨界点 Join 性能较差，逻辑复杂。⽔平分表： 表很⼤，分割后可以降低在查询时需要读的数据和索引的⻚数，同时也降低了索引的层 数，提⾼查询次数。
适⽤场景 表中的数据本身就有独⽴性，例如表中分表记录各个地区的数据或者不同时期的数据，特别是有些数据常⽤，有些不常⽤。需要把数据存放在多个介质上。⽔平切分的缺点给应⽤增加复杂度，通常查询时需要多个表名，查询所有数据都需 UNION 操作。 - 在许多数据库应⽤中，这
种复杂度会超过它带来的优点，查询时会增加读⼀个索引层的磁盘次数。 数据库分⽚的两种常⻅⽅案：客户端代理：分⽚逻辑在应⽤端，封装在 jar 包中，通过修改或者封装 JDBC 层来实现。当当⽹ 的 Sharding-JDBC 、阿⾥的 TDDL是两种⽐较常⽤的实现。中间件代理：在应⽤和数据中间加了⼀个代理层。分⽚逻辑统⼀维护在中间件服务中。** 我们现在谈的 Mycat**  、360 的 Atlas、⽹易的 DDB 等等都是这种架构的实现。分库分表后⾯临的问题事务⽀持 分库分表后，就成了分布式事务了。如果依赖数据库本身的分布式事务管理功能去执⾏事 务，将付出⾼昂的性能代价；  如果由应⽤程序去协助控制，形成程序逻辑上的事务，⼜会 造成编程⽅⾯的负担。跨库 join 只要是进⾏切分，跨节点 Join 的问题是不可避免的。但是良好的设计和切分却可以减少此 类情况的发⽣。解决这⼀问题的普遍做法是分两次查询实现。在第⼀次查询的结果集中找 出关联数据的 id,根据这些 id 发起第⼆次请求得到关联数据。 数据迁移，容量规划，扩容等问题来⾃淘宝综合业务平台团队，它利⽤对 2 的倍数取余具有向前兼容的特性（如对 4 取余得 1 的数对 2 取余也是 1）来分配数据，避免了⾏级别的数据迁移，但是依然需要进⾏表级 别的迁移，同时对扩容规模和分表数量都有限制。总得来说，这些⽅案都不是⼗分的理想，多多少少都存在⼀些缺点，这也从⼀个侧⾯反映出了 Sharding 扩容的难度。ID 问题 ⼀旦数据库被切分到多个物理结点上，我们将不能再依赖数据库⾃身的主键⽣成机制。⼀ ⽅⾯，某个分区数据库⾃⽣成的 ID ⽆法保证在全局上是唯⼀的；另⼀⽅⾯，应⽤程序在 插⼊数据之前需要先获得 ID,以便进⾏ SQL 路由、⼀些常⻅的主键⽣成策略UUID  使⽤ UUID 作主键是最简单的⽅案，但是缺点也是⾮常明显的。由于 UUID ⾮常的 ⻓，除占⽤⼤量存储空间外，最主要的问题是在索引上，在建⽴索引和基于索引进⾏查询 时都存在性能问题。 Twitter 的分布式⾃增 ID 算法 Snowflake 在分布式系统中，需要⽣ 成全局 UID 的场合还是⽐较多的，twitter 的 snowflake 解决了这种需求，实现也还是很 简单的，除去配置信息，核⼼代码就是毫秒级时间 41 位  机器 ID 10 位  毫秒内序列 12 位。 跨分⽚的排序分⻚问题⼀般来讲，分⻚时需要按照指定字段进⾏排序。当排序字段就是分⽚字段的时候，我们通 过分⽚规则可以⽐较容易定位到指定的分⽚，⽽当排序字段⾮分⽚字段的时候，情况就会 变得⽐较复杂了。为了最终结果的准确性，我们需要在不同的分⽚节点中将数据进⾏排序 并返回，并将不同分⽚返回的结果集进⾏汇总和再次排序，最后再返回给⽤户。如下图所 示： 
B+ Tree 索引和 Hash 索引区别？ hash 索引适合等值查询，但是⽆法进⾏范围查询。hash 索引没办法利⽤索引完成排序。hash 索引不⽀持多列联合索引的最左匹配规则。如果有⼤量重复健值得情况下，hash 索引的效率会很低，因为哈希碰撞问题。数据库索引的原理，为什么要⽤ B+树，为什么不⽤⼆叉树？ 可以从⼏个维度去看这个问题，查询是否够快，效率是否稳定，存储数据多少，以及查找 磁盘次数，为什么不是⼆叉树，为什么不是平衡⼆叉树，为什么不是 B树，⽽偏偏是 B+树呢？ 为什么不是⼀般⼆叉树？ 如果⼆叉树特殊化为⼀个链表，相当于全表扫描。平衡⼆叉树相⽐于⼆叉查找树来说，查 找效率更稳定，总体的查找速度也更快。为什么不是平衡⼆叉树呢？ 我们知道，在内存⽐在磁盘的数据，查询效率快得多。如果树这种数据结构作为索引，那 我们每查找⼀次数据就需要从磁盘中读取⼀个节点，也就是我们说的⼀个磁盘块，但是平 衡⼆叉树可是每个节点只存储⼀个键值和数据的，如果是 B树，可以存储更多的节点数 据，树的⾼度也会降低，因此读取磁盘的次数就降下来啦，查询效率就快啦。 那为什么不是 B 树⽽是 B+树呢？ 1）B+树⾮叶⼦节点上是不存储数据的，仅存储键值，⽽ B树节点中不仅存储键值，也会 存储数据。innodb 中⻚的默认⼤⼩是 16KB，如果不存储数据，那么就会存储更多的键 值，相应的树的阶数（节点的⼦节点树）就会更⼤，树就会更矮更胖，如此⼀来我们查找 数据进⾏磁盘的 IO 次数有会再次减少，数据查询的效率也会更快。 2）B+树索引的所有数据均存储在叶⼦节点，⽽且数据是按照顺序排列的，链表连着的。 那么 B+树使得范围查找，排序查找，分组查找以及去重查找变得异常简单。  
   据库三⼤范式是什么 第⼀范式：每个列都不可以再拆分。第⼆范式：在第⼀范式的基础上，⾮主键列完全依赖于主键，⽽不能是依赖于主键的⼀部分。第三范式：在第⼆范式的基础上，⾮主键列只依赖于主键，不依赖于其他⾮主键。在设计数据库结构的时候，要尽量遵守三范式，如果不遵守，必须有⾜够的理由。⽐如性能。事实上我们经常会为了性能⽽妥协数据库的设计。MySQL 有关权限的表都有哪⼏个？ MySQL服务器通过权限表来控制⽤户对数据库的访问，权限表存放在 mysql 数据库⾥，由 mysql_install_db 脚本初始化。这些权限表分别 user，db， table_priv，columns_priv 和 host。下⾯分别介绍⼀下这些表的结构和内容：user 权限表：记录允许连接到服务器的⽤户帐号信息，⾥⾯的权限是全局级的。db 权限表：记录各个帐号在各个数据库上的操作权限。table_priv 权限表：记录数据表级的操作权限。columns_priv 权限表：记录数据列级的操作权限。host 权限表：配合 db 权限表对给定主机上数据库级操作权限作更细致的控制。这个权限表不受 GRANT和 REVOKE语句的影响。MySQL 的 Binlog 有有⼏种录⼊格式？分别有什么区别？ 有三种格式，statement，row和 mixed。statement 模式下，每⼀条会修改数据的 sql 都会记录在 binlog 中。不需要记录每⼀⾏的变化，减少了 binlog ⽇志量，节约了 IO，提⾼性能。由于 sql 的执⾏是有上下⽂的，因此在保存的时候需要保存相关的信息，同时还有⼀些使⽤了函数之类的语句⽆法被记录复制。row级别下，不记录 sql 语句上下⽂相关信息，仅保存哪条记录被修改。记录单元为每⼀⾏的改动，基本是可以全部记下来但是由于很多操作，会导致⼤量⾏的改动(⽐如 alter table)，因此这种模式的⽂件保存的信息太多，⽇志量太⼤。mixed，⼀种折中的⽅案，普通操作使⽤ statement 记录，当⽆法使⽤ statement 的时候使⽤ row。MySQL 存储引擎 MyISAM 与 InnoDB 区别 锁粒度⽅⾯：由于锁粒度不同，InnoDB⽐ MyISAM⽀持更⾼的并发;InnoDB 的锁粒度为⾏锁、MyISAM的锁粒度为表锁、⾏锁需要对每⼀⾏进⾏加锁，所以锁的开销更⼤，但是能解决脏读和不可重复读的问题，相对来说也更容易发⽣死锁可恢复性上：由于 InnoDB是有事务⽇志的，所以在产⽣由于数据库崩溃等条件后，可以根据⽇志⽂件进⾏恢复。⽽ MyISAM 则没有事务⽇志。查询性能上:MylSAM要优于 InnoDB因为 InnoDB在查询过程中，是需要维护数据缓存，⽽且查询过程是先定位到⾏所在的数据块，然后在从数据块中定位到要查找的⾏;⽽ MyISAM 可以直接定位到数据所在的内存地
址，可以直接找到数据。表结构⽂件上:MyISAM的表结构⽂件包括:frm(表结构定义),.MYI(索引),.MYD(数据);⽽ InnoDB的表数据⽂件为:ibd 和 frm(表结构定义)。MyISAM 索引与 InnoDB 索引的区别？ InnoDB索引是聚簇索引，MyISAM索引是⾮聚簇索引。InnoDB的主键索引的叶⼦节点存储着⾏数据，因此主键索引⾮常⾼效。MyISAM索引的叶⼦节点存储的是⾏数据地址，需要再寻址⼀次才能得到数据。InnoDB⾮主键索引的叶⼦节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会⾮常⾼效。什么是索引？ 索引是⼀种特殊的⽂件(InnoDB数据表上的索引是表空间的⼀个组成部分)，它们包含着对数据表⾥所有记录的引⽤指针。索引是⼀种数据结构。数据库索引，是数据库管理系统中⼀个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使⽤ B树及其变种 B+树。更通俗的说，索引就相当于⽬录。为了⽅便查找书中的内容，通过对内容建⽴索引形成⽬录。索引是⼀个⽂件，它是要占据物理空间的。索引有哪些优缺点？ 索引的优点可以⼤⼤加快数据的检索速度，这也是创建索引的最主要的原因。通过使⽤索引，可以在查询的过程中，使⽤优化隐藏器，提⾼系统的性能。索引的缺点时间⽅⾯：创建索引和维护索引要耗费时间，具体地，当对表中的数据进⾏增加、删除和修改的时候，索引也要动态的维护，会降低增/改/删的执⾏效率；空间⽅⾯：索引需要占物理空间。索引有哪⼏种类型？ 主键索引: 数据列不允许重复，不允许为 NULL，⼀个表只能有⼀个主键。唯⼀索引: 数据列不允许重复，允许为 NULL值，⼀个表允许多个列创建唯⼀索引。可以通过 ALTER TABLE table_name ADD UNIQUE (column); 创建唯⼀索引。可以通过 ALTER TABLE table_name ADD UNIQUE (column1,column2); 创建唯⼀组合索引。普通索引: 基本的索引类型，没有唯⼀性的限制，允许为 NULL值。可以通过 ALTER TABLE table_name ADD INDEX index_name (column);创建普通索引
可以通过 ALTER TABLE table_name ADD INDEX index_name(column1, column2, column3);创建组合索引。全⽂索引：是⽬前搜索引擎使⽤的⼀种关键技术。可以通过 ALTER TABLE table_name ADD FULLTEXT (column);创建全⽂索引。MySQL 中有哪⼏种锁？ 表级锁：开销⼩，加锁快；不会出现死锁；锁定粒度⼤，发⽣锁冲突的概率最⾼，并发度最低。⾏级锁：开销⼤，加锁慢；会出现死锁；锁定粒度最⼩，发⽣锁冲突的概率最低，并发度也最⾼。⻚⾯锁：开销和加锁时间界于表锁和⾏锁之间；会出现死锁；锁定粒度界于表锁和⾏锁之间，并发度⼀般。MySQL 中 InnoDB ⽀持的四种事务隔离级别名称，以及逐级之间的区别？ SQL标准定义的四个隔离级别为：read uncommited：读到未提交数据read committed：脏读，不可重复读repeatable read：可重读serializable：串⾏事物char 和 varchar 的区别？ char 和 varchar 类型在存储和检索⽅⾯有所不同char 列⻓度固定为创建表时声明的⻓度，⻓度值范围是1 到255 当 char 值被存储时，它们被⽤空格填充到特定⻓度，检索 char 值时需删除尾随空格。主键和候选键有什么区别？ 表格的每⼀⾏都由主键唯⼀标识,⼀个表只有⼀个主键。主键也是候选键。按照惯例，候选键可以被指定为主键，并且可以⽤于任何外键引⽤。如何在 Unix 和 MySQL 时间戳之间进⾏转换？ UNIX_TIMESTAMP是从 Mysql时间戳转换为 Unix 时间戳的命令 FROM_UNIXTIME 是从 Unix 时间戳转换为 Mysql时间戳的命令。MyISAM 表类型将在哪⾥存储，并且还提供其存储格式？ 每个 MyISAM 表格以三种格式存储在磁盘上：“.frm”⽂件存储表定义数据⽂件具有“.MYD”（MYData）扩展名索引⽂件具有“.MYI”（MYIndex）扩展名
MySQL ⾥记录货币⽤什么字段类型好 NUMERIC和 DECIMAL类型被 Mysql实现为同样的类型，这在 SQL92标准允许。他们被⽤于保存值，该值的准确精度是极其重要的值，例如与⾦钱有关的数据。当声明⼀个类是这些类型之⼀时，精度和规模的能被(并且通常是)指定。例如：salary DECIMAL(9,2)在这个例⼦中，9(precision)代表将被⽤于存储值的总的⼩数位数，⽽2(scale)代表将被⽤于存储⼩数点后的位数。因此，在这种情况下，能被存储在 salary 列中的值的范围是从-9999999.99 到9999999.99。创建索引时需要注意什么？ ⾮空字段：应该指定列为 NOT NULL，除⾮你想存储 NULL。在 mysql 中，含有空值的列很难进⾏查询优化，因为它们使得索引、索引的统计信息以及⽐较运算更加复杂。应该⽤0、⼀个特殊的值或者⼀个空串代替空值；取值离散⼤的字段：（变量各个取值之间的差异程度）的列放到联合索引的前⾯，可以通过 count()函数查看字段的差异值，返回值越⼤说明字段的唯⼀值越多字段的离散程度⾼；索引字段越⼩越好：数据库的数据存储以⻚为单位⼀⻚存储的数据越多⼀次 IO操作获取的数据越⼤效率越⾼。使⽤索引查询⼀定能提⾼查询的性能吗？为什么 通常，通过索引查询数据⽐全表扫描要快。但是我们也必须注意到它的代价。索引需要空间来存储，也需要定期维护，每当有记录在表中增减或索引列被修改时，索引本身也会被修改。这意味着每条记录的 INSERT，DELETE，UPDATE 将为此多付出4，5 次的磁盘 I/O。因为索引需要额外的存储空间和处理，那些不必要的索引反⽽会使查询反应时间变慢。使⽤索引查询不⼀定能提⾼查询性能，索引范围查询(INDEX RANGE SCAN)适⽤于两种情况: 基于⼀个范围的检索，⼀般查询返回结果集⼩于表中记录数的30%基于⾮唯⼀性索引的检索百万级别或以上的数据如何删除 关于索引：由于索引需要额外的维护成本，因为索引⽂件是单独存在的⽂件,所以当我们对数据的增加,修改,删除,都会产⽣额外的对索引⽂件的操作,这些操作需要消耗额外的 IO,会降低增/改/删的执⾏效率。所以，在我们删除数据库百万级别数据的时候，查询 MySQL官⽅⼿册得知删除数据的速度和创建的索引数量是成正⽐的。所以我们想要删除百万数据的时候可以先删除索引（此时⼤概耗时三分多钟）然后删除其中⽆⽤数据（此过程需要不到两分钟）删除完成后重新创建索引(此时数据较少了)创建索引也⾮常快，约⼗分钟左右。与之前的直接删除绝对是要快速很多，更别说万⼀删除中断,⼀切删除会回滚。那更是坑了。什么是最左前缀原则？什么是最左匹配原则 顾名思义，就是最左优先，在创建多列索引时，要根据业务需求，where ⼦句中使⽤最频繁的⼀列放在最左边。最左前缀匹配原则，⾮常重要的原则，mysql 会⼀直向右匹配直到遇到范围查询(>、<、between、like)就停⽌匹配，⽐如 a = 1 and b = 2 and c > 3 and d = 4 如果建⽴(a,b,c,d)顺序的索引，d 是⽤不到索引的，如果建⽴(a,b,d,c)的索引则都可以⽤到，a,b,d 的顺序可以任意调整。=和 in 可以乱序，⽐如 a = 1 and b = 2 and c = 3 建⽴(a,b,c)索引可以任意顺序，mysql 的查询优化器会帮你优化成索引可以识别的形式。
什么是聚簇索引？何时使⽤聚簇索引与⾮聚簇索引 聚簇索引：将数据存储与索引放到了⼀块，找到索引也就找到了数据⾮聚簇索引：将数据存储于索引分开结构，索引结构的叶⼦节点指向了数据的对应⾏，myisam通过 key_buffer 把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在 key buffer 命中时，速度慢的原因。MySQL 连接器 ⾸先需要在 MySQL客户端登陆才能使⽤，所以需要个连接器来连接⽤户和 MySQL数据库，我们⼀般是使⽤来进⾏ MySQL登陆，和服务端建⽴连接。在完成 TCP握⼿后，连接器会根据你输⼊的⽤户名和密码验证你的登录身份。如果⽤户名或者密码错误，MySQL就会提示 Access denied for user，来结束执⾏。如果登录成功后，MySQL会根据权限表中的记录来判定你的权限。MySQL 查询缓存 连接完成后，你就可以执⾏ SQL语句了，这⾏逻辑就会来到第⼆步:查询缓存。 MySQL在得到⼀个执⾏请求后，会⾸先去查询缓存中查找，是否执⾏过这条 SQL语句，之前执⾏过的语句以及结果会以 key-value 对的形式，被直接放在内存中。key 是查询语句，value 是查询的结果。如果通过 key 能够查找到这条 SQL语句，就直接妾返回 SQL的执⾏结果。如果语句不在查询缓存中，就会继续后⾯的执⾏阶段。执⾏完成后，执⾏结果就会被放⼊查询缓存中。可以看到，如果查询命中缓存，MySQL不需要执⾏后⾯的复杂操作，就可以直接返回结果，效率会很⾼。MySQL 分析器 如果没有命中查询，就开始执⾏真正的 SQL语句。⾸先，MySQL会根据你写的 SQL语句进⾏解析，分析器会先做词法分析，你写的 SQL就是由多个字符串和空格组成的⼀条 SQL语句，MySQL需要识别出⾥⾯的字符串是什么，代表什么。然后进⾏语法分析，根据词法分析的结果，语法分析器会根据语法规则，判断你输⼊的这个 SQL语句是否满⾜ MySQL语法。如果 SQL语句不正确，就会提示 You have an error in your SQL syntax。MySQL 优化器 经过分析器的词法分析和语法分析后，你这条 SQL就合法了，MySQL就知道你要做什么了。但是在执⾏前，还需要进⾏优化器的处理，优化器会判断你使⽤了哪种索引，使⽤了何种连接，优化器的作⽤就是确定效率最⾼的执⾏⽅案。mysql-u ⽤户名-p 密码
MySQL 执⾏器 MySQL通过分析器知道了你的 SQL语句是否合法，你想要做什么操作，通过优化器知道了该怎么做效率最⾼，然后就进⼊了执⾏阶段，开始执⾏这条 SQL语句在执⾏阶段，MySQL⾸先会判断你有没有执⾏这条语句的权限，没有权限的话，就会返回没有权限的错误。如果有权限，就打开表继续执⾏。打开表的时候，执⾏器就会根据表的引擎定义，去使⽤这个引擎提供的接⼝。对于有索引的表，执⾏的逻辑也差不多。什么是临时表，何时删除临时表？ 什么是临时表?MySQL在执⾏ SQL语句的过程中通常会临时创建⼀些存储中间结果集的表，临时表只对当前连接可⻅，在连接关闭时，临时表会被删除并释放所有表空间。临时表分为两种:⼀种是内存临时表，⼀种是磁盘临时表，什么区别呢?内存临时表使⽤的是 MEMORY存储引擎，⽽临时表采⽤的是 MylSAM 存储引擎。MySQL会在下⾯这⼏种情况产⽣临时表。使⽤ UNION查询:UNION有两种，⼀种是 UNION，⼀种是 UNION ALL，它们都⽤于联合查询;区别是使⽤ UNION会去掉两个表中的重复数据，相当于对结果集做了⼀下去重(distinct)。使⽤ UNIONALL，则不会排重，返回所有的⾏。使⽤ UNION查询会产⽣临时表。使⽤ TEMPTABLE算法或者是 UNION查询中的视图。TEMPTABLE算法是⼀种创建临时表的算法，它是将结果放置到临时表中，意味这要 MySQL要先创建好⼀个临时表，然后将结果放到临时表中去，然后再使⽤这个临时表进⾏相应的查询。ORDER BY和 GROUPBY的⼦句不⼀样时也会产⽣临时表。DISTINCT 查询并且加上 ORDER BY时; SQL中⽤到 SQL_SMALL_RESULT选项时;如果查询结果⽐较⼩的时候，可以加上 SQL SMALL RESULT来优化，产⽣临时表FROM中的⼦查询; EXPLAIN 查看执⾏计划结果的 Extra 列中，如果使⽤ Using Temporary 就表示会⽤到临时表。谈谈 SQL 优化的经验 查询语句⽆论是使⽤哪种判断条件等于、⼩于、⼤于，WHERE 左侧的条件查询字段不要使⽤函数或者表达式使⽤ EXPLAIN 命令优化你的 SELECT 查询，对于复杂、效率低的 sql 语句，我们通常是使⽤ explainsql 来分析这条 sql 语句，这样⽅便我们分析，进⾏优化。当你的 SELECT 查询语句只需要使⽤⼀条记录时，要使⽤ LIMIT 1。不要直接使⽤ SELECT*，⽽应该使⽤具体需要查询的表字段，因为使⽤ EXPLAIN 进⾏分析时，SELECT"使⽤的是全表扫描，也就是 type =all 。为每⼀张表设置⼀个 ID属性。避免在 MHERE 字句中对字段进⾏ NULL 判断避免在 WHERE中使⽤!或>操作符使⽤ BETWEEN AND 替代 IN 为搜索字段创建索引选择正确的存储引擎，InnoDB、MyISAM、MEMORY等使⽤ LIKE%abc%不会⾛索引，⽽使⽤ LIKE abc%会⾛索引。对于枚举类型的字段(即有固定罗列值的字段)，建议使⽤ ENUM ⽽不是 VARCHAR，如性别、星期、类型、类别等。拆分⼤的 DELETE或 INSERT 语句选择合适的字段类型，选择标准是尽可能⼩、尽可能定⻓、尽可能使⽤整数。字段设计尽可能使⽤ NOT NULL 
进⾏⽔平切割或者垂直分割什么叫外链接？ 外连接分为三种，分别是是左外连接(LEFT OUTER J0IN 或 LEFT JOIN 右外连接(RIGHT OUTER JOIN 或 RIC GHT JOIN、全外连接(FULL OUTER JOIN 或 FULLJOIN)。左外连接:⼜称为左连接，这种连接⽅式会显示左表不符合条件的数据⾏，右边不符合条件的数据⾏直接显示 NULL。右外连接:也被称为右连接，他与左连接相对，这种连接⽅式会显示右表不符合条件的数据⾏，左表不符合条件的数据⾏直接显示 NULL。什么叫内链接？ 结合两个表中相同的字段，返回关联字段相符的记录就是内链接。
使⽤ union 和 union all 时需要注意些什么？ 通过 union 连接的 SQL分别单独取出的列数必须相同。使⽤ union 时，多个相等的⾏将会被合并，由于合升⽐较耗时，⼀般不直接使⽤ union 进⾏合并，⽽是通常采⽤ union all 进⾏合并。MyISAM 存储引擎的特点 在5.1 版本之前，MyISAM是 MySQL的默认存储引擎，MylSAM并发性⽐较差，使⽤的场景⽐较少主要特点是: 不⽀持事务操作，ACID的特性也就不存在了，这⼀设计是为了性能和效率考虑的，不⽀持外键操作，如果强⾏增加外键，MySQL不会报错，只不过外键不起作⽤。MyISAM 默认的锁粒度是表级锁，所以并发性能⽐较差，加锁⽐较快，锁冲突⽐较少，不太容易发⽣死锁的情况。MyISAM会在磁盘上存储三个⽂件，⽂件名和表名相同，扩展名分别是 frm(存储表定义)、MYD(MYData，存储数据)、MYI(MyIndex，存储索引)。这⾥需要特别注意的是 MyISAM只缓存索引⽂件，并不缓存数据⽂件。MyISAM⽀持的索引类型有全局索引(Full-Text)、B-Tree 索引、R-Tree 索引Full-Text 索引:它的出现是为了解决针对⽂本的模糊查询效率较低的问题。B-Tree 索引:所有的索引节点都按照平衡树的数据结构来存储，所有的索引数据节点都在叶节点
R-Tree 索引:它的存储⽅式和 B-Tree 索引有⼀些区别，主要设计⽤于存储空间和多维数据的字段做索引⽬前的 MySQL版本仅⽀持 geometry 类型的字段作索引，相对于 BTREE,RTREE的优势在于范围查找。数据库所在主机如果宕机，MyISAM的数据⽂件容易损坏，⽽且难以恢复。增删改查性能⽅⾯:SELECT性能较⾼，适⽤于查询较多的情况InnoDB 存储引擎的特点 ⾃从 MySQL5.1之后，默认的存储引擎变成了 InnoDB存储引擎，相对于MylSAM，InnoDB 存储引擎有了较⼤的改变，它的主要特点是⽀持事务操作，具有事务 ACID隔离特性，默认的隔离级别是可重复读(repetable-read)、通过 MVCC(并发版本控制)来实现的。能够解决脏读和不可重复读的问题。 InnoDB ⽀持外键操作。InnoDB 默认的锁粒度⾏级锁，并发性能⽐较好，会发⽣死锁的情况。和 MyISAM⼀样的是，InnoDB存储引擎也有 frm ⽂件存储表结构定义，但是不同的是，InnoDB的表数据与索引数据是存储在⼀起的，都位于 B+数的叶⼦节点上，⽽ MylSAM的表数据和索引数据是分开的。InnoDB有安全的⽇志⽂件，这个⽇志⽂件⽤于恢复因数据库崩溃或其他情况导致的数据丢失问题，保证数据的⼀致性。InnoDB和 MylSAM⽀持的索引类型相同，但具体实现因为⽂件结构的不同有很⼤差异。增删改查性能⽅⾯，果执⾏⼤量的增删改操作，推荐使⽤ InnoDB存储引擎，它在删除操作时是对⾏删除，不会重建表。Mysql⾼可⽤⽅案有哪些? Mysql⾼可⽤⽅案包括:1. 主从复制⽅案这是MySQL⾃身提供的⼀种⾼可⽤解决⽅案，数据同步⽅法采⽤的是MySQL replication技术。MySQL replication就是从服务器到主服务器拉取⼆进制⽇志⽂件，然后再将⽇志⽂件解析成相应的SQL在从服务器上重新执⾏⼀遍主服务器的操作，通过这种⽅式保证数据的⼀致性。为了达到更⾼的可⽤性，在实际的应⽤环境中，⼀般都是采⽤MySQL replication技术配合⾼可⽤集群软件keepalived来实现⾃动failover，这种⽅式可以实现95.000%的SLA。1. MMM/MHA⾼可⽤⽅案MMM提供了MySQL主主复制配置的监控、故障转移和管理的⼀套可伸缩的脚本套件。在MMM⾼可⽤⽅案中，典型的应⽤是双主多从架构，通过MySQL replication技术可以实现两个服务器互为主从，且在任何时候只有⼀个节点可以被写⼊，避免了多点写⼊的数据冲突。同时，当可写的主节点故障时，MMM套件可以⽴刻监控到，然后将服务⾃动切换到另⼀个主节点，继续提供服务，从⽽实现MySQL的⾼可⽤。1. Heartbeat/SAN⾼可⽤⽅案在这个⽅案中，处理failover的⽅式是⾼可⽤集群软件Heartbeat，它监控和管理各个节点间连接的⽹络，并监控集群服务，当节点出现故障或者服务不可⽤时，⾃动在其他节点启动集群服务。在数据共享⽅⾯，通过SAN（Storage Area Network）存储来共享数据，这种⽅案可以实现99.990%的SLA。1. Heartbeat/DRBD⾼可⽤⽅案这个⽅案处理failover的⽅式上依旧采⽤Heartbeat，不同的是，在数据共享⽅⾯，采⽤了基于块级别的数据同步软件DRBD来实现。DRBD是⼀个⽤软件实现的、⽆共享的、服务器之间镜像块设备内容的存储复制解决⽅案。和SAN⽹络不同，它并不共享存储，⽽是通过服务器之间的⽹络复制数据。
1. NDB CLUSTER⾼可⽤⽅案国内⽤NDB集群的公司⾮常少，貌似有些银⾏有⽤。NDB集群不需要依赖第三⽅组件，全部都使⽤官⽅组件，能保证数据的⼀致性，某个数据节点挂掉，其他数据节点依然可以提供服务，管理节点需要做冗余以防挂掉。缺点是：管理和配置都很复杂，⽽且某些SQL语句例如join语句需要避免。 Linux 什么是 Linux Linux 是⼀套免费使⽤和⾃由传播的类 Unix 操作系统，是⼀个基于 POSIX和 Unix 的多⽤户、多任务、⽀持多线程和多 CPU的操作系统。它能运⾏主要的 Unix ⼯具软件、应⽤程序和⽹络协议。它⽀持32 位和64 位硬件。Linux 继承了 Unix 以⽹络为核⼼的设计思想，是⼀个性能稳定的多⽤户⽹络操作系统。Unix 和 Linux 有什么区别？ Linux 和 Unix 都是功能强⼤的操作系统，都是应⽤⼴泛的服务器操作系统，有很多相似之处，甚⾄有⼀部分⼈错误地认为 Unix 和 Linux 操作系统是⼀样的，然⽽，事实并⾮如此，以下是两者的区别。开源性：Linux 是⼀款开源操作系统，不需要付费，即可使⽤；Unix 是⼀款对源码实⾏知识产权保护的传统商业软件，使⽤需要付费授权使⽤。跨平台性：Linux 操作系统具有良好的跨平台性能，可运⾏在多种硬件平台上；Unix 操作系统跨平台性能较弱，⼤多需与硬件配套使⽤。可视化界⾯：Linux 除了进⾏命令⾏操作，还有窗体管理系统；Unix 只是命令⾏下的系统。硬件环境：Linux 操作系统对硬件的要求较低，安装⽅法更易掌握；Unix 对硬件要求⽐较苛刻，按照难度较⼤。⽤户群体：Linux 的⽤户群体很⼴泛，个⼈和企业均可使⽤；Unix 的⽤户群体⽐较窄，多是安全性要求⾼的⼤型企业使⽤，如银⾏、电信部⻔等，或者 Unix 硬件⼚商使⽤，如 Sun等。相⽐于 Unix 操作系统，Linux 操作系统更受⼴⼤计算机爱好者的喜爱，主要原因是 Linux 操作系统具有 Unix 操作系统的全部功能，并且能够在普通 PC计算机上实现全部的 Unix 特性，开源免费的特性，更容易普及使⽤！什么是 Linux 内核？ Linux 系统的核⼼是内核。内核控制着计算机系统上的所有硬件和软件，在必要时分配硬件，并根据需要执⾏软件。系统内存管理应⽤程序管理硬件设备管理⽂件系统管理Linux 的基本组件是什么？ 就像任何其他典型的操作系统⼀样，Linux 拥有所有这些组件：内核，shell 和 GUI，系统实⽤程序和应⽤程序。Linux ⽐其他操作系统更具优势的是每个⽅⾯都附带其他功能，所有代码都可以免费下载。
Linux 的体系结构 从⼤的⽅⾯讲，Linux 体系结构可以分为两块：⽤户空间(User Space)：⽤户空间⼜包括⽤户的应⽤程序(User Applications)、C 库(C Library)。内核空间(Kernel Space)：内核空间⼜包括系统调⽤接⼝(System Call Interface)、内核(Kernel)、平台架构相关的代码(Architecture - Dependent  Kernel Code)。为什么 Linux 体系结构要分为⽤户空间和内核空间的原因？现代 CPU 实现了不同的⼯作模式，不同模式下 CPU 可以执⾏的指令和访问的寄存器不同。Linux 从 CPU 的⻆度出发，为了保护内核的安全，把系统分成了两部分。⽤户空间和内核空间是程序执⾏的两种不同的状态，我们可以通过两种⽅式完成⽤户空间到内核空间的转移：1）系统调⽤；2）硬件中断。BASH 和 DOS 之间的基本区别是什么？ BASH和 DOS控制台之间的主要区别在于3 个⽅⾯：BASH命令区分⼤⼩写，⽽ DOS命令则不区分; 在 BASH下，/ character 是⽬录分隔符，\作为转义字符。在 DOS下，/⽤作命令参数分隔符，\是⽬录分隔符DOS遵循命名⽂件中的约定，即8 个字符的⽂件名后跟⼀个点，扩展名为3 个字符。BASH没有遵循这样的惯例。Linux 开机启动过程？ 了解即可主机加电⾃检，加载 BIOS 硬件信息读取 MBR 的引导⽂件(GRUB、LILO)引导 Linux 内核运⾏第⼀个进程 init (进程号永远为1 )进⼊相应的运⾏级别运⾏终端，输⼊⽤户名和密码Linux 系统缺省的运⾏级别？ 关机单机⽤户模式字符界⾯的多⽤户模式(不⽀持⽹络)字符界⾯的多⽤户模式未分配使⽤图形界⾯的多⽤户模式重启Linux 使⽤的进程间通信⽅式？ 管道(pipe)、流管道(s_pipe)、有名管道(FIFO)信号(signal)消息队列共享内存
信号量套接字(socket)Linux 有哪些系统⽇志⽂件？ ⽐较重要的是/var/log/messages ⽇志⽂件。该⽇志⽂件是许多进程⽇志⽂件的汇总，从该⽂件可以看出任何⼊侵企图或成功的⼊侵。另外，如果胖友的系统⾥有
ELK ⽇志集中收集，它也会被收集进去。Linux 系统安装多个桌⾯环境有帮助吗？ 通常，⼀个桌⾯环境，如 KDE或 Gnome，⾜以在没有问题的情况下运⾏。尽管系统允许从⼀个环境切换到另⼀个环境，但这对⽤户来说都是优先考虑的问题。有些程序在⼀个环境中⼯作⽽在另⼀个环境中⽆法⼯作，因此它也可以被视为选择使⽤哪个环境的⼀个因素。什么是交换空间？ 交换空间是 Linux 使⽤的⼀定空间，⽤于临时保存⼀些并发运⾏的程序。当 RAM没有⾜够的内存来容纳正在执⾏的所有程序时，就会发⽣这种情况。什么是 Root 帐户 root 帐户就像⼀个系统管理员帐户，允许你完全控制系统。你可以在此处创建和维护⽤户帐户，为每个帐户分配不同的权限。每次安装 Linux 时都是默认帐户。什么是 LILO？ LILO是 Linux 的引导加载程序。它主要⽤于将 Linux 操作系统加载到主内存中，以便它可以开始运⾏。什么是 BASH？ BASH是 Bourne Again SHell 的缩写。它由 Steve Bourne 编写，作为原始 Bourne Shell（由/ bin / sh 表示）的替代品。它结合了原始版本的 Bourne Shell 的所有功能，以及其他功能，使其更容易使⽤。从那以后，它已被改编为运⾏ Linux 的⼤多数系统的默认 shell。什么是 CLI？ 命令⾏界⾯（英语：command-line interface，缩写]：CLI）是在图形⽤户界⾯得到普及之前使⽤最为⼴泛的⽤户界⾯，它通常不⽀持⿏标，⽤户通过键盘输⼊指令，计算机接收到指令后，予以执⾏。也有⼈称之为字符⽤户界⾯CUI）。
通常认为，命令⾏界⾯（CLI）没有图形⽤户界⾯（GUI）那么⽅便⽤户操作。因为，命令⾏界⾯的软件通常需要⽤户记忆操作的命令，但是，由于其本身的特点，命令⾏界⾯要较图形⽤户界⾯节约计算机系统的资源。在熟记命令的前提下，使⽤命令⾏界⾯往往要较使⽤图形⽤户界⾯的操作速度要快。所以，图形⽤户界⾯的操作系统中，都保留着可选的命令⾏界⾯。什么是 GUI？ 图形⽤户界⾯（Graphical User Interface，简称 GUI，⼜称图形⽤户接⼝）是指采⽤图形⽅式显示的计算机操作⽤户界⾯。图形⽤户界⾯是⼀种⼈与计算机通信的界⾯显示格式，允许⽤户使⽤⿏标等输⼊设备操纵屏幕上的图标或菜单选项，以选择命令、调⽤⽂件、启动程序或执⾏其它⼀些⽇常任务。与通过键盘输⼊⽂本或字符命令来完成例⾏任务的字符界⾯相⽐，图形⽤户界⾯有许多优点。开源的优势是什么？ 开源允许你将软件（包括源代码）免费分发给任何感兴趣的⼈。然后，⼈们可以添加功能，甚⾄可以调试和更正源代码中的错误。它们甚⾄可以让它运⾏得更好，然后再次⾃由地重新分配这些增强的源代码。这最终使社区中的每个⼈受益。GNU 项⽬的重要性是什么？ 这种所谓的⾃由软件运动具有多种优势，例如可以⾃由地运⾏程序以及根据你的需要⾃由学习和修改程序。它还允许你将软件副本重新分发给其他⼈，以及⾃由改进软件并将其发布给公众。 绝对路径⽤什么符号表示？当前⽬录、上层⽬录⽤什么表示？主⽬录⽤什么表示? 切换⽬录⽤什么命令？ 绝对路径：如/etc/init.d当前⽬录和上层⽬录：./ ../主⽬录：~/切换⽬录：cd怎么查看当前进程？怎么执⾏退出？怎么查看当前路径？ 查看当前进程：ps执⾏退出：exit查看当前路径：pwd怎么清屏？怎么退出当前命令？怎么执⾏睡眠？怎么查看当前⽤户 id？查看指定帮助⽤什么命令？ 清屏：clear退出当前命令：ctrl+c 彻底退出执⾏睡眠 ：ctrl+z 挂起当前进程fg 恢复后台查看当前⽤户 id：”id“：查看显示⽬前登陆账户的 uid 和 gid 及所属分组及⽤户名查看指定帮助：如 man adduser 这个很全 ⽽且有例⼦；adduser --help 这个告诉你⼀些常⽤参数；info adduesr；
Ls 命令执⾏什么功能？可以带哪些参数，有什么区别？ ls 执⾏的功能：列出指定⽬录中的⽬录，以及⽂件哪些参数以及区别：a 所有⽂件l 详细信息，包括⼤⼩字节数，可读可写可执⾏的权限等建⽴软链接(快捷⽅式)，以及硬链接的命令。 软链接：ln -s slink source硬链接：ln link source⽬录创建⽤什么命令？创建⽂件⽤什么命令？复制⽂件⽤什么命令？ 创建⽬录：mkdir创建⽂件：典型的如 touch，vi 也可以创建⽂件，其实只要向⼀个不存在的⽂件输出，都会创建⽂件复制⽂件：cp 7. ⽂件权限修改⽤什么命令？格式是怎么样的？⽂件权限修改：chmod格式如下：$ chmod u+x file 给 file 的属主增加执⾏权限$ chmod 751 file 给 file 的属主分配读、写、执⾏(7)的权限，给 file 的所在组分配读、执⾏(5)的权限，给其他⽤户分配执⾏(1)的权限$ chmod u=rwx,g=rx,o=x file 上例的另⼀种形式$ chmod =r file 为所有⽤户分配读权限$ chmod 444 file 同上例$ chmod a-wx,a+r file同上例$ chmod -R u+r directory 递归地给 directory ⽬录下所有⽂件和⼦⽬录的属主分配读的权限查看⽂件内容有哪些命令可以使⽤？ vi ⽂件名 #编辑⽅式查看，可修改cat ⽂件名 #显示全部⽂件内容more ⽂件名 #分⻚显示⽂件内容less ⽂件名 #与 more 相似，更好的是可以往前翻⻚tail ⽂件名 #仅查看尾部，还可以指定⾏数head ⽂件名 #仅查看头部,还可以指定⾏数随意写⽂件命令？怎么向屏幕输出带空格的字符串，⽐如”hello world”? 写⽂件命令：vi向屏幕输出带空格的字符串:echo hello world 
终端是哪个⽂件夹下的哪个⽂件？⿊洞⽂件是哪个⽂件夹下的哪个命令？ 终端 /dev/tty⿊洞⽂件 /dev/null移动⽂件⽤哪个命令？改名⽤哪个命令？ mv mv复制⽂件⽤哪个命令？如果需要连同⽂件夹⼀块复制呢？如果需要有提示功能呢？ cp cp -r ？？？？删除⽂件⽤哪个命令？如果需要连⽬录及⽬录下⽂件⼀块删除呢？删除空⽂件夹⽤什么命令？ rm rm -r rmdirLinux 下命令有哪⼏种可使⽤的通配符？分别代表什么含义? “？”可替代单个字符。“*”可替代任意多个字符。⽅括号“[charset]”可替代 charset 集中的任何单个字符，如[a-z]，[abABC] ⽤什么命令对⼀个⽂件的内容进⾏统计？(⾏号、单词数、字节数) wc 命令 - c 统计字节数 - l 统计⾏数 - w 统计字数。Grep 命令有什么⽤？如何忽略⼤⼩写？如何查找不含该串的⾏? 是⼀种强⼤的⽂本搜索⼯具，它能使⽤正则表达式搜索⽂本，并把匹 配的⾏打印出来。grep [stringSTRING] filename grep [^string] filenameLinux 中进程有哪⼏种状态？在 ps 显示出来的信息中，分别⽤什么符号表示的？ （1）、不可中断状态：进程处于睡眠状态，但是此刻进程是不可中断的。不可中断， 指进程不响应异步信号。（2）、暂停状态/跟踪状态：向进程发送⼀个 SIGSTOP 信号，它就会因响应该信号 ⽽进⼊ TASK_STOPPED 状态;当进程正在被跟踪时，它处于 TASK_TRACED 这个特殊的状态。“正在被跟踪”指的是进程暂停下来，等待跟踪它的进程对它进⾏操作。（3）、就绪状态：在 run_queue 队列⾥的状态
（4）、运⾏状态：在 run_queue 队列⾥的状态（5）、可中断睡眠状态：处于这个状态的进程因为等待某某事件的发⽣（⽐如等待 socket 连接、等待信号量），⽽被挂起（6）、zombie 状态（僵⼫）：⽗亲没有通过 wait 系列的系统调⽤会顺便将⼦进程的⼫体（task_struct）也释放掉（7）、退出状态D 不可中断 Uninterruptible（usually IO）R 正在运⾏，或在队列中的进程S 处于休眠状态T 停⽌或被追踪Z 僵⼫进程W 进⼊内存交换（从内核 2.6 开始⽆效）X 死掉的进程怎么使⼀个命令在后台运⾏? ⼀般都是使⽤ & 在命令结尾来让程序⾃动运⾏。(命令后可以不追加空格)利⽤ ps 怎么显示所有的进程? 怎么利⽤ ps 查看指定进程的信息？ ps -ef (system v 输出)ps -aux bsd 格式输出ps -ef | grep pid哪个命令专⻔⽤来查看后台任务? job -l把后台任务调到前台执⾏使⽤什么命令?把停下的后台任务在后台执⾏起来⽤什么命令? 把后台任务调到前台执⾏ fg把停下的后台任务在后台执⾏起来 bg 终⽌进程⽤什么命令? 带什么参数? kill [-s <信息名称或编号>][程序] 或 kill [-l <信息编号>]kill-9 pid 
怎么查看系统⽀持的所有信号？ kill -l搜索⽂件⽤什么命令? 格式是怎么样的? find <指定⽬录> <指定条件> <指定动作>whereis 加参数与⽂件名locate 只加⽂件名find 直接搜索磁盘，较慢。find / -name "string*" 查看当前谁在使⽤该主机⽤什么命令? 查找⾃⼰所在的终端信息⽤什么命令? 查找⾃⼰所在的终端信息：who am i查看当前谁在使⽤该主机：who 使⽤什么命令查看⽤过的命令列表? history使⽤什么命令查看磁盘使⽤空间？空闲空间呢? df -hl⽂件系统 容量 已⽤ 可⽤ 已⽤% 挂载点Filesystem Size Used Avail Use% Mounted on /dev/hda2 45G 19G 24G 44% //dev/hda1 494M 19M 450M 4% /boot使⽤什么命令查看⽹络是否连通? netstat使⽤什么命令查看 ip 地址及接⼝信息？ ifconfig
查看各类环境变量⽤什么命令? 查看所有 env查看某个，如 home：env $HOME通过什么命令指定命令提示符? \u：显示当前⽤户账号\h：显示当前主机名\W：只显示当前路径最后⼀个⽬录\w：显示当前绝对路径（当前⽤户⽬录会以~代替）$PWD：显示当前全路径$：显示命令⾏’$'或者’#'符号#：下达的第⼏个命令\d：代表⽇期，格式为week day month date，例如："MonAug1"\t：显示时间为24⼩时格式，如：HH：MM：SS\T：显示时间为12⼩时格式\A：显示时间为24⼩时格式：HH：MM\v：BASH的版本信息 如export PS1=’[\u@\h\w#]$‘查找命令的可执⾏⽂件是去哪查找的? 怎么对其进⾏设置及添加? whereis [-bfmsu][-B <⽬录>...][-M <⽬录>...][-S <⽬录>...][⽂件...]补充说明：whereis 指令会在特定⽬录中查找符合条件的⽂件。这些⽂件的烈性应属于原始代码，⼆进制⽂件，或是帮助⽂件。-b 只查找⼆进制⽂件。-B<⽬录> 只在设置的⽬录下查找⼆进制⽂件。-f 不显示⽂件名前的路径名称。-m 只查找说明⽂件。-M<⽬录> 只在设置的⽬录下查找说明⽂件。-s 只查找原始代码⽂件。-S<⽬录> 只在设置的⽬录下查找原始代码⽂件。-u 查找不包含指定类型的⽂件。which 指令会在 PATH 变量指定的路径中，搜索某个系统命令的位置，并且返回第⼀个搜索结果。-n 指定⽂件名⻓度，指定的⻓度必须⼤于或等于所有⽂件中最⻓的⽂件名。-p 与-n 参数相同，但此处的包括了⽂件的路径。-w 指定输出时栏位的宽度。-V 显示版本信息通过什么命令查找执⾏命令? which 只能查可执⾏⽂件whereis 只能查⼆进制⽂件、说明⽂档，源⽂件等怎么对命令进⾏取别名？ alias la='ls -a'
du 和 df 的定义，以及区别？ du 显示⽬录或⽂件的⼤⼩df 显示每个<⽂件>所在的⽂件系统的信息，默认是显示所有⽂件系统。（⽂件系统分配其中的⼀些磁盘块⽤来记录它⾃身的⼀些数据，如 i 节点，磁盘分布图，间接块，超级块等。这些数据对⼤多数⽤户级的程序来说是不可⻅的，通常称为 Meta Data。） du 命令是⽤户级的程序，它不考虑 Meta Data，⽽ df 命令则查看⽂件系统的磁盘分配图并考虑 Meta Data。df 命令获得真正的⽂件系统数据，⽽ du 命令只查看⽂件系统的部分情况。awk 详解。 awk '{pattern + action}' {filenames}#cat /etc/passwd |awk -F ':' '{print $1"\t"$7}' //-F 的意思是以':'分隔 root /bin/bashdaemon /bin/sh 搜索/etc/passwd 有 root 关键字的所有⾏#awk -F: '/root/' /etc/passwd root
❌0:0:root:/root:/bin/bash当你需要给命令绑定⼀个宏或者按键的时候，应该怎么做呢？ 可以使⽤bind命令，bind可以很⽅便地在shell中实现宏或按键的绑定。在进⾏按键绑定的时候，我们需要先获取到绑定按键对应的字符序列。⽐如获取F12的字符序列获取⽅法如下：先按下Ctrl+V,然后按下F12 .我们就可以得到F12的字符序列 ^[[24~。接着使⽤bind进⾏绑定。[root@localhost ~]# bind ‘”\e[24~":"date"'注意：相同的按键在不同的终端或终端模拟器下可能会产⽣不同的字符序列。【附】也可以使⽤showkey -a命令查看按键对应的字符序列。 如果⼀个linux新⼿想要知道当前系统⽀持的所有命令的列表，他需要怎么做？ 使⽤命令compgen -c，可以打印出所有⽀持的命令列表。[root@localhost ~]$ compgen -cl.lllswhichifthenelseelifficase
esacforselectwhileuntildodone…如果你的助⼿想要打印出当前的⽬录栈，你会建议他怎么做？ 使⽤Linux 命令dirs可以将当前的⽬录栈打印出来。[root@localhost ~]# dirs/usr/share/X11【附】：⽬录栈通过pushd popd 来操作。 你的系统⽬前有许多正在运⾏的任务，在不重启机器的条件下，有什么⽅法可以把所有正在运⾏的进程移除呢？ 使⽤linux命令 ’disown -r ’可以将所有正在运⾏的进程移除。 bash shell 中的hash 命令有什么作⽤？ linux命令’hash’管理着⼀个内置的哈希表，记录了已执⾏过的命令的完整路径, ⽤该命令可以打印出你所使⽤过的命令以及执⾏的次数。[root@localhost ~]# hashhits command2 /bin/ls2 /bin/su哪⼀个bash内置命令能够进⾏数学运算。 bash shell 的内置命令let 可以进⾏整型数的数学运算。#! /bin/bash……let c=a+b……
怎样⼀⻚⼀⻚地查看⼀个⼤⽂件的内容呢？ 通过管道将命令”cat file_name.txt” 和 ’more’ 连接在⼀起可以实现这个需要.[root@localhost ~]# cat file_name.txt | more 数据字典属于哪⼀个⽤户的？ 数据字典是属于’SYS’⽤户的，⽤户‘SYS’ 和 ’SYSEM’是由系统默认⾃动创建的 怎样查看⼀个linux命令的概要与⽤法？假设你在/bin⽬录中偶然看到⼀个你从没⻅过的的命令，怎样才能知道它的作⽤和⽤法呢？ 使⽤命令whatis 可以先出显示出这个命令的⽤法简要，⽐如，你可以使⽤whatis zcat 去查看‘zcat’的介绍以及使⽤简要。[root@localhost ~]# whatis zcatzcat [gzip] (1) – compress or expand files使⽤哪⼀个命令可以查看⾃⼰⽂件系统的磁盘空间配额呢？ 使⽤命令repquota 能够显示出⼀个⽂件系统的配额信息【附】只有root⽤户才能够查看其它⽤户的配额。 说⼀下异步和⾮阻塞的区别? 异步和⾮阻塞的区别:1. 异步：调⽤在发出之后，这个调⽤就直接返回，不管有⽆结果；异步是过程。2. ⾮阻塞：关注的是程序在等待调⽤结果（消息，返回值）时的状态，指在不能⽴刻得到结果之前，该调⽤不会阻塞当前线程。同步和异步的区别：1. 步：⼀个服务的完成需要依赖其他服务时，只有等待被依赖的服务完成后，才算完成，这是⼀种可靠的服务序列。要么成功都成功，失败都失败，服务的状态可以保持⼀致。2. 异步：⼀个服务的完成需要依赖其他服务时，只通知其他依赖服务开始执⾏，⽽不需要等待被依赖的服务完成，此时该服务就算完成了。被依赖的服务是否最终完成⽆法确定，⼀次它是⼀个不可靠的服务序列。消息通知中的同步和异步：1. 同步：当⼀个同步调⽤发出后，调⽤者要⼀直等待返回消息（或者调⽤结果）通知后，才能进⾏后续的执⾏。2. 异步：当⼀个异步过程调⽤发出后，调⽤者不能⽴刻得到返回消息（结果）。在调⽤结束之后，通过消息回调来通知调⽤者是否调⽤成功。阻塞与⾮阻塞的区别：
1. 阻塞：阻塞调⽤是指调⽤结果返回之前，当前线程会被挂起，⼀直处于等待消息通知，不能够执⾏其他业务,函数只有在得到结果之后才会返回。2. ⾮阻塞：⾮阻塞和阻塞的概念相对应，指在不能⽴刻得到结果之前，该函数不会阻塞当前线程，⽽会⽴刻返回。同步与异步是对应的，它们是线程之间的关系，两个线程之间要么是同步的，要么是异步的。阻塞与⾮阻塞是对同⼀个线程来说的，在某个时刻，线程要么处于阻塞，要么处于⾮阻塞。阻塞是使⽤同步机制的结果，⾮阻塞则是使⽤异步机制的结果。滑动窗⼝的概念以及应⽤? 滑动窗⼝概念不仅存在于数据链路层，也存在于传输层，两者有不同的协议，但基本原理是相近的。其中⼀个重要区别是，⼀个是针对于帧的传送，另⼀个是字节数据的传送。滑动窗⼝（Sliding window）是⼀种流量控制技术。早期的⽹络通信中，通信双⽅不会考虑⽹络的拥挤情况直接发送数据。由于⼤家不知道⽹络拥塞状况，同时发送数据，导致中间节点阻塞掉包，谁也发不了数据，所以就有了滑动窗⼝机制来解决此问题。参⻅滑动窗⼝如何根据⽹络拥塞发送数据仿真视频。滑动窗⼝协议是⽤来改善吞吐量的⼀种技术，即容许发送⽅在接收任何应答之前传送附加的包。接收⽅告诉发送⽅在某⼀时刻能送多少包（称窗⼝尺⼨）。CP中采⽤滑动窗⼝来进⾏传输控制，滑动窗⼝的⼤⼩意味着接收⽅还有多⼤的缓冲区可以⽤于接收数据。发送⽅可以通过滑动窗⼝的⼤⼩来确定应该发送多少字节的数据。当滑动窗⼝为0时，发送⽅⼀般不能再发送数据报，但有两种情况除外，⼀种情况是可以发送紧急数据，例如，允许⽤户终⽌在远端机上的运⾏进程。另⼀种情况是发送⽅可以发送⼀个1字节的数据报来通知接收⽅重新声明它希望接收的下⼀字节及发送⽅的滑动窗⼝⼤⼩。 Epoll原理. 开发⾼性能⽹络程序时，windows开发者们⾔必称Iocp，linux开发者们则⾔必称Epoll。⼤家都明⽩Epoll是⼀种IO多路复⽤技术，可以⾮常⾼效的处理数以百万计的Socket句柄，⽐起以前的Select和Poll效率提⾼了很多。先简单了解下如何使⽤C库封装的3个epoll系统调⽤。使⽤起来很清晰，⾸先要调⽤epoll_create建⽴⼀个epoll对象。参数size是内核保证能够正确处理的最⼤句柄数，多于这个最⼤数时内核可不保证效果。 epoll_ctl可以操作上⾯建⽴的epoll，例如，将刚建⽴的socket加⼊到epoll中让其监控，或者把 epoll正在监控的某个socket句柄移出epoll，不再监控它等等。epoll_wait在调⽤时，在给定的timeout时间内，当在监控的所有句柄中有事件发⽣时，就返回⽤户态的进程。从调⽤⽅式就可以看到epoll相⽐select/poll的优越之处是,因为后者每次调⽤时都要传递你所要监控的所有socket给select/poll系统调⽤，这意味着需要将⽤户态的socket列表copy到内核态，如果以万计的句柄会导致每次都要copy⼏⼗⼏百KB的内存到内核态，⾮常低效。⽽我们调⽤epoll_wait时就相当于以往调⽤select/poll，但是这时却不⽤传递socket句柄给内核，因为内核已经在epoll_ctl中拿到了要监控的句柄列表。int epoll_create(int size);  int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);  int epoll_wait(int epfd, struct epoll_event *events,int maxevents, int timeout);  
所以，实际上在你调⽤epoll_create后，内核就已经在内核态开始准备帮你存储要监控的句柄了，每次调⽤epoll_ctl只是在往内核的数据结构⾥塞⼊新的socket句柄。在内核⾥，⼀切皆⽂件。所以，epoll向内核注册了⼀个⽂件系统，⽤于存储上述的被监控socket。当你调⽤epoll_create时，就会在这个虚拟的epoll⽂件系统⾥创建⼀个file结点。当然这个file不是普通⽂件，它只服务于epoll。epoll在被内核初始化时（操作系统启动），同时会开辟出epoll⾃⼰的内核⾼速cache区，⽤于安置每⼀个我们想监控的socket，这些socket会以红⿊树的形式保存在内核cache⾥，以⽀持快速的查找、插⼊、删除。这个内核⾼速cache区，就是建⽴连续的物理内存⻚，然后在之上建⽴slab层，通常来讲，就是物理上分配好你想要的size的内存对象，每次使⽤时都是使⽤空闲的已分配好的对象。
epoll的⾼效就在于，当我们调⽤epoll_ctl往⾥塞⼊百万个句柄时，epoll_wait仍然可以⻜快的返回，并有效的将发⽣事件的句柄给我们⽤户。这是由于我们在调⽤epoll_create时，内核除了帮我们在epoll⽂件系统⾥建了个file结点，在内核cache⾥建了个红⿊树⽤于存储以后epoll_ctl传来的socket外，还会再建⽴⼀个list链表，⽤于存储准备就绪的事件，当epoll_wait调⽤时，仅仅观察这个list链表⾥有没有数据即可。有数据就返回，没有数据就sleep，等到timeout时间到后即使链表没数据也返回。所以，epoll_wait⾮常⾼效。⽽且，通常情况下即使我们要监控百万计的句柄，⼤多⼀次也只返回很少量的准备就绪句柄⽽已，所以，epoll_wait仅需要从内核态copy少量的句柄到⽤户态⽽已，因此就会⾮常的⾼效！然⽽,这个准备就绪list链表是怎么维护的呢？当我们执⾏epoll_ctl时，除了把socket放到epoll⽂件系统⾥file对象对应的红⿊树上之外，还会给内核中断处理程序注册⼀个回调函数，告诉内核，如果这个句柄的中断到了，就把它放到准备就绪list链表⾥。所以，当⼀个socket上有数据到了，内核在把⽹卡上的数据copy到内核中后就来把socket插⼊到准备就绪链表⾥了。如此，⼀个红⿊树，⼀张准备就绪句柄链表，少量的内核cache，就帮我们解决了⼤并发下的socket处理问题。执⾏epoll_create时，创建了红⿊树和就绪链表，执⾏epoll_ctl时，如果增加socket句柄，则检查在红⿊树中是否存在，存在⽴即返回，不存在则添加到树⼲上，然后向内核注册回调函数，⽤于当中断事件来临时向准备就绪链表中插⼊数据。执⾏epoll_wait时⽴刻返回准备就绪链表⾥的数据即可。最后看看epoll独有的两种模式LT和ET。⽆论是LT和ET模式，都适⽤于以上所说的流程。区别是，LT模式下，只要⼀个句柄上的事件⼀次没有处理完，会在以后调⽤epoll_wait时每次返回这个句柄，⽽ET模式仅在第⼀次返回。static int __init eventpoll_init(void)  {      ... ...        /* Allocates slab cache used to allocate "struct epitem" items */      epi_cache = kmem_cache_create("eventpoll_epi", sizeof(struct epitem),              0, SLAB_HWCACHE_ALIGN|EPI_SLAB_DEBUG|SLAB_PANIC,              NULL, NULL);        /* Allocates slab cache used to allocate "struct eppoll_entry" */      pwq_cache = kmem_cache_create("eventpoll_pwq",              sizeof(struct eppoll_entry), 0,              EPI_SLAB_DEBUG|SLAB_PANIC, NULL, NULL);   ... ...   }
当⼀个socket句柄上有事件时，内核会把该句柄插⼊上⾯所说的准备就绪list链表，这时我们调⽤epoll_wait，会把准备就绪的socket拷⻉到⽤户态内存，然后清空准备就绪list链表，最后，epoll_wait需要做的事情，就是检查这些socket，如果不是ET模式（就是LT模式的句柄了），并且这些socket上确实有未处理的事件时，⼜把该句柄放回到刚刚清空的准备就绪链表了。所以，⾮ET的句柄，只要它上⾯还有事件，epoll_wait每次都会返回。⽽ET模式的句柄，除⾮有新中断到，即使socket上的事件没有处理完，也是不会每次从epoll_wait返回的。因此epoll⽐select的提⾼实际上是⼀个⽤空间换时间思想的具体应⽤.对⽐阻塞IO的处理模型, 可以看到采⽤了多路复⽤IO之后, 程序可以⾃由的进⾏⾃⼰除了IO操作之外的⼯作, 只有到IO状态发⽣变化的时候由多路复⽤IO进⾏通知, 然后再采取相应的操作, ⽽不⽤⼀直阻塞等待IO状态发⽣变化,提⾼效率. 负载均衡原理是什么? 负载均衡Load Balance）是⾼可⽤⽹络基础架构的关键组件，通常⽤于将⼯作负载分布到多个服务器来提⾼⽹站、应⽤、数据库或其他服务的性能和可靠性。负载均衡，其核⼼就是⽹络流量分发，分很多维度。负载均衡（Load Balance）通常是分摊到多个操作单元上进⾏执⾏，例如Web服务器、FTP服务器、企业关键应⽤服务器和其它关键任务服务器等，从⽽共同完成⼯作任务。负载均衡是建⽴在现有⽹络结构之上，它提供了⼀种廉价有效透明的⽅法扩展⽹络设备和服务器的带宽、增加吞吐量、加强⽹络数据处理能⼒、提⾼⽹络的灵活性和可⽤性。通过⼀个例⼦详细介绍:没有负载均衡 web 架构
在这⾥⽤户是直连到 web 服务器，如果这个服务器宕机了，那么⽤户⾃然也就没办法访问了。 另外，如果同时有很多⽤户试图访问服务器，超过了其能处理的极限，就会出现加载速度缓慢或根本⽆法连接的情况。⽽通过在后端引⼊⼀个负载均衡器和⾄少⼀个额外的 web 服务器，可以缓解这个故障。 通常情况下，所有的后端服务器会保证提供相同的内容，以便⽤户⽆论哪个服务器响应，都能收到⼀致的内容。有负载均衡 web 架构
⽤户访问负载均衡器，再由负载均衡器将请求转发给后端服务器。在这种情况下，单点故障现在转移到负载均衡器上了。 这⾥⼜可以通过引⼊第⼆个负载均衡器来缓解。那么负载均衡器的⼯作⽅式是什么样的呢,负载均衡器⼜可以处理什么样的请求？负载均衡器的管理员能主要为下⾯四种主要类型的请求设置转发规则：HTTP (七层)HTTPS (七层)TCP (四层)UDP (四层)负载均衡器如何选择要转发的后端服务器？负载均衡器⼀般根据两个因素来决定要将请求转发到哪个服务器。⾸先，确保所选择的服务器能够对请求做出响应，然后根据预先配置的规则从健康服务器池（healthy pool）中进⾏选择。因为，负载均衡器应当只选择能正常做出响应的后端服务器，因此就需要有⼀种判断后端服务器是否健康的⽅法。为了监视后台服务器的运⾏状况，运⾏状态检查服务会定期尝试使⽤转发规则定义的协议和端⼝去连接后端服务器。 如果，服务器⽆法通过健康检查，就会从池中剔除，保证流量不会被转发到该服务器，直到其再次通过健康检查为⽌。
负载均衡算法负载均衡算法决定了后端的哪些健康服务器会被选中。 其中常⽤的算法包括：Round Robin（轮询）：为第⼀个请求选择列表中的第⼀个服务器，然后按顺序向下移动列表直到结尾，然后循环。Least Connections（最⼩连接）：优先选择连接数最少的服务器，在普遍会话较⻓的情况下推荐使⽤。Source：根据请求源的 IP 的散列（hash）来选择要转发的服务器。这种⽅式可以⼀定程度上保证特定⽤户能连接到相同的服务器。如果你的应⽤需要处理状态⽽要求⽤户能连接到和之前相同的服务器。可以通过 Source 算法基于客户端的 IP 信息创建关联，或者使⽤粘性会话（sticky sessions）。除此之外，想要解决负载均衡器的单点故障问题，可以将第⼆个负载均衡器连接到第⼀个上，从⽽形成⼀个集群。  LVS相关了解. LVS是 Linux Virtual Server 的简称，也就是Linux虚拟服务器。这是⼀个由章⽂嵩博⼠发起的⼀个开源项⽬，它的官⽅⽹站是LinuxVirtualServer现在 LVS 已经是 Linux 内核标准的⼀部分。使⽤ LVS 可以达到的技术⽬标是：通过 LVS 达到的负载均衡技术和 Linux 操作系统实现⼀个⾼性能⾼可⽤的 Linux 服务器集群，它具有良好的可靠性、可扩展性和可操作性。 从⽽以低廉的成本实现最优的性能。LVS 是⼀个实现负载均衡集群的开源软件项⽬，LVS架构从逻辑上可分为调度层、Server集群层和共享存储。LVS的基本⼯作原理:
1. 当⽤户向负载均衡调度器（Director Server）发起请求，调度器将请求发往⾄内核空间2. PREROUTING链⾸先会接收到⽤户请求，判断⽬标IP确定是本机IP，将数据包发往INPUT链3. IPVS是⼯作在INPUT链上的，当⽤户请求到达INPUT时，IPVS会将⽤户请求和⾃⼰已定义好的集群服务进⾏⽐对，如果⽤户请求的就是定义的集群服务，那么此时IPVS会强⾏修改数据包⾥的⽬标IP地址及端⼝，并将新的数据包发往POSTROUTING链4. POSTROUTING链接收数据包后发现⽬标IP地址刚好是⾃⼰的后端服务器，那么此时通过选路，将数据包最终
发送给后端的服务器LVS的组成:LVS 由2部分程序组成，包括 ipvs 和 ipvsadm。1. ipvs(ip virtual server)：⼀段代码⼯作在内核空间，叫ipvs，是真正⽣效实现调度的代码。2. ipvsadm：另外⼀段是⼯作在⽤户空间，叫ipvsadm，负责为ipvs内核框架编写规则，定义谁是集群服务，⽽谁是后端真实的服务器(Real Server)详细的LVS的介绍可以参考LVS详解. ⽹络和操作系统 进程和线程的区别？ 调度：进程是资源管理的基本单位，线程是程序执⾏的基本单位。切换：线程上下⽂切换⽐进程上下⽂切换要快得多。拥有资源：进程是拥有资源的⼀个独⽴单位，线程不拥有系统资源，但是可以访问⾪属于进程的资源。系统开销：创建或撤销进程时，系统都要为之分配或回收系统资源，如内存空间，I/O 设备等，OS所付出的开销显著⼤于在创建或撤销线程时的开销，进程切换的开销也远⼤于线程切换的开销。协程与线程的区别？ 线程和进程都是同步机制，⽽协程是异步机制。线程是抢占式，⽽协程是⾮抢占式的。需要⽤户释放使⽤权切换到其他协程，因此同⼀时间其实只有⼀个协程拥有运⾏权，相当于单线程的能⼒。⼀个线程可以有多个协程，⼀个进程也可以有多个协程。协程不被操作系统内核管理，⽽完全是由程序控制。线程是被分割的 CPU 资源，协程是组织好的代码流程，线程是协程的资源。但协程不会直接使⽤线程，协程直接利⽤的是执⾏器关联任意线程或线程池。协程能保留上⼀次调⽤时的状态。并发和并⾏有什么区别？ 并发就是在⼀段时间内，多个任务都会被处理；但在某⼀时刻，只有⼀个任务在执⾏。单核处理器可以做到并发。⽐如有两个进程 A 和 B，A 运⾏⼀个时间⽚之后，切换到 B，B 运⾏⼀个时间⽚之后⼜切换到 A。因为切换速度⾜够快，所以宏观上表现为在⼀段时间内能同时运⾏多个程序。并⾏就是在同⼀时刻，有多个任务在执⾏。这个需要多核处理器才能完成，在微观上就能同时执⾏多条指令，不同的程序被放到不同的处理器上运⾏，这个是物理上的多个进程同时进⾏。进程与线程的切换流程？ 进程切换分两步：1、切换⻚表以使⽤新的地址空间，⼀旦去切换上下⽂，处理器中所有已经缓存的内存地址⼀瞬间都作废了。2、切换内核栈和硬件上下⽂。
对于 linux 来说，线程和进程的最⼤区别就在于地址空间，对于线程切换，第1 步是不需要做的，第2 步是进程和线程切换都要做的。因为每个进程都有⾃⼰的虚拟地址空间，⽽线程是共享所在进程的虚拟地址空间的，因此同⼀个进程中的线程进⾏线程切换时不涉及虚拟地址空间的转换。为什么虚拟地址空间切换会⽐较耗时？ 进程都有⾃⼰的虚拟地址空间，把虚拟地址转换为物理地址需要查找⻚表，⻚表查找是⼀个很慢的过程，因此通常使⽤ Cache 来缓存常⽤的地址映射，这样可以加速⻚表查找，这个 Cache 就是 TLB（translation Lookaside Buffer， TLB本质上就是⼀个 Cache，是⽤来加速⻚表查找的）。由于每个进程都有⾃⼰的虚拟地址空间，那么显然每个进程都有⾃⼰的⻚表，那么当进程切换后⻚表也要进⾏切换，⻚表切换后 TLB就失效了，Cache 失效导致命中率降低，那么虚拟地址转换为物理地址就会变慢，表现出来的就是程序运⾏会变慢，⽽线程切换则不会导致 TLB失效，因为线程⽆需切换地址空间，因此我们通常说线程切换要⽐较进程切换块，原因就在这⾥。进程间通信⽅式有哪些？ 管道：管道这种通讯⽅式有两种限制，⼀是半双⼯的通信，数据只能单向流动，⼆是只能在具有亲缘关系的进程间使⽤。进程的亲缘关系通常是指⽗⼦进程关系。管道可以分为两类：匿名管道和命名管道。匿名管道是单向的，只能在有亲缘关系的进程间通信；命名管道以磁盘⽂件的⽅式存在，可以实现本机任意两个进程通信。信号：信号是⼀种⽐较复杂的通信⽅式，信号可以在任何时候发给某⼀进程，⽽⽆需知道该进程的状态。Linux 系统中常⽤信号：1）SIGHUP：⽤户从终端注销，所有已启动进程都将收到该进程。系统缺省状态下对该信号的处理是终⽌进程。2）SIGINT：程序终⽌信号。程序运⾏过程中，按 Ctrl+C 键将产⽣该信号。3）SIGQUIT：程序退出信号。程序运⾏过程中，按 Ctrl+\键将产⽣该信号。（4）SIGBUS和 SIGSEGV：进程访问⾮法地址。5）SIGFPE：运算中出现致命错误，如除零操作、数据溢出等。6）SIGKILL：⽤户终⽌进程执⾏信号。shell 下执⾏ kill -9 发送该信号。7）SIGTERM：结束进程信号。shell 下执⾏ kill 进程 pid 发送该信号。8）SIGALRM：定时器信号。9）SIGCLD：⼦进程退出信号。如果其⽗进程没有忽略该信号也没有处理该信号，则⼦进程退出后将形成僵⼫进程。信号量：信号量是⼀个计数器，可以⽤来控制多个进程对共享资源的访问。它常作为⼀种锁机制，防⽌某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同⼀进程内不同线程之间的同步⼿段。消息队列：消息队列是消息的链接表，包括 Posix 消息队列和 System V 消息队列。有⾜够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读⾛队列中的消息。消息队列克服了信号承载信息量少，管道只能承载⽆格式字节流以及缓冲区⼤⼩受限等缺点。共享内存：共享内存就是映射⼀段能被其他进程所访问的内存，这段共享内存由⼀个进程创建，但多个进程都可以访问。共享内存是最快的 IPC ⽅式，它是针对其他进程间通信⽅式运⾏效率低⽽专⻔设计的。它往往与其他通信机制，如信号量，配合使⽤，来实现进程间的同步和通信。Socket：与其他通信机制不同的是，它可⽤于不同机器间的进程通信。优缺点：管道：速度慢，容量有限；
Socket：任何进程间都能通讯，但速度慢；消息队列：容量受到系统限制，且要注意第⼀次读的时候，要考虑上⼀次没有读完数据的问题；信号量：不能传递复杂消息，只能⽤来同步；共享内存区：能够很容易控制容量，速度快，但要保持同步，⽐如⼀个进程在写的时候，另⼀个进程要注意读写的问题，相当于线程中的线程安全，当然，共享内存区同样可以⽤作线程间通讯，不过没这个必要，线程间本来就已经共享了同⼀进程内的⼀块内存。进程间同步的⽅式有哪些？ 临界区：通过对多线程的串⾏化来访问公共资源或⼀段代码，速度快，适合控制数据访问。优点：保证在某⼀时刻只有⼀个线程能访问数据的简便办法。缺点：虽然临界区同步速度很快，但却只能⽤来同步本进程内的线程，⽽不可⽤来同步多个进程中的线程。互斥量：为协调共同对⼀个共享资源的单独访问⽽设计的。互斥量跟临界区很相似，⽐临界区复杂，互斥对象只有⼀个，只有拥有互斥对象的线程才具有访问资源的权限。优点：使⽤互斥不仅仅能够在同⼀应⽤程序不同线程中实现资源的安全共享，⽽且可以在不同应⽤程序的线程之间实现对资源的安全共享。缺点：互斥量是可以命名的，也就是说它可以跨越进程使⽤，所以创建互斥量需要的资源更多，所以如果只为了在进程内部是⽤的话使⽤临界区会带来速度上的优势并能够减少资源占⽤量。通过互斥量可以指定资源被独占的⽅式使⽤，但如果有下⾯⼀种情况通过互斥量就⽆法处理，⽐如现在⼀位⽤户购买了⼀份三个并发访问许可的数据库系统，可以根据⽤户购买的访问许可数量来决定有多少个线程/进程能同时进⾏数据库操作，这时候如果利⽤互斥量就没有办法完成这个要求，信号量对象可以说是⼀种资源计数器。信号量：为控制⼀个具有有限数量⽤户资源⽽设计。它允许多个线程在同⼀时刻访问同⼀资源，但是需要限制在同⼀时刻访问此资源的最⼤线程数⽬。互斥量是信号量的⼀种特殊情况，当信号量的最⼤资源数=1就是互斥量了。优点：适⽤于对 Socket（套接字）程序中线程的同步。缺点: 信号量机制必须有公共内存，不能⽤于分布式操作系统，这是它最⼤的弱点；信号量机制功能强⼤，但使⽤时对信号量的操作分散，⽽且难以控制，读写和维护都很困难，加重了程序员的编码负担；核⼼操作 P-V分散在各⽤户程序的代码中，不易控制和管理，⼀旦错误，后果严重，且不易发现和纠正。事件：⽤来通知线程有⼀些事件已发⽣，从⽽启动后继任务的开始。优点：事件对象通过通知操作的⽅式来保持线程的同步，并且可以实现不同进程中的线程同步操作。线程同步的⽅式有哪些？ 临界区：当多个线程访问⼀个独占性共享资源时，可以使⽤临界区对象。拥有临界区的线程可以访问被保护起来的资源或代码段，其他线程若想访问，则被挂起，直到拥有临界区的线程放弃临界区为⽌，以此达到⽤原⼦⽅式操作共享资源的⽬的。事件：事件机制，则允许⼀个线程在处理完⼀个任务后，主动唤醒另外⼀个线程执⾏任务。互斥量：互斥对象和临界区对象⾮常相似，只是其允许在进程间使⽤，⽽临界区只限制与同⼀进程的各个线程之间使⽤，但是更节省资源，更有效率。信号量：当需要⼀个计数器来限制可以使⽤某共享资源的线程数⽬时，可以使
⽤“信号量”对象。区别：互斥量与临界区的作⽤⾮常相似，但互斥量是可以命名的，也就是说互斥量可以跨越进程使⽤，但创建互斥量需要的资源更多，所以如果只为了在进程内部是⽤的话使⽤临界区会带来速度上的优势并能够减少资源占⽤量。因为互斥量是跨进程的互斥量⼀旦被创建，就可以通过名字打开它。互斥量，信号量，事件都可以被跨越进程使⽤来进⾏同步数据操作。线程的分类？ 从线程的运⾏空间来说，分为⽤户级线程（user-level thread, ULT）和内核级线程（kernel-level, KLT）内核级线程：这类线程依赖于内核，⼜称为内核⽀持的线程或轻量级进程。⽆论是在⽤户程序中的线程还是系统进程中的线程，它们的创建、撤销和切换都由内核实现。⽐如英特尔 i5-8250U是4 核8 线程，这⾥的线程就是内核级线程⽤户级线程：它仅存在于⽤户级中，这种线程是不依赖于操作系统核⼼的。应⽤进程利⽤线程库来完成其创建和管理，速度⽐较快，操作系统内核⽆法感知⽤户级线程的存在。什么是临界区，如何解决冲突？ 每个进程中访问临界资源的那段程序称为临界区，⼀次仅允许⼀个进程使⽤的资源称为临界资源。解决冲突的办法：如果有若⼲进程要求进⼊空闲的临界区，⼀次仅允许⼀个进程进⼊，如已有进程进⼊⾃⼰的临界区，则其它所有试图进⼊临界区的进程必须等待；进⼊临界区的进程要在有限时间内退出。如果进程不能进⼊⾃⼰的临界区，则应让出 CPU，避免进程出现“忙等”现象。什么是死锁？死锁产⽣的条件？ 什么是死锁：在两个或者多个并发进程中，如果每个进程持有某种资源⽽⼜等待其它进程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这⼀组进程产⽣了死锁。通俗的讲就是两个或多个进程⽆限期的阻塞、相互等待的⼀种状态。死锁产⽣的四个必要条件：（有⼀个条件不成⽴，则不会产⽣死锁）互斥条件：⼀个资源⼀次只能被⼀个进程使⽤请求与保持条件：⼀个进程因请求资源⽽阻塞时，对已获得资源保持不放不剥夺条件：进程获得的资源，在未完全使⽤完之前，不能强⾏剥夺循环等待条件：若⼲进程之间形成⼀种头尾相接的环形等待资源关系如何处理死锁问题：忽略该问题。例如鸵⻦算法，该算法可以应⽤在极少发⽣死锁的的情况下。为什么叫鸵⻦算法呢，因为传说中鸵⻦看到危险就把头埋在地底下，可能鸵⻦觉得看不到危险也就没危险了吧。跟掩⽿盗铃有点像。检测死锁并且恢复。仔细地对资源进⾏动态分配，以避免死锁。通过破除死锁四个必要条件之⼀，来防⽌死锁产⽣。
进程调度策略有哪⼏种？ 先来先服务：⾮抢占式的调度算法，按照请求的顺序进⾏调度。有利于⻓作业，但不利于短作业，因为短作业必须⼀直等待前⾯的⻓作业执⾏完毕才能执⾏，⽽⻓作业⼜需要执⾏很⻓时间，造成了短作业等待时间过⻓。另外，对 I/O 密集型进程也不利，因为这种进程每次进⾏ I/O 操作之后⼜得重新排队。短作业优先：⾮抢占式的调度算法，按估计运⾏时间最短的顺序进⾏调度。⻓作业有可能会饿死，处于⼀直等待短作业执⾏完毕的状态。因为如果⼀直有短作业到来，那么⻓作业永远得不到调度。最短剩余时间优先：最短作业优先的抢占式版本，按剩余运⾏时间的顺序进⾏调度。当⼀个新的作业到达时，其整个运⾏时间与当前进程的剩余时间作⽐较。如果新的进程需要的时间更少，则挂起当前进程，运⾏新的进程。否则新的进程等待。时间⽚轮转：将所有就绪进程按 FCFS的原则排成⼀个队列，每次调度时，把 CPU时间分配给队⾸进程，该进程可以执⾏⼀个时间⽚。当时间⽚⽤完时，由计时器发出时钟中断，调度程序便停⽌该进程的执⾏，并将它送往就绪队列的末尾，同时继续把 CPU时间分配给队⾸的进程。时间⽚轮转算法的效率和时间⽚的⼤⼩有很⼤关系：因为进程切换都要保存进程的信息并且载⼊新进程的信息，如果时间⽚太⼩，会导致进程切换得太频繁，在进程切换上就会花过多时间。⽽如果时间⽚过⻓，那么实时性就不能得到保证。优先级调度：为每个进程分配⼀个优先级，按优先级进⾏调度。为了防⽌低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。进程有哪些状态？ 进程⼀共有5 种状态，分别是创建、就绪、运⾏（执⾏）、终⽌、阻塞。
运⾏状态就是进程正在 CPU上运⾏。在单处理机环境下，每⼀时刻最多只有⼀个进程处于运⾏状态。就绪状态就是说进程已处于准备运⾏的状态，即进程获得了除 CPU之外的⼀切所需资源，⼀旦得到 CPU即可运⾏。阻塞状态就是进程正在等待某⼀事件⽽暂停运⾏，⽐如等待某资源为可⽤或等待 I/O 完成。即使 CPU空闲，该进程也不能运⾏。运⾏态→阻塞态：往往是由于等待外设，等待主存等资源分配或等待⼈⼯⼲预⽽引起的。阻塞态→就绪态：则是等待的条件已满⾜，只需分配到处理器后就能运⾏。
运⾏态→就绪态：不是由于⾃身原因，⽽是由外界原因使运⾏状态的进程让出处理器，这时候就变成就绪态。例如时间⽚⽤完，或有更⾼优先级的进程来抢占处理器等。就绪态→运⾏态：系统按某种策略选中就绪队列中的⼀个进程占⽤处理器，此时就变成了运⾏态。什么是分⻚？ 把内存空间划分为⼤⼩相等且固定的块，作为主存的基本单位。因为程序数据存储在不同的⻚⾯中，⽽⻚⾯⼜离散的分布在内存中，因此需要⼀个⻚表来记录映射关系，以实现从⻚号到物理块号的映射。访问分⻚系统中内存数据需要两次的内存访问(⼀次是从内存中访问⻚表，从中找到指定的物理块号，加上⻚内偏移得到实际物理地址；第⼆次就是根据第⼀次得到的物理地址访问内存取出数据)。
什么是分段？ 分⻚是为了提⾼内存利⽤率，⽽分段是为了满⾜程序员在编写代码的时候的⼀些逻辑需求(⽐如数据共享，数据保护，动态链接等)。分段内存管理当中，地址是⼆维的，⼀维是段号，⼆维是段内地址；其中每个段的⻓度是不⼀样的，⽽且每个段内部都是从0 开始编址的。由于分段管理中，每个段内部是连续内存分配，但是段和段之间是离散分配的，因此也存在⼀个逻辑地址到物理地址的映射关系，相应的就是段表机制。
分⻚和分段有什区别？ 分⻚对程序员是透明的，但是分段需要程序员显式划分每个段。分⻚的地址空间是⼀维地址空间，分段是⼆维的。⻚的⼤⼩不可变，段的⼤⼩可以动态改变。分⻚主要⽤于实现虚拟内存，从⽽获得更⼤的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独⽴的地址空间并且有助于共享和保护。什么是交换空间？ 操作系统把物理内存(physical RAM)分成⼀块⼀块的⼩内存，每⼀块内存被称为⻚(page)。当内存资源不⾜时，Linux 把某些⻚的内容转移⾄硬盘上的⼀块空间上，以释放内存空间。硬盘上的那块空间叫做交换空间(swap space),⽽这⼀过程被称为交换(swapping)。物理内存和交换空间的总容量就是虚拟内存的可⽤容量。⽤途：物理内存不⾜时⼀些不常⽤的⻚可以被交换出去，腾给系统。程序启动时很多内存⻚被⽤来初始化，之后便不再需要，可以交换出去。⻚⾯替换算法有哪些？ 在程序运⾏过程中，如果要访问的⻚⾯不在内存中，就发⽣缺⻚中断从⽽将该⻚调⼊内存中。此时如果内存已⽆空闲空间，系统必须从内存中调出⼀个⻚⾯到磁盘对换区中来腾出空间。包括以下算法：最佳算法：所选择的被换出的⻚⾯将是最⻓时间内不再被访问，通常可以保证获得最低的缺⻚率。这是⼀种理论上的算法，因为⽆法知道⼀个⻚⾯多⻓时间不再被访问。先进先出：选择换出的⻚⾯是最先进⼊的⻚⾯。该算法将那些经常被访问的⻚⾯也被换出，从⽽使缺⻚率升⾼。LRU：虽然⽆法知道将来要使⽤的⻚⾯情况，但是可以知道过去使⽤⻚⾯的情况。 LRU将最近最久未使⽤的⻚⾯换出。为了实现 LRU，需要在内存中维护⼀个所有⻚⾯的链表。当⼀个⻚⾯被访问时，将这个⻚⾯移到链表表头。这样就能保证链表表尾的⻚⾯是最近最久未访问的。因为每次访问都需要更新链表，因此这种⽅式实现的 LRU代价很⾼。时钟算法：时钟算法使⽤环形链表将⻚⾯连接起来，再使⽤⼀个指针指向最⽼的⻚⾯。它将整个环形链表的每⼀个⻚⾯做⼀个标记，如果标记是0，那么暂时就不会被替换，然后时钟算法遍历整个环，遇到标记为1 的就
替换，否则将标记为0 的标记为1。什么是缓冲区溢出？有什么危害？ 缓冲区溢出是指当计算机向缓冲区填充数据时超出了缓冲区本身的容量，溢出的数据覆盖在合法数据上。危害有以下两点：程序崩溃，导致拒绝额服务跳转并且执⾏⼀段恶意代码造成缓冲区溢出的主要原因是程序中没有仔细检查⽤户输⼊。什么是虚拟内存？ 虚拟内存就是说，让物理内存扩充成更⼤的逻辑内存，从⽽让程序获得更多的可⽤内存。虚拟内存使⽤部分加载的技术，让⼀个进程或者资源的某些⻚⾯加载进内存，从⽽能够加载更多的进程，甚⾄能加载⽐内存⼤的进程，这样看起来好像内存变⼤了，这部分内存其实包含了磁盘或者硬盘，并且就叫做虚拟内存。讲⼀讲 IO 多路复⽤？ IO多路复⽤是指内核⼀旦发现进程指定的⼀个或者多个 IO条件准备读取，它就通知该进程。IO多路复⽤适⽤如下场合：当客户处理多个描述字时（⼀般是交互式输⼊和⽹络套接⼝），必须使⽤ I/O 复⽤。当⼀个客户同时处理多个套接⼝时，⽽这种情况是可能的，但很少出现。如果⼀个 TCP服务器既要处理监听套接⼝，⼜要处理已连接套接⼝，⼀般也要⽤到 I/O 复⽤。如果⼀个服务器即要处理 TCP，⼜要处理 UDP，⼀般要使⽤ I/O 复⽤。如果⼀个服务器要处理多个服务或多个协议，⼀般要使⽤ I/O 复⽤。与多进程和多线程技术相⽐，I/O 多路复⽤技术的最⼤优势是系统开销⼩，系统不必创建进程/线程，也不必维护这些进程/线程，从⽽⼤⼤减⼩了系统的开销。硬链接和软链接有什么区别？ 硬链接就是在⽬录下创建⼀个条⽬，记录着⽂件名与 inode 编号，这个 inode 就是源⽂件的 inode。删除任意⼀个条⽬，⽂件还是存在，只要引⽤数量不为0。但是硬链接有限制，它不能跨越⽂件系统，也不能对⽬录进⾏链接。符号链接⽂件保存着源⽂件所在的绝对路径，在读取时会定位到源⽂件上，可以理解为 Windows的快捷⽅式。当源⽂件被删除了，链接⽂件就打不开了。因为记录的是路径，所以可以为⽬录建⽴符号链接。中断的处理过程? 保护现场：将当前执⾏程序的相关数据保存在寄存器中，然后⼊栈。开中断：以便执⾏中断时能响应较⾼级别的中断请求。中断处理关中断：保证恢复现场时不被新中断打扰恢复现场：从堆栈中按序取出程序数据，恢复中断前的执⾏状态。
中断和轮询有什么区别？ 轮询：CPU对特定设备轮流询问。中断：通过特定事件提醒 CPU。轮询：效率低等待时间⻓，CPU利⽤率不⾼。中断：容易遗漏问题，CPU利⽤率不⾼。请详细介绍⼀下 TCP 的三次握⼿机制，为什么要三次握⼿？ 在讲三次握⼿之前⾸先要介绍 TCP 报⽂中两个重要的字段：⼀个是序号字段，另⼀个是确认号字段，这两个字段将在握⼿阶段以及整个信息传输过程起到重要作⽤。第⼀步：客户端 TCP 向服务端的 TCP发送⼀个不带额外数据的特殊 TCP 报⽂段，该报⽂段的 SYN 标志位会被置1，所以把它称为 SYN 报⽂段。这时客户端会选取⼀个初始序列号（假设为 client_num），并将此编号放置在序号字段中。该报⽂段会被封装在⼀个 IP 数据报中发送给服务器。第⼆步：服务器接收到 SYN 报⽂段后，会为该 TCP 分配缓存和变量，并发送允许连接的确认报⽂。在允许连接的报⽂中， SYN 标志位仍被置为1，确认号字段填的是 client_num +1 的值。最后服务端也会选取⼀个 server_num 存放到序号字段中，这个报⽂段称为 SYNACK 报⽂段。第三步：在接收到 SYNACK 报⽂段后，客户端最后也要向服务端发送⼀个确认报⽂，这个报⽂和前两个不⼀样， SYN 标志位置0，在确认号字段中填上 server_num +1 的值，并且这个报⽂段可以携带数据。⼀旦完成这3 个步骤，客户端和服务器之间就可以相互发送包含数据的报⽂了。如果不是三次握⼿，⼆次两次的话，服务器就不知道客户端是否接收到了⾃⼰的 SYNACK 报⽂段，从⽽⽆法建⽴连接；四次握⼿就显得多余了。讲⼀讲 SYN 超时，洪泛攻击，以及解决策略 什么 SYN 是洪泛攻击？在 TCP 的三次握⼿机制的第⼀步中，客户端会向服务器发送 SYN 报⽂段。服务器接收到 SYN 报⽂段后会为该 TCP分配缓存和变量，如果攻击分⼦⼤量地往服务器发送 SYN 报⽂段，服务器的连接资源终将被耗尽，导致内存溢出⽆法继续服务。解决策略：当服务器接受到 SYN 报⽂段时，不直接为该 TCP 分配资源，⽽只是打开⼀个半开的套接字。接着会使⽤ SYN 报⽂段的源 Id，⽬的 Id，端⼝号以及只有服务器⾃⼰知道的⼀个秘密函数⽣成⼀个 cookie，并把 cookie 作为序列号响应给客户端。如果客户端是正常建⽴连接，将会返回⼀个确认字段为 cookie +1 的报⽂段。接下来服务器会根据确认报⽂的源 Id，⽬的 Id，端⼝号以及秘密函数计算出⼀个结果，如果结果的值+1 等于确认字段的值，则证明是刚刚请求连接的客户端，这时候才为该 TCP 分配资源这样⼀来就不会为恶意攻击的 SYN 报⽂段分配资源空间，避免了攻击。详细介绍⼀下 TCP 的四次挥⼿机制，为什么要有 TIME_WAIT 状态，为什么需要四次握⼿？服务器出现了⼤量 CLOSE_WAIT 状态如何解决？ 当客户端要服务器断开连接时，客户端 TCP 会向服务器发送⼀个特殊的报⽂段，该报⽂段的 FIN 标志位会被置1，接着服务器会向客户端发送⼀个确认报⽂段。然后服务器也会客户端发送⼀个 FIN 标志位为1 的终⽌报⽂段，随后客户端回送⼀个确认报⽂段，服务器⽴即断开连接。客户端等待⼀段时间后也断开连接。其实四次挥⼿的过程是很容易理解的，由于 TCP 协议是全双⼯的，也就是说客户端和服务端都可以发起断开连接。两边各发起⼀次断开连接的申请，加上各⾃的两次确认，看起来就像执⾏了四次挥⼿。
MQ描述RabbitMQerlang 开发，对消息堆积的⽀持并不好，当⼤量消息积压的时候，会导致 RabbitMQ 的性能急剧下 降。每秒钟可以处理⼏万到⼗⼏万条消息。RocketMQJava 开发，⾯向互联⽹集群化功能丰富，对在线业务的响应时延做了很多的优化，⼤多数情况下可以做 到毫秒级的响应，每秒钟⼤概能处理⼏⼗万条消息。KafkaScala 开发，⾯向⽇志功能丰富，性能最⾼。当你的业务场景中，每秒钟消息数量没有那么多的时候， Kafka 的时延反⽽会⽐较⾼。所以，Kafka 不太适合在线业务场景。ActiveMQJava 开发，简单，稳定，性能不如前⾯三个。⼩型系统⽤也可以，但是不推荐。推荐⽤互联⽹主流的。
作⽤描述解耦系统耦合度降低，没有强依赖关系。异步不需要同步执⾏的远程调⽤可以有效提⾼响应时间。削峰请求达到峰值后，后端 service 还可以保持固定消费速率消费，不会被压垮。为什么要有 TIME_WAIT 状态？因为客户端最后向服务器发送的确认 ACK 是有可能丢失的，当出现超时，服务端会再次发送 FIN 报⽂段，如果客户端已经关闭了就收不到了。还有⼀点是避免新旧连接混杂。⼤量 CLOSE_WAIT 表示程序出现了问题，对⽅的 socket 已经关闭连接，⽽我⽅忙于读或写没有及时关闭连接，需要检查代码，特别是释放资源的代码，或者是处理请求的线程配置。  RocketMQ ⾯试题 多个 MQ 如何选型？  
为什么要使⽤ MQ？ 因为项⽬⽐较⼤，做了分布式系统，所有远程服务调⽤请求都是同步执⾏经常出问题，所 以引⼊了 MQ。  RocketMQ 由哪些⻆⾊组成，每个⻆⾊作⽤和特点是什么？  
⻆⾊作⽤Nameserver⽆状态，动态列表；这是和 ZooKeeper 的重要区别之⼀。ZooKeeper 是有状态的。Producer消息⽣产者，负责发消息到 Broker。Broker就是 MQ 本身，负责收发消息、持久化消息等。Consumer消息消费者，负责从 Broker 上拉取消息进⾏消费，消费完进⾏ ack。RocketMQ 中的 Topic 和 JMS 的 queue 有什么区别？ queue 就是来源于数据结构的 FIFO 队列。⽽ Topic 是个抽象的概念，每个 Topic 底层对 应 N 个 queue，⽽数据也真实存在 queue 上的。 RocketMQ 消费模式有⼏种？ 消费模型由 Consumer 决定，消费维度为 Topic。 集群消费 1.⼀条消息只会被同 Group 中的⼀个 Consumer 消费 2.多个 Group 同时消费⼀个 Topic 时，每个 Group 都会有⼀个 Consumer 消费到数据。 ⼴播消费 消息将对⼀个 Consumer Group  下的各个  Consumer  实例都消费⼀遍。即即使这些Consumer  属于同⼀个 Consumer Group，消息也会被  Consumer Group  中的每个 Consumer  都消费⼀次。Broker 如何处理拉取请求的？ Consumer ⾸次请求 Broker。 Broker 中是否有符合条件的消息有 响应 Consumer。 等待下次 Consumer 的请求。 没有 DefaultMessageStore#ReputMessageService#run ⽅法。 - PullRequestHoldService  来 Hold 连接，每个 5s 执⾏⼀次检查pullRequestTable 有没有消息，有的话⽴即推送。 每隔 1ms 检查 commitLog 中是否有新消息，有的话写⼊到pullRequestTable。 当有新消息的时候返回请求。 挂起 consumer 的请求，即不断开连接，也不返回数据。 使⽤ consumer 的 offset。  
RocketMQ 如何做负载均衡？ 通过 Topic 在多 Broker 中分布式存储实现。producer 端 发送端指定 message queue 发送消息到相应的 broker，来达到写⼊时的负载均衡提升写⼊吞吐量，当多个 producer 同时向⼀个 broker 写⼊数据的时候，性能会下降 - 消息分布在多 broker 中，为负载消费做准备默认策略是随机选择：producer 维护⼀个 index 每次取节点会⾃增index 向所有 broker 个数取余 ⾃带容错策略其他实现：SelectMessageQueueByHashhash 的是传⼊的 args SelectMessageQueueByRandomSelectMessageQueueByMachineRoom  没有实现 也可以⾃定义实现 MessageQueueSelector 接⼝中的 select ⽅法 consumer 端 采⽤的是平均分配算法来进⾏负载均衡。其他负载均衡算法平均分配策略(默认)(AllocateMessageQueueAveragely)  环形分配策略 (AllocateMessageQueueAveragelyByCircle)  ⼿动配置分配策略 (AllocateMessageQueueByConfig)  机房分配策略 (AllocateMessageQueueByMachineRoom)  ⼀致性哈希分配策略 (AllocateMessageQueueConsistentHash)  靠近机房策略 (AllocateMachineRoomNearby)追问：当消费负载均衡 consumer 和 queue 不对等的时候会发⽣什么？Consumer 和 queue 会优先平均分配，如果 Consumer 少于 queue 的个数，则会存在部 分 Consumer 消费多个 queue 的情况，如果 Consumer 等于 queue 的个数，那就是⼀ 个 Consumer 消费⼀个 queue，如果 Consumer 个数⼤于 queue 的个数，那么会有部分 Consumer 空余出来，⽩⽩的浪费了。消息重复消费 影响消息正常发送和消费的重要原因是⽹络的不确定性。引起重复消费的原因ACK 正常情况下在 consumer 真正消费完消息后应该发送 ack，通知 broker 该消息 已正常消费，从 queue 中剔除 MESSAGEQUEUE SELECT(FINAL LIST<MESSAGEQUEUE> MQS, FINAL MESSAGE MSG, FINAL OBJECT ARG); 
当 ack 因为⽹络原因⽆法发送到 broker，broker 会认为词条消息没有被消费， 此后会开启消息重投机制把消息再次投递到 consumer 消费模式 在 CLUSTERING模式下，消息在 broker 中会保证相同 group 的 consumer 消 费⼀次，但是针对不同 group 的 consumer 会推送多次解决⽅案 数据库表 处理消息前，使⽤消息主键在表中带有约束的字段中 insert Map 单机时可以使⽤ map ConcurrentHashMap -> putIfAbsent    guava cache - Redis 分布式锁搞起来。RocketMQ 如何保证消息不丢失 ⾸先在如下三个部分都可能会出现丢失消息的情况：Producer 端 Broker 端 Consumer 端 Producer 端如何保证消息不丢失 采取 send()同步发消息，发送结果是同步感知的。发送失败后可以重试，设置重试次数。默认 3 次。 PRODUCER.SETRETRYTIMESWHENSENDFAILED(10); 集群部署，⽐如发送失败了的原因可能是当前 Broker 宕机了，重试的时候会发送到其他 Broker 上。 Broker 端如何保证消息不丢失 修改刷盘策略为同步刷盘。默认情况下是异步刷盘的。 FLUSHDISKTYPE = SYNC_FLUSH 集群部署，主从模式，⾼可⽤。Consumer 端如何保证消息不丢失 完全消费正常后在进⾏⼿动 ack 确认。 ⾼吞吐量下如何优化⽣产者和消费者的性能? 开发 同⼀ group 下，多机部署，并⾏消费 - 单个 Consumer 提⾼消费线程个数 - 批量消费 消息批量拉取业务逻辑批量处理运维 
⽹卡调优 jvm 调优 多线程与 cpu 调优 - Page Cache   Kafka Kafka 是什么？主要应⽤场景有哪些？ Kafka 是⼀个分布式流式处理平台。流平台具有三个关键功能：消息队列：发布和订阅消息流，这个功能类似于消息队列，这也是 Kafka 也被归类为消息队列的原因。容错的持久⽅式存储记录消息流：Kafka 会把消息持久化到磁盘，有效避免了消息丢失的⻛险。流式处理平台：在消息发布的时候进⾏处理，Kafka 提供了⼀个完整的流式处理类库。Kafka 主要有两⼤应⽤场景：消息队列：建⽴实时流数据管道，以可靠地在系统或应⽤程序之间获取数据。数据处理：构建实时的流数据处理程序来转换或处理数据流。和其他消息队列相⽐，Kafka 的优势在哪⾥？ 我们现在经常提到 Kafka 的时候就已经默认它是⼀个⾮常优秀的消息队列了，我们也会经常拿它跟 RocketMQ、RabbitMQ 对⽐。我觉得 Kafka 相⽐其他消息队列主要的优势如下：极致的性能：基于 Scala 和 Java 语⾔开发，设计中⼤量使⽤了批量处理和异步的思想，最⾼可以每秒处理千万级别的消息。⽣态系统兼容性⽆可匹敌：Kafka 与周边⽣态系统的兼容性是最好的没有之⼀，尤其在⼤数据和流计算领域。实际上在早期的时候 Kafka 并不是⼀个合格的消息队列，早期的 Kafka 在消息队列领域就像是⼀个⾐衫褴褛的孩⼦⼀样，功能不完备并且有⼀些⼩问题⽐如丢失消息、不保证消息可靠性等等。当然，这也和 LinkedIn 最早开发 Kafka ⽤于处理海量的⽇志有很⼤关系，哈哈哈，⼈家本来最开始就不是为了作为消息队列滴，谁知道后⾯误打误撞在消息队列领域占据了⼀席之地。什么是 Producer、Consumer、Broker、Topic、 Partition？ Kafka 将⽣产者发布的消息发送到 Topic（主题）中，需要这些消息的消费者可以订阅这些 Topic（主题）。Kafka ⽐较重要的⼏个概念：Producer（⽣产者）: 产⽣消息的⼀⽅。Consumer（消费者）: 消费消息的⼀⽅。Broker（代理）: 可以看作是⼀个独⽴的 Kafka 实例。多个 Kafka Broker 组成⼀个 Kafka Cluster。Topic（主题）: Producer 将消息发送到特定的主题，Consumer 通过订阅特定的 Topic(主题)来消费消息。Partition（分区）: Partition 属于 Topic 的⼀部分。⼀个 Topic 可以有多个 Partition ，并且同⼀ Topic 下的 Partition 可以分布在不同的 Broker 上，这也就表明⼀个 Topic 可以横跨多个 Broker 。这正如我上⾯所画的图⼀样。
Kafka 的多副本机制了解吗？ Kafka 为分区（Partition）引⼊了多副本（Replica）机制。分区Partition）中的多个副本之间会有⼀个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进⾏同步。⽣产者和消费者只与 leader 副本交互。你可以理解为其他副本只是 leader 副本的拷⻉，它们的存在只是为了保证消息存储的安全性。当 leader 副本发⽣故障时会从 follower 中选举出⼀个 leader,但是 follower 中如果有和 leader 同步程度达不到要求的参加不了 leader 的竞选。Kafka 的多分区（Partition）以及多副本（Replica）机制有什么好处呢？ Kafka 通过给特定 Topic 指定多个 Partition,⽽各个 Partition 可以分布在不同的 Broker 上,这样便能提供⽐较好的并发能⼒（负载均衡）。Partition 可以指定对应的 Replica 数,这也极⼤地提⾼了消息存储的安全性,提⾼了容灾能⼒，不过也相应的增加了所需要的存储空间。Zookeeper 在 Kafka 中的作⽤知道吗？ Broker 注册：在 Zookeeper 上会有⼀个专⻔⽤来进⾏ Broker 服务器列表记录的节点。每个 Broker 在启动时，都会到 Zookeeper 上进⾏注册，即到/brokers/ids 下创建属于⾃⼰的节点。每个 Broker 就会将⾃⼰的 IP 地址和端⼝等信息记录到该节点中去Topic 注册：在 Kafka 中，同⼀个 Topic 的消息会被分成多个分区并将其分布在多个 Broker 上，这些分区信息及与 Broker 的对应关系也都是由 Zookeeper 在维护。⽐如我创建了⼀个名字为 my-topic 的主题并且它有两个分区，对应到 zookeeper 中会创建这些⽂件夹：/brokers/topics/my-topic/Partitions/0、/brokers/topics/my - topic/Partitions/1负载均衡：上⾯也说过了 Kafka 通过给特定 Topic 指定多个 Partition,⽽各个 Partition 可以分布在不同的 Broker 上,这样便能提供⽐较好的并发能⼒。对于同⼀个 Topic 的不同 Partition，Kafka 会尽⼒将这些 Partition 分布到不同的 Broker 服务器上。当⽣产者产⽣消息后也会尽量投递到不同 Broker 的 Partition ⾥⾯。当 Consumer 消费的时候，Zookeeper 可以根据当前的 Partition 数量以及 Consumer 数量来实现动态负载均衡。Kafka 如何保证消息的消费顺序？ 我们在使⽤消息队列的过程中经常有业务场景需要严格保证消息的消费顺序，⽐如我们同时发了2 个消息，这2 个消息对应的操作分别对应的数据库操作是：更改⽤户会员等级。根据会员等级计算订单价格。假如这两条消息的消费顺序不⼀样造成的最终结果就会截然不同。 Kafka 中 Partition(分区)是真正保存消息的地⽅，我们发送的消息都被放在了这⾥。⽽我们的 Partition(分区)⼜存在于 Topic(主题)这个概念中，并且我们可以给特定 Topic 指定多个 Partition。每次添加消息到 Partition(分区)的时候都会采⽤尾加法，如上图所示。 Kafka 只能为我们保证 Partition(分区)中的消息有序。消息在被追加到 Partition(分区)的时候都会分配⼀个特定的偏移量
offset）。Kafka 通过偏移量（offset）来保证消息在分区内的顺序性。所以，我们就有⼀种很简单的保证消息消费顺序的⽅法：1 个 Topic 只对应⼀个 Partition。这样当然可以解决问题，但是破坏了 Kafka 的设计初衷。 Kafka 中发送1 条消息的时候，可以指定 topic, partition, key,data（数据）4 个参数。如果你发送消息的时候指定了 Partition 的话，所有消息都会被发送到指定的 Partition。并且，同⼀个 key 的消息可以保证只发送到同⼀个 partition，这个我们可以采⽤表/对象的 id 来作为 key。总结⼀下，对于如何保证 Kafka 中消息消费的顺序，有了下⾯两种⽅法：1 个 Topic 只对应⼀个 Partition。发送消息的时候指定 key/Partition。Kafka 如何保证消息不丢失？ ⽣产者丢失消息的情况⽣产者(Producer)调⽤ send ⽅法发送消息之后，消息可能因为⽹络问题并没有发送过去。所以，我们不能默认在调⽤ send ⽅法发送消息之后消息发送成功了。为了确定消息是发送成功，我们要判断消息发送的结果。但是要注意的是 Kafka ⽣产者(Producer)使⽤ send ⽅法发送消息实际上是异步的操作，我们可以通过 get()⽅法获取调⽤结果，但是这样也让它变为了同步操作。消费者丢失消息的情况我们知道消息在被追加到 Partition(分区)的时候都会分配⼀个特定的偏移量offset）。偏移量（offset)表示 Consumer 当前消费到的 Partition(分区)的所在的位置。Kafka 通过偏移量（offset）可以保证消息在分区内的顺序性。当消费者拉取到了分区的某个消息之后，消费者会⾃动提交了 offset。⾃动提交的话会有⼀个问题，试想⼀下，当消费者刚拿到这个消息准备进⾏真正消费的时候，突然挂掉了，消息实际上并没有被消费，但是 offset 却被⾃动提交了。解决办法也⽐较粗暴，我们⼿动关闭⾃动提交 offset，每次在真正消费完消息之后再⾃⼰⼿动提交 offset 。但是，细⼼的朋友⼀定会发现，这样会带来消息被重新消费的问题。⽐如你刚刚消费完消息之后，还没提交 offset，结果⾃⼰挂掉了，那么这个消息理论上就会被消费两次。Kafka 判断⼀个节点是否还活着有那两个条件？ 节点必须可以维护和 ZooKeeper 的连接，Zookeeper 通过⼼跳机制检查每个节点的连接；如果节点是个 follower,他必须能及时的同步 leader 的写操作，延时不能太久。producer 是否直接将数据发送到 broker 的 leader（主节点）？ producer 直接将数据发送到 broker 的 leader(主节点)，不需要在多个节点进⾏分发，为了帮助 producer 做到这点，所有的 Kafka 节点都可以及时的告知:哪些节点是活动的，⽬标topic ⽬标分区的 leader 在哪。这样 producer 就可以直接将消息发送到⽬的地了。
Kafka consumer 是否可以消费指定分区消息吗？ Kafa consumer 消费消息时，向 broker 发出"fetch"请求去消费特定分区的消息，consumer 指定消息在⽇志中的偏移量（offset），就可以消费从这个位置开始的消息，customer 拥有了 offset 的控制权，可以向后回滚去重新消费之前的消息，这是很有意义的。Kafka ⾼效⽂件存储设计特点是什么？ Kafka 把 topic 中⼀个 parition ⼤⽂件分成多个⼩⽂件段，通过多个⼩⽂件段，就容易定期清除或删除已经消费完⽂件，减少磁盘占⽤。通过索引信息可以快速定位 message 和确定 response 的最⼤⼤⼩。通过 index 元数据全部映射到 memory，可以避免 segment file 的 IO 磁盘操作。通过索引⽂件稀疏存储，可以⼤幅降低 index ⽂件元数据占⽤空间⼤⼩。partition 的数据如何保存到硬盘？ topic 中的多个 partition 以⽂件夹的形式保存到 broker，每个分区序号从0 递增，且消息有序。Partition ⽂件下有多个 segment（xxx.index，xxx.log）segment ⽂件⾥的⼤⼩和配置⽂件⼤⼩⼀致可以根据要求修改，默认为1g。如果⼤⼩⼤于1g 时，会滚动⼀个新的 segment 并且以上⼀个 segment 最后⼀条消息的偏移量命名。kafka ⽣产数据时数据的分组策略是怎样的？ ⽣产者决定数据产⽣到集群的哪个 partition 中，每⼀条消息都是以（key， value）格式，Key 是由⽣产者发送数据传⼊，所以⽣产者（key）决定了数据产⽣到集群的哪个 partition。consumer 是推还是拉？ customer 应该从 brokes 拉取消息还是 brokers 将消息推送到 consumer，也就是 pull 还 push。在这⽅⾯，Kafka 遵循了⼀种⼤部分消息系统共同的传统的设计：producer 将消息推送到 broker，consumer 从 broker 拉取消息。 push 模式，将消息推送到下游的 consumer。这样做有好处也有坏处：由 broker 决定消息推送的速率，对于不同消费速率的 consumer 就不太好处理了。消息系统都致⼒于让 consumer 以最⼤的速率最快速的消费消息，但不幸的是，push 模式下，当 broker 推送的速率远⼤于 consumer 消费的速率时， consumer 恐怕就要崩溃了。最终 Kafka 还是选取了传统的 pull 模式。kafka 维护消费状态跟踪的⽅法有什么？ ⼤部分消息系统在 broker 端的维护消息被消费的记录：⼀个消息被分发到 consumer 后 broker 就⻢上进⾏标记或者等待 customer 的通知后进⾏标记。这样也可以在消息在消费后⽴⻢就删除以减少空间占⽤。 是什么确保了 Kafka 中服务器的负载平衡？ 由于领导者的主要⻆⾊是执⾏分区的所有读写请求的任务，⽽追随者被动地复制领导者。因 此，在领导者失败时，其中⼀个追随者接管了领导者的⻆⾊。基本上，整个过程可确保服务 器的负载平衡。
消费者 API 的作⽤是什么？ 允许应⽤程序订阅⼀个或多个主题并处理⽣成给它们的记录流的 API，我们称之为消费者 API。 解释流 API 的作⽤？ ⼀种允许应⽤程序充当流处理器的 API，它还使⽤⼀个或多个主题的输⼊流，并⽣成⼀个输 出流到⼀个或多个输出主题，此外，有效地将输⼊流转换为输出流，我们称之为流 API。 Kafka 为什么那么快? Cache Filesystem Cache PageCache  缓存。 顺序写：由于现代的操作系统提供了预读和写技术，磁盘的顺序写⼤多数情况下⽐随机写内存还要快。Zero-copy  零拷技术减少拷⻉次数。 Batching of Messages  批量处理。合并⼩的请求，然后以流的⽅式进⾏交互，直顶⽹络上限。 Pul- 拉模式  使⽤拉模式进⾏消息的获取消费，与消费端处理能⼒相符。Kafka 系统⼯具有哪些类型？ Kafka 迁移⼯具：它有助于将代理从⼀个版本迁移到另⼀个版本。Mirror Maker：Mirror Maker ⼯具有助于将⼀个 Kafka 集群的镜像提供给另⼀个。 - 消费者检查:对于指定的主题集和消费者组，它显示主题，分区，所有者。partition 的数据如何保存到硬盘 topic  中的多个  partition  以⽂件夹的形式保存到  broker，每个分区序号从  0  递增， 且消息有序。Partition  ⽂件下有多个  segment（xxx.index，xxx.log），segment  ⽂件⾥ 的⼤⼩和配置⽂件⼤⼩⼀致可以根据要求修改默认为  1g。如果⼤⼩⼤于  1g  时，会滚动⼀ 个新的  segment  并且以上⼀个  segment  最后⼀条消息的偏移量命名。 Zookeeper 对于 Kafka 的作⽤是什么？ Zookeeper 是⼀个开放源码的、⾼性能的协调服务，它⽤于 Kafka 的分布式应⽤。 Zookeeper 主要⽤于在集群中不同节点之间进⾏通信。 在 Kafka 中，它被⽤于提交偏移量，因此如果节点在任何情况下都失败了，它都可以从 之前提交的偏移量中获取。 除此之外，它还执⾏其他活动，如: leader 检测、分布式同步、配置管理、识别新节点 何时离开或连接、集群、节点实时状态等等。
流 API 的作⽤是什么？ ⼀种允许应⽤程序充当流处理器的 API，它还使⽤⼀个或多个主题的输⼊流，并⽣成⼀个输 出流到⼀个或多个输出主题，此外，有效地将输⼊流转换为输出流，我们称之为流 API。 Kafka 的流处理是什么意思？ 连续、实时、并发和以逐记录⽅式处理数据的类型，我们称之为 Kafka 流处理。 Kafka 集群中保留期的⽬的是什么？ 保留期限保留了 Kafka 群集中的所有已记录。它不会检查它们是否已被消耗。此外，可以通 过使⽤保留期的配置设置来丢弃记录，⽽且，它可以释放⼀些空间。        Memcached ⾯试题 Memcached 的多线程是什么？如何使⽤它们？ 线程就是定律（threads rule）！在 Steven Grimm 和 Facebook 的努⼒下， Memcached 1.2 及更⾼版本拥有了多线程模式。多线程模式允许 Memcached 能够充分利⽤多个 CPU，并在 CPU 之间共享所有的缓存数据。 Memcached 使⽤⼀种简单的锁机制来保证数据更新操作的互斥。相⽐在同⼀ 个物理机器上运⾏多个 Memcached 实例，这种⽅式能够更有效地处理 multi gets。 如果你的系统负载并不重，也许你不需要启⽤多线程⼯作模式。如果你在运⾏ ⼀个拥有⼤规模硬件的、庞⼤的⽹站，你将会看到多线程的好处。 简单地总结⼀下：命令解析（Memcached 在这⾥花了⼤部分时间）可以运⾏ 在多线程模式下。Memcached 内部对数据的操作是基于很多全局锁的（因此 这部分⼯作不是多线程的）。未来对多线程模式的改进，将移除⼤量的全局锁， 提⾼ Memcached 在负载极⾼的场景下的性能。Memcached 是什么，有什么作⽤？ Memcached 是⼀个开源的，⾼性能的内存绶存软件，从名称上看 Mem 就是 内存的意思，⽽ Cache 就是缓存的意思。Memcached 的作⽤：通过在事先规 划好的内存空间中临时绶存数据库中的各类数据，以达到减少业务对数据库的 直接⾼并发访问，从⽽达到提升数据库的访问性能，加速⽹站集群动态应⽤服务的能⼒。 
Memcached 与 Redis 的区别？ Redis 不仅仅⽀持简单的 K/V类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。⽽ memcache 只⽀持简单数据类型，需要客户 端⾃⼰处理复杂对象。 Redis ⽀持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进⾏使⽤（PS：持久化在 rdb、aof）。 由于 Memcache 没有持久化机制，因此宕机所有缓存数据失效。Redis 配置为持久化，宕机重启后，将⾃动加载宕机时刻的数据到缓存系统中。具 有更好的灾备机制。Memcache 可以使⽤ Magent 在客户端进⾏⼀致性 hash 做分布式。Redis ⽀持在服务器端做分布式（PS:Twemproxy/Codis/Redis-cluster 多 种分布式实现⽅式）。 Memcached 的简单限制就是键（key）和 Value 的限制。最⼤键⻓为 250个字符。可以接受的储存数据不能超过 1MB（可修改配置⽂件变⼤），因 为这是典型 slab  的最⼤值，不适合虚拟机使⽤。⽽ Redis 的 Key ⻓度⽀ 持到 512K。 Redis 使⽤的是单线程模型，保证了数据按顺序提交。Memcache 需要使⽤ cas 保证数据⼀致性。CAS（Check and Set）是⼀个确保并发⼀致性的 机制，属于“乐观锁”范畴；原理很简单：拿版本号，操作，对⽐版本号，如果⼀致就操作，不⼀致就放弃任何操作。 CPU 利⽤：由于 Redis 只使⽤单核，⽽ Memcached 可以使⽤多核，所以平均每⼀个核上 Redis 在存储⼩数据时⽐ Memcached 性能更⾼。⽽在 100k 以上的数据中，Memcached 性能要⾼于 Redis  。 Memcached 内存管理：使⽤ Slab Allocation。原理相当简单，预先分配⼀系列⼤⼩固定的组，然后根据数据⼤⼩选择最合适的块存储。避免了内 存碎⽚。（缺点：不能变⻓，浪费了⼀定空间）Memcached 默认情况下下 ⼀个 slab 的最⼤值为前⼀个的 1.25 倍。 Redis 内存管理：  Redis 通过定义⼀个数组来记录所有的内存分配情况，Redis 采⽤的是包装的 malloc/free，相较于 Memcached 的内存  管理⽅ 法来说，要简单很多。由于 malloc  ⾸先以链表的⽅式搜索已管理的内存 中可⽤的空间分配，导致内存碎⽚⽐较多。 什么是⼆进制协议，我该关注吗？ 关于⼆进制最好的信息当然是⼆进制协议规范： ⼆进制协议尝试为端提供⼀个更有效的、可靠的协议，减少客户端/服务器端因 处理协议⽽产⽣的 CPU 时间。 根据 Facebook 的测试，解析 ASCII协议是 Memcached 中消耗 CPU 时间最 多的环节。所以，我们为什么不改进 ASCII协议呢？ 
如果缓存数据在导出导⼊之间过期了，你⼜怎么处理这些数据 呢？ 因此，批量导出导⼊数据并不像你想象中的那么有⽤。不过在⼀个场景倒是很 有⽤。如果你有⼤量的从不变化的数据，并且希望缓存很快热（warm）起 来，批量导⼊缓存数据是很有帮助的。虽然这个场景并不典型，但却经常发 ⽣，因此我们会考虑在将来实现批量导出导⼊的功能。如果⼀个 Memcached 节点 down 了让你很痛苦，那么你还会陷⼊其他很多麻 烦。你的系统太脆弱了。你需要做⼀些优化⼯作。⽐如处理”惊群”问题（⽐ 如  Memcached 节点都失效了，反复的查询让你的数据库不堪重负…这个问题 在 FAQ 的其他提到过），或者优化不好的查询。记住，Memcached  并不是你 逃避优化查询的借⼝。如何实现集群中的 session 共享存储？ Session 是运⾏在⼀台服务器上的，所有的访问都会到达我们的唯⼀服务器 上，这样我们可以根据客户端传来的 sessionID，来获取 session，或在对应 Session 不存在的情况下（session  ⽣命周期到了/⽤户第⼀次登录），创建⼀个新的 Session；但是，如果我们在集群环境下，假设我们有两台服务器 A， B，⽤户的请求会由 Nginx 服务器进⾏转发（别的⽅案也是同理），⽤户登录时，Nginx 将请求转发⾄服务器 A 上，A 创建了新的 session，并将SessionID 返回给客户端，⽤户在浏览其他⻚⾯时，客户端验证登录状态，Nginx 将请求转发⾄服务器 B，由于 B 上并没有对应客户端发来 sessionId 的 session，所以会重新创建⼀个新的 session，并且再将这个新的 sessionID 返 回给客户端，这样，我们可以想象⼀下，⽤户每⼀次操作都有 1/2 的概率进⾏ 再次的登录，这样不仅对⽤户体验特别差，还会让服务器上的 session 激增， 加⼤服务器的运⾏压⼒。为了解决集群环境下的 seesion 共享问题，共有 4 种解决⽅案：粘性 session 粘性 session 是指 Ngnix 每次都将同⼀⽤户的所有请求转发⾄同⼀台服务器 上，即将⽤户与服务器绑定。服务器 session 复制 即每次 session 发⽣变化时，创建或者修改，就⼴播给所有集群中的服务器， 使所有的服务器上的 session 相同。 session 共享 缓存 session，使⽤ Redis，  Memcached。 session 持久化 将 session 存储⾄数据库中，像操作数据⼀样才做 session。 Memcached 和 MySQL 的 query cache 相⽐，有什么优缺点？ 把 Memcached 引⼊应⽤中，还是需要不少⼯作量的。MySQL 有个使⽤⽅便 的 query cache，可以⾃动地缓存 SQL 查询的结果，被缓存的 SQL 查询可以 被反复地快速执⾏。Memcached 与之相⽐，怎么样呢？MySQL 的 query cache 是集中式的，连接到该 query cache 的 MySQL 服务器都会受益。 当你修改表时，MySQL 的 query cache 会⽴刻被刷新（flush）。存储⼀个 Memcached item 只需要很少的时间，但是当写操作很频繁时，MySQL 的 query cache 会经常让所有缓存数据都失效。 
在多核 CPU 上，MySQL 的 query cache 会遇到扩展问题（scalability issues）。在多核 CPU 上，query cache 会增加⼀个全局锁（global lock）, 由于需要刷新更多的缓存数据，速度会变得更慢。在  MySQL 的 query cache 中，我们是不能存储任意的数据的（只能是 SQL 查询结果）。⽽利⽤ Memcached，我们可以搭建出各种⾼效的缓存。⽐ 如，可以执⾏多个独⽴的查询，构建出⼀个⽤户对象（user object），然后将 ⽤户对象缓存到 Memcached 中。⽽ query cache 是 SQL 语句级别的，不可 能做到这⼀点。在⼩的⽹站中，query cache 会有所帮助，但随着⽹站规模的 增加，query cache 的弊将⼤于利。query cache 能够利⽤的内存容量受到 MySQL 服务器空闲内存空间的限 制。给数据库服务器增加更多的内存来缓存数据，固然是很好的。但是，有了 Memcached，只要你有空闲的内存，都可以⽤来增加 Memcached 集群的规 模，然后你就可以缓存更多的数据。Memcached 是原⼦的吗？ 所有的被发送到 Memcached 的单个命令是完全原⼦的。如果你针对同⼀份数据同时发送了⼀个 set 命令和⼀个 get 命令，它们不会影响对⽅。它们将被串 ⾏化、先后执⾏。即使在多线程模式，所有的命令都是原⼦的，除⾮程序有 bug。 命令序列不是原⼦的。如果你通过 get 命令获取了⼀个 item，修改了它，然后 想把它 set 回 Memcached，我们不保证这个 item 没有被其他进程 （process，未必是操作系统中的进程）操作过。在并发的情况下，你也可能 覆写了⼀个被其他进程 set 的 item。 Memcached 1.2.5 以及更⾼版本，提供了 gets 和 cas 命令，它们可以解决上 ⾯的问题。如果你使⽤ gets 命令查询某个 key 的 item，Memcached 会给你 返回该 item 当前值的唯⼀标识。如果你覆写了这个 item 并想把它写回到 Memcached 中，你可以通过 cas 命令把那个唯⼀标识⼀起发送给 Memcached。如果该 item 存放在 Memcached 中的唯⼀标识与你提供的⼀ 致，你的写操作将会成功。如果另⼀个进程在这期间也修改了这个  item，那 么该 item 存放在 Memcached 中的唯⼀标识将会改变，你的写操作就会失 败。 Memcached 能够更有效地使⽤内存吗？ Memcache 客户端仅根据哈希算法来决定将某个 key 存储在哪个节点上，⽽不 考虑节点的内存⼤⼩。因此，你可以在不同的节点上使⽤⼤⼩不等的缓存。但 是⼀般都是这样做的：拥有较多内存的节点上可以运⾏多个 Memcached 实 例，每个实例使⽤的内存跟其他节点上的实例相同。Memcached 的内存分配器是如何⼯作的？为什么不适⽤ malloc/free？为何要使⽤ slabs？ 实际上，这是⼀个编译时选项。默认会使⽤内部的 slab 分配器。你确实确实应 该使⽤内建的 slab 分配器。最早的时候，Memcached 只使⽤  malloc/free 来管理内存。然⽽，这种⽅式不能与 OS 的内存管理以前很好地⼯作。反复地 malloc/free 造成了内存碎⽚，OS 最终花费⼤量的时间去查找连续的内存块来 满⾜ malloc 的请求，⽽不是运⾏ Memcached 进程。如果你不同意，当然可 以使⽤ malloc。 slab 分配器就是为了解决这个问题⽽⽣的。内存被分配并划分成 chunks，⼀ 直被重复使⽤。因为内存被划分成⼤⼩不等的 slabs，如果 item  的⼤⼩与被选 择存放它的 slab 不是很合适的话，就会浪费⼀些内存。Steven Grimm 正在这 ⽅⾯已经做出了有效的改进。  MongoDB ⾯试题
MongoDB ⾯试题 ObjectID 有哪些部分组成 ⼀共有四部分组成:时间戳、客户端 ID、客户进程 ID、三个字节的增量计数 器。 当我试图更新⼀个正在被迁移的块(chunk)上的⽂档时会发⽣什 么? 更新操作会⽴即发⽣在旧的分⽚(shard)上,然后更改才会在所有权转移 (ownership transfers)前复制到新的分⽚上。 为什么要在 MongoDB 中使⽤分析器 MongoDB 中包括了⼀个可以显示数据库中每个操作性能特点的数据库分析 器。通过这个分析器你可以找到⽐预期慢的查询(或写操作);利⽤这⼀信息,⽐如, 可以确定是否需要添加索引。 解释⼀下 MongoDB 中的索引是什么？ 索引是 MongoDB 中的特殊结构，它以易于遍历的形式存储⼀⼩部分数据集。索引按索引中指定的字段的值排序，存储特定字段或⼀组字段的值。什么是集合（表） 集合就是⼀组  MongoDB  ⽂档。它相当于关系型数据库（RDBMS）中的表这 种概念。集合位于单独的⼀个数据库中。⼀个集合内的多个⽂档可以有多个不 同的字段。⼀般来说，集合中的⽂档都有着相同或相关的⽬的。提到如何检查函数的源代码？ 要检查没有任何括号的函数源代码，必须调⽤该函数。什么是 NoSQL 数据库？NoSQL 和 RDBMS 有什么区别？在哪 些情况下使⽤和不使⽤ NoSQL 数据库？ NoSQL 是⾮关系型数据库，NoSQL = Not Only SQL。 关系型数据库采⽤的结构化的数据，NoSQL 采⽤的是键值对的⽅式存储数据。 在处理⾮结构化/半结构化的⼤数据时；在⽔平⽅向上进⾏扩展时，随时应对动 态增加的数据项时可以优先考虑。 使⽤ NoSQL 数据库。  在考虑数据库的成熟度；⽀持；分析和商业智能；管理 及专业性等问题时，应优先考虑关系型数据库。提及插⼊⽂档的命令语法是什么？ ⽤于插⼊⽂档的命令语法是 database.collection.insert（⽂档）。
如果在⼀个分⽚（shard）停⽌或者很慢的时候,我发起⼀个查询 会怎样? 如果⼀个分⽚（shard）停⽌了，除⾮查询设置了“partial”选项,否则查询会 返回⼀个错误。如果⼀个分⽚（shard）响应很慢，MongoDB 则会等待它的 响应。 如何执⾏事务/加锁？ 因为 MongoDB 设计就是轻量⾼性能，所以没有传统的锁和复杂的事务的回 滚。      Nginx ⾯试题 Nginx 是如何实现⾼并发的？ 如果⼀个  server  采⽤⼀个进程(或者线程)负责⼀个 request 的⽅式，那么进 程数就是并发数。那么显⽽易⻅的，就是会有很多进程在等待中。等什么？最 多的应该是等待⽹络传输。其缺点胖友应该也感觉到了，此处不述。⽽  Nginx  的异步⾮阻塞⼯作⽅式正是利⽤了这点等待的时间。在需要等待的 时候，这些进程就空闲出来待命了。因此表现为少数⼏个进程就解决了⼤量的 并发问题。Nginx 是如何利⽤的呢，简单来说：同样的  4  个进程，如果采⽤⼀个进程负 责⼀个  request  的⽅式，那么，同时进来  4  个  request  之后，每个进程就 负责其中⼀个，直⾄会话关闭。期间，如果有第  5  个 request 进来了。就⽆ 法及时反应了，因为  4  个进程都没⼲完活呢，因此，⼀般有个调度进程，每当 新进来了⼀个  request  ，就新开个进程来处理。Nginx  不这样，每进来⼀个  request  ，会有⼀个  worker  进程去处理。但不 是全程的处理，处理到什么程度呢？处理到可能发⽣阻塞的地⽅，⽐如向上游 （后端）服务器转发  request  ，并等待请求返回。那么，这个处理的  worker 不会这么傻等着，他会在发送完请求后，注册⼀个事件：“如果  upstream  返 回了，告诉我⼀声，我再接着⼲”。于是他就休息去了。此时，如果再有 request  进来，他就可以很快再按这种⽅式处理。⽽⼀旦上游服务器返回了， 就会触发这个事件，worker  才会来接⼿，这个  request  才会接着往下⾛。 这就是为什么说，Nginx  基于事件模型。由于  web server  的⼯作性质决定了每个  request  的⼤部份⽣命都是在⽹络 传输中，实际上花费在  server  机器上的时间⽚不多。这是⼏个进程就解决⾼ 并发的秘密所在。即：webserver  刚好属于⽹络  IO  密集型应⽤，不算是计算密集型。异步，⾮阻 塞，使⽤  epol- ，和⼤量细节处的优化，也正是  Nginx  之所以然的技术基 ⽯。 
请解释 Nginx 如何处理 HTTP 请求。 Nginx  使⽤反应器模式。主事件循环等待操作系统发出准备事件的信号，这样 数据就可以从套接字读取，在该实例中读取到缓冲区并进⾏处理。单个线程可 以提供数万个并发连接。为什么要做动、静分离？ 在我们的软件开发中，有些请求是需要后台处理的（如：.jsp,.do 等等），有些 请求是不需要经过后台处理的（如：css、html、jpg、js 等等），这些不需要 经过后台处理的⽂件称为静态⽂件，否则动态⽂件。因此我们后台处理忽略静 态⽂件，但是如果直接忽略静态⽂件的话，后台的请求次数就明显增多了。在 我们对资源的响应速度有要求的时候，应该使⽤这种动静分离的策略去解决动、静分离将⽹站静态资源（HTML，JavaScript，CSS 等）与后台应⽤分开 部署，提⾼⽤户访问静态代码的速度，降低对后台应⽤访问。这⾥将静态资源 放到 nginx 中，动态资源转发到 tomcat 服务器中,毕竟 Tomcat 的优势是处理 动态请求。nginx 是如何实现⾼并发的？ ⼀个主进程，多个⼯作进程，每个⼯作进程可以处理多个请求，每进来⼀个 request，会有⼀个 worker 进程去处理。但不是全程的处理，处理到可能发⽣ 阻塞的地⽅，⽐如向上游（后端）服务器转发 request，并等待请求返回。那 么，这个处理的 worker 继续处理其他请求，⽽⼀旦上游服务器返回了，就会 触发这个事件，worker 才会来接⼿，这个 request 才会接着往下⾛。由于 web server 的⼯作性质决定了每个 request 的⼤部份⽣命都是在⽹络传输中， 实际上花费在 server 机器上的时间⽚不多。这是⼏个进程就解决⾼并发的秘密 所在。即 webserver 刚好属于⽹络  IO  密集型应⽤，不算是计算密集型。Nginx 静态资源? 静态资源访问，就是存放在 nginx 的 html ⻚⾯，我们可以⾃⼰编写。 Nginx 配置⾼可⽤性怎么配置？ 当上游服务器(真实访问服务器)，⼀旦出现故障或者是没有及时相应的话，应该直接轮训到下⼀台服务器，保证服务器的⾼可⽤。 Nginx 配置代码：server {      listen 80;      server\_name www.lijie.com;cc  nginx 发送给上游服务器(真实访问的服 务器)超时时间          proxy\_send\_timeout 1s;###         nginx 接受上游服务器(真实访问的服务器)超时时间          proxy\_read\_timeout 1s;         index index.html index.htm;
 502 错误可能原因 FastCGI 进程是否已经启动FastCGI worker 进程数是否不够FastCGI 执⾏时间过⻓fastcgi_connect_timeout 300; - fastcgi_send_timeout 300;fastcgi_read_timeout 300;FastCGI Buffer 不够 nginx 和 apache ⼀样，有前端缓冲限制，可以调整缓冲参数 - fastcgi_buffer_size 32k;fastcgi_buffers 8 32k;Proxy Buffer 不够 如果你⽤了 Proxying，调整 proxy_buffer_size 16k;proxy_buffers 4 16k;php 脚本执⾏时间过⻓将 php-fpm.conf 的 0s 的 0s 改成⼀个时间在 Nginx 中，解释如何在 URL 中保留双斜线? 要在  URL 中保留双斜线，就必须使⽤ 语法:merge_slashes [on/off] 默认值: merge_slashes on环境: http，server    merge_slashes_off;Nginx 服务器上的 Master 和 Worker 进程分别是什么? Master 进程：读取及评估配置和维持  ；Worker 进程：处理请求。Nginx 的优缺点？ 优点： 占内存⼩，可实现⾼并发连接，处理响应快。 可实现 HTTP 服务器、虚拟主机、⽅向代理、负载均衡。 - Nginx 配置简单。 可以不暴露正式的服务器 IP 地址。 缺点： 动态处理差，nginx 处理静态⽂件好,耗费内存少，但是处理动态⻚⾯则很鸡 肋，现在⼀般前端⽤ nginx 作为反向代理抗住压⼒。  RabbitMQ     } } 
RabbitMQ RabbitMQ routing 路由模式 
消息⽣产者将消息发送给交换机按照路由判断,路由是字符串(info)  当前产⽣的消息携 带路由字符(对象的⽅法)，交换机根据路由的 key，只能匹配上路由 key 对应的消息队列, 对应的消费者才能消费消息。 根据业务功能定义路由字符串。 从系统的代码逻辑中获取对应的功能字符串,将消息任务扔到对应的队列中。业务场景：error  通知、EXCEPTION、错误通知的功能、传统意义的错误通知、客户 通知、利⽤ key 路由，可以将程序中的错误封装成消息传⼊到消息队列中，开发者可以⾃ 定义消费者，实时接收错误。  消息怎么路由？ 消息提供⽅->路由->⼀⾄多个队列消息发布到交换器时，消息将拥有⼀个路由键 （routing key），在消息创建时设定。通过队列路由键，可以把队列绑定到交换器上。消 息到达交换器后，RabbitMQ  会将消息的路由键与队列的路由键进⾏匹配（针对不同的交换器有不同的路由规则）。 常⽤的交换器主要分为⼀下三种：fanout：如果交换器收到消息，将会⼴播到所有绑定的队列上。 direct：如果路由键完全匹配，消息就被投递到相应的队列。 topic：可以使来⾃不同源头的消息能够到达同⼀个队列。  使⽤  topic  交换器时，可以使⽤通配符。 RabbitMQ publish/subscribe 发布订阅(共享资源) 
每个消费者监听⾃⼰的队列。 ⽣产者将消息发给 broker，由交换机将消息转发到绑定此交换机的每个队列，每个绑定交换机的队列都将接收到消息。 能够在地理上分开的不同数据中⼼使⽤ RabbitMQ cluster 么？ 不能。 第⼀，你⽆法控制所创建的  queue  实际分布在  cluster  ⾥的哪个  node  上（⼀般使⽤HAProxy + cluster  模型时都是这样），这可能会导致各种跨地域访问时的常⻅问题。 第⼆，Erlang  的  OTP  通信框架对延迟的容忍度有限，这可能会触发各种超时，导致业务 疲于处理。 第三，在⼴域⽹上的连接失效问题将导致经典的“脑裂”问题，⽽ RabbitMQ  ⽬前⽆法 处理（该问题主要是说  Mnesia）。 RabbitMQ 有那些基本概念？ Broker：简单来说就是消息队列服务器实体。 Exchange：消息交换机，它指定消息按什么规则，路由到哪个队列。 Queue：消息队列载体，每个消息都会被投⼊到⼀个或多个队列。 Binding：绑定，它的作⽤就是把 exchange 和 queue 按照路由规则绑定起来。 Routing Key：路由关键字，exchange 根据这个关键字进⾏消息投递。 VHost：vhost  可以理解为虚拟  broker  ，即  mini-RabbitMQ server。其内部均含有独⽴的  queue、exchange  和  binding  等，但最最重要的是，其拥有独⽴的权限 系统，可以做到  vhost  范围的⽤户控制。当然，从  RabbitMQ  的全局⻆度，vhost 可以作为不同权限隔离的⼿段（⼀个典型的例⼦就是不同的应⽤可以跑在不同的 vhost  中）。 Producer：消息⽣产者，就是投递消息的程序。 Consumer：消息消费者，就是接受消息的程序。 Channel：消息通道，在客户端的每个连接⾥，可建⽴多个 channel，每个 channel代表⼀个会话任务。 由 Exchange、Queue、RoutingKey 三个才能决定⼀个从 Exchange 到 Queue 的唯⼀的线路。
什么情况下会出现 blackholed 问题？ blackholed  问题是指，向  exchange  投递了  message  ，⽽由于各种原因导致该 message  丢失，但发送者却不知道。可导致  blackholed  的情况：1.向未绑定  queue 的 exchange  发送  message；2.exchange  以  binding_key key_A  绑定了  queue queue_A，但向该  exchange  发送  message  使⽤的  routing_key  却是  key_B。 什么是消费者 Consumer? 消费消息，也就是接收消息的⼀⽅。消费者连接到 RabbitMQ 服务器，并订阅到队列上。消费消息时只消费消息体，丢弃标 签。 消息如何分发？ 若该队列⾄少有⼀个消费者订阅，消息将以循环（round-robin）的⽅式发送给消费者。每条消息只会分发给⼀个订阅的消费者（前提是消费者能够正常处理消息并进⾏ 确认）。 通过路由可实现多消费的功能Basic.Reject 的⽤法是什么？ 该信令可⽤于  consumer  对收到的  message  进⾏  reject  。若在该信令中设置 requeue=true，则当  RabbitMQ server  收到该拒绝信令后，会将该  message  重新发 送到下⼀个处于  consume  状态的  consumer  处（理论上仍可能将该消息发送给当前 consumer）。若设置  requeue=false  ，则  RabbitMQ server  在收到拒绝信令后，将直 接将该 message  从  queue  中移除。 另外⼀种移除  queue  中  message  的⼩技巧是，consumer  回复  Basic.Ack  但不对获 取到的 message  做任何处理。⽽  Basic.Nack  是对  Basic.Reject  的扩展，以⽀持⼀次 拒绝多条  message  的能⼒。 什么是 Binding 绑定？ 通过绑定将交换器和队列关联起来，⼀般会指定⼀个 BindingKey,这样 RabbitMq 就知道 如何正确路由消息到队列了。  分布式 分布式服务接⼝的幂等性如何设计？ 所谓幂等性，就是说⼀个接⼝，多次发起同⼀个请求，你这个接⼝得保证结果是准确得。⽐如不能多扣款。不能多插⼊⼀条数据，不能将统计值多加了1，这就是幂等性。其实保证幂等性主要是三点：对于每个请求必须有⼀个唯⼀的标识，举个例⼦：订单⽀付请求，肯定得包含订单 ID，⼀个订单 ID最多⽀付⼀次。每次处理完请求之后，必须有⼀个记录标识这个请求处理过了，⽐如说常⻅得⽅案是再 mysql 中记录个状态
啥得，⽐如⽀付之前记录⼀条这个订单得⽀付流⽔，⽽且⽀付流⽔采⽤ order id 作为唯⼀键（unique key）。只有成功插⼊这个⽀付流⽔，才可以执⾏实际得⽀付扣款每次接收请求需要进⾏判断之前是否处理过得逻辑处理，⽐如说，如果有⼀个订单已经⽀付了，就已经有了⼀条⽀付流⽔，那么如果重复发送这个请求，则此时先插⼊⽀付流⽔，order id 已经存在了，唯⼀键约束⽣效，报错插⼊不进去得。然后你就不⽤再扣款了。分布式系统中的接⼝调⽤如何保证顺序性？ 可以接⼊ MQ，如果是系统 A使⽤多线程处理的话，可以使⽤内存队列，来保证顺序性，如果你要100%的顺序性，当然可以使⽤分布式锁来搞，会影响系统的并发性。  分布式锁实现原理，⽤过吗？ 在分析分布式锁的三种实现⽅式之前，先了解⼀下分布式锁应该具备哪些条件：1. 在分布式系统环境下，⼀个⽅法在同⼀时间只能被⼀个机器的⼀个线程执⾏；2. ⾼可⽤的获取锁与释放锁；3. ⾼性能的获取锁与释放锁；4. 具备可重⼊特性；5. 具备锁失效机制，防⽌死锁；6. 具备⾮阻塞锁特性，即没有获取到锁将直接返回获取锁失败。分布式的CAP理论告诉我们“任何⼀个分布式系统都⽆法同时满⾜⼀致性（Consistency）、可⽤性（Availability）和分区容错性（Partition tolerance），最多只能同时满⾜两项。”所以，很多系统在设计之初就要对这三者做出取舍。在互联⽹领域的绝⼤多数的场景中，都需要牺牲强⼀致性来换取系统的⾼可⽤性，系统往往只需要保证“最终⼀致性”，只要这个最终时间是在⽤户可以接受的范围内即可。通常分布式锁以单独的服务⽅式实现，⽬前⽐较常⽤的分布式锁实现有三种：基于数据库实现分布式锁。基于缓存（redis，memcached，tair）实现分布式锁。基于Zookeeper实现分布式锁。尽管有这三种⽅案，但是不同的业务也要根据⾃⼰的情况进⾏选型，他们之间没有最好只有更适合！基于数据库的实现⽅式基于数据库的实现⽅式的核⼼思想是：在数据库中创建⼀个表，表中包含⽅法名等字段，并在⽅法名字段上创建唯⼀索引，想要执⾏某个⽅法，就使⽤这个⽅法名向表中插⼊数据，成功插⼊则获取锁，执⾏完成后删除对应的⾏数据释放锁。创建⼀个表：
想要执⾏某个⽅法，就使⽤这个⽅法名向表中插⼊数据：因为我们对method_name做了唯⼀性约束，这⾥如果有多个请求同时提交到数据库的话，数据库会保证只有⼀个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该⽅法的锁，可以执⾏⽅法体内容。成功插⼊则获取锁，执⾏完成后删除对应的⾏数据释放锁：注意：这⾥只是使⽤基于数据库的⼀种⽅法，使⽤数据库实现分布式锁还有很多其他的⽤法可以实现！使⽤基于数据库的这种实现⽅式很简单，但是对于分布式锁应该具备的条件来说，它有⼀些问题需要解决及优化：1、因为是基于数据库实现的，数据库的可⽤性和性能将直接影响分布式锁的可⽤性及性能，所以，数据库需要双机部署、数据同步、主备切换；2、不具备可重⼊的特性，因为同⼀个线程在释放锁之前，⾏数据⼀直存在，⽆法再次成功插⼊数据，所以，需要在表中新增⼀列，⽤于记录当前获取到锁的机器和线程信息，在再次获取锁的时候，先查询表中机器和线程信息是否和当前机器和线程相同，若相同则直接获取锁；3、没有锁失效机制，因为有可能出现成功插⼊数据后，服务器宕机了，对应的数据没有被删除，当服务恢复后⼀直获取不到锁，所以，需要在表中新增⼀列，⽤于记录失效时间，并且需要有定时任务清除这些失效的数据；4、不具备阻塞锁特性，获取不到锁直接返回失败，所以需要优化获取逻辑，循环多次去获取。5、在实施的过程中会遇到各种不同的问题，为了解决这些问题，实现⽅式将会越来越复杂；依赖数据库需要⼀定的资源开销，性能问题需要考虑。基于Redis的实现⽅式选⽤Redis实现分布式锁原因：1. Redis有很⾼的性能；2. Redis命令对此⽀持较好，实现起来⽐较⽅便主要实现⽅式:1. SET lock currentTime+expireTime EX 600 NX，使⽤set设置lock值，并设置过期时间为600秒，如果成功，则获取锁；DROP TABLE IF EXISTS `method_lock`;CREATE TABLE `method_lock` (  `id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',  `method_name` varchar(64) NOT NULL COMMENT '锁定的⽅法名',  `desc` varchar(255) NOT NULL COMMENT '备注信息',  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,  PRIMARY KEY (`id`),  UNIQUE KEY `uidx_method_name` (`method_name`) USING BTREE) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8 COMMENT='锁定中的⽅法';INSERT INTO method_lock (method_name, desc) VALUES ('methodName', '测试的methodName');
delete from method_lock where method_name ='methodName';
2. 获取锁后，如果该节点掉线，则到过期时间ock值⾃动失效；3. 释放锁时，使⽤del删除lock键值；使⽤redis单机来做分布式锁服务，可能会出现单点问题，导致服务可⽤性差，因此在服务稳定性要求⾼的场合，官⽅建议使⽤redis集群（例如5台，成功请求锁超过3台就认为获取锁），来实现redis分布式锁。详⻅RedLock。优点:性能⾼，redis可持久化，也能保证数据不易丢失,redis集群⽅式提⾼稳定性。缺点:使⽤redis主从切换时可能丢失部分数据。基于ZooKeeper的实现⽅式ZooKeeper是⼀个为分布式应⽤提供⼀致性服务的开源组件，它内部是⼀个分层的⽂件系统⽬录树结构，规定同⼀个⽬录下只能有⼀个唯⼀⽂件名。基于ZooKeeper实现分布式锁的步骤如下：1. 创建⼀个⽬录mylock；2. 线程A想获取锁就在mylock⽬录下创建临时顺序节点；3. 获取mylock⽬录下所有的⼦节点，然后获取⽐⾃⼰⼩的兄弟节点，如果不存在，则说明当前线程顺序号最⼩，获得锁；4. 线程B获取所有节点，判断⾃⼰不是最⼩节点，设置监听⽐⾃⼰次⼩的节点；5. 线程A处理完，删除⾃⼰的节点，线程B监听到变更事件，判断⾃⼰是不是最⼩的节点，如果是则获得锁。这⾥推荐⼀个Apache的开源库Curator，它是⼀个ZooKeeper客户端，Curator提供的InterProcessMutex是分布式锁的实现，acquire⽅法⽤于获取锁，release⽅法⽤于释放锁。优点：具备⾼可⽤、可重⼊、阻塞锁特性，可解决失效死锁问题。缺点：因为需要频繁的创建和删除节点，性能上不如Redis⽅式。上⾯的三种实现⽅式，没有在所有场合都是完美的，所以，应根据不同的应⽤场景选择最适合的实现⽅式。在分布式环境中，对资源进⾏上锁有时候是很重要的，⽐如抢购某⼀资源，这时候使⽤分布式锁就可以很好地控制资源。Etcd怎么实现分布式锁? ⾸先思考下Etcd是什么？可能很多⼈第⼀反应可能是⼀个键值存储仓库，却没有重视官⽅定义的后半句，⽤于配置共享和服务发现。实际上，etcd 作为⼀个受到 ZooKeeper 与 doozer 启发⽽催⽣的项⽬，除了拥有与之类似的功能外，更专注于以下四点。简单：基于 HTTP+JSON 的 API 让你⽤ curl 就可以轻松使⽤。安全：可选 SSL 客户认证机制。快速：每个实例每秒⽀持⼀千次写操作。可信：使⽤ Raft 算法充分实现了分布式。但是这⾥我们主要讲述Etcd如何实现分布式锁?因为 Etcd 使⽤ Raft 算法保持了数据的强⼀致性，某次操作存储到集群中的值必然是全局⼀致的，所以很容易实现分布式锁。锁服务有两种使⽤⽅式，⼀是保持独占，⼆是控制时序。A highly-available key value store for shared configuration and service discovery.
保持独占即所有获取锁的⽤户最终只有⼀个可以得到。etcd 为此提供了⼀套实现分布式锁原⼦操作 CAS（CompareAndSwap）的 API。通过设置prevExist值，可以保证在多个节点同时去创建某个⽬录时，只有⼀个成功。⽽创建成功的⽤户就可以认为是获得了锁。控制时序，即所有想要获得锁的⽤户都会被安排执⾏，但是获得锁的顺序也是全局唯⼀的，同时决定了执⾏顺序。etcd 为此也提供了⼀套 API（⾃动创建有序键），对⼀个⽬录建值时指定为POST动作，这样 etcd 会⾃动在⽬录下⽣成⼀个当前最⼤的值为键，存储这个新的值（客户端编号）。同时还可以使⽤ API 按顺序列出所有当前⽬录下的键值。此时这些键的值就是客户端的时序，⽽这些键中存储的值可以是代表客户端的编号。在这⾥Ectd实现分布式锁基本实现原理为：1. 在ectd系统⾥创建⼀个key2. 如果创建失败，key存在，则监听该key的变化事件，直到该key被删除，回到13. 如果创建成功，则认为我获得了锁应⽤示例:package etcdsyncimport (    "fmt"    "io"    "os"    "sync"    "time"    "github.com/coreos/etcd/client"    "github.com/coreos/etcd/Godeps/_workspace/src/golang.org/x/net/context")const (    defaultTTL = 60    defaultTry = 3    deleteAction = "delete"    expireAction = "expire")// A Mutex is a mutual exclusion lock which is distributed across a cluster.type Mutex struct {    key    string    id     string // The identity of the caller    client client.Client    kapi   client.KeysAPI    ctx    context.Context    ttl    time.Duration    mutex  *sync.Mutex    logger io.Writer}// New creates a Mutex with the given key which must be the same// across the cluster nodes.
// machines are the ectd cluster addressesfunc New(key string, ttl int, machines []string) *Mutex {    cfg := client.Config{        Endpoints:               machines,        Transport:               client.DefaultTransport,        HeaderTimeoutPerRequest: time.Second,    }    c, err := client.New(cfg)    if err != nil {        return nil    }    hostname, err := os.Hostname()    if err != nil {        return nil    }    if len(key) == 0 || len(machines) == 0 {        return nil    }    if key[0] != '/' {        key = "/" + key    }    if ttl < 1 {        ttl = defaultTTL    }    return &Mutex{        key:    key,        id:     fmt.Sprintf("%v-%v-%v", hostname, os.Getpid(), time.Now().Format("20060102-15:04:05.999999999")),        client: c,        kapi:   client.NewKeysAPI(c),        ctx: context.TODO(),        ttl: time.Second * time.Duration(ttl),        mutex:  new(sync.Mutex),    }}// Lock locks m.// If the lock is already in use, the calling goroutine// blocks until the mutex is available.func (m *Mutex) Lock() (err error) {    m.mutex.Lock()    for try := 1; try <= defaultTry; try++ {        if m.lock() == nil {
            return nil        }                m.debug("Lock node %v ERROR %v", m.key, err)        if try < defaultTry {            m.debug("Try to lock node %v again", m.key, err)        }    }    return err}func (m *Mutex) lock() (err error) {    m.debug("Trying to create a node : key=%v", m.key)    setOptions := &client.SetOptions{        PrevExist:client.PrevNoExist,        TTL:      m.ttl,    }    resp, err := m.kapi.Set(m.ctx, m.key, m.id, setOptions)    if err == nil {        m.debug("Create node %v OK [%q]", m.key, resp)        return nil    }    m.debug("Create node %v failed [%v]", m.key, err)    e, ok := err.(client.Error)    if !ok {        return err    }    if e.Code != client.ErrorCodeNodeExist {        return err    }    // Get the already node's value.    resp, err = m.kapi.Get(m.ctx, m.key, nil)    if err != nil {        return err    }    m.debug("Get node %v OK", m.key)    watcherOptions := &client.WatcherOptions{        AfterIndex : resp.Index,        Recursive:false,    }    watcher := m.kapi.Watcher(m.key, watcherOptions)    for {        m.debug("Watching %v ...", m.key)        resp, err = watcher.Next(m.ctx)        if err != nil {            return err        }
其实类似的实现有很多，但⽬前都已经过时，使⽤的都是被官⽅标记为deprecated的项⽬。且⼤部分接⼝都不如上述代码简单。 使⽤上，跟Golang官⽅sync包的Mutex接⼝⾮常类似，先New()，然后调⽤Lock()，使⽤完后调⽤Unlock()，就三个接⼝，就是这么简单。示例代码如下：        m.debug("Received an event : %q", resp)        if resp.Action == deleteAction || resp.Action == expireAction {            return nil        }    }}// Unlock unlocks m.// It is a run-time error if m is not locked on entry to Unlock.//// A locked Mutex is not associated with a particular goroutine.// It is allowed for one goroutine to lock a Mutex and then// arrange for another goroutine to unlock it.func (m *Mutex) Unlock() (err error) {    defer m.mutex.Unlock()    for i := 1; i <= defaultTry; i++ {        var resp *client.Response        resp, err = m.kapi.Delete(m.ctx, m.key, nil)        if err == nil {            m.debug("Delete %v OK", m.key)            return nil        }        m.debug("Delete %v falied: %q", m.key, resp)        e, ok := err.(client.Error)        if ok && e.Code == client.ErrorCodeKeyNotFound {            return nil        }    }    return err}func (m *Mutex) debug(format string, v ...interface{}) {    if m.logger != nil {        m.logger.Write([]byte(m.id))        m.logger.Write([]byte(" "))        m.logger.Write([]byte(fmt.Sprintf(format, v...)))        m.logger.Write([]byte("\n"))    }}func (m *Mutex) SetDebugLogger(w io.Writer) {    m.logger = w}
  说说 ZooKeeper ⼀般都有哪些使⽤场景？ 分布式协调：这个其实就是 zk 很经典的⼀个⽤法，简单来说，就好⽐，你系统 A发送个请求到 mq，然后 B消费了之后处理。那 A系统如何指导 B系统的处理结果？⽤ zk 就可以实现分布式系统之间的协调⼯作。A系统发送请求之后可以在 zk 上对某个节点的值注册个监听器，⼀旦 B系统处理完了就修改 zk 那个节点的值，A⽴⻢就可以收到通知，完美解决。分布所锁：对某⼀个数据联系发出两个修改操作，两台机器同时收到请求，但是只能⼀台机器先执⾏另外⼀个机器再执⾏，那么此时就可以使⽤ zk 分布式锁，⼀个机器接收到了请求之后先获取 zk 上的⼀把分布式锁，就是可以去创建⼀个 znode，接着执⾏操作，然后另外⼀个机器也尝试去创建那个 znode，结果发现⾃⼰创建不了，因为被别⼈创建了，那只能等着，等等⼀个机器执⾏完了⾃⼰再执⾏。配置信息管理：zk 可以⽤作很多系统的配置信息的管理，⽐如 kafka，storm 等等很多分布式系统都会选⽤ zk 来做⼀些元数据，配置信息的管理，包括 dubbo 注册中⼼不也⽀持 zk 么。package mainimport (    "github.com/zieckey/etcdsync"    "log")func main() {    //etcdsync.SetDebug(true)    log.SetFlags(log.Ldate|log.Ltime|log.Lshortfile)    m := etcdsync.New("/etcdsync", "123", []string{"http://127.0.0.1:2379"})    if m == nil {        log.Printf("etcdsync.NewMutex failed")    }    err := m.Lock()    if err != nil {        log.Printf("etcdsync.Lock failed")    } else {        log.Printf("etcdsync.Lock OK")    }    log.Printf("Get the lock. Do something here.")    err = m.Unlock()    if err != nil {        log.Printf("etcdsync.Unlock failed")    } else {        log.Printf("etcdsync.Unlock OK")    }}
HA⾼可⽤性：这个应该是很常⻅的，⽐如 hdfs，yarn 等很多⼤数据系统，都选择基于 zk 来开发 HA⾼可⽤机制，就是⼀个重要进程⼀般会主备两个，主进程挂了⽴⻢通过 zk 感知到切换到备份进程。说说你们的分布式 session ⽅案是啥？怎么做的？ Tomcat + redis 其实还挺⽅便的，就是使⽤ session 的代码跟以前⼀样，还是基于 tomcat 原⽣的 session ⽀持即可，然后就是⽤⼀个叫做 tomcat RedisSessionManager 的东⻄，让我们部署的 tomcat 都将 session 数据存储到 redis 即可.Spring Session + redis 分布式会话的这个东⻄重耦合在 tomcat，如果我要将 web容器迁移成 jetty，不能重新把 jetty 都配置⼀遍.所以现在⽐较好⽤的还是基于 java 的⼀站式解决⽅案，使⽤ spring session 是⼀个很好的选择，给 spring session 配置基于 redis 来存储 session 数据，然后配置⼀个 spring session 的过滤器，这样的话，session 相关操作都会交给 spring session 来管了。接着在代码中，就是⽤原⽣的 session 操作，就是直接基于 spring session 从 redis 中获取数据了。分布式事务了解吗？ XA⽅案/两阶段提交⽅案第⼀个阶段（先询问）第⼆个阶段（再执⾏）TCC⽅案TCC的全程是：Try、Confirm、Cancel 这个其实是⽤到了补偿的概念，分为了三个阶段Try 阶段：这个阶段说的是对各个服务的资源做检测以及对资源进⾏锁定或者预留Confirm 阶段：这个阶段说的是在各个服务中执⾏实际的操作Cancel 阶段：如果任何⼀个服务的业务⽅法执⾏出错，那么这⾥就需要进⾏补偿，就是执⾏已经成功的业务逻辑的回滚操作本地消息表可靠消息最终⼀致性⽅案最⼤努⼒通知⽅案那常⻅的分布式锁有哪些解决⽅案？ Reids 的分布式锁，很多⼤公司会基于 Reidis 做扩展开发基于 Zookeeper 基于数据库，⽐如 Mysql 
ZK 和 Redis 的区别，各⾃有什么优缺点？ 先说 Redis：Redis 只保证最终⼀致性，副本间的数据复制是异步进⾏（Set 是写，Get 是读，Reids 集群⼀般是读写分离架构，存在主从同步延迟情况），主从切换之后可能有部分数据没有复制过去可能会丢失锁情况，故强⼀致性要求的业务不推荐使⽤ Reids，推荐使⽤ zk。Redis 集群各⽅法的响应时间均为最低。随着并发量和业务数量的提升其响应时间会有明显上升（公有集群影响因素偏⼤），但是极限 qps 可以达到最⼤且基本⽆异常。再说 ZK：使⽤ ZooKeeper 集群，锁原理是使⽤ ZooKeeper 的临时节点，临时节点的⽣命周期在 Client 与集群的 Session 结束时结束。因此如果某个 Client 节点存在⽹络问题，与 ZooKeeper 集群断开连接，Session 超时同样会导致锁被错误的释放（导致被其他线程错误地持有），因此 ZooKeeper 也⽆法保证完全⼀致。ZK具有较好的稳定性；响应时间抖动很⼩，没有出现异常。但是随着并发量和业务数量的提升其响应时间和 qps 会明显下降。MySQL 如何做分布式锁？ ⽅法⼀：利⽤ Mysql 的锁表，创建⼀张表，设置⼀个 UNIQUE KEY 这个 KEY 就是要锁的 KEY，所以同⼀个 KEY 在 mysql 表⾥只能插⼊⼀次了，这样对锁的竞争就交给了数据库，处理同⼀个 KEY 数据库保证了只有⼀个节点能插⼊成功，其他节点都会插⼊失败。DB分布式锁的实现：通过主键 id 的唯⼀性进⾏加锁，说⽩了就是加锁的形式是向⼀张表中插⼊⼀条数据，该条数据的 id 就是⼀把分布式锁，例如当⼀次请求插⼊了⼀条 id 为1 的数据，其他想要进⾏插⼊数据的并发请求必须等第⼀次请求执⾏完成后删除这条 id 为1 的数据才能继续插⼊，实现了分布式锁的功能。⽅法⼆：使⽤流⽔号+时间戳做幂等操作，可以看作是⼀个不会释放的锁。你了解业界哪些⼤公司的分布式锁框架 Google:Chubby Chubby是⼀套分布式协调系统，内部使⽤ Paxos 协调 Master 与 Replicas。 Chubby lock service 被应⽤在 GFS, BigTable 等项⽬中，其⾸要设计⽬标是⾼可靠性，⽽不是⾼性能。Chubby被作为粗粒度锁使⽤，例如被⽤于选主。持有锁的时间跨度⼀般为⼩时或天，⽽不是秒级。Chubby对外提供类似于⽂件系统的 API，在 Chubby创建⽂件路径即加锁操作。 Chubby使⽤ Delay 和 SequenceNumber来优化锁机制。Delay 保证客户端异常释放锁时，Chubby仍认为该客户端⼀直持有锁。Sequence number 指锁的持有者向 Chubby服务端请求⼀个序号（包括⼏个属性），然后之后在需要使⽤锁的时候将该序号⼀并发给 Chubby 服务器，服务端检查序号的合法性，包括 number 是否有效等。京东 SharkLock  SharkLock 是基于 Redis 实现的分布式锁。锁的排他性由 SETNX原语实现，使⽤ timeout 与续租机制实现锁的强制释放。
蚂蚁⾦服 SOFAJRaft-RheaKV 分布式锁 RheaKV 是基于 SOFAJRaft 和 RocksDB 实现的嵌⼊式、分布式、⾼可⽤、强⼀致的 KV 存储类库。RheaKV对外提供 lock 接⼝，为了优化数据的读写，按不同的存储类型，提供不同的锁特性。RheaKV提供 wathcdog 调度器来控制锁的⾃动续租机制，避免锁在任务完成前提前释放，和锁永不释放造成死锁。Netflix: Curator Curator 是 ZooKeeper 的客户端封装，其分布式锁的实现完全由 ZooKeeper 完成。在 ZooKeeper 创建 EPHEMERAL_SEQUENTIAL节点视为加锁，节点的 EPHEMERAL特性保证了锁持有者与 ZooKeeper 断开时强制释放锁；节点的 SEQUENTIAL特性避免了加锁较多时的惊群效应。请讲⼀下你对 CAP 理论的理解 在理论计算机科学中，CAP定理（CAP theorem），⼜被称作布鲁尔定理Brewer’s theorem），它指出对于⼀个分布式计算系统来说，不可能同时满⾜以下三点：Consistency（⼀致性）指数据在多个副本之间能够保持⼀致的特性（严格的⼀致性）Availability（可⽤性）指系统提供的服务必须⼀直处于可⽤的状态，每次请求都能获取到⾮错的响应（不保证获取的数据为最新数据）Partition tolerance（分区容错性）分布式系统在遇到任何⽹络分区故障的时候，仍然能够对外提供满⾜⼀致性和可⽤性的服务，除⾮整个⽹络环境都发⽣了故障Spring Cloud 在 CAP法则上主要满⾜的是 A和 P法则，Dubbo和 Zookeeper 在 CAP法则主要满⾜的是 C和 P法则。CAP仅适⽤于原⼦读写的 NOSQL场景中，并不适合数据库系统。现在的分布式系统具有更多特性⽐如扩展性、可⽤性等等，在进⾏系统设计和开发时，我们不应该仅仅局限在 CAP问题上。现实⽣活中，⼤部分⼈解释这⼀定律时，常常简单的表述为：“⼀致性、可⽤性、分区容忍性三者你只能同时达到其中两个，不可能同时达到”。实际上这是⼀个⾮常具有误导性质的说法，⽽且在 CAP理论诞⽣12 年之后，CAP之⽗也在2012 年重写了之前的论⽂。当发⽣⽹络分区的时候，如果我们要继续服务，那么强⼀致性和可⽤性只能2 选1。也就是说当⽹络分区之后 P是前提，决定了 P之后才有 C和 A的选择。也就是说分区容错性（Partition tolerance）我们是必须要实现的。请讲⼀下你对 BASE 理论的理解 BASE理论由 eBay架构师 Dan Pritchett 提出，在2008 年上被分表为论⽂，并且 eBay给出了他们在实践中总结的基于 BASE理论的⼀套新的分布式事务解决⽅案。BASE 是 Basically Available（基本可⽤）、Soft-state（软状态）和 Eventually Consistent（最终⼀致性）三个短语的缩写。BASE理论是对 CAP 中⼀致性和可⽤性权衡的结果，其来源于对⼤规模互联⽹系统分布式实践的总结，是基于 CAP定理逐步演化⽽来的，它⼤⼤降低了我们对系统的要求。 BASE理论的核⼼思想是即使⽆法做到强⼀致性，但每个应⽤都可以根据⾃身业务特点，采⽤适当的⽅式来使系统达到最终⼀致性。也就是牺牲数据的⼀致性来满⾜系统的⾼可⽤性，系统中⼀部分数据不可⽤或者不⼀致时，仍需要保持系统整体“主要可⽤”。针对数据库领域，BASE思想的主要实现是对业务数据进⾏拆分，让不同的数据分布在不同的机器上，以提升系统的可⽤性，当前主要有以下两种做法：按功能划分数据库分⽚（如开源的 Mycat、Amoeba等）。
分布式与集群的区别是什么？ 分布式：⼀个业务分拆多个⼦业务，部署在不同的服务器上集群：同⼀个业务，部署在多个服务器上。⽐如之前做电商⽹站搭的 redis 集群以及 solr 集群都是属于将 redis 服务器提供的缓存服务以及 solr 服务器提供的搜索服务部署在多个服务器上以提⾼系统性能、并发量解决海量存储问题。请讲⼀下 BASE 理论的三要素 基本可⽤基本可⽤是指分布式系统在出现不可预知故障的时候，允许损失部分可⽤性。但是，这绝不等价于系统不可⽤。⽐如：响应时间上的损失：正常情况下，⼀个在线搜索引擎需要在0.5 秒之内返回给⽤户相应的查询结果，但由于出现故障，查询结果的响应时间增加了1~2秒系统功能上的损失：正常情况下，在⼀个电⼦商务⽹站上进⾏购物的时候，消费者⼏乎能够顺利完成每⼀笔订单，但是在⼀些节⽇⼤促购物⾼峰的时候，由于消费者的购物⾏为激增，为了保护购物系统的稳定性，部分消费者可能会被引导到⼀个降级⻚⾯软状态软状态指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可⽤性，即允许系统在不同节点的数据副本之间进⾏数据同步的过程存在延时。最终⼀致性强调的是系统中所有的数据副本，在经过⼀段时间的同步后，最终能够达到⼀个⼀致的状态。因此，最终⼀致性的本质是需要系统保证最终数据能够达到⼀致，⽽不需要实时保证系统数据的强⼀致性。请说⼀下对两阶段提交协议的理解 分布式系统的⼀个难点是如何保证架构下多个节点在进⾏事务性操作的时候保持⼀致性。为实现这个⽬的，⼆阶段提交算法的成⽴基于以下假设：该分布式系统中，存在⼀个节点作为协调者(Coordinator)，其他节点作为参与者(Cohorts)。且节点之间可以进⾏⽹络通信。所有节点都采⽤预写式⽇志，且⽇志被写⼊后即被保持在可靠的存储设备上，即使节点损坏不会导致⽇志数据的消失。所有节点不会永久性损坏，即使损坏后仍然可以恢复。## 第⼀阶段（投票阶段）协调者节点向所有参与者节点询问是否可以执⾏提交操作(vote)，并开始等待各参与者节点的响应。参与者节点执⾏询问发起为⽌的所有事务操作，并将 Undo信息和 Redo信息写⼊⽇志。（注意：若成功这⾥其实每个参与者已经执⾏了事务操作）各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执⾏成功，则它返回⼀个”同意”消息；如果参与者节点的事务操作实际执⾏失败，则它返回⼀个”中⽌”消息。第⼆阶段（提交执⾏阶段）当协调者节点从所有参与者节点获得的相应消息都为”同意”：协调者节点向所有参与者节点发出”正式提交(commit)”的请求。参与者节点正式完成操作，并释放在整个事务期间内占⽤的资源。参与者节点向协调者节点发送”完成”消息。协调者节点受到所有参与者节点反馈的”完成”消息后，完成事务。如果任⼀参与者节点在第⼀阶段返回的响应
消息为”中⽌”：协调者节点向所有参与者节点发出”回滚操作(rollback)”的请求。参与者节点利⽤之前写⼊的 Undo信息执⾏回滚，并释放在整个事务期间内占⽤的资源。参与者节点向协调者节点发送”回滚完成”消息。协调者节点受到所有参与者节点反馈的”回滚完成”消息后，取消事务。请讲⼀下对 TCC 协议的理解 Try Confirm Cancel Try：尝试待执⾏的业务，这个过程并未执⾏业务，只是完成所有业务的⼀致性检查，并预留好执⾏所需的全部资源。Confirm：执⾏业务，这个过程真正开始执⾏业务，由于 Try 阶段已经完成了⼀致性检查，因此本过程直接执⾏，⽽不做任何检查。并且在执⾏的过程中，会使⽤到 Try 阶段预留的业务资源。Cancel：取消执⾏的业务，若业务执⾏失败，则进⼊ Cancel 阶段，它会释放所有占⽤的业务资源，并回滚 Confirm 阶段执⾏的操作。    ClickHouse ⾯试题 什么是 ClickHouse？ ClickHouse 是近年来备受关注的开源列式数据库管理系统，主要⽤于数据分析 （OLAP）领域。通过向量化执⾏以及对 cpu 底层指令集（SIMD）的使⽤，它 可以对海量数据进⾏并⾏处理，从⽽加快数据的处理速度。ClickHouse 从 OLAP 场景需求出发，定制开发了⼀套全新的⾼效列式存储引擎，并且实现了数据有序 存储、主键索引、稀疏索引、数据 Sharding、数据 Partitioning、TTL、主备复 制等丰富功能。ClickHouse 有哪些应⽤场景？ 1. 绝⼤多数请求都是⽤于读访问的；2. 数据需要以⼤批次（⼤于 1000 ⾏）进⾏更新，⽽不是单⾏更新；3. 数据只是添加到数据库，没有必要修改；4. 读取数据时，会从数据库中提取出⼤量的⾏，但只⽤到⼀⼩部分列；5. 表很“宽”，即表中包含⼤量的列；6. 查询频率相对较低（通常每台服务器每秒查询数百次或更少）；7. 对于简单查询，允许⼤约 50 毫秒的延迟；8. 列的值是⽐较⼩的数值和短字符串（例如，每个 URL只有 60 个字节）；9. 在处理单个查询时需要⾼吞吐量（每台服务器每秒⾼达数⼗亿⾏）；10. 不需要事务；11. 数据⼀致性要求较低； 12. 每次查询中只会查询⼀个⼤表。除了⼀个⼤表，其余都是⼩表；13. 查询结果显著⼩于数据源。即数据有过滤或聚合。返回结果不超过单个服务 器内存。 
ClickHouse 列式存储的优点有哪些？ 当分析场景中往往需要读⼤量⾏但是少数⼏个列时，在⾏存模式下，数据按⾏连续存储，所有列的数据都存储在⼀个 block 中，不参与计算的列在 IO 时也要全部读出，读取操作被严重放⼤。⽽列存模式下，只需要读取参与计 算的列即可，极⼤的减低了 IO cost，加速了查询。同⼀列中的数据属于同⼀类型，压缩效果显著。列存往往有着⾼达⼗倍甚⾄更⾼的压缩⽐，节省了⼤量的存储空间，降低了存储成本。更⾼的压缩⽐意味着更⼩的 data size，从磁盘中读取相应数据耗时更短。 - ⾃由的压缩算法选择。不同列的数据具有不同的数据类型，适⽤的压缩算法也就不尽相同。可以针对不同列类型，选择最合适的压缩算法。⾼压缩⽐，意味着同等⼤⼩的内存能够存放更多数据，系统 cache 效果更好。 ClickHouse 的缺点是是什么？ 不⽀持事务，不⽀持真正的删除/更新； - 不⽀持⼆级索引； join 实现与众不同； 不⽀持窗⼝功能； 元数据管理需要⼈为⼲预。 ClickHouse 的架构是怎样的？  ClickHouse  采⽤典型的分组式的分布式架构，其中：Shard。集群内划分为多个分⽚或分组（Shard 0 … Shard N），通过 Shard的线性扩展能⼒，⽀持海量数据的分布式存储计算。Node。每个 Shard 内包含⼀定数量的节点（Node，即进程），同⼀ Shard 内的节点互为副本，保障数据可靠。ClickHouse 中副本数可按需建设，且逻辑上不同 Shard 内的副本数可不同。ZooKeeper Service。集群所有节点对等，节点间通过 ZooKeeper 服务进⾏分布式协调。ClickHouse 的逻辑数据模型？ 从⽤户使⽤⻆度看，ClickHouse  的逻辑数据模型与关系型数据库有⼀定的相似： ⼀个集群包含多个数据库，⼀个数据库包含多张表，表⽤于实际存储数据。 
ClickHouse 的核⼼特性？ 列存储：列存储是指仅从存储系统中读取必要的列数据，⽆⽤列不读取，速度⾮常快。ClickHouse 采⽤列存储，这对于分析型请求⾮常⾼效。⼀个典型 且真实的情况是，如果我们需要分析的数据有  50 列，⽽每次分析仅读取其 中的  5  列，那么通过列存储，我们仅需读取必要的列数据，相⽐于普通⾏存，可减少  10  倍左右的读取、解压、处理等开销，对性能会有质的影响。向量化执⾏：在⽀持列存的基础上，ClickHouse  实现了⼀套⾯向  向量化处理  的计算引擎，⼤量的处理操作都是向量化执⾏的。相⽐于传统⽕⼭模型中 的逐⾏处理模式，向量化执⾏引擎采⽤批量处理模式，可以⼤幅减少函数调 ⽤开销，降低指令、数据的  Cache Miss，提升  CPU  利⽤效率。并且 ClickHouse  可 利 ⽤  SIMD  指 令 进 ⼀ 步 加 速 执 ⾏ 效 率 。 这 部 分 是 ClickHouse  优于⼤量同类  OLAP  产品的重要因素。编码压缩：由于  ClickHouse  采⽤列存储，相同列的数据连续存储，且底层数据在存储时是经过排序的，这样数据的局部规律性⾮常强，有利于获得更 ⾼的数据压缩⽐。此外，ClickHouse  除了⽀持  LZ### ZSTD  等通⽤压缩算 法外，还⽀持  Delta、DoubleDelta、Gorilla  等专⽤编码算法，⽤于进⼀步 提⾼数据压缩⽐。多索引：列存⽤于裁剪不必要的字段读取，⽽索引则⽤于裁剪不必要的记录读取。ClickHouse ⽀持丰富的索引，从⽽在查询时尽可能的裁剪不必要的 记录读取，提⾼查询性能。使⽤ ClickHouse 时有哪些注意点？ 分区和索引 分区粒度根据业务特点决定，不宜过粗或过细。⼀般选择按天分区，也可指定为tuple()；以单表 1 亿数据为例，分区⼤⼩控制在 10-30 个为最佳。必须指定索引列，clickhouse 中的索引列即排序列，通过 order by 指定，⼀般 在查询条件中经常被⽤来充当筛选条件的属性被纳⼊进来；可以是单⼀维度，也 可以是组合维度的索引；通常需要满⾜⾼级列在前、查询频率⼤的在前原则；还 有基数特别⼤的不适合做索引列，如⽤户表的 userid 字段；通常筛选后的数据 满⾜在百万以内为最佳。数据采样策略 通过采⽤运算可极⼤提升数据分析的性能。数据量太⼤时应避免使⽤ select *  操作，查询的性能会与查询的字段⼤⼩和数 量成线性变换；字段越少，消耗的 IO 资源就越少，性能就会越⾼。 千万以上数据集⽤ order by 查询时需要搭配 where 条件和 limit 语句⼀起使⽤。如⾮必须不要在结果集上构建虚拟列，虚拟列⾮常消耗资源浪费性能，可以考虑 在前端进⾏处理，或者在表中构造实际字段进⾏额外存储。 不建议在⾼基列上执⾏ distinct 去重查询，改为近似去重  uniqCombined。 多表 Join 时要满⾜⼩表在右的原则，右表关联时被加载到内存中与左表进⾏⽐ 较。 存储 ClickHouse 不⽀持设置多数据⽬录，为了提升数据 ⼀个券组绑定多块物理磁盘提升读写性能；多数查询场景 硬盘快 2-3 倍。  io 性能，可以挂载虚拟券组，SSD 盘会⽐普通机械
ClickHouse 的引擎有哪些？ ClickHouse 提供了⼤量的数据引擎，分为数据库引擎、表引擎，根据数据特点 及使⽤场景选择合适的引擎⾄关重要。ClickHouse 引擎分类  在以下⼏种情况下，ClickHouse 使⽤⾃⼰的数据库引擎：决定表存储在哪⾥以及以何种⽅式存储； - ⽀持哪些查询以及如何⽀持； 并发数据访问； 索引的使⽤； 是否可以执⾏多线程请求； 数据复制参数。 在所有的表引擎中，最为核⼼的当属 MergeTree 系列表引擎，这些表引擎拥有 最为强⼤的性能和最⼴泛的使⽤场合。对于⾮ MergeTree 系列的其他引擎⽽⾔， 主要⽤于特殊⽤途，场景相对有限。⽽ MergeTree 系列表引擎是官⽅主推的存 储引擎，⽀持⼏乎所有 ClickHouse 核⼼功能。MergeTree 作为家族系列最基础的表引擎，主要有以下特点：存储的数据按照主键排序：允许创建稀疏索引，从⽽加快数据查询速度； - ⽀持分区，可以通过 PRIMARY KEY语句指定分区字段； ⽀持数据副本； ⽀持数据采样。 建表引擎参数有哪些？ ENGINE：ENGINE = MergeTree()，MergeTree 引擎没有参数。ORDER BY：order by  设定了分区内的数据按照哪些字段顺序进⾏有序保 存。 order by 是 MergeTree 中唯⼀⼀个必填项，甚⾄⽐ primary key  还重要，因 为当⽤户不设置主键的情况，很多处理会依照 order by 的字段进⾏处理。 要求：主键必须是 order by 字段的前缀字段。如果 ORDER BY与 PRIMARY KEY不同，PRIMARY KEY必须是 ORDER BY的 前缀(为了保证分区内数据和主键的有序性)。 ORDER BY 决定了每个分区中数据的排序规则; PRIMARY KEY 决定了⼀级索引(primary.idx); ORDER BY 可以指代 PRIMARY KEY, 通常只⽤声明 ORDER BY 即可。 PARTITION BY：分区字段，可选。如果不填：只会使⽤⼀个分区。 分区⽬录：MergeTree  是以列⽂件+索引⽂件+表定义⽂件组成的，但是如果设 定了分区那么这些⽂件就会保存到不同的分区⽬录中。PRIMARY KEY：指定主键，如果排序字段与主键不⼀致，可以单独指定主 键字段。否则默认主键是排序字段。可选。SAMPLE BY：采样字段，如果指定了该字段，那么主键中也必须包含该字 段。⽐如 SAMPLE BY intHash32(UserID) ORDER BY (CounterID, EventDate, intHash32(UserID))。可选。 
TTL：数据的存活时间。在 MergeTree 中，可以为某个列字段或整张表设置 TTL。当时间到达时，如果是列字段级别的 TTL，则会删除这⼀列的数据；如果 是表级别的 TTL，则会删除整张表的数据。可选。SETTINGS：额外的参数配置。可选。  Elasticsearch ⾯试题 Elasticsearch 读取数据 使⽤ RestFul API 向对应的 node 发送查询请求，根据 did 来判断在哪个 shard 上，返回的是 primary 和 replica 的 node 节点集合。 这样会负载均衡地把查询发送到对应节点，之后对应节点接收到请求，将document 数据返回协调节点，协调节点把 document 返回给客户端。 
您能解释⼀下 X-Pack for Elasticsearch 的功能和重要性吗？ X-Pack  是与 Elasticsearch ⼀起安装的扩展程序。X-Pack 的各种功能包括安全性（基于⻆⾊的访问，特权/权限，⻆⾊和⽤户安 全性），监视，报告，警报等。Elasticsearch 中的节点（⽐如共 20 个），其中的 10 个选了 ⼀个master，另外 10 个选了另⼀个 master，怎么办？ 当集群  master  候选数量不⼩于  3  个时，可以通过设置最少投票通过数量（discovery.zen.minimum_master_nodes）超过所有候选节点⼀半以上 来解决脑裂问题；当候选数量为两个时，只能修改为唯⼀的⼀个  master  候选，其他作为data 节点，避免脑裂问题。
解释⼀下 Elasticsearch 集群中的 索引的概念 ？ Elasticsearch  集群可以包含多个索引，与关系数据库相⽐，它们相当于数据库 表。 你可以列出 Elasticsearch 各种类型的分析器吗？ Elasticsearch Analyzer  的类型为内置分析器和⾃定义分析器。 Standard Analyzer 标准分析器是默认分词器，如果未指定，则使⽤该分词器。 它基于 Unicode ⽂本分割算法，适⽤于⼤多数语⾔。Whitespace Analyzer基于空格字符切词。Stop Analyzer 在 simple Analyzer 的基础上，移除停⽤词。Keyword Analyzer 不切词，将输⼊的整个串⼀起返回。⾃定义分词器的模板⾃定义分词器的在 Mapping 的 Setting 部分设置：
其中： “char_filter”:{},——对应字符过滤部分； “tokenizer”:{},——对应⽂本切分为分词部分；“filter”:{},——对应分词后再过滤部分； “analyzer”:{}——对应分词器组成部分，其中会包含：1. 2. 3。 PUT my\_custom\_index {    "settings":{        "analysis":{            "char\_filter":{            },            "tokenizer":{            },            "filter":{            },            "analyzer":{            }        }    }}
解释⼀下 Elasticsearch Node？ 节点是  Elasticsearch  的实例。实际业务中，我们会说：ES 集群包含 3 个节 点、7 个节点。 这⾥节点实际就是：⼀个独⽴的  Elasticsearch  进程，⼀般将⼀个节点部署到 ⼀台独⽴的服务器或者虚拟机、容器中。 不同节点根据⻆⾊不同，可以划分为：主节点 帮助配置和管理在整个集群中添加和删除节点。数据节点 存储数据并执⾏诸如 CRUD（创建/读取/更新/删除）操作，对数据进⾏搜索和 聚合的操作。客户端节点（或者说：协调节点）  将集群请求转发到主节点，将与数据相 关的请求转发到数据节点。 摄取节点  ⽤于在索引之前对⽂档进⾏预处理。 在安装 Elasticsearch 时，请说明不同的软件包及其重要性？ 这个貌似没什么好说的，去官⽅⽂档下载对应操作系统安装包即可。 部分功能是收费的，如机器学习、⾼级别  kerberos  认证安全等选型要知悉。 Elasticsearch 在部署时，对 Linux 的设置有哪些优化⽅法？ 关闭缓存 swap; 堆内存设置为：Min（节点内存/2, 32GB）; 设置最⼤⽂件句柄数；线程池+队列⼤⼩根据业务需要做调整；磁盘存储 raid ⽅式——存储有条件使⽤ RAID10，增加单节点性能以及避 免单节点存储故障。 请解释有关 Elasticsearch 的 NRT？ 从⽂档索引（写⼊）到可搜索到之间的延迟默认⼀秒钟，因此 Elasticsearch 是 近实时（NRT）搜索平台。也就是说：⽂档写⼊，最快⼀秒钟被索引到，不能再快了。 写⼊调优的时候，我们通常会动态调整：refresh_interval = 30s  或者更达 值，以使得写⼊数据更晚⼀点时间被搜索到。 
elasticsearch 的 document 设计 在使⽤ es 时  避免使⽤复杂的查询语句（Join  、聚合），就是在建⽴索引时， 就根据查询语句建⽴好对应的元数据。
